{"traceEvents": [{"ph": "M", "pid": 20956, "tid": 20956, "name": "process_name", "args": {"name": "MainProcess"}}, {"ph": "M", "pid": 20956, "tid": 2192355, "name": "thread_name", "args": {"name": "MainThread"}}, {"pid": 20956, "tid": 2192355, "ts": 253575755489.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575755489.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755489.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755492.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755492.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575755493.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575755493.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575755493.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755494.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575755492.06, "ph": "X", "cat": "fee", "dur": 2.02, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755495.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253575755495.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253575755495.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755492.04, "ph": "X", "cat": "fee", "dur": 3.96, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755496.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253575755496.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575755497.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575755497.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755498.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_builtin"}, {"pid": 20956, "tid": 2192355, "ts": 253575755497.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755498.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575755498.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755499.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575755499.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755499.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_frozen"}, {"pid": 20956, "tid": 2192355, "ts": 253575755499.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755499.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575755499.16, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755500.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575755500.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755500.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575755501.04, "ph": "X", "cat": "fee", "dur": 10.96, "name": "posix.getcwd"}, {"pid": 20956, "tid": 2192355, "ts": 253575755514.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575755514.08, "ph": "X", "cat": "fee", "dur": 1.92, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575755514.06, "ph": "X", "cat": "fee", "dur": 1.96, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755514.0, "ph": "X", "cat": "fee", "dur": 3.0, "name": "__init__ (<frozen zipimport>:63)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755519.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575755519.02, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755519.0, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755518.02, "ph": "X", "cat": "fee", "dur": 2.98, "name": "_path_isdir (<frozen importlib._bootstrap_external>:159)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755522.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:1472)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755522.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:1472)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755522.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:1472)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755522.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:1472)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755521.04, "ph": "X", "cat": "fee", "dur": 1.12, "name": "list.extend"}, {"pid": 20956, "tid": 2192355, "ts": 253575755523.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:1472)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755523.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:1472)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755523.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "list.extend"}, {"pid": 20956, "tid": 2192355, "ts": 253575755523.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:1472)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755523.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "<genexpr> (<frozen importlib._bootstrap_external>:1472)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755523.12, "ph": "X", "cat": "fee", "dur": 0.9, "name": "list.extend"}, {"pid": 20956, "tid": 2192355, "ts": 253575755524.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253575755524.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "_path_isabs (<frozen importlib._bootstrap_external>:175)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755521.02, "ph": "X", "cat": "fee", "dur": 3.98, "name": "__init__ (<frozen importlib._bootstrap_external>:1466)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755518.0, "ph": "X", "cat": "fee", "dur": 7.02, "name": "path_hook_for_FileFinder (<frozen importlib._bootstrap_external>:1597)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755513.0, "ph": "X", "cat": "fee", "dur": 12.04, "name": "_path_hooks (<frozen importlib._bootstrap_external>:1324)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755501.02, "ph": "X", "cat": "fee", "dur": 24.04, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755526.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755526.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575755526.12, "ph": "X", "cat": "fee", "dur": 1.88, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575755526.1, "ph": "X", "cat": "fee", "dur": 1.92, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755528.06, "ph": "X", "cat": "fee", "dur": 46.94, "name": "posix.listdir"}, {"pid": 20956, "tid": 2192355, "ts": 253575755575.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253575755577.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253575755578.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755578.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755579.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755579.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755579.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755579.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755579.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755579.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755579.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755580.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755580.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755580.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755580.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755580.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755580.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755580.24, "ph": "X", "cat": "fee", "dur": 0.76, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755581.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755581.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755581.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755581.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755582.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755582.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755582.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755582.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755582.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755582.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755582.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755583.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755583.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755583.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755583.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755583.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755578.02, "ph": "X", "cat": "fee", "dur": 5.18, "name": "<setcomp> (<frozen importlib._bootstrap_external>:1585)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755528.04, "ph": "X", "cat": "fee", "dur": 55.18, "name": "_fill_cache (<frozen importlib._bootstrap_external>:1556)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755584.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755585.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755585.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755585.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755585.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755585.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755586.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755587.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755587.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755586.1, "ph": "X", "cat": "fee", "dur": 0.98, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755587.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755586.08, "ph": "X", "cat": "fee", "dur": 1.06, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755587.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755588.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755588.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755588.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755588.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755588.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755588.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755589.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755589.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755589.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755589.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755589.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755589.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755590.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755590.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755590.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755590.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755590.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755590.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755526.04, "ph": "X", "cat": "fee", "dur": 64.2, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755591.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575755591.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755591.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755592.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575755592.1, "ph": "X", "cat": "fee", "dur": 1.9, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575755592.08, "ph": "X", "cat": "fee", "dur": 1.94, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755594.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755595.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755595.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755595.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755595.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755595.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755595.2, "ph": "X", "cat": "fee", "dur": 0.8, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755596.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755596.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755596.04, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755596.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755596.02, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755596.22, "ph": "X", "cat": "fee", "dur": 0.78, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755597.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755597.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755597.04, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755597.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755597.02, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755598.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755598.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755598.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755598.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755598.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755598.04, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755599.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755599.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755599.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755599.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755599.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755599.04, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755599.24, "ph": "X", "cat": "fee", "dur": 0.76, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755592.02, "ph": "X", "cat": "fee", "dur": 8.0, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755600.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575755600.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755600.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575755600.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755601.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755601.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575755601.14, "ph": "X", "cat": "fee", "dur": 1.86, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575755601.12, "ph": "X", "cat": "fee", "dur": 1.9, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755603.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755603.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755604.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755603.1, "ph": "X", "cat": "fee", "dur": 0.96, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755604.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755603.08, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755604.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755605.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755605.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755605.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755605.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755605.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755605.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755606.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755606.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755606.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755606.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755606.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755606.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755607.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755607.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755607.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755607.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755607.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755607.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755608.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755608.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755608.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755608.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755607.24, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755608.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755601.06, "ph": "X", "cat": "fee", "dur": 7.16, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755608.24, "ph": "X", "cat": "fee", "dur": 0.76, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575755609.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755609.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755609.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575755609.18, "ph": "X", "cat": "fee", "dur": 1.82, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575755609.16, "ph": "X", "cat": "fee", "dur": 1.86, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755611.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755612.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755612.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755611.1, "ph": "X", "cat": "fee", "dur": 0.98, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755612.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755611.08, "ph": "X", "cat": "fee", "dur": 1.06, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755612.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755613.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755613.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755613.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755613.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755613.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755613.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755614.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755614.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755614.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755614.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755614.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755614.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755615.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755615.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755614.26, "ph": "X", "cat": "fee", "dur": 0.82, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755615.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755614.24, "ph": "X", "cat": "fee", "dur": 0.9, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755615.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755615.24, "ph": "X", "cat": "fee", "dur": 0.76, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755616.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755615.22, "ph": "X", "cat": "fee", "dur": 0.84, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755616.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755615.2, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755616.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755609.1, "ph": "X", "cat": "fee", "dur": 7.08, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755616.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575755616.24, "ph": "X", "cat": "fee", "dur": 0.76, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755617.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755617.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575755617.14, "ph": "X", "cat": "fee", "dur": 1.86, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575755617.12, "ph": "X", "cat": "fee", "dur": 1.9, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755619.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755619.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755620.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755619.1, "ph": "X", "cat": "fee", "dur": 0.96, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755620.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755619.08, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755620.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755621.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755621.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755621.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755621.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755620.18, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755621.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755622.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755622.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755622.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755622.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755621.22, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755622.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755623.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755623.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755622.24, "ph": "X", "cat": "fee", "dur": 0.84, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755623.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755622.22, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755623.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755623.24, "ph": "X", "cat": "fee", "dur": 0.76, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755624.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755623.22, "ph": "X", "cat": "fee", "dur": 0.84, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755624.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755623.2, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755624.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755617.06, "ph": "X", "cat": "fee", "dur": 7.12, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755624.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575755624.24, "ph": "X", "cat": "fee", "dur": 0.76, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755625.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755625.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575755625.14, "ph": "X", "cat": "fee", "dur": 2.86, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575755625.12, "ph": "X", "cat": "fee", "dur": 2.9, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755628.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755629.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755629.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755629.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755629.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755629.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755630.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755630.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755630.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755630.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755630.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755631.0, "ph": "X", "cat": "fee", "dur": 13.0, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575755630.24, "ph": "X", "cat": "fee", "dur": 13.78, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755630.22, "ph": "X", "cat": "fee", "dur": 14.78, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755630.2, "ph": "X", "cat": "fee", "dur": 14.82, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755645.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755645.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755645.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755646.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755645.04, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755646.12, "ph": "X", "cat": "fee", "dur": 2.88, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575755646.1, "ph": "X", "cat": "fee", "dur": 2.92, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755646.08, "ph": "X", "cat": "fee", "dur": 2.96, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755646.06, "ph": "X", "cat": "fee", "dur": 3.0, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755649.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755649.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755649.1, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755650.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755649.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755650.12, "ph": "X", "cat": "fee", "dur": 1.88, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575755650.1, "ph": "X", "cat": "fee", "dur": 1.92, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755650.08, "ph": "X", "cat": "fee", "dur": 1.96, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755650.06, "ph": "X", "cat": "fee", "dur": 2.0, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755653.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755653.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755653.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755653.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755653.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755653.26, "ph": "X", "cat": "fee", "dur": 7.74, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575755653.24, "ph": "X", "cat": "fee", "dur": 7.78, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755653.22, "ph": "X", "cat": "fee", "dur": 7.82, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755653.2, "ph": "X", "cat": "fee", "dur": 8.8, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755662.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap_external>:1006)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755663.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253575755663.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "__init__ (<frozen importlib._bootstrap>:351)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755663.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "spec_from_file_location (<frozen importlib._bootstrap_external>:696)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755662.02, "ph": "X", "cat": "fee", "dur": 2.02, "name": "_get_spec (<frozen importlib._bootstrap_external>:1500)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755625.06, "ph": "X", "cat": "fee", "dur": 39.0, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755500.1, "ph": "X", "cat": "fee", "dur": 163.98, "name": "_get_spec (<frozen importlib._bootstrap_external>:1374)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755500.08, "ph": "X", "cat": "fee", "dur": 164.92, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755665.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575755665.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755496.12, "ph": "X", "cat": "fee", "dur": 168.98, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755666.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755666.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755666.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "create_module (<frozen importlib._bootstrap_external>:841)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755666.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "_new_module (<frozen importlib._bootstrap>:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755667.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755667.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755668.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755668.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755668.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755669.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "has_location (<frozen importlib._bootstrap>:406)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755669.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755670.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755671.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.endswith"}, {"pid": 20956, "tid": 2192355, "ts": 253575755671.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253575755672.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "str.rfind"}, {"pid": 20956, "tid": 2192355, "ts": 253575755672.04, "ph": "X", "cat": "fee", "dur": 0.98, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755673.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755672.02, "ph": "X", "cat": "fee", "dur": 1.06, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253575755672.0, "ph": "X", "cat": "fee", "dur": 1.1, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755674.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575755674.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755675.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755675.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755675.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755675.02, "ph": "X", "cat": "fee", "dur": 0.14, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755675.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755675.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755671.06, "ph": "X", "cat": "fee", "dur": 4.98, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755671.0, "ph": "X", "cat": "fee", "dur": 5.06, "name": "_get_cached (<frozen importlib._bootstrap_external>:491)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755670.06, "ph": "X", "cat": "fee", "dur": 6.02, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755676.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755667.02, "ph": "X", "cat": "fee", "dur": 9.12, "name": "_init_module_attrs (<frozen importlib._bootstrap>:486)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755666.06, "ph": "X", "cat": "fee", "dur": 10.94, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755678.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "get_filename (<frozen importlib._bootstrap_external>:1031)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755677.06, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_check_name_wrapper (<frozen importlib._bootstrap_external>:523)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755678.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253575755679.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rfind"}, {"pid": 20956, "tid": 2192355, "ts": 253575755678.16, "ph": "X", "cat": "fee", "dur": 0.88, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755679.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755678.14, "ph": "X", "cat": "fee", "dur": 0.96, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253575755678.12, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755679.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575755679.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755680.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755680.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755680.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755680.04, "ph": "X", "cat": "fee", "dur": 0.14, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755681.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755680.02, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755678.06, "ph": "X", "cat": "fee", "dur": 3.0, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755681.12, "ph": "X", "cat": "fee", "dur": 2.88, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575755681.1, "ph": "X", "cat": "fee", "dur": 2.92, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755681.08, "ph": "X", "cat": "fee", "dur": 2.96, "name": "path_stats (<frozen importlib._bootstrap_external>:1077)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755685.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575755685.04, "ph": "X", "cat": "fee", "dur": 33.96, "name": "io.open_code"}, {"pid": 20956, "tid": 2192355, "ts": 253575755719.02, "ph": "X", "cat": "fee", "dur": 2.98, "name": "_io.BufferedReader.read"}, {"pid": 20956, "tid": 2192355, "ts": 253575755722.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_io.BufferedReader.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253575755684.06, "ph": "X", "cat": "fee", "dur": 39.96, "name": "get_data (<frozen importlib._bootstrap_external>:1036)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755725.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253575755725.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253575755725.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253575755725.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755724.04, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_classify_pyc (<frozen importlib._bootstrap_external>:560)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755727.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253575755727.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253575755727.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755727.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253575755727.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253575755727.14, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755727.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_validate_timestamp_pyc (<frozen importlib._bootstrap_external>:593)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755728.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755728.08, "ph": "X", "cat": "fee", "dur": 2.92, "name": "marshal.loads"}, {"pid": 20956, "tid": 2192355, "ts": 253575755731.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575755731.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755732.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp._fix_co_filename"}, {"pid": 20956, "tid": 2192355, "ts": 253575755728.06, "ph": "X", "cat": "fee", "dur": 3.98, "name": "_compile_bytecode (<frozen importlib._bootstrap_external>:645)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755677.04, "ph": "X", "cat": "fee", "dur": 55.02, "name": "get_code (<frozen importlib._bootstrap_external>:916)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755734.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755735.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575755736.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575755736.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575755735.08, "ph": "X", "cat": "fee", "dur": 1.0, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755737.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575755735.02, "ph": "X", "cat": "fee", "dur": 2.02, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755737.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253575755738.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253575755737.06, "ph": "X", "cat": "fee", "dur": 0.98, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755735.0, "ph": "X", "cat": "fee", "dur": 3.06, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755738.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253575755739.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575755740.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575755740.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755741.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755741.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575755741.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755741.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575755741.12, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755742.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_frozen"}, {"pid": 20956, "tid": 2192355, "ts": 253575755741.2, "ph": "X", "cat": "fee", "dur": 0.84, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755742.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575755742.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755742.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575755742.14, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755743.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575755744.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575755744.08, "ph": "X", "cat": "fee", "dur": 4.92, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575755744.06, "ph": "X", "cat": "fee", "dur": 4.96, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755744.0, "ph": "X", "cat": "fee", "dur": 6.0, "name": "__init__ (<frozen zipimport>:63)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755752.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575755752.0, "ph": "X", "cat": "fee", "dur": 2.02, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755751.04, "ph": "X", "cat": "fee", "dur": 3.0, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755751.02, "ph": "X", "cat": "fee", "dur": 3.04, "name": "_path_isdir (<frozen importlib._bootstrap_external>:159)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755755.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:1472)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755755.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:1472)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755755.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:1472)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755755.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:1472)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755755.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "list.extend"}, {"pid": 20956, "tid": 2192355, "ts": 253575755756.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:1472)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755756.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:1472)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755756.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "list.extend"}, {"pid": 20956, "tid": 2192355, "ts": 253575755756.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "<genexpr> (<frozen importlib._bootstrap_external>:1472)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755757.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:1472)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755756.14, "ph": "X", "cat": "fee", "dur": 0.92, "name": "list.extend"}, {"pid": 20956, "tid": 2192355, "ts": 253575755757.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253575755757.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "_path_isabs (<frozen importlib._bootstrap_external>:175)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755754.08, "ph": "X", "cat": "fee", "dur": 3.92, "name": "__init__ (<frozen importlib._bootstrap_external>:1466)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755751.0, "ph": "X", "cat": "fee", "dur": 7.02, "name": "path_hook_for_FileFinder (<frozen importlib._bootstrap_external>:1597)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755743.08, "ph": "X", "cat": "fee", "dur": 14.96, "name": "_path_hooks (<frozen importlib._bootstrap_external>:1324)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755743.06, "ph": "X", "cat": "fee", "dur": 15.0, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755758.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755759.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575755759.1, "ph": "X", "cat": "fee", "dur": 1.9, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575755759.08, "ph": "X", "cat": "fee", "dur": 1.94, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755762.0, "ph": "X", "cat": "fee", "dur": 25.0, "name": "posix.listdir"}, {"pid": 20956, "tid": 2192355, "ts": 253575755787.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253575755789.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253575755789.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755790.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755790.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755790.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755790.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755790.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755790.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755790.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755791.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755791.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755791.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755791.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755791.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755791.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755791.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755791.28, "ph": "X", "cat": "fee", "dur": 0.72, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755792.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755792.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253575755789.04, "ph": "X", "cat": "fee", "dur": 3.06, "name": "<setcomp> (<frozen importlib._bootstrap_external>:1585)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755761.04, "ph": "X", "cat": "fee", "dur": 31.08, "name": "_fill_cache (<frozen importlib._bootstrap_external>:1556)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755792.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755793.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755793.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755793.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755794.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755793.02, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755794.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755795.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755795.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755795.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755795.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755794.12, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755795.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755796.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755796.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755796.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755796.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755796.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755796.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755797.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755797.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755797.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755797.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755797.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755797.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755798.06, "ph": "X", "cat": "fee", "dur": 7.94, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575755798.04, "ph": "X", "cat": "fee", "dur": 7.98, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755798.02, "ph": "X", "cat": "fee", "dur": 8.02, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755798.0, "ph": "X", "cat": "fee", "dur": 8.06, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755807.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap_external>:1006)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755807.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253575755808.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:351)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755807.06, "ph": "X", "cat": "fee", "dur": 0.98, "name": "spec_from_file_location (<frozen importlib._bootstrap_external>:696)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755807.0, "ph": "X", "cat": "fee", "dur": 1.06, "name": "_get_spec (<frozen importlib._bootstrap_external>:1500)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755759.02, "ph": "X", "cat": "fee", "dur": 49.06, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755743.0, "ph": "X", "cat": "fee", "dur": 66.0, "name": "_get_spec (<frozen importlib._bootstrap_external>:1374)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755742.22, "ph": "X", "cat": "fee", "dur": 66.8, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755809.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575755809.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755740.0, "ph": "X", "cat": "fee", "dur": 69.12, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755810.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755810.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755810.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "create_module (<frozen importlib._bootstrap_external>:841)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755810.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "_new_module (<frozen importlib._bootstrap>:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755811.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755811.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755811.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755812.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575755812.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755812.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755813.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "has_location (<frozen importlib._bootstrap>:406)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755813.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755815.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755816.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "str.endswith"}, {"pid": 20956, "tid": 2192355, "ts": 253575755817.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253575755818.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rfind"}, {"pid": 20956, "tid": 2192355, "ts": 253575755817.12, "ph": "X", "cat": "fee", "dur": 0.92, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755818.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755817.1, "ph": "X", "cat": "fee", "dur": 1.0, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253575755817.08, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755818.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575755819.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755820.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755820.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755820.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755820.02, "ph": "X", "cat": "fee", "dur": 0.14, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755820.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755820.0, "ph": "X", "cat": "fee", "dur": 0.22, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755817.02, "ph": "X", "cat": "fee", "dur": 3.98, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755816.04, "ph": "X", "cat": "fee", "dur": 4.98, "name": "_get_cached (<frozen importlib._bootstrap_external>:491)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755816.02, "ph": "X", "cat": "fee", "dur": 5.02, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755821.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755811.02, "ph": "X", "cat": "fee", "dur": 10.08, "name": "_init_module_attrs (<frozen importlib._bootstrap>:486)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755810.06, "ph": "X", "cat": "fee", "dur": 11.06, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755822.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "get_filename (<frozen importlib._bootstrap_external>:1031)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755822.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "_check_name_wrapper (<frozen importlib._bootstrap_external>:523)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755822.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253575755823.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rfind"}, {"pid": 20956, "tid": 2192355, "ts": 253575755823.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755823.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755823.04, "ph": "X", "cat": "fee", "dur": 0.14, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253575755823.02, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755824.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575755824.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755824.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755825.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755825.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755824.1, "ph": "X", "cat": "fee", "dur": 0.98, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755825.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755824.08, "ph": "X", "cat": "fee", "dur": 1.06, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755822.12, "ph": "X", "cat": "fee", "dur": 3.04, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755825.22, "ph": "X", "cat": "fee", "dur": 2.78, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575755825.2, "ph": "X", "cat": "fee", "dur": 2.82, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755825.18, "ph": "X", "cat": "fee", "dur": 2.86, "name": "path_stats (<frozen importlib._bootstrap_external>:1077)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755829.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575755829.06, "ph": "X", "cat": "fee", "dur": 18.94, "name": "io.open_code"}, {"pid": 20956, "tid": 2192355, "ts": 253575755848.02, "ph": "X", "cat": "fee", "dur": 3.98, "name": "_io.BufferedReader.read"}, {"pid": 20956, "tid": 2192355, "ts": 253575755852.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_io.BufferedReader.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253575755829.0, "ph": "X", "cat": "fee", "dur": 24.02, "name": "get_data (<frozen importlib._bootstrap_external>:1036)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755854.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253575755854.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253575755855.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253575755854.06, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755854.0, "ph": "X", "cat": "fee", "dur": 1.06, "name": "_classify_pyc (<frozen importlib._bootstrap_external>:560)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755856.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253575755856.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253575755856.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755856.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253575755856.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253575755856.12, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755855.08, "ph": "X", "cat": "fee", "dur": 1.16, "name": "_validate_timestamp_pyc (<frozen importlib._bootstrap_external>:593)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755857.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755857.06, "ph": "X", "cat": "fee", "dur": 42.94, "name": "marshal.loads"}, {"pid": 20956, "tid": 2192355, "ts": 253575755900.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575755900.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755900.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "_imp._fix_co_filename"}, {"pid": 20956, "tid": 2192355, "ts": 253575755857.04, "ph": "X", "cat": "fee", "dur": 43.98, "name": "_compile_bytecode (<frozen importlib._bootstrap_external>:645)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755822.02, "ph": "X", "cat": "fee", "dur": 79.02, "name": "get_code (<frozen importlib._bootstrap_external>:916)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755904.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755904.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575755905.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575755905.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575755905.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755906.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575755904.08, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755907.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253575755907.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253575755906.08, "ph": "X", "cat": "fee", "dur": 1.0, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755904.06, "ph": "X", "cat": "fee", "dur": 3.04, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755908.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253575755908.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575755909.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575755909.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755909.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_builtin"}, {"pid": 20956, "tid": 2192355, "ts": 253575755909.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755910.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575755910.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755910.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575755910.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755910.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_frozen"}, {"pid": 20956, "tid": 2192355, "ts": 253575755910.16, "ph": "X", "cat": "fee", "dur": 0.06, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755911.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575755911.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755911.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575755911.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755911.2, "ph": "X", "cat": "fee", "dur": 0.8, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575755912.04, "ph": "X", "cat": "fee", "dur": 9.96, "name": "posix.getcwd"}, {"pid": 20956, "tid": 2192355, "ts": 253575755912.02, "ph": "X", "cat": "fee", "dur": 10.98, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755923.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755923.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575755924.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575755924.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755926.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755927.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755927.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755926.06, "ph": "X", "cat": "fee", "dur": 1.02, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755927.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755926.04, "ph": "X", "cat": "fee", "dur": 1.1, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755927.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755928.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755928.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755928.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755928.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755928.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755929.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755929.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755929.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755929.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755929.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755929.04, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755929.24, "ph": "X", "cat": "fee", "dur": 0.76, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755930.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755930.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755930.04, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755930.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755930.02, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755930.22, "ph": "X", "cat": "fee", "dur": 0.78, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755931.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755931.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755931.04, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755931.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755931.02, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755931.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755923.06, "ph": "X", "cat": "fee", "dur": 8.94, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755932.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575755932.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755932.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755932.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575755933.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575755933.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755934.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755935.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755935.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755935.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755935.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755935.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755936.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755936.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755936.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755936.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755936.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755937.04, "ph": "X", "cat": "fee", "dur": 2.96, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575755937.02, "ph": "X", "cat": "fee", "dur": 3.0, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755937.0, "ph": "X", "cat": "fee", "dur": 3.04, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755936.2, "ph": "X", "cat": "fee", "dur": 3.86, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755940.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755941.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755940.1, "ph": "X", "cat": "fee", "dur": 0.94, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755941.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755940.08, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755941.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575755941.16, "ph": "X", "cat": "fee", "dur": 0.86, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755941.14, "ph": "X", "cat": "fee", "dur": 0.9, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755941.12, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755943.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755943.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755943.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755943.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755943.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755943.26, "ph": "X", "cat": "fee", "dur": 1.74, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575755943.24, "ph": "X", "cat": "fee", "dur": 1.78, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755943.22, "ph": "X", "cat": "fee", "dur": 1.82, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755943.2, "ph": "X", "cat": "fee", "dur": 1.86, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755945.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755945.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755945.1, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755946.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755945.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755946.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575755946.1, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755946.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755946.06, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755948.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755948.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755947.1, "ph": "X", "cat": "fee", "dur": 0.98, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755948.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755947.08, "ph": "X", "cat": "fee", "dur": 1.06, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755948.22, "ph": "X", "cat": "fee", "dur": 0.78, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575755948.2, "ph": "X", "cat": "fee", "dur": 0.82, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755948.18, "ph": "X", "cat": "fee", "dur": 0.86, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755948.16, "ph": "X", "cat": "fee", "dur": 0.9, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755950.06, "ph": "X", "cat": "fee", "dur": 1.94, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575755950.04, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755950.02, "ph": "X", "cat": "fee", "dur": 2.02, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755950.0, "ph": "X", "cat": "fee", "dur": 2.06, "name": "_path_isdir (<frozen importlib._bootstrap_external>:159)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755953.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755953.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755953.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755953.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755953.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755953.2, "ph": "X", "cat": "fee", "dur": 0.8, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755954.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755954.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755954.04, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755954.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755954.02, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755954.22, "ph": "X", "cat": "fee", "dur": 0.78, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755955.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755955.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755955.04, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755955.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755955.02, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755955.22, "ph": "X", "cat": "fee", "dur": 0.78, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755956.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755956.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755956.04, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755956.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755956.02, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755956.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755957.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755957.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755957.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755957.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755957.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755957.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755932.14, "ph": "X", "cat": "fee", "dur": 25.86, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755958.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575755958.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755958.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575755958.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755959.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755959.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575755959.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575755959.12, "ph": "X", "cat": "fee", "dur": 1.88, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755961.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755961.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755962.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755961.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755962.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755961.06, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755962.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755963.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755963.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755963.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755963.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755962.16, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755963.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755964.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755964.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755963.24, "ph": "X", "cat": "fee", "dur": 0.84, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755964.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755963.22, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755964.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755965.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755965.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755964.22, "ph": "X", "cat": "fee", "dur": 0.86, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755965.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755964.2, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755965.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755966.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755966.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755965.22, "ph": "X", "cat": "fee", "dur": 0.86, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755966.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755965.2, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755966.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755959.06, "ph": "X", "cat": "fee", "dur": 7.14, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755966.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575755966.26, "ph": "X", "cat": "fee", "dur": 0.74, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755967.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755967.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575755967.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575755967.12, "ph": "X", "cat": "fee", "dur": 0.9, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755969.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755969.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755969.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755969.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755969.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755969.04, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755970.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755970.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755970.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755970.1, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755970.22, "ph": "X", "cat": "fee", "dur": 0.78, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755970.08, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755971.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755971.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755971.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755971.1, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755971.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755971.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755972.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755972.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755972.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755972.08, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755972.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755972.06, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755973.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755973.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755973.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755973.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755973.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755973.04, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755973.24, "ph": "X", "cat": "fee", "dur": 0.76, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755967.06, "ph": "X", "cat": "fee", "dur": 6.96, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755974.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575755974.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755974.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755974.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575755975.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575755975.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755976.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755977.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755977.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755977.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755977.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755977.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755978.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755978.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755978.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755978.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755978.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755978.26, "ph": "X", "cat": "fee", "dur": 1.74, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575755978.24, "ph": "X", "cat": "fee", "dur": 1.78, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755978.22, "ph": "X", "cat": "fee", "dur": 2.78, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755978.2, "ph": "X", "cat": "fee", "dur": 2.82, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755981.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755981.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755981.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755981.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755981.04, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755982.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575755982.04, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755982.02, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755982.0, "ph": "X", "cat": "fee", "dur": 1.06, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755984.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755984.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755984.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755984.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755983.08, "ph": "X", "cat": "fee", "dur": 1.08, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755984.24, "ph": "X", "cat": "fee", "dur": 0.76, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575755984.22, "ph": "X", "cat": "fee", "dur": 0.8, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755984.2, "ph": "X", "cat": "fee", "dur": 1.8, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755984.18, "ph": "X", "cat": "fee", "dur": 1.84, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755986.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755986.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575755986.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755986.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575755986.04, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755987.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575755987.0, "ph": "X", "cat": "fee", "dur": 2.02, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755986.26, "ph": "X", "cat": "fee", "dur": 2.78, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755986.24, "ph": "X", "cat": "fee", "dur": 2.82, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755990.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap_external>:1006)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755990.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253575755990.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "__init__ (<frozen importlib._bootstrap>:351)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755990.06, "ph": "X", "cat": "fee", "dur": 0.96, "name": "spec_from_file_location (<frozen importlib._bootstrap_external>:696)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755990.0, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_get_spec (<frozen importlib._bootstrap_external>:1500)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755974.16, "ph": "X", "cat": "fee", "dur": 16.9, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755911.18, "ph": "X", "cat": "fee", "dur": 79.9, "name": "_get_spec (<frozen importlib._bootstrap_external>:1374)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755911.16, "ph": "X", "cat": "fee", "dur": 80.84, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755992.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575755992.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755908.1, "ph": "X", "cat": "fee", "dur": 84.0, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755993.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755993.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755993.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "create_module (<frozen importlib._bootstrap_external>:841)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755993.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_new_module (<frozen importlib._bootstrap>:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755994.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755994.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755994.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755994.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755995.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755995.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "has_location (<frozen importlib._bootstrap>:406)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755996.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755996.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755997.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.endswith"}, {"pid": 20956, "tid": 2192355, "ts": 253575755998.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253575755998.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rfind"}, {"pid": 20956, "tid": 2192355, "ts": 253575755998.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755998.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755998.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253575755998.04, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755999.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575755999.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575756000.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575756000.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575756000.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575756000.02, "ph": "X", "cat": "fee", "dur": 0.14, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756000.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575756000.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755997.1, "ph": "X", "cat": "fee", "dur": 3.94, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755997.04, "ph": "X", "cat": "fee", "dur": 4.02, "name": "_get_cached (<frozen importlib._bootstrap_external>:491)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755997.02, "ph": "X", "cat": "fee", "dur": 4.06, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756001.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755994.0, "ph": "X", "cat": "fee", "dur": 7.14, "name": "_init_module_attrs (<frozen importlib._bootstrap>:486)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755993.04, "ph": "X", "cat": "fee", "dur": 8.12, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756002.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "get_filename (<frozen importlib._bootstrap_external>:1031)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756002.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "_check_name_wrapper (<frozen importlib._bootstrap_external>:523)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756002.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253575756003.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rfind"}, {"pid": 20956, "tid": 2192355, "ts": 253575756003.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756003.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756003.04, "ph": "X", "cat": "fee", "dur": 0.14, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253575756003.02, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756004.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575756004.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575756004.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575756004.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575756005.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575756004.1, "ph": "X", "cat": "fee", "dur": 0.96, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756005.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575756004.08, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756002.12, "ph": "X", "cat": "fee", "dur": 3.02, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756005.2, "ph": "X", "cat": "fee", "dur": 1.8, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575756005.18, "ph": "X", "cat": "fee", "dur": 1.84, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756005.16, "ph": "X", "cat": "fee", "dur": 1.88, "name": "path_stats (<frozen importlib._bootstrap_external>:1077)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756008.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575756008.04, "ph": "X", "cat": "fee", "dur": 12.96, "name": "io.open_code"}, {"pid": 20956, "tid": 2192355, "ts": 253575756021.02, "ph": "X", "cat": "fee", "dur": 2.98, "name": "_io.BufferedReader.read"}, {"pid": 20956, "tid": 2192355, "ts": 253575756024.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_io.BufferedReader.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253575756007.06, "ph": "X", "cat": "fee", "dur": 17.96, "name": "get_data (<frozen importlib._bootstrap_external>:1036)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756026.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253575756026.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253575756026.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253575756026.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756026.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_classify_pyc (<frozen importlib._bootstrap_external>:560)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756027.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253575756027.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253575756027.04, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756028.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253575756028.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253575756028.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756027.02, "ph": "X", "cat": "fee", "dur": 1.1, "name": "_validate_timestamp_pyc (<frozen importlib._bootstrap_external>:593)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756028.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756029.0, "ph": "X", "cat": "fee", "dur": 9.0, "name": "marshal.loads"}, {"pid": 20956, "tid": 2192355, "ts": 253575756038.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575756039.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756039.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp._fix_co_filename"}, {"pid": 20956, "tid": 2192355, "ts": 253575756028.18, "ph": "X", "cat": "fee", "dur": 10.9, "name": "_compile_bytecode (<frozen importlib._bootstrap_external>:645)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756002.02, "ph": "X", "cat": "fee", "dur": 37.08, "name": "get_code (<frozen importlib._bootstrap_external>:916)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756042.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756042.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575756043.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575756043.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575756043.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756044.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575756042.06, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756044.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253575756045.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253575756044.06, "ph": "X", "cat": "fee", "dur": 0.98, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756042.04, "ph": "X", "cat": "fee", "dur": 3.02, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756045.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253575756045.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575756046.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575756046.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756047.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756047.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575756047.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756047.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575756047.14, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756048.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_frozen"}, {"pid": 20956, "tid": 2192355, "ts": 253575756047.22, "ph": "X", "cat": "fee", "dur": 0.82, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756048.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575756048.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756048.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575756048.14, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756049.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575756049.08, "ph": "X", "cat": "fee", "dur": 9.92, "name": "_path_hooks (<frozen importlib._bootstrap_external>:1324)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756049.06, "ph": "X", "cat": "fee", "dur": 10.94, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756060.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575756060.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575756060.12, "ph": "X", "cat": "fee", "dur": 1.88, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756062.02, "ph": "X", "cat": "fee", "dur": 31.98, "name": "_fill_cache (<frozen importlib._bootstrap_external>:1556)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756094.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756095.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756096.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756096.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756097.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756097.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756098.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756098.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756099.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756099.04, "ph": "X", "cat": "fee", "dur": 3.96, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756103.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_get_spec (<frozen importlib._bootstrap_external>:1500)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756060.06, "ph": "X", "cat": "fee", "dur": 43.96, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756049.0, "ph": "X", "cat": "fee", "dur": 56.0, "name": "_get_spec (<frozen importlib._bootstrap_external>:1374)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756048.22, "ph": "X", "cat": "fee", "dur": 56.8, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756105.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575756105.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756046.02, "ph": "X", "cat": "fee", "dur": 59.1, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756106.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575756106.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575756106.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "create_module (<frozen importlib._bootstrap_external>:841)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756106.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_new_module (<frozen importlib._bootstrap>:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756107.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575756107.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575756107.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575756107.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575756107.14, "ph": "X", "cat": "fee", "dur": 0.88, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756108.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575756109.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "has_location (<frozen importlib._bootstrap>:406)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756109.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575756109.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575756110.04, "ph": "X", "cat": "fee", "dur": 3.96, "name": "_get_cached (<frozen importlib._bootstrap_external>:491)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756110.02, "ph": "X", "cat": "fee", "dur": 4.0, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756114.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756107.0, "ph": "X", "cat": "fee", "dur": 7.08, "name": "_init_module_attrs (<frozen importlib._bootstrap>:486)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756106.04, "ph": "X", "cat": "fee", "dur": 8.06, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756115.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "get_filename (<frozen importlib._bootstrap_external>:1031)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756115.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "_check_name_wrapper (<frozen importlib._bootstrap_external>:523)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756115.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253575756116.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756116.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575756117.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575756117.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756115.12, "ph": "X", "cat": "fee", "dur": 2.9, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756118.06, "ph": "X", "cat": "fee", "dur": 1.94, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756118.04, "ph": "X", "cat": "fee", "dur": 1.98, "name": "path_stats (<frozen importlib._bootstrap_external>:1077)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756120.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575756121.0, "ph": "X", "cat": "fee", "dur": 15.0, "name": "io.open_code"}, {"pid": 20956, "tid": 2192355, "ts": 253575756136.02, "ph": "X", "cat": "fee", "dur": 2.98, "name": "_io.BufferedReader.read"}, {"pid": 20956, "tid": 2192355, "ts": 253575756139.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_io.BufferedReader.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253575756120.04, "ph": "X", "cat": "fee", "dur": 20.98, "name": "get_data (<frozen importlib._bootstrap_external>:1036)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756141.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253575756142.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756141.04, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_classify_pyc (<frozen importlib._bootstrap_external>:560)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756143.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756143.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756143.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_validate_timestamp_pyc (<frozen importlib._bootstrap_external>:593)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756144.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756144.06, "ph": "X", "cat": "fee", "dur": 40.94, "name": "marshal.loads"}, {"pid": 20956, "tid": 2192355, "ts": 253575756186.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575756186.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756186.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp._fix_co_filename"}, {"pid": 20956, "tid": 2192355, "ts": 253575756144.04, "ph": "X", "cat": "fee", "dur": 42.08, "name": "_compile_bytecode (<frozen importlib._bootstrap_external>:645)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756115.02, "ph": "X", "cat": "fee", "dur": 71.12, "name": "get_code (<frozen importlib._bootstrap_external>:916)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756187.04, "ph": "X", "cat": "fee", "dur": 7597.96, "name": "<module> (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/jsonschema/_format.py:1)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756187.02, "ph": "X", "cat": "fee", "dur": 7598.0, "name": "builtins.exec"}, {"pid": 20956, "tid": 2192355, "ts": 253575756187.0, "ph": "X", "cat": "fee", "dur": 7598.04, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756115.0, "ph": "X", "cat": "fee", "dur": 7670.06, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763790.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253575763791.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756105.14, "ph": "X", "cat": "fee", "dur": 7685.9, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763791.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575763792.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575756045.12, "ph": "X", "cat": "fee", "dur": 7746.92, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763792.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253575763793.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253575763792.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763792.06, "ph": "X", "cat": "fee", "dur": 1.0, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763793.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575763793.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253575763794.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575763793.08, "ph": "X", "cat": "fee", "dur": 0.98, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756041.0, "ph": "X", "cat": "fee", "dur": 7753.08, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763796.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763797.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575763797.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575763797.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575763797.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763798.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575763797.0, "ph": "X", "cat": "fee", "dur": 1.06, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763798.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253575763799.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253575763798.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763796.06, "ph": "X", "cat": "fee", "dur": 3.0, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763799.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253575763799.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575763800.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575763800.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763800.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763801.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575763801.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763801.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575763801.1, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763801.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_frozen"}, {"pid": 20956, "tid": 2192355, "ts": 253575763801.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763802.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575763802.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763802.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575763802.1, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763802.22, "ph": "X", "cat": "fee", "dur": 0.78, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575763803.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763803.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575763803.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575763803.16, "ph": "X", "cat": "fee", "dur": 2.84, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763806.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763806.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763807.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763808.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763808.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763808.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763809.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763809.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763810.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763810.06, "ph": "X", "cat": "fee", "dur": 3.94, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763814.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_get_spec (<frozen importlib._bootstrap_external>:1500)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763803.1, "ph": "X", "cat": "fee", "dur": 12.92, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763802.2, "ph": "X", "cat": "fee", "dur": 13.84, "name": "_get_spec (<frozen importlib._bootstrap_external>:1374)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763802.18, "ph": "X", "cat": "fee", "dur": 13.88, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763816.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575763816.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763800.0, "ph": "X", "cat": "fee", "dur": 17.0, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763817.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575763817.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575763817.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "create_module (<frozen importlib._bootstrap_external>:841)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763818.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_new_module (<frozen importlib._bootstrap>:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763818.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575763818.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575763819.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575763819.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575763819.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763820.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575763820.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "has_location (<frozen importlib._bootstrap>:406)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763821.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575763821.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575763822.04, "ph": "X", "cat": "fee", "dur": 3.96, "name": "_get_cached (<frozen importlib._bootstrap_external>:491)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763822.02, "ph": "X", "cat": "fee", "dur": 4.0, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763827.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763818.04, "ph": "X", "cat": "fee", "dur": 9.0, "name": "_init_module_attrs (<frozen importlib._bootstrap>:486)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763817.08, "ph": "X", "cat": "fee", "dur": 9.98, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763828.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "get_filename (<frozen importlib._bootstrap_external>:1031)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763828.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "_check_name_wrapper (<frozen importlib._bootstrap_external>:523)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763828.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253575763829.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763829.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575763830.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575763830.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763828.1, "ph": "X", "cat": "fee", "dur": 2.92, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763831.06, "ph": "X", "cat": "fee", "dur": 1.94, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763831.04, "ph": "X", "cat": "fee", "dur": 1.98, "name": "path_stats (<frozen importlib._bootstrap_external>:1077)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763834.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575763834.04, "ph": "X", "cat": "fee", "dur": 14.96, "name": "io.open_code"}, {"pid": 20956, "tid": 2192355, "ts": 253575763849.02, "ph": "X", "cat": "fee", "dur": 2.98, "name": "_io.BufferedReader.read"}, {"pid": 20956, "tid": 2192355, "ts": 253575763852.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_io.BufferedReader.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253575763833.04, "ph": "X", "cat": "fee", "dur": 19.98, "name": "get_data (<frozen importlib._bootstrap_external>:1036)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763854.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253575763855.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763854.0, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_classify_pyc (<frozen importlib._bootstrap_external>:560)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763856.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763856.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763856.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_validate_timestamp_pyc (<frozen importlib._bootstrap_external>:593)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763857.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763857.1, "ph": "X", "cat": "fee", "dur": 17.9, "name": "marshal.loads"}, {"pid": 20956, "tid": 2192355, "ts": 253575763875.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575763875.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763875.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp._fix_co_filename"}, {"pid": 20956, "tid": 2192355, "ts": 253575763857.08, "ph": "X", "cat": "fee", "dur": 18.06, "name": "_compile_bytecode (<frozen importlib._bootstrap_external>:645)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763828.0, "ph": "X", "cat": "fee", "dur": 47.16, "name": "get_code (<frozen importlib._bootstrap_external>:916)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763876.04, "ph": "X", "cat": "fee", "dur": 2803.96, "name": "<module> (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/jsonschema/_types.py:1)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763876.02, "ph": "X", "cat": "fee", "dur": 2804.0, "name": "builtins.exec"}, {"pid": 20956, "tid": 2192355, "ts": 253575763876.0, "ph": "X", "cat": "fee", "dur": 2804.04, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763827.08, "ph": "X", "cat": "fee", "dur": 2852.98, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766681.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253575766682.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763817.02, "ph": "X", "cat": "fee", "dur": 2865.02, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766682.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575766683.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575763799.12, "ph": "X", "cat": "fee", "dur": 2883.94, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766684.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253575766685.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253575766684.02, "ph": "X", "cat": "fee", "dur": 1.02, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766684.0, "ph": "X", "cat": "fee", "dur": 1.06, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766685.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575766686.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253575766686.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575766685.08, "ph": "X", "cat": "fee", "dur": 1.02, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253575763796.0, "ph": "X", "cat": "fee", "dur": 2890.12, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766690.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766690.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575766691.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575766691.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575766691.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766692.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575766690.08, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766693.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253575766693.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253575766693.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766690.06, "ph": "X", "cat": "fee", "dur": 3.06, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766694.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253575766694.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575766695.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575766695.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766695.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766696.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575766696.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766696.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575766696.1, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766697.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_frozen"}, {"pid": 20956, "tid": 2192355, "ts": 253575766696.18, "ph": "X", "cat": "fee", "dur": 0.86, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766697.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575766697.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766697.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575766697.14, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766698.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575766698.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766698.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575766699.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575766699.08, "ph": "X", "cat": "fee", "dur": 5.92, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766705.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766706.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766707.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766708.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766709.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766709.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766710.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766710.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766710.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766711.02, "ph": "X", "cat": "fee", "dur": 2.98, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766714.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_get_spec (<frozen importlib._bootstrap_external>:1500)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766699.02, "ph": "X", "cat": "fee", "dur": 17.0, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766698.02, "ph": "X", "cat": "fee", "dur": 18.98, "name": "_get_spec (<frozen importlib._bootstrap_external>:1374)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766698.0, "ph": "X", "cat": "fee", "dur": 19.02, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766717.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575766717.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766695.0, "ph": "X", "cat": "fee", "dur": 22.12, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766718.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575766718.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575766718.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "create_module (<frozen importlib._bootstrap_external>:841)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766718.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "_new_module (<frozen importlib._bootstrap>:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766719.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575766719.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575766720.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575766720.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575766720.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766720.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575766721.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "has_location (<frozen importlib._bootstrap>:406)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766721.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575766722.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575766723.04, "ph": "X", "cat": "fee", "dur": 3.96, "name": "_get_cached (<frozen importlib._bootstrap_external>:491)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766723.02, "ph": "X", "cat": "fee", "dur": 4.98, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766728.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766719.02, "ph": "X", "cat": "fee", "dur": 9.04, "name": "_init_module_attrs (<frozen importlib._bootstrap>:486)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766718.06, "ph": "X", "cat": "fee", "dur": 10.02, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766729.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "get_filename (<frozen importlib._bootstrap_external>:1031)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766729.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "_check_name_wrapper (<frozen importlib._bootstrap_external>:523)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766730.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253575766730.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766731.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575766731.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575766732.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766730.0, "ph": "X", "cat": "fee", "dur": 2.04, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766733.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766733.0, "ph": "X", "cat": "fee", "dur": 2.02, "name": "path_stats (<frozen importlib._bootstrap_external>:1077)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766735.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575766736.02, "ph": "X", "cat": "fee", "dur": 12.98, "name": "io.open_code"}, {"pid": 20956, "tid": 2192355, "ts": 253575766749.02, "ph": "X", "cat": "fee", "dur": 3.98, "name": "_io.BufferedReader.read"}, {"pid": 20956, "tid": 2192355, "ts": 253575766753.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_io.BufferedReader.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253575766735.04, "ph": "X", "cat": "fee", "dur": 19.96, "name": "get_data (<frozen importlib._bootstrap_external>:1036)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766755.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253575766756.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766755.02, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_classify_pyc (<frozen importlib._bootstrap_external>:560)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766757.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766757.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766757.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_validate_timestamp_pyc (<frozen importlib._bootstrap_external>:593)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766758.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766758.08, "ph": "X", "cat": "fee", "dur": 77.92, "name": "marshal.loads"}, {"pid": 20956, "tid": 2192355, "ts": 253575766836.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575766836.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766836.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp._fix_co_filename"}, {"pid": 20956, "tid": 2192355, "ts": 253575766758.06, "ph": "X", "cat": "fee", "dur": 78.08, "name": "_compile_bytecode (<frozen importlib._bootstrap_external>:645)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766729.0, "ph": "X", "cat": "fee", "dur": 108.0, "name": "get_code (<frozen importlib._bootstrap_external>:916)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766838.0, "ph": "X", "cat": "fee", "dur": 3737.0, "name": "<module> (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/jsonschema/validators.py:1)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766837.04, "ph": "X", "cat": "fee", "dur": 3737.98, "name": "builtins.exec"}, {"pid": 20956, "tid": 2192355, "ts": 253575766837.02, "ph": "X", "cat": "fee", "dur": 3738.98, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766728.1, "ph": "X", "cat": "fee", "dur": 3847.92, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770578.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253575770579.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766718.0, "ph": "X", "cat": "fee", "dur": 3861.04, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770580.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575770580.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575766694.04, "ph": "X", "cat": "fee", "dur": 3886.96, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770581.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253575770582.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253575770581.04, "ph": "X", "cat": "fee", "dur": 1.0, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770581.02, "ph": "X", "cat": "fee", "dur": 1.04, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770583.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575770583.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253575770583.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575770582.08, "ph": "X", "cat": "fee", "dur": 1.04, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253575766690.0, "ph": "X", "cat": "fee", "dur": 3894.0, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770584.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "__getattr__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/jsonschema/validators.py:30)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756040.04, "ph": "X", "cat": "fee", "dur": 14545.96, "name": "<module> (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/jsonschema/__init__.py:1)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756040.02, "ph": "X", "cat": "fee", "dur": 14546.98, "name": "builtins.exec"}, {"pid": 20956, "tid": 2192355, "ts": 253575756040.0, "ph": "X", "cat": "fee", "dur": 14547.02, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253575756002.0, "ph": "X", "cat": "fee", "dur": 14585.04, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770587.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253575770588.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755992.12, "ph": "X", "cat": "fee", "dur": 14595.92, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755908.04, "ph": "X", "cat": "fee", "dur": 14680.02, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770588.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253575770589.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253575770588.1, "ph": "X", "cat": "fee", "dur": 0.94, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770588.08, "ph": "X", "cat": "fee", "dur": 0.98, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770589.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575770589.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253575770590.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575770589.08, "ph": "X", "cat": "fee", "dur": 0.98, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755904.0, "ph": "X", "cat": "fee", "dur": 14686.08, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770591.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575770591.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575770591.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770592.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575770593.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575770592.02, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770593.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253575770594.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253575770593.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770594.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253575770594.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253575770594.06, "ph": "X", "cat": "fee", "dur": 0.96, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770592.0, "ph": "X", "cat": "fee", "dur": 3.04, "name": "_lock_unlock_module (<frozen importlib._bootstrap>:203)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770595.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575770595.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575770596.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.format"}, {"pid": 20956, "tid": 2192355, "ts": 253575770598.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770598.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575770599.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575770600.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575770599.0, "ph": "X", "cat": "fee", "dur": 1.04, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770601.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575770598.08, "ph": "X", "cat": "fee", "dur": 2.96, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770601.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253575770601.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253575770601.06, "ph": "X", "cat": "fee", "dur": 0.96, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770598.06, "ph": "X", "cat": "fee", "dur": 3.98, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770602.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253575770602.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575770604.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575770604.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770604.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770605.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575770605.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770605.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575770605.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770606.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_frozen"}, {"pid": 20956, "tid": 2192355, "ts": 253575770605.16, "ph": "X", "cat": "fee", "dur": 0.88, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770606.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575770606.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770607.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575770607.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770608.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575770608.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770609.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575770609.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575770610.02, "ph": "X", "cat": "fee", "dur": 8.98, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575770610.0, "ph": "X", "cat": "fee", "dur": 9.02, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770620.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770622.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575770622.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575770622.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770622.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575770621.02, "ph": "X", "cat": "fee", "dur": 2.0, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770623.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770624.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575770624.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575770624.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770624.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575770624.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770624.2, "ph": "X", "cat": "fee", "dur": 0.8, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770625.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575770625.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575770625.04, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770625.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575770625.02, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770626.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770626.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575770626.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575770626.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770626.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575770626.04, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770627.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770627.1, "ph": "X", "cat": "fee", "dur": 25.9, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575770627.08, "ph": "X", "cat": "fee", "dur": 25.94, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770627.06, "ph": "X", "cat": "fee", "dur": 26.94, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770627.04, "ph": "X", "cat": "fee", "dur": 26.98, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770654.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "__init__ (<frozen importlib._bootstrap_external>:1006)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770656.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253575770656.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "__init__ (<frozen importlib._bootstrap>:351)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770655.02, "ph": "X", "cat": "fee", "dur": 2.0, "name": "spec_from_file_location (<frozen importlib._bootstrap_external>:696)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770654.04, "ph": "X", "cat": "fee", "dur": 3.0, "name": "_get_spec (<frozen importlib._bootstrap_external>:1500)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770609.06, "ph": "X", "cat": "fee", "dur": 48.0, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770607.12, "ph": "X", "cat": "fee", "dur": 50.88, "name": "_get_spec (<frozen importlib._bootstrap_external>:1374)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770607.1, "ph": "X", "cat": "fee", "dur": 50.92, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770658.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575770658.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770603.0, "ph": "X", "cat": "fee", "dur": 56.0, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770659.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575770659.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575770660.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "create_module (<frozen importlib._bootstrap_external>:841)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770660.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_new_module (<frozen importlib._bootstrap>:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770661.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575770661.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575770662.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575770662.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575770662.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770663.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575770663.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "has_location (<frozen importlib._bootstrap>:406)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770664.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575770664.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575770666.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.endswith"}, {"pid": 20956, "tid": 2192355, "ts": 253575770667.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253575770667.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770668.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770667.06, "ph": "X", "cat": "fee", "dur": 1.0, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253575770667.04, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770669.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575770669.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575770670.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575770671.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575770671.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575770670.02, "ph": "X", "cat": "fee", "dur": 1.08, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770671.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575770670.0, "ph": "X", "cat": "fee", "dur": 1.16, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770666.04, "ph": "X", "cat": "fee", "dur": 5.14, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770665.04, "ph": "X", "cat": "fee", "dur": 6.16, "name": "_get_cached (<frozen importlib._bootstrap_external>:491)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770665.02, "ph": "X", "cat": "fee", "dur": 6.98, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770672.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770661.02, "ph": "X", "cat": "fee", "dur": 11.04, "name": "_init_module_attrs (<frozen importlib._bootstrap>:486)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770659.08, "ph": "X", "cat": "fee", "dur": 13.0, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770673.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "get_filename (<frozen importlib._bootstrap_external>:1031)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770673.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "_check_name_wrapper (<frozen importlib._bootstrap_external>:523)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770674.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253575770674.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rfind"}, {"pid": 20956, "tid": 2192355, "ts": 253575770674.1, "ph": "X", "cat": "fee", "dur": 0.06, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770674.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770674.08, "ph": "X", "cat": "fee", "dur": 0.14, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253575770674.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770675.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575770675.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575770676.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575770676.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575770676.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253575770676.02, "ph": "X", "cat": "fee", "dur": 0.14, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770676.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253575770676.0, "ph": "X", "cat": "fee", "dur": 0.22, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770674.0, "ph": "X", "cat": "fee", "dur": 2.24, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770677.04, "ph": "X", "cat": "fee", "dur": 2.96, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253575770677.02, "ph": "X", "cat": "fee", "dur": 3.0, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770677.0, "ph": "X", "cat": "fee", "dur": 3.04, "name": "path_stats (<frozen importlib._bootstrap_external>:1077)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770681.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575770682.0, "ph": "X", "cat": "fee", "dur": 37.0, "name": "io.open_code"}, {"pid": 20956, "tid": 2192355, "ts": 253575770720.0, "ph": "X", "cat": "fee", "dur": 10.0, "name": "_io.BufferedReader.read"}, {"pid": 20956, "tid": 2192355, "ts": 253575770730.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_io.BufferedReader.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253575770681.0, "ph": "X", "cat": "fee", "dur": 51.02, "name": "get_data (<frozen importlib._bootstrap_external>:1036)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770733.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253575770734.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253575770734.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253575770734.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770733.0, "ph": "X", "cat": "fee", "dur": 2.0, "name": "_classify_pyc (<frozen importlib._bootstrap_external>:560)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770736.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253575770736.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253575770736.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770736.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253575770736.2, "ph": "X", "cat": "fee", "dur": 0.8, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253575770736.14, "ph": "X", "cat": "fee", "dur": 0.88, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770736.0, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_validate_timestamp_pyc (<frozen importlib._bootstrap_external>:593)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770737.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770738.0, "ph": "X", "cat": "fee", "dur": 103.0, "name": "marshal.loads"}, {"pid": 20956, "tid": 2192355, "ts": 253575770842.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575770842.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770842.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_imp._fix_co_filename"}, {"pid": 20956, "tid": 2192355, "ts": 253575770737.1, "ph": "X", "cat": "fee", "dur": 105.92, "name": "_compile_bytecode (<frozen importlib._bootstrap_external>:645)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770673.0, "ph": "X", "cat": "fee", "dur": 170.04, "name": "get_code (<frozen importlib._bootstrap_external>:916)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770846.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253575770847.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575770846.0, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770853.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770854.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575770854.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770856.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575770854.0, "ph": "X", "cat": "fee", "dur": 2.04, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770856.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253575770857.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253575770856.06, "ph": "X", "cat": "fee", "dur": 0.98, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770853.06, "ph": "X", "cat": "fee", "dur": 4.0, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770857.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253575770858.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575770859.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770859.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770860.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770860.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770861.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770861.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770861.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770862.0, "ph": "X", "cat": "fee", "dur": 78.0, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770940.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770858.06, "ph": "X", "cat": "fee", "dur": 82.94, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770941.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575770941.08, "ph": "X", "cat": "fee", "dur": 9.92, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770951.02, "ph": "X", "cat": "fee", "dur": 46427.98, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817389.0, "ph": "X", "cat": "fee", "dur": 6.0, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253575817396.0, "ph": "X", "cat": "fee", "dur": 4.0, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770941.02, "ph": "X", "cat": "fee", "dur": 46459.98, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770858.0, "ph": "X", "cat": "fee", "dur": 46543.02, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817402.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253575817403.0, "ph": "X", "cat": "fee", "dur": 5.0, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253575817402.0, "ph": "X", "cat": "fee", "dur": 12.0, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817401.04, "ph": "X", "cat": "fee", "dur": 17.96, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817425.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575817426.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253575817426.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575817420.0, "ph": "X", "cat": "fee", "dur": 6.1, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770853.0, "ph": "X", "cat": "fee", "dur": 46574.0, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817429.02, "ph": "X", "cat": "fee", "dur": 4.98, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817435.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575817435.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817441.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575817434.04, "ph": "X", "cat": "fee", "dur": 7.98, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817442.06, "ph": "X", "cat": "fee", "dur": 4.94, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253575817448.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253575817442.04, "ph": "X", "cat": "fee", "dur": 6.96, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817434.02, "ph": "X", "cat": "fee", "dur": 15.0, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817449.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253575817449.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575817455.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817460.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817461.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817462.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817466.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817467.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817468.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817472.0, "ph": "X", "cat": "fee", "dur": 83.0, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817556.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817454.0, "ph": "X", "cat": "fee", "dur": 107.0, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817562.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.format"}, {"pid": 20956, "tid": 2192355, "ts": 253575817449.08, "ph": "X", "cat": "fee", "dur": 117.92, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817568.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253575817569.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253575817568.02, "ph": "X", "cat": "fee", "dur": 1.02, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817568.0, "ph": "X", "cat": "fee", "dur": 1.06, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817569.1, "ph": "X", "cat": "fee", "dur": 5.9, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575817575.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253575817576.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575817569.08, "ph": "X", "cat": "fee", "dur": 6.96, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817429.0, "ph": "X", "cat": "fee", "dur": 147.06, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817578.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "TorchPlaceHolder (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:20)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817577.0, "ph": "X", "cat": "fee", "dur": 11.0, "name": "builtins.__build_class__"}, {"pid": 20956, "tid": 2192355, "ts": 253575817590.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817591.06, "ph": "X", "cat": "fee", "dur": 5.94, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575817602.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817607.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253575817591.04, "ph": "X", "cat": "fee", "dur": 20.96, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817613.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253575817613.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253575817613.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817591.02, "ph": "X", "cat": "fee", "dur": 27.98, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817619.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253575817620.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253575817620.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817625.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817626.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817627.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817627.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817628.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817632.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817633.02, "ph": "X", "cat": "fee", "dur": 63.98, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817697.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817620.06, "ph": "X", "cat": "fee", "dur": 81.94, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817703.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575817704.02, "ph": "X", "cat": "fee", "dur": 10.98, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817719.0, "ph": "X", "cat": "fee", "dur": 321348.0, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139081.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576139081.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817703.0, "ph": "X", "cat": "fee", "dur": 321378.08, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817620.0, "ph": "X", "cat": "fee", "dur": 321461.1, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139082.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576139082.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576139082.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139082.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139083.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139083.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576139083.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139083.04, "ph": "X", "cat": "fee", "dur": 0.14, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253575817590.0, "ph": "X", "cat": "fee", "dur": 321494.0, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770844.04, "ph": "X", "cat": "fee", "dur": 368245.96, "name": "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:1)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770844.02, "ph": "X", "cat": "fee", "dur": 368246.0, "name": "builtins.exec"}, {"pid": 20956, "tid": 2192355, "ts": 253575770844.0, "ph": "X", "cat": "fee", "dur": 368246.04, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770672.1, "ph": "X", "cat": "fee", "dur": 368417.96, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139092.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576139092.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770659.02, "ph": "X", "cat": "fee", "dur": 368433.98, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139093.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576139093.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575770602.1, "ph": "X", "cat": "fee", "dur": 368491.92, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139095.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576139095.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576139095.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139094.04, "ph": "X", "cat": "fee", "dur": 1.08, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139096.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139096.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576139096.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139096.0, "ph": "X", "cat": "fee", "dur": 0.14, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770598.0, "ph": "X", "cat": "fee", "dur": 368499.0, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139097.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139097.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139097.04, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139098.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576139098.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576139098.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139098.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576139099.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576139098.12, "ph": "X", "cat": "fee", "dur": 0.92, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139097.02, "ph": "X", "cat": "fee", "dur": 2.04, "name": "_lock_unlock_module (<frozen importlib._bootstrap>:203)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770596.08, "ph": "X", "cat": "fee", "dur": 368503.0, "name": "builtins.__import__"}, {"pid": 20956, "tid": 2192355, "ts": 253575770596.06, "ph": "X", "cat": "fee", "dur": 368503.04, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253575770595.06, "ph": "X", "cat": "fee", "dur": 368504.06, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139102.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "TuneResults (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/integration.py:61)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139102.0, "ph": "X", "cat": "fee", "dur": 7.0, "name": "builtins.__build_class__"}, {"pid": 20956, "tid": 2192355, "ts": 253575755902.02, "ph": "X", "cat": "fee", "dur": 383207.98, "name": "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/integration.py:1)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755902.0, "ph": "X", "cat": "fee", "dur": 383208.02, "name": "builtins.exec"}, {"pid": 20956, "tid": 2192355, "ts": 253575755901.06, "ph": "X", "cat": "fee", "dur": 383211.94, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755822.0, "ph": "X", "cat": "fee", "dur": 383291.02, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139114.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576139114.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755810.0, "ph": "X", "cat": "fee", "dur": 383305.02, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139115.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576139115.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253575755739.0, "ph": "X", "cat": "fee", "dur": 383377.02, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139117.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576139117.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576139116.06, "ph": "X", "cat": "fee", "dur": 1.02, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139116.04, "ph": "X", "cat": "fee", "dur": 1.06, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139117.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139118.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576139118.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139117.12, "ph": "X", "cat": "fee", "dur": 0.96, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755734.0, "ph": "X", "cat": "fee", "dur": 383384.1, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139120.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139120.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139121.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139121.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139121.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139122.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139120.08, "ph": "X", "cat": "fee", "dur": 1.96, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139122.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576139123.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576139122.06, "ph": "X", "cat": "fee", "dur": 0.98, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139120.06, "ph": "X", "cat": "fee", "dur": 3.0, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139123.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576139123.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576139124.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139124.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139125.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139125.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139125.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139125.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139125.12, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139126.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_frozen"}, {"pid": 20956, "tid": 2192355, "ts": 253576139125.2, "ph": "X", "cat": "fee", "dur": 0.84, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139126.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139126.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139126.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139126.14, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139127.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576139127.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139127.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139128.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576139128.08, "ph": "X", "cat": "fee", "dur": 5.92, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576139128.06, "ph": "X", "cat": "fee", "dur": 5.96, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139134.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139136.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576139136.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576139135.04, "ph": "X", "cat": "fee", "dur": 1.04, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139136.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576139135.02, "ph": "X", "cat": "fee", "dur": 1.12, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139137.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139137.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576139137.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576139137.06, "ph": "X", "cat": "fee", "dur": 0.96, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139138.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576139137.04, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139138.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139139.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576139139.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576139138.16, "ph": "X", "cat": "fee", "dur": 0.92, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139139.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576139138.14, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139139.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139140.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576139140.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576139140.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139140.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576139139.2, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139140.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139141.04, "ph": "X", "cat": "fee", "dur": 15.96, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576139141.02, "ph": "X", "cat": "fee", "dur": 16.0, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139141.0, "ph": "X", "cat": "fee", "dur": 16.04, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139140.22, "ph": "X", "cat": "fee", "dur": 17.78, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139158.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap_external>:1006)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139159.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576139159.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:351)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139158.08, "ph": "X", "cat": "fee", "dur": 1.92, "name": "spec_from_file_location (<frozen importlib._bootstrap_external>:696)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139158.02, "ph": "X", "cat": "fee", "dur": 2.0, "name": "_get_spec (<frozen importlib._bootstrap_external>:1500)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139128.0, "ph": "X", "cat": "fee", "dur": 32.04, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139127.0, "ph": "X", "cat": "fee", "dur": 33.06, "name": "_get_spec (<frozen importlib._bootstrap_external>:1374)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139126.22, "ph": "X", "cat": "fee", "dur": 33.86, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139160.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139160.1, "ph": "X", "cat": "fee", "dur": 0.92, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139124.0, "ph": "X", "cat": "fee", "dur": 37.04, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139161.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139161.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139162.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "create_module (<frozen importlib._bootstrap_external>:841)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139162.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_new_module (<frozen importlib._bootstrap>:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139162.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139163.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139163.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139163.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576139163.1, "ph": "X", "cat": "fee", "dur": 0.06, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139164.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139164.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "has_location (<frozen importlib._bootstrap>:406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139165.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139165.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139166.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.endswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576139166.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576139167.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rfind"}, {"pid": 20956, "tid": 2192355, "ts": 253576139167.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139167.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139167.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576139167.02, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139168.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576139169.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576139170.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576139170.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576139170.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576139169.06, "ph": "X", "cat": "fee", "dur": 1.06, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139170.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576139169.04, "ph": "X", "cat": "fee", "dur": 1.14, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139166.1, "ph": "X", "cat": "fee", "dur": 4.1, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139166.04, "ph": "X", "cat": "fee", "dur": 4.18, "name": "_get_cached (<frozen importlib._bootstrap_external>:491)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139166.02, "ph": "X", "cat": "fee", "dur": 4.98, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139171.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139162.08, "ph": "X", "cat": "fee", "dur": 8.98, "name": "_init_module_attrs (<frozen importlib._bootstrap>:486)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139161.12, "ph": "X", "cat": "fee", "dur": 9.96, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139172.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "get_filename (<frozen importlib._bootstrap_external>:1031)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139172.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "_check_name_wrapper (<frozen importlib._bootstrap_external>:523)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139172.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576139173.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rfind"}, {"pid": 20956, "tid": 2192355, "ts": 253576139173.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139173.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139173.02, "ph": "X", "cat": "fee", "dur": 0.14, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576139173.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139174.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576139174.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576139174.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576139175.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576139175.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576139174.1, "ph": "X", "cat": "fee", "dur": 1.0, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139175.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576139174.08, "ph": "X", "cat": "fee", "dur": 1.08, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139172.1, "ph": "X", "cat": "fee", "dur": 3.08, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139175.24, "ph": "X", "cat": "fee", "dur": 2.76, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576139175.22, "ph": "X", "cat": "fee", "dur": 2.8, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139175.2, "ph": "X", "cat": "fee", "dur": 2.84, "name": "path_stats (<frozen importlib._bootstrap_external>:1077)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139179.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576139179.06, "ph": "X", "cat": "fee", "dur": 28.94, "name": "io.open_code"}, {"pid": 20956, "tid": 2192355, "ts": 253576139208.02, "ph": "X", "cat": "fee", "dur": 3.98, "name": "_io.BufferedReader.read"}, {"pid": 20956, "tid": 2192355, "ts": 253576139212.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_io.BufferedReader.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576139179.0, "ph": "X", "cat": "fee", "dur": 35.02, "name": "get_data (<frozen importlib._bootstrap_external>:1036)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139214.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576139215.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576139215.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576139215.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139214.04, "ph": "X", "cat": "fee", "dur": 1.1, "name": "_classify_pyc (<frozen importlib._bootstrap_external>:560)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139216.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576139216.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576139216.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139217.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576139217.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576139217.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139216.0, "ph": "X", "cat": "fee", "dur": 1.12, "name": "_validate_timestamp_pyc (<frozen importlib._bootstrap_external>:593)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139217.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139218.0, "ph": "X", "cat": "fee", "dur": 52.0, "name": "marshal.loads"}, {"pid": 20956, "tid": 2192355, "ts": 253576139271.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576139271.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139271.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp._fix_co_filename"}, {"pid": 20956, "tid": 2192355, "ts": 253576139217.18, "ph": "X", "cat": "fee", "dur": 53.94, "name": "_compile_bytecode (<frozen importlib._bootstrap_external>:645)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139172.0, "ph": "X", "cat": "fee", "dur": 99.14, "name": "get_code (<frozen importlib._bootstrap_external>:916)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139275.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576139275.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139275.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139279.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139279.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139279.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139280.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576139280.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576139279.14, "ph": "X", "cat": "fee", "dur": 0.94, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139281.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576139281.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576139281.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139279.0, "ph": "X", "cat": "fee", "dur": 2.12, "name": "_lock_unlock_module (<frozen importlib._bootstrap>:203)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139282.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139283.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139283.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139284.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139283.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139284.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139283.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139285.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576139285.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576139285.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139283.0, "ph": "X", "cat": "fee", "dur": 2.14, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139286.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576139286.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576139287.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139287.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139287.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139288.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139287.14, "ph": "X", "cat": "fee", "dur": 0.9, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139288.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139288.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139288.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_frozen"}, {"pid": 20956, "tid": 2192355, "ts": 253576139288.14, "ph": "X", "cat": "fee", "dur": 0.06, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139288.24, "ph": "X", "cat": "fee", "dur": 0.76, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139288.22, "ph": "X", "cat": "fee", "dur": 0.8, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139289.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139289.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139289.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576139289.2, "ph": "X", "cat": "fee", "dur": 0.8, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139290.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139290.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576139290.14, "ph": "X", "cat": "fee", "dur": 2.86, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576139290.12, "ph": "X", "cat": "fee", "dur": 3.88, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139294.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139295.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576139295.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576139295.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139295.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576139295.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139296.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139296.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576139297.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576139296.1, "ph": "X", "cat": "fee", "dur": 0.94, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139297.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576139296.08, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139297.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139298.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576139298.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576139297.18, "ph": "X", "cat": "fee", "dur": 0.9, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139298.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576139297.16, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139298.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139299.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576139299.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576139298.22, "ph": "X", "cat": "fee", "dur": 0.86, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139299.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576139298.2, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139299.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139300.0, "ph": "X", "cat": "fee", "dur": 10.0, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576139299.24, "ph": "X", "cat": "fee", "dur": 10.78, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139299.22, "ph": "X", "cat": "fee", "dur": 10.82, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139299.2, "ph": "X", "cat": "fee", "dur": 10.86, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139311.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap_external>:1006)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139311.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576139312.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:351)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139311.06, "ph": "X", "cat": "fee", "dur": 0.98, "name": "spec_from_file_location (<frozen importlib._bootstrap_external>:696)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139311.0, "ph": "X", "cat": "fee", "dur": 1.06, "name": "_get_spec (<frozen importlib._bootstrap_external>:1500)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139290.06, "ph": "X", "cat": "fee", "dur": 22.02, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139289.14, "ph": "X", "cat": "fee", "dur": 23.86, "name": "_get_spec (<frozen importlib._bootstrap_external>:1374)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139289.12, "ph": "X", "cat": "fee", "dur": 23.9, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139313.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139313.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139287.0, "ph": "X", "cat": "fee", "dur": 26.12, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139316.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139316.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139317.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "create_module (<frozen importlib._bootstrap_external>:841)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139317.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_new_module (<frozen importlib._bootstrap>:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139317.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139317.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139318.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139318.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576139318.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139319.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139319.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "has_location (<frozen importlib._bootstrap>:406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139319.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139320.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139321.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.endswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576139321.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576139322.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rfind"}, {"pid": 20956, "tid": 2192355, "ts": 253576139322.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139322.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139322.04, "ph": "X", "cat": "fee", "dur": 0.14, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576139322.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139323.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576139323.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576139324.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576139324.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576139324.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576139324.02, "ph": "X", "cat": "fee", "dur": 0.14, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139325.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576139324.0, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139321.1, "ph": "X", "cat": "fee", "dur": 3.96, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139321.04, "ph": "X", "cat": "fee", "dur": 4.04, "name": "_get_cached (<frozen importlib._bootstrap_external>:491)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139321.02, "ph": "X", "cat": "fee", "dur": 4.08, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139325.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139317.1, "ph": "X", "cat": "fee", "dur": 8.06, "name": "_init_module_attrs (<frozen importlib._bootstrap>:486)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139316.06, "ph": "X", "cat": "fee", "dur": 9.12, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139326.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "get_filename (<frozen importlib._bootstrap_external>:1031)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139326.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "_check_name_wrapper (<frozen importlib._bootstrap_external>:523)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139327.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576139327.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rfind"}, {"pid": 20956, "tid": 2192355, "ts": 253576139327.1, "ph": "X", "cat": "fee", "dur": 0.06, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139327.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139327.08, "ph": "X", "cat": "fee", "dur": 0.14, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576139327.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139328.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576139328.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576139329.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576139329.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576139329.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576139328.12, "ph": "X", "cat": "fee", "dur": 1.0, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139329.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576139328.1, "ph": "X", "cat": "fee", "dur": 1.08, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139327.0, "ph": "X", "cat": "fee", "dur": 2.2, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139330.0, "ph": "X", "cat": "fee", "dur": 2.0, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576139329.24, "ph": "X", "cat": "fee", "dur": 2.78, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139329.22, "ph": "X", "cat": "fee", "dur": 2.82, "name": "path_stats (<frozen importlib._bootstrap_external>:1077)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139333.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576139333.06, "ph": "X", "cat": "fee", "dur": 26.94, "name": "io.open_code"}, {"pid": 20956, "tid": 2192355, "ts": 253576139360.02, "ph": "X", "cat": "fee", "dur": 3.98, "name": "_io.BufferedReader.read"}, {"pid": 20956, "tid": 2192355, "ts": 253576139364.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_io.BufferedReader.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576139333.0, "ph": "X", "cat": "fee", "dur": 32.02, "name": "get_data (<frozen importlib._bootstrap_external>:1036)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139366.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576139366.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576139366.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576139366.04, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139365.04, "ph": "X", "cat": "fee", "dur": 1.12, "name": "_classify_pyc (<frozen importlib._bootstrap_external>:560)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139367.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576139367.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576139367.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139368.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576139368.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576139368.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139367.0, "ph": "X", "cat": "fee", "dur": 1.12, "name": "_validate_timestamp_pyc (<frozen importlib._bootstrap_external>:593)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139368.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139369.0, "ph": "X", "cat": "fee", "dur": 402.0, "name": "marshal.loads"}, {"pid": 20956, "tid": 2192355, "ts": 253576139772.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576139772.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139772.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp._fix_co_filename"}, {"pid": 20956, "tid": 2192355, "ts": 253576139368.18, "ph": "X", "cat": "fee", "dur": 403.94, "name": "_compile_bytecode (<frozen importlib._bootstrap_external>:645)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139326.02, "ph": "X", "cat": "fee", "dur": 446.98, "name": "get_code (<frozen importlib._bootstrap_external>:916)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139775.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576139775.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139775.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139780.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139781.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139781.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139782.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139781.06, "ph": "X", "cat": "fee", "dur": 1.0, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139782.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139781.0, "ph": "X", "cat": "fee", "dur": 2.0, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139783.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576139783.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576139783.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139780.06, "ph": "X", "cat": "fee", "dur": 3.96, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139784.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576139784.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576139785.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139785.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139786.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_builtin"}, {"pid": 20956, "tid": 2192355, "ts": 253576139785.1, "ph": "X", "cat": "fee", "dur": 0.94, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139787.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139787.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139787.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139787.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139787.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_frozen"}, {"pid": 20956, "tid": 2192355, "ts": 253576139787.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139788.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139788.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139788.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139788.1, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139789.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576139789.06, "ph": "X", "cat": "fee", "dur": 13.94, "name": "posix.getcwd"}, {"pid": 20956, "tid": 2192355, "ts": 253576139789.04, "ph": "X", "cat": "fee", "dur": 13.98, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139803.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139804.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576139804.08, "ph": "X", "cat": "fee", "dur": 1.92, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139806.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139807.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139808.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139809.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139809.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139810.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139810.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139811.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139811.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139812.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139812.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139804.02, "ph": "X", "cat": "fee", "dur": 8.06, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139813.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576139813.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139813.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139813.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576139813.18, "ph": "X", "cat": "fee", "dur": 1.82, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139816.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139816.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139817.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139817.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139818.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139818.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139819.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139819.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139820.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139820.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139820.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139813.12, "ph": "X", "cat": "fee", "dur": 7.9, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139821.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576139821.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139822.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576139822.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139822.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139822.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576139822.18, "ph": "X", "cat": "fee", "dur": 1.82, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139824.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139825.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139825.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139826.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139826.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139827.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139827.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139827.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139828.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139828.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139829.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139822.12, "ph": "X", "cat": "fee", "dur": 6.94, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139829.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576139829.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139830.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139830.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576139830.12, "ph": "X", "cat": "fee", "dur": 1.88, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139832.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139832.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139833.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139833.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139834.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139834.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139835.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139835.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139835.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139836.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139836.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139830.06, "ph": "X", "cat": "fee", "dur": 6.02, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139837.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576139837.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139837.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139837.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576139837.18, "ph": "X", "cat": "fee", "dur": 1.82, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139839.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139840.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139840.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139841.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139841.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139842.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139842.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139843.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139843.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139844.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139844.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139837.12, "ph": "X", "cat": "fee", "dur": 6.96, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139844.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576139845.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139845.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139845.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576139845.16, "ph": "X", "cat": "fee", "dur": 2.84, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139848.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139848.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139849.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139849.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139850.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139850.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139851.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139851.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139851.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139852.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139852.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139845.1, "ph": "X", "cat": "fee", "dur": 6.98, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139852.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576139853.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139853.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139853.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576139853.16, "ph": "X", "cat": "fee", "dur": 1.84, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139855.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139856.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139856.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139857.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139857.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139857.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139858.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139858.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139859.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139859.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139859.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139853.1, "ph": "X", "cat": "fee", "dur": 6.92, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139860.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:351)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139788.2, "ph": "X", "cat": "fee", "dur": 72.8, "name": "_get_spec (<frozen importlib._bootstrap_external>:1374)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139788.18, "ph": "X", "cat": "fee", "dur": 72.84, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139861.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139861.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139862.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139862.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139863.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "str.partition"}, {"pid": 20956, "tid": 2192355, "ts": 253576139863.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_module_matches_namespace (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/pkg_resources/extern/__init__.py:24)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139862.08, "ph": "X", "cat": "fee", "dur": 1.96, "name": "find_spec (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/pkg_resources/extern/__init__.py:57)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139864.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139864.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139864.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139864.14, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139865.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/six.py:194)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139865.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139865.04, "ph": "X", "cat": "fee", "dur": 0.98, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139785.0, "ph": "X", "cat": "fee", "dur": 81.04, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139866.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "str.format"}, {"pid": 20956, "tid": 2192355, "ts": 253576139784.08, "ph": "X", "cat": "fee", "dur": 82.94, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139868.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576139868.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576139868.02, "ph": "X", "cat": "fee", "dur": 1.0, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139868.0, "ph": "X", "cat": "fee", "dur": 1.04, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139869.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139869.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576139870.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139869.06, "ph": "X", "cat": "fee", "dur": 0.98, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139780.0, "ph": "X", "cat": "fee", "dur": 90.06, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139871.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139872.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139872.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139873.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139872.1, "ph": "X", "cat": "fee", "dur": 0.94, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139873.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139872.04, "ph": "X", "cat": "fee", "dur": 1.06, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139873.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576139874.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576139873.12, "ph": "X", "cat": "fee", "dur": 0.94, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139872.02, "ph": "X", "cat": "fee", "dur": 2.06, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139874.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576139874.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576139875.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139875.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139876.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139876.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139876.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139876.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139876.12, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139876.22, "ph": "X", "cat": "fee", "dur": 0.78, "name": "_imp.is_frozen"}, {"pid": 20956, "tid": 2192355, "ts": 253576139876.2, "ph": "X", "cat": "fee", "dur": 0.82, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139877.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139877.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139877.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139877.12, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139877.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576139878.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139878.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139878.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576139878.14, "ph": "X", "cat": "fee", "dur": 2.86, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139881.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139882.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139882.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139883.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139883.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139883.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139884.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139884.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139885.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139885.04, "ph": "X", "cat": "fee", "dur": 6.96, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139892.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_get_spec (<frozen importlib._bootstrap_external>:1500)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139878.08, "ph": "X", "cat": "fee", "dur": 15.94, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139877.22, "ph": "X", "cat": "fee", "dur": 16.82, "name": "_get_spec (<frozen importlib._bootstrap_external>:1374)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139877.2, "ph": "X", "cat": "fee", "dur": 17.8, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139895.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576139895.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139875.02, "ph": "X", "cat": "fee", "dur": 20.08, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139896.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139896.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139896.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "create_module (<frozen importlib._bootstrap_external>:841)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139896.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "_new_module (<frozen importlib._bootstrap>:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139897.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139897.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139897.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139898.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576139897.16, "ph": "X", "cat": "fee", "dur": 0.88, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139898.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139899.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "has_location (<frozen importlib._bootstrap>:406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139899.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139899.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139900.04, "ph": "X", "cat": "fee", "dur": 3.96, "name": "_get_cached (<frozen importlib._bootstrap_external>:491)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139900.02, "ph": "X", "cat": "fee", "dur": 4.0, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139904.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139897.02, "ph": "X", "cat": "fee", "dur": 8.0, "name": "_init_module_attrs (<frozen importlib._bootstrap>:486)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139896.06, "ph": "X", "cat": "fee", "dur": 8.98, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139906.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "get_filename (<frozen importlib._bootstrap_external>:1031)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139905.1, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_check_name_wrapper (<frozen importlib._bootstrap_external>:523)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139906.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576139906.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139907.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576139907.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576139908.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139906.06, "ph": "X", "cat": "fee", "dur": 1.98, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139909.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139909.0, "ph": "X", "cat": "fee", "dur": 2.02, "name": "path_stats (<frozen importlib._bootstrap_external>:1077)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139912.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576139912.06, "ph": "X", "cat": "fee", "dur": 20.94, "name": "io.open_code"}, {"pid": 20956, "tid": 2192355, "ts": 253576139933.02, "ph": "X", "cat": "fee", "dur": 2.98, "name": "_io.BufferedReader.read"}, {"pid": 20956, "tid": 2192355, "ts": 253576139936.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_io.BufferedReader.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576139912.0, "ph": "X", "cat": "fee", "dur": 25.02, "name": "get_data (<frozen importlib._bootstrap_external>:1036)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139938.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576139938.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139938.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_classify_pyc (<frozen importlib._bootstrap_external>:560)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139940.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139940.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139939.04, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_validate_timestamp_pyc (<frozen importlib._bootstrap_external>:593)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139941.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139941.06, "ph": "X", "cat": "fee", "dur": 30.94, "name": "marshal.loads"}, {"pid": 20956, "tid": 2192355, "ts": 253576139973.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576139973.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139973.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp._fix_co_filename"}, {"pid": 20956, "tid": 2192355, "ts": 253576139941.04, "ph": "X", "cat": "fee", "dur": 32.08, "name": "_compile_bytecode (<frozen importlib._bootstrap_external>:645)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139905.08, "ph": "X", "cat": "fee", "dur": 68.06, "name": "get_code (<frozen importlib._bootstrap_external>:916)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139974.04, "ph": "X", "cat": "fee", "dur": 274.96, "name": "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/cupy.py:1)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139974.02, "ph": "X", "cat": "fee", "dur": 275.0, "name": "builtins.exec"}, {"pid": 20956, "tid": 2192355, "ts": 253576139974.0, "ph": "X", "cat": "fee", "dur": 275.04, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139905.06, "ph": "X", "cat": "fee", "dur": 344.0, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140250.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576140251.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139896.0, "ph": "X", "cat": "fee", "dur": 355.06, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140251.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576140252.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139874.14, "ph": "X", "cat": "fee", "dur": 377.9, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140252.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576140253.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576140252.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140252.06, "ph": "X", "cat": "fee", "dur": 1.0, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140253.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576140253.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576140254.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576140253.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139871.0, "ph": "X", "cat": "fee", "dur": 383.06, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140255.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140256.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576140256.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576140256.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576140256.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140257.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576140256.02, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140257.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576140258.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576140257.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140256.0, "ph": "X", "cat": "fee", "dur": 2.06, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140258.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576140258.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576140259.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576140259.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140259.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140260.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576140260.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140260.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576140260.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140260.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_frozen"}, {"pid": 20956, "tid": 2192355, "ts": 253576140260.16, "ph": "X", "cat": "fee", "dur": 0.06, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140261.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576140260.24, "ph": "X", "cat": "fee", "dur": 0.8, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140261.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576140261.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140261.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576140261.22, "ph": "X", "cat": "fee", "dur": 0.78, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140262.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576140262.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576140262.12, "ph": "X", "cat": "fee", "dur": 2.88, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140265.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140266.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140267.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140267.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140268.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140268.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140268.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140269.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140269.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140270.0, "ph": "X", "cat": "fee", "dur": 8.0, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140278.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_get_spec (<frozen importlib._bootstrap_external>:1500)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140262.06, "ph": "X", "cat": "fee", "dur": 17.96, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140261.16, "ph": "X", "cat": "fee", "dur": 18.88, "name": "_get_spec (<frozen importlib._bootstrap_external>:1374)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140261.14, "ph": "X", "cat": "fee", "dur": 18.92, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140281.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576140280.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140259.0, "ph": "X", "cat": "fee", "dur": 22.06, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140281.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576140281.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576140282.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "create_module (<frozen importlib._bootstrap_external>:841)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140282.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_new_module (<frozen importlib._bootstrap>:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140282.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576140283.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576140283.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576140283.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576140283.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140283.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576140284.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "has_location (<frozen importlib._bootstrap>:406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140284.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576140285.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576140286.0, "ph": "X", "cat": "fee", "dur": 3.0, "name": "_get_cached (<frozen importlib._bootstrap_external>:491)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140285.06, "ph": "X", "cat": "fee", "dur": 3.96, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140289.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140282.1, "ph": "X", "cat": "fee", "dur": 7.9, "name": "_init_module_attrs (<frozen importlib._bootstrap>:486)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140281.14, "ph": "X", "cat": "fee", "dur": 8.88, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140291.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "get_filename (<frozen importlib._bootstrap_external>:1031)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140290.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_check_name_wrapper (<frozen importlib._bootstrap_external>:523)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140291.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576140291.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140292.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576140292.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576140293.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140291.06, "ph": "X", "cat": "fee", "dur": 1.98, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140294.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140294.0, "ph": "X", "cat": "fee", "dur": 2.02, "name": "path_stats (<frozen importlib._bootstrap_external>:1077)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140297.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576140297.06, "ph": "X", "cat": "fee", "dur": 21.94, "name": "io.open_code"}, {"pid": 20956, "tid": 2192355, "ts": 253576140320.0, "ph": "X", "cat": "fee", "dur": 3.0, "name": "_io.BufferedReader.read"}, {"pid": 20956, "tid": 2192355, "ts": 253576140323.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_io.BufferedReader.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576140297.0, "ph": "X", "cat": "fee", "dur": 27.02, "name": "get_data (<frozen importlib._bootstrap_external>:1036)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140325.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576140325.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140324.04, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_classify_pyc (<frozen importlib._bootstrap_external>:560)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140326.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140326.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140326.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_validate_timestamp_pyc (<frozen importlib._bootstrap_external>:593)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140327.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140327.06, "ph": "X", "cat": "fee", "dur": 43.94, "name": "marshal.loads"}, {"pid": 20956, "tid": 2192355, "ts": 253576140371.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576140371.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140371.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "_imp._fix_co_filename"}, {"pid": 20956, "tid": 2192355, "ts": 253576140327.04, "ph": "X", "cat": "fee", "dur": 44.98, "name": "_compile_bytecode (<frozen importlib._bootstrap_external>:645)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140290.06, "ph": "X", "cat": "fee", "dur": 81.98, "name": "get_code (<frozen importlib._bootstrap_external>:916)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140373.0, "ph": "X", "cat": "fee", "dur": 428.0, "name": "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/cuda.py:1)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140372.08, "ph": "X", "cat": "fee", "dur": 428.94, "name": "builtins.exec"}, {"pid": 20956, "tid": 2192355, "ts": 253576140372.06, "ph": "X", "cat": "fee", "dur": 428.98, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140290.04, "ph": "X", "cat": "fee", "dur": 511.02, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140803.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576140803.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140281.08, "ph": "X", "cat": "fee", "dur": 522.0, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140804.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576140804.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576140258.12, "ph": "X", "cat": "fee", "dur": 545.96, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140804.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576140805.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576140804.12, "ph": "X", "cat": "fee", "dur": 0.92, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140804.1, "ph": "X", "cat": "fee", "dur": 0.96, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140805.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576140806.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576140806.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576140805.08, "ph": "X", "cat": "fee", "dur": 1.0, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140255.0, "ph": "X", "cat": "fee", "dur": 551.1, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140807.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140808.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576140808.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576140808.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576140808.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140809.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576140808.02, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140809.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576140810.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576140809.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140808.0, "ph": "X", "cat": "fee", "dur": 2.06, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140810.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576140810.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576140811.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576140811.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140811.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140812.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576140812.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140812.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576140812.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140812.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_frozen"}, {"pid": 20956, "tid": 2192355, "ts": 253576140812.16, "ph": "X", "cat": "fee", "dur": 0.06, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140813.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576140813.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140813.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576140813.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140813.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576140814.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140814.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576140814.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576140814.14, "ph": "X", "cat": "fee", "dur": 2.86, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140817.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140818.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140818.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140819.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140819.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140820.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140820.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140821.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140821.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140821.08, "ph": "X", "cat": "fee", "dur": 8.92, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140830.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_get_spec (<frozen importlib._bootstrap_external>:1500)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140814.08, "ph": "X", "cat": "fee", "dur": 17.94, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140813.18, "ph": "X", "cat": "fee", "dur": 18.86, "name": "_get_spec (<frozen importlib._bootstrap_external>:1374)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140813.16, "ph": "X", "cat": "fee", "dur": 18.9, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140832.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576140832.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140811.02, "ph": "X", "cat": "fee", "dur": 21.98, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140833.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576140833.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576140833.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "create_module (<frozen importlib._bootstrap_external>:841)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140834.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_new_module (<frozen importlib._bootstrap>:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140834.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576140834.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576140834.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576140835.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576140835.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140835.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576140836.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "has_location (<frozen importlib._bootstrap>:406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140836.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576140837.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576140837.06, "ph": "X", "cat": "fee", "dur": 3.94, "name": "_get_cached (<frozen importlib._bootstrap_external>:491)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140837.04, "ph": "X", "cat": "fee", "dur": 3.98, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140841.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140834.04, "ph": "X", "cat": "fee", "dur": 7.04, "name": "_init_module_attrs (<frozen importlib._bootstrap>:486)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140833.08, "ph": "X", "cat": "fee", "dur": 8.92, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140842.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "get_filename (<frozen importlib._bootstrap_external>:1031)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140842.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_check_name_wrapper (<frozen importlib._bootstrap_external>:523)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140843.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576140843.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140844.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576140844.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576140845.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140843.02, "ph": "X", "cat": "fee", "dur": 2.02, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140845.08, "ph": "X", "cat": "fee", "dur": 2.92, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140845.06, "ph": "X", "cat": "fee", "dur": 2.96, "name": "path_stats (<frozen importlib._bootstrap_external>:1077)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140849.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576140849.06, "ph": "X", "cat": "fee", "dur": 15.94, "name": "io.open_code"}, {"pid": 20956, "tid": 2192355, "ts": 253576140865.02, "ph": "X", "cat": "fee", "dur": 2.98, "name": "_io.BufferedReader.read"}, {"pid": 20956, "tid": 2192355, "ts": 253576140868.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_io.BufferedReader.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576140849.0, "ph": "X", "cat": "fee", "dur": 20.02, "name": "get_data (<frozen importlib._bootstrap_external>:1036)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140870.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576140870.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140870.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_classify_pyc (<frozen importlib._bootstrap_external>:560)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140872.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140872.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140871.04, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_validate_timestamp_pyc (<frozen importlib._bootstrap_external>:593)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140872.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140873.04, "ph": "X", "cat": "fee", "dur": 27.96, "name": "marshal.loads"}, {"pid": 20956, "tid": 2192355, "ts": 253576140901.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576140901.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140902.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp._fix_co_filename"}, {"pid": 20956, "tid": 2192355, "ts": 253576140873.02, "ph": "X", "cat": "fee", "dur": 29.02, "name": "_compile_bytecode (<frozen importlib._bootstrap_external>:645)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140842.04, "ph": "X", "cat": "fee", "dur": 60.02, "name": "get_code (<frozen importlib._bootstrap_external>:916)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140903.0, "ph": "X", "cat": "fee", "dur": 10197.0, "name": "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/opencl.py:1)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140902.1, "ph": "X", "cat": "fee", "dur": 10197.92, "name": "builtins.exec"}, {"pid": 20956, "tid": 2192355, "ts": 253576140902.08, "ph": "X", "cat": "fee", "dur": 10197.96, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140842.02, "ph": "X", "cat": "fee", "dur": 10258.04, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151104.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576151104.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140833.02, "ph": "X", "cat": "fee", "dur": 10271.06, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151105.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576151105.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576140810.12, "ph": "X", "cat": "fee", "dur": 10294.96, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151106.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576151106.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576151106.02, "ph": "X", "cat": "fee", "dur": 1.0, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151106.0, "ph": "X", "cat": "fee", "dur": 1.04, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151107.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576151107.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576151107.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576151107.06, "ph": "X", "cat": "fee", "dur": 0.14, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576140807.0, "ph": "X", "cat": "fee", "dur": 10301.0, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151110.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151110.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576151111.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576151111.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576151111.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151112.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576151110.06, "ph": "X", "cat": "fee", "dur": 2.0, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151112.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576151113.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576151112.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151110.04, "ph": "X", "cat": "fee", "dur": 3.02, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151114.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576151114.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576151115.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576151115.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151115.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151116.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576151116.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151116.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576151116.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151117.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_frozen"}, {"pid": 20956, "tid": 2192355, "ts": 253576151117.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151117.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576151117.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151117.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576151117.16, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151118.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576151118.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151119.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576151119.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576151120.0, "ph": "X", "cat": "fee", "dur": 4.0, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151125.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151126.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151127.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151128.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151128.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151129.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151129.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151130.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151130.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151131.0, "ph": "X", "cat": "fee", "dur": 11.0, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151143.0, "ph": "X", "cat": "fee", "dur": 2.0, "name": "_get_spec (<frozen importlib._bootstrap_external>:1500)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151119.06, "ph": "X", "cat": "fee", "dur": 25.96, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151118.02, "ph": "X", "cat": "fee", "dur": 27.02, "name": "_get_spec (<frozen importlib._bootstrap_external>:1374)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151118.0, "ph": "X", "cat": "fee", "dur": 27.06, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151146.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576151146.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151115.0, "ph": "X", "cat": "fee", "dur": 31.08, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151146.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576151147.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576151147.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "create_module (<frozen importlib._bootstrap_external>:841)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151147.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "_new_module (<frozen importlib._bootstrap>:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151148.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576151148.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576151148.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576151149.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576151149.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151149.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576151150.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "has_location (<frozen importlib._bootstrap>:406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151150.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576151151.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576151152.04, "ph": "X", "cat": "fee", "dur": 4.96, "name": "_get_cached (<frozen importlib._bootstrap_external>:491)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151152.02, "ph": "X", "cat": "fee", "dur": 5.0, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151157.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151148.02, "ph": "X", "cat": "fee", "dur": 9.06, "name": "_init_module_attrs (<frozen importlib._bootstrap>:486)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151147.02, "ph": "X", "cat": "fee", "dur": 10.08, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151159.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "get_filename (<frozen importlib._bootstrap_external>:1031)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151158.04, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_check_name_wrapper (<frozen importlib._bootstrap_external>:523)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151159.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576151159.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151160.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576151160.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576151161.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151159.06, "ph": "X", "cat": "fee", "dur": 2.96, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151162.06, "ph": "X", "cat": "fee", "dur": 2.94, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151162.04, "ph": "X", "cat": "fee", "dur": 2.98, "name": "path_stats (<frozen importlib._bootstrap_external>:1077)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151166.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576151166.06, "ph": "X", "cat": "fee", "dur": 27.94, "name": "io.open_code"}, {"pid": 20956, "tid": 2192355, "ts": 253576151195.0, "ph": "X", "cat": "fee", "dur": 3.0, "name": "_io.BufferedReader.read"}, {"pid": 20956, "tid": 2192355, "ts": 253576151198.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_io.BufferedReader.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576151166.0, "ph": "X", "cat": "fee", "dur": 33.02, "name": "get_data (<frozen importlib._bootstrap_external>:1036)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151200.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576151201.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151200.0, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_classify_pyc (<frozen importlib._bootstrap_external>:560)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151202.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151203.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151202.0, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_validate_timestamp_pyc (<frozen importlib._bootstrap_external>:593)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151203.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151204.0, "ph": "X", "cat": "fee", "dur": 42.0, "name": "marshal.loads"}, {"pid": 20956, "tid": 2192355, "ts": 253576151246.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576151246.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151247.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp._fix_co_filename"}, {"pid": 20956, "tid": 2192355, "ts": 253576151203.1, "ph": "X", "cat": "fee", "dur": 43.94, "name": "_compile_bytecode (<frozen importlib._bootstrap_external>:645)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151158.02, "ph": "X", "cat": "fee", "dur": 89.04, "name": "get_code (<frozen importlib._bootstrap_external>:916)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151248.02, "ph": "X", "cat": "fee", "dur": 58.98, "name": "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/c.py:1)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151248.0, "ph": "X", "cat": "fee", "dur": 59.02, "name": "builtins.exec"}, {"pid": 20956, "tid": 2192355, "ts": 253576151247.08, "ph": "X", "cat": "fee", "dur": 59.96, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151158.0, "ph": "X", "cat": "fee", "dur": 149.06, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151308.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576151308.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151146.1, "ph": "X", "cat": "fee", "dur": 162.9, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151309.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576151309.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576151114.04, "ph": "X", "cat": "fee", "dur": 195.06, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151310.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576151311.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576151310.02, "ph": "X", "cat": "fee", "dur": 1.02, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151310.0, "ph": "X", "cat": "fee", "dur": 1.06, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151311.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576151311.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576151312.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576151311.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151109.0, "ph": "X", "cat": "fee", "dur": 203.06, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151314.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151314.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576151315.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576151315.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576151315.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151316.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576151314.08, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151316.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576151317.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576151316.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151314.06, "ph": "X", "cat": "fee", "dur": 3.0, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151317.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576151318.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576151319.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576151319.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151319.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151319.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576151319.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151320.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576151320.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151320.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_frozen"}, {"pid": 20956, "tid": 2192355, "ts": 253576151320.1, "ph": "X", "cat": "fee", "dur": 0.06, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151321.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576151321.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151321.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576151321.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151322.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576151322.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151322.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576151322.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576151323.0, "ph": "X", "cat": "fee", "dur": 3.0, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151327.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151327.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151329.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151329.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151330.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151330.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151331.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151331.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151331.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151332.0, "ph": "X", "cat": "fee", "dur": 7.0, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151339.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_get_spec (<frozen importlib._bootstrap_external>:1500)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151322.12, "ph": "X", "cat": "fee", "dur": 18.9, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151321.18, "ph": "X", "cat": "fee", "dur": 19.86, "name": "_get_spec (<frozen importlib._bootstrap_external>:1374)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151321.16, "ph": "X", "cat": "fee", "dur": 20.84, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151342.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576151342.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151318.06, "ph": "X", "cat": "fee", "dur": 24.04, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151342.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576151343.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576151343.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "create_module (<frozen importlib._bootstrap_external>:841)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151343.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "_new_module (<frozen importlib._bootstrap>:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151344.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576151344.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576151344.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576151345.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576151344.16, "ph": "X", "cat": "fee", "dur": 0.88, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151345.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576151346.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "has_location (<frozen importlib._bootstrap>:406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151346.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576151347.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576151348.0, "ph": "X", "cat": "fee", "dur": 4.0, "name": "_get_cached (<frozen importlib._bootstrap_external>:491)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151347.04, "ph": "X", "cat": "fee", "dur": 4.98, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151352.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151344.02, "ph": "X", "cat": "fee", "dur": 8.06, "name": "_init_module_attrs (<frozen importlib._bootstrap>:486)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151343.02, "ph": "X", "cat": "fee", "dur": 9.08, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151353.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "get_filename (<frozen importlib._bootstrap_external>:1031)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151353.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "_check_name_wrapper (<frozen importlib._bootstrap_external>:523)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151354.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576151354.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151355.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576151355.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576151355.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151354.0, "ph": "X", "cat": "fee", "dur": 2.02, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151356.06, "ph": "X", "cat": "fee", "dur": 2.94, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151356.04, "ph": "X", "cat": "fee", "dur": 2.98, "name": "path_stats (<frozen importlib._bootstrap_external>:1077)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151359.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576151360.02, "ph": "X", "cat": "fee", "dur": 19.98, "name": "io.open_code"}, {"pid": 20956, "tid": 2192355, "ts": 253576151380.02, "ph": "X", "cat": "fee", "dur": 2.98, "name": "_io.BufferedReader.read"}, {"pid": 20956, "tid": 2192355, "ts": 253576151383.02, "ph": "X", "cat": "fee", "dur": 2.98, "name": "_io.BufferedReader.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576151359.04, "ph": "X", "cat": "fee", "dur": 26.98, "name": "get_data (<frozen importlib._bootstrap_external>:1036)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151387.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576151387.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151387.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_classify_pyc (<frozen importlib._bootstrap_external>:560)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151388.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151389.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151388.02, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_validate_timestamp_pyc (<frozen importlib._bootstrap_external>:593)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151389.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151390.04, "ph": "X", "cat": "fee", "dur": 37.96, "name": "marshal.loads"}, {"pid": 20956, "tid": 2192355, "ts": 253576151428.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576151429.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151429.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp._fix_co_filename"}, {"pid": 20956, "tid": 2192355, "ts": 253576151390.02, "ph": "X", "cat": "fee", "dur": 39.08, "name": "_compile_bytecode (<frozen importlib._bootstrap_external>:645)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151353.02, "ph": "X", "cat": "fee", "dur": 76.1, "name": "get_code (<frozen importlib._bootstrap_external>:916)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151430.04, "ph": "X", "cat": "fee", "dur": 2775.96, "name": "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/python.py:1)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151430.02, "ph": "X", "cat": "fee", "dur": 2776.0, "name": "builtins.exec"}, {"pid": 20956, "tid": 2192355, "ts": 253576151430.0, "ph": "X", "cat": "fee", "dur": 2776.04, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151353.0, "ph": "X", "cat": "fee", "dur": 2853.06, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154207.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576154207.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151342.12, "ph": "X", "cat": "fee", "dur": 2865.9, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154208.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576154208.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576151318.0, "ph": "X", "cat": "fee", "dur": 2891.0, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154209.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576154210.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154209.04, "ph": "X", "cat": "fee", "dur": 1.0, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154209.02, "ph": "X", "cat": "fee", "dur": 1.04, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154210.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154210.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576154210.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154210.08, "ph": "X", "cat": "fee", "dur": 0.94, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576151314.0, "ph": "X", "cat": "fee", "dur": 2897.04, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154213.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154213.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154213.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154213.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576154214.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154213.14, "ph": "X", "cat": "fee", "dur": 0.9, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154214.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576154215.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154214.06, "ph": "X", "cat": "fee", "dur": 0.98, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154213.0, "ph": "X", "cat": "fee", "dur": 2.06, "name": "_lock_unlock_module (<frozen importlib._bootstrap>:203)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154216.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576154217.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "sys.intern"}, {"pid": 20956, "tid": 2192355, "ts": 253576154218.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.isidentifier"}, {"pid": 20956, "tid": 2192355, "ts": 253576154218.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "frozenset.__contains__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154218.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.isidentifier"}, {"pid": 20956, "tid": 2192355, "ts": 253576154218.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "frozenset.__contains__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154218.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "str.isidentifier"}, {"pid": 20956, "tid": 2192355, "ts": 253576154219.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "frozenset.__contains__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154219.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.isidentifier"}, {"pid": 20956, "tid": 2192355, "ts": 253576154219.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "frozenset.__contains__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154219.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.isidentifier"}, {"pid": 20956, "tid": 2192355, "ts": 253576154219.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "frozenset.__contains__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154219.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.isidentifier"}, {"pid": 20956, "tid": 2192355, "ts": 253576154219.26, "ph": "X", "cat": "fee", "dur": 0.02, "name": "frozenset.__contains__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154219.3, "ph": "X", "cat": "fee", "dur": 0.7, "name": "str.isidentifier"}, {"pid": 20956, "tid": 2192355, "ts": 253576154220.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "frozenset.__contains__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154220.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.isidentifier"}, {"pid": 20956, "tid": 2192355, "ts": 253576154220.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "frozenset.__contains__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154220.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.isidentifier"}, {"pid": 20956, "tid": 2192355, "ts": 253576154220.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "frozenset.__contains__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154220.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576154221.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "set.add"}, {"pid": 20956, "tid": 2192355, "ts": 253576154221.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576154221.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "set.add"}, {"pid": 20956, "tid": 2192355, "ts": 253576154221.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576154221.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "set.add"}, {"pid": 20956, "tid": 2192355, "ts": 253576154221.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576154221.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "set.add"}, {"pid": 20956, "tid": 2192355, "ts": 253576154222.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576154222.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "set.add"}, {"pid": 20956, "tid": 2192355, "ts": 253576154222.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576154222.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "set.add"}, {"pid": 20956, "tid": 2192355, "ts": 253576154222.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576154222.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "set.add"}, {"pid": 20956, "tid": 2192355, "ts": 253576154222.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576154222.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "set.add"}, {"pid": 20956, "tid": 2192355, "ts": 253576154223.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576154223.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154224.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/collections/__init__.py:419)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154224.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/collections/__init__.py:419)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154224.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/collections/__init__.py:419)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154225.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/collections/__init__.py:419)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154225.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/collections/__init__.py:419)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154225.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/collections/__init__.py:419)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154225.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/collections/__init__.py:419)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154225.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/collections/__init__.py:419)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154225.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/collections/__init__.py:419)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154224.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154259.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<module> (<string>:1)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154227.0, "ph": "X", "cat": "fee", "dur": 33.0, "name": "builtins.eval"}, {"pid": 20956, "tid": 2192355, "ts": 253576154263.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "sys.intern"}, {"pid": 20956, "tid": 2192355, "ts": 253576154263.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "sys.intern"}, {"pid": 20956, "tid": 2192355, "ts": 253576154264.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "sys.intern"}, {"pid": 20956, "tid": 2192355, "ts": 253576154264.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "sys.intern"}, {"pid": 20956, "tid": 2192355, "ts": 253576154264.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "sys.intern"}, {"pid": 20956, "tid": 2192355, "ts": 253576154265.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "sys.intern"}, {"pid": 20956, "tid": 2192355, "ts": 253576154265.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "sys.intern"}, {"pid": 20956, "tid": 2192355, "ts": 253576154266.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "sys.intern"}, {"pid": 20956, "tid": 2192355, "ts": 253576154274.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "sys._getframe"}, {"pid": 20956, "tid": 2192355, "ts": 253576154274.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576154216.0, "ph": "X", "cat": "fee", "dur": 59.02, "name": "namedtuple (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/collections/__init__.py:345)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154276.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "KernelInstance (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/core.py:31)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154276.0, "ph": "X", "cat": "fee", "dur": 10.0, "name": "builtins.__build_class__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154287.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "KernelSource (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/core.py:48)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154287.0, "ph": "X", "cat": "fee", "dur": 6.0, "name": "builtins.__build_class__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154293.04, "ph": "X", "cat": "fee", "dur": 1.96, "name": "DeviceInterface (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/core.py:194)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154293.02, "ph": "X", "cat": "fee", "dur": 6.98, "name": "builtins.__build_class__"}, {"pid": 20956, "tid": 2192355, "ts": 253576139774.0, "ph": "X", "cat": "fee", "dur": 14527.0, "name": "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/core.py:1)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139773.04, "ph": "X", "cat": "fee", "dur": 14527.98, "name": "builtins.exec"}, {"pid": 20956, "tid": 2192355, "ts": 253576139773.02, "ph": "X", "cat": "fee", "dur": 14528.02, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139326.0, "ph": "X", "cat": "fee", "dur": 14975.06, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154302.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576154302.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139316.0, "ph": "X", "cat": "fee", "dur": 14987.0, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154303.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576154303.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139286.04, "ph": "X", "cat": "fee", "dur": 15017.06, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154304.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576154304.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154304.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154303.12, "ph": "X", "cat": "fee", "dur": 1.0, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154305.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154305.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576154305.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154305.0, "ph": "X", "cat": "fee", "dur": 0.14, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139282.0, "ph": "X", "cat": "fee", "dur": 15024.0, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154306.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154306.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154306.04, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154306.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576154307.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154306.16, "ph": "X", "cat": "fee", "dur": 0.9, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154307.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576154308.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154307.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154306.02, "ph": "X", "cat": "fee", "dur": 2.04, "name": "_lock_unlock_module (<frozen importlib._bootstrap>:203)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154309.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154310.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154310.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154310.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154310.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154311.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154309.08, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154311.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576154312.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154311.08, "ph": "X", "cat": "fee", "dur": 0.98, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154309.06, "ph": "X", "cat": "fee", "dur": 3.02, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154312.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576154313.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576154314.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154314.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154315.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154315.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154315.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154315.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154314.08, "ph": "X", "cat": "fee", "dur": 1.92, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154316.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576154316.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154316.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154314.06, "ph": "X", "cat": "fee", "dur": 2.08, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154317.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576154317.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576154318.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154318.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154318.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154318.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154318.12, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154319.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154319.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154319.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_frozen"}, {"pid": 20956, "tid": 2192355, "ts": 253576154319.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154319.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154319.16, "ph": "X", "cat": "fee", "dur": 0.86, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154320.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154320.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154320.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576154321.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154321.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154321.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576154322.02, "ph": "X", "cat": "fee", "dur": 2.98, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576154322.0, "ph": "X", "cat": "fee", "dur": 3.02, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154326.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154327.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154327.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154327.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154327.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154326.04, "ph": "X", "cat": "fee", "dur": 1.12, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154328.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154328.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154328.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154328.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154328.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154329.06, "ph": "X", "cat": "fee", "dur": 8.94, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576154329.04, "ph": "X", "cat": "fee", "dur": 8.98, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154329.02, "ph": "X", "cat": "fee", "dur": 9.02, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154329.0, "ph": "X", "cat": "fee", "dur": 9.06, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154339.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154339.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154339.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154339.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154339.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154340.1, "ph": "X", "cat": "fee", "dur": 1.9, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576154340.08, "ph": "X", "cat": "fee", "dur": 1.94, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154340.06, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154340.04, "ph": "X", "cat": "fee", "dur": 2.96, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154343.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154343.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154343.04, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154343.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154343.02, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154344.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576154344.0, "ph": "X", "cat": "fee", "dur": 2.02, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154343.24, "ph": "X", "cat": "fee", "dur": 2.8, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154343.22, "ph": "X", "cat": "fee", "dur": 2.84, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154346.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154346.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154346.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154347.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154346.08, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154347.14, "ph": "X", "cat": "fee", "dur": 6.86, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576154347.12, "ph": "X", "cat": "fee", "dur": 6.9, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154347.1, "ph": "X", "cat": "fee", "dur": 7.9, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154347.08, "ph": "X", "cat": "fee", "dur": 7.94, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154355.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap_external>:1006)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154356.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576154356.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "__init__ (<frozen importlib._bootstrap>:351)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154356.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "spec_from_file_location (<frozen importlib._bootstrap_external>:696)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154355.04, "ph": "X", "cat": "fee", "dur": 2.0, "name": "_get_spec (<frozen importlib._bootstrap_external>:1500)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154321.08, "ph": "X", "cat": "fee", "dur": 35.98, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154320.14, "ph": "X", "cat": "fee", "dur": 36.94, "name": "_get_spec (<frozen importlib._bootstrap_external>:1374)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154320.12, "ph": "X", "cat": "fee", "dur": 37.88, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154358.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154358.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154317.1, "ph": "X", "cat": "fee", "dur": 41.0, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154359.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154359.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154359.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "create_module (<frozen importlib._bootstrap_external>:841)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154359.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "_new_module (<frozen importlib._bootstrap>:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154360.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154360.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154360.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154361.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154361.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154362.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "has_location (<frozen importlib._bootstrap>:406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154362.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154362.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154364.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.endswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576154364.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576154364.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576154364.1, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154366.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576154366.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154367.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154368.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154367.0, "ph": "X", "cat": "fee", "dur": 1.06, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154364.04, "ph": "X", "cat": "fee", "dur": 4.04, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154363.04, "ph": "X", "cat": "fee", "dur": 5.06, "name": "_get_cached (<frozen importlib._bootstrap_external>:491)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154363.02, "ph": "X", "cat": "fee", "dur": 5.1, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154368.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154360.02, "ph": "X", "cat": "fee", "dur": 9.0, "name": "_init_module_attrs (<frozen importlib._bootstrap>:486)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154359.04, "ph": "X", "cat": "fee", "dur": 10.0, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154370.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "get_filename (<frozen importlib._bootstrap_external>:1031)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154369.1, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_check_name_wrapper (<frozen importlib._bootstrap_external>:523)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154370.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576154371.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rfind"}, {"pid": 20956, "tid": 2192355, "ts": 253576154371.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154371.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154370.14, "ph": "X", "cat": "fee", "dur": 0.98, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576154370.12, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154371.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576154372.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154372.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154373.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154373.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154372.08, "ph": "X", "cat": "fee", "dur": 1.0, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154373.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154372.06, "ph": "X", "cat": "fee", "dur": 1.08, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154370.06, "ph": "X", "cat": "fee", "dur": 3.1, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154374.0, "ph": "X", "cat": "fee", "dur": 2.0, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576154373.2, "ph": "X", "cat": "fee", "dur": 2.82, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154373.18, "ph": "X", "cat": "fee", "dur": 2.86, "name": "path_stats (<frozen importlib._bootstrap_external>:1077)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154377.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576154377.06, "ph": "X", "cat": "fee", "dur": 23.94, "name": "io.open_code"}, {"pid": 20956, "tid": 2192355, "ts": 253576154401.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_io.BufferedReader.read"}, {"pid": 20956, "tid": 2192355, "ts": 253576154403.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_io.BufferedReader.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154377.0, "ph": "X", "cat": "fee", "dur": 28.02, "name": "get_data (<frozen importlib._bootstrap_external>:1036)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154406.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576154406.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576154406.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576154406.04, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154405.04, "ph": "X", "cat": "fee", "dur": 1.12, "name": "_classify_pyc (<frozen importlib._bootstrap_external>:560)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154407.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576154407.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576154407.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154408.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576154408.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576154408.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154407.0, "ph": "X", "cat": "fee", "dur": 1.12, "name": "_validate_timestamp_pyc (<frozen importlib._bootstrap_external>:593)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154408.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154409.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "marshal.loads"}, {"pid": 20956, "tid": 2192355, "ts": 253576154410.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576154410.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154410.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp._fix_co_filename"}, {"pid": 20956, "tid": 2192355, "ts": 253576154409.0, "ph": "X", "cat": "fee", "dur": 1.14, "name": "_compile_bytecode (<frozen importlib._bootstrap_external>:645)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154369.08, "ph": "X", "cat": "fee", "dur": 41.08, "name": "get_code (<frozen importlib._bootstrap_external>:916)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154411.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/runners/__init__.py:1)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154411.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "builtins.exec"}, {"pid": 20956, "tid": 2192355, "ts": 253576154411.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154369.06, "ph": "X", "cat": "fee", "dur": 42.96, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154412.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576154412.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154358.12, "ph": "X", "cat": "fee", "dur": 54.9, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154413.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576154413.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154317.04, "ph": "X", "cat": "fee", "dur": 96.98, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154414.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576154415.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154414.06, "ph": "X", "cat": "fee", "dur": 0.98, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154414.04, "ph": "X", "cat": "fee", "dur": 1.02, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154415.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154415.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576154416.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154415.08, "ph": "X", "cat": "fee", "dur": 0.98, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154314.0, "ph": "X", "cat": "fee", "dur": 102.08, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154417.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154417.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154417.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154417.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576154418.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154417.12, "ph": "X", "cat": "fee", "dur": 0.92, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154418.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576154418.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154418.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154416.1, "ph": "X", "cat": "fee", "dur": 2.08, "name": "_lock_unlock_module (<frozen importlib._bootstrap>:203)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154313.06, "ph": "X", "cat": "fee", "dur": 105.94, "name": "builtins.__import__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154313.04, "ph": "X", "cat": "fee", "dur": 105.98, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154419.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154419.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154420.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154420.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154420.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154420.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154420.14, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154421.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_frozen"}, {"pid": 20956, "tid": 2192355, "ts": 253576154421.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154421.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154421.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154421.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154421.16, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154422.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576154423.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576154424.02, "ph": "X", "cat": "fee", "dur": 4.98, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576154424.0, "ph": "X", "cat": "fee", "dur": 5.02, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154423.02, "ph": "X", "cat": "fee", "dur": 6.98, "name": "__init__ (<frozen zipimport>:63)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154431.08, "ph": "X", "cat": "fee", "dur": 1.92, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576154431.06, "ph": "X", "cat": "fee", "dur": 1.96, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154431.04, "ph": "X", "cat": "fee", "dur": 2.0, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154431.02, "ph": "X", "cat": "fee", "dur": 2.98, "name": "_path_isdir (<frozen importlib._bootstrap_external>:159)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154435.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:1472)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154435.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:1472)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154435.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:1472)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154435.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:1472)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154434.04, "ph": "X", "cat": "fee", "dur": 1.12, "name": "list.extend"}, {"pid": 20956, "tid": 2192355, "ts": 253576154436.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:1472)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154436.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:1472)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154436.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "list.extend"}, {"pid": 20956, "tid": 2192355, "ts": 253576154436.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:1472)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154436.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:1472)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154436.12, "ph": "X", "cat": "fee", "dur": 0.1, "name": "list.extend"}, {"pid": 20956, "tid": 2192355, "ts": 253576154437.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576154437.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "_path_isabs (<frozen importlib._bootstrap_external>:175)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154434.02, "ph": "X", "cat": "fee", "dur": 3.06, "name": "__init__ (<frozen importlib._bootstrap_external>:1466)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154431.0, "ph": "X", "cat": "fee", "dur": 7.0, "name": "path_hook_for_FileFinder (<frozen importlib._bootstrap_external>:1597)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154423.0, "ph": "X", "cat": "fee", "dur": 15.02, "name": "_path_hooks (<frozen importlib._bootstrap_external>:1324)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154422.08, "ph": "X", "cat": "fee", "dur": 15.96, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154438.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154439.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576154439.06, "ph": "X", "cat": "fee", "dur": 1.94, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576154439.04, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154442.0, "ph": "X", "cat": "fee", "dur": 21.0, "name": "posix.listdir"}, {"pid": 20956, "tid": 2192355, "ts": 253576154463.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576154464.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576154465.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253576154465.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253576154465.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253576154465.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253576154465.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "<setcomp> (<frozen importlib._bootstrap_external>:1585)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154441.04, "ph": "X", "cat": "fee", "dur": 24.96, "name": "_fill_cache (<frozen importlib._bootstrap_external>:1556)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154466.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154467.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154467.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154467.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154467.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154467.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154468.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154469.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154469.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154468.08, "ph": "X", "cat": "fee", "dur": 1.0, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154469.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154468.06, "ph": "X", "cat": "fee", "dur": 1.08, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154469.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154470.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154470.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154470.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154470.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154469.2, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154470.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154471.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154471.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154471.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154471.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154471.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154471.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154472.06, "ph": "X", "cat": "fee", "dur": 5.94, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576154472.04, "ph": "X", "cat": "fee", "dur": 5.98, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154472.02, "ph": "X", "cat": "fee", "dur": 6.02, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154472.0, "ph": "X", "cat": "fee", "dur": 7.0, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154479.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap_external>:1006)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154479.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576154480.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:351)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154479.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "spec_from_file_location (<frozen importlib._bootstrap_external>:696)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154479.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_get_spec (<frozen importlib._bootstrap_external>:1500)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154438.1, "ph": "X", "cat": "fee", "dur": 42.92, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154422.02, "ph": "X", "cat": "fee", "dur": 59.02, "name": "_get_spec (<frozen importlib._bootstrap_external>:1374)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154422.0, "ph": "X", "cat": "fee", "dur": 59.06, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154481.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154481.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154419.04, "ph": "X", "cat": "fee", "dur": 62.96, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154482.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154482.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154482.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "create_module (<frozen importlib._bootstrap_external>:841)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154483.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_new_module (<frozen importlib._bootstrap>:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154483.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154483.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154484.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154484.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576154484.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154484.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154485.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "has_location (<frozen importlib._bootstrap>:406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154485.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154486.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154487.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.endswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576154487.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576154488.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rfind"}, {"pid": 20956, "tid": 2192355, "ts": 253576154488.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154488.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154488.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576154488.02, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154489.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576154489.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154490.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154490.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154491.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154490.04, "ph": "X", "cat": "fee", "dur": 1.02, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154491.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154490.02, "ph": "X", "cat": "fee", "dur": 1.1, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154487.1, "ph": "X", "cat": "fee", "dur": 4.04, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154487.04, "ph": "X", "cat": "fee", "dur": 4.12, "name": "_get_cached (<frozen importlib._bootstrap_external>:491)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154487.02, "ph": "X", "cat": "fee", "dur": 4.16, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154491.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154483.06, "ph": "X", "cat": "fee", "dur": 8.94, "name": "_init_module_attrs (<frozen importlib._bootstrap>:486)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154482.08, "ph": "X", "cat": "fee", "dur": 9.94, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154492.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "get_filename (<frozen importlib._bootstrap_external>:1031)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154492.08, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_check_name_wrapper (<frozen importlib._bootstrap_external>:523)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154493.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576154493.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rfind"}, {"pid": 20956, "tid": 2192355, "ts": 253576154493.14, "ph": "X", "cat": "fee", "dur": 0.06, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154493.22, "ph": "X", "cat": "fee", "dur": 0.78, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154493.12, "ph": "X", "cat": "fee", "dur": 0.9, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576154493.1, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154494.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576154494.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154495.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154495.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154495.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154495.02, "ph": "X", "cat": "fee", "dur": 0.14, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154495.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154495.0, "ph": "X", "cat": "fee", "dur": 0.22, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154493.04, "ph": "X", "cat": "fee", "dur": 2.2, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154496.04, "ph": "X", "cat": "fee", "dur": 1.96, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576154496.02, "ph": "X", "cat": "fee", "dur": 2.0, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154496.0, "ph": "X", "cat": "fee", "dur": 2.04, "name": "path_stats (<frozen importlib._bootstrap_external>:1077)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154499.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576154499.06, "ph": "X", "cat": "fee", "dur": 17.94, "name": "io.open_code"}, {"pid": 20956, "tid": 2192355, "ts": 253576154518.0, "ph": "X", "cat": "fee", "dur": 2.0, "name": "_io.BufferedReader.read"}, {"pid": 20956, "tid": 2192355, "ts": 253576154520.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_io.BufferedReader.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154499.0, "ph": "X", "cat": "fee", "dur": 23.02, "name": "get_data (<frozen importlib._bootstrap_external>:1036)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154523.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576154523.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576154523.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576154523.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154523.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_classify_pyc (<frozen importlib._bootstrap_external>:560)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154524.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576154524.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576154524.04, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154525.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576154525.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576154525.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154524.02, "ph": "X", "cat": "fee", "dur": 1.1, "name": "_validate_timestamp_pyc (<frozen importlib._bootstrap_external>:593)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154525.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154526.0, "ph": "X", "cat": "fee", "dur": 14.0, "name": "marshal.loads"}, {"pid": 20956, "tid": 2192355, "ts": 253576154540.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576154540.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154540.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp._fix_co_filename"}, {"pid": 20956, "tid": 2192355, "ts": 253576154525.18, "ph": "X", "cat": "fee", "dur": 14.96, "name": "_compile_bytecode (<frozen importlib._bootstrap_external>:645)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154492.06, "ph": "X", "cat": "fee", "dur": 48.1, "name": "get_code (<frozen importlib._bootstrap_external>:916)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154543.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576154543.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154542.0, "ph": "X", "cat": "fee", "dur": 1.08, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154545.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "SequentialRunner (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/runners/sequential.py:11)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154545.0, "ph": "X", "cat": "fee", "dur": 6.0, "name": "builtins.__build_class__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154541.04, "ph": "X", "cat": "fee", "dur": 9.98, "name": "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/runners/sequential.py:1)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154541.02, "ph": "X", "cat": "fee", "dur": 10.02, "name": "builtins.exec"}, {"pid": 20956, "tid": 2192355, "ts": 253576154541.0, "ph": "X", "cat": "fee", "dur": 10.06, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154492.04, "ph": "X", "cat": "fee", "dur": 59.96, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154552.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576154552.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154482.02, "ph": "X", "cat": "fee", "dur": 71.0, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154553.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576154553.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154312.14, "ph": "X", "cat": "fee", "dur": 240.98, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154554.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576154554.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154554.02, "ph": "X", "cat": "fee", "dur": 1.0, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154554.0, "ph": "X", "cat": "fee", "dur": 1.04, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154555.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154555.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576154555.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154555.06, "ph": "X", "cat": "fee", "dur": 0.14, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154309.0, "ph": "X", "cat": "fee", "dur": 247.0, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154557.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154557.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154558.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154558.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154558.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154559.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154557.08, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154559.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576154560.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154559.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154557.06, "ph": "X", "cat": "fee", "dur": 3.0, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154560.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576154560.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576154561.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154561.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154561.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154562.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154562.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154562.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154562.1, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154562.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_frozen"}, {"pid": 20956, "tid": 2192355, "ts": 253576154562.18, "ph": "X", "cat": "fee", "dur": 0.06, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154563.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154563.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154563.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154563.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154563.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576154564.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154564.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154564.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576154564.16, "ph": "X", "cat": "fee", "dur": 2.84, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576154564.14, "ph": "X", "cat": "fee", "dur": 2.88, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154568.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154568.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154569.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154568.06, "ph": "X", "cat": "fee", "dur": 1.0, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154569.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154568.04, "ph": "X", "cat": "fee", "dur": 1.08, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154569.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154570.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154570.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154570.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154570.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154570.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154570.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154571.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154571.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154571.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154571.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154571.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154571.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154572.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154572.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154572.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154572.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154572.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154572.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154573.06, "ph": "X", "cat": "fee", "dur": 5.94, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576154573.04, "ph": "X", "cat": "fee", "dur": 5.98, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154573.02, "ph": "X", "cat": "fee", "dur": 6.02, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154573.0, "ph": "X", "cat": "fee", "dur": 6.06, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154580.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap_external>:1006)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154580.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576154580.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "__init__ (<frozen importlib._bootstrap>:351)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154580.04, "ph": "X", "cat": "fee", "dur": 0.98, "name": "spec_from_file_location (<frozen importlib._bootstrap_external>:696)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154579.08, "ph": "X", "cat": "fee", "dur": 1.96, "name": "_get_spec (<frozen importlib._bootstrap_external>:1500)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154564.08, "ph": "X", "cat": "fee", "dur": 16.98, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154563.18, "ph": "X", "cat": "fee", "dur": 17.9, "name": "_get_spec (<frozen importlib._bootstrap_external>:1374)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154563.16, "ph": "X", "cat": "fee", "dur": 17.94, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154582.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154582.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154561.0, "ph": "X", "cat": "fee", "dur": 21.08, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154582.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154583.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154583.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "create_module (<frozen importlib._bootstrap_external>:841)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154583.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_new_module (<frozen importlib._bootstrap>:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154583.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154583.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154584.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154584.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576154584.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154584.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154585.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "has_location (<frozen importlib._bootstrap>:406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154585.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154586.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154587.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.endswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576154587.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576154588.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rfind"}, {"pid": 20956, "tid": 2192355, "ts": 253576154588.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154588.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154587.14, "ph": "X", "cat": "fee", "dur": 0.98, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576154587.12, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154588.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576154589.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154590.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154590.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154590.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154589.08, "ph": "X", "cat": "fee", "dur": 1.04, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154590.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154589.06, "ph": "X", "cat": "fee", "dur": 1.12, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154587.06, "ph": "X", "cat": "fee", "dur": 3.14, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154587.0, "ph": "X", "cat": "fee", "dur": 3.22, "name": "_get_cached (<frozen importlib._bootstrap_external>:491)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154586.06, "ph": "X", "cat": "fee", "dur": 4.18, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154591.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154583.12, "ph": "X", "cat": "fee", "dur": 7.92, "name": "_init_module_attrs (<frozen importlib._bootstrap>:486)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154582.16, "ph": "X", "cat": "fee", "dur": 8.9, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154592.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "get_filename (<frozen importlib._bootstrap_external>:1031)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154591.12, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_check_name_wrapper (<frozen importlib._bootstrap_external>:523)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154592.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576154592.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rfind"}, {"pid": 20956, "tid": 2192355, "ts": 253576154592.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154593.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154592.14, "ph": "X", "cat": "fee", "dur": 0.92, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576154592.12, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154593.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576154593.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154594.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154594.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154594.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154594.02, "ph": "X", "cat": "fee", "dur": 0.14, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154594.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154594.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154592.06, "ph": "X", "cat": "fee", "dur": 2.98, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154595.1, "ph": "X", "cat": "fee", "dur": 1.9, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576154595.08, "ph": "X", "cat": "fee", "dur": 2.92, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154595.06, "ph": "X", "cat": "fee", "dur": 2.96, "name": "path_stats (<frozen importlib._bootstrap_external>:1077)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154598.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576154598.1, "ph": "X", "cat": "fee", "dur": 15.9, "name": "io.open_code"}, {"pid": 20956, "tid": 2192355, "ts": 253576154614.02, "ph": "X", "cat": "fee", "dur": 2.98, "name": "_io.BufferedReader.read"}, {"pid": 20956, "tid": 2192355, "ts": 253576154617.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_io.BufferedReader.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154598.04, "ph": "X", "cat": "fee", "dur": 20.96, "name": "get_data (<frozen importlib._bootstrap_external>:1036)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154619.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576154619.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576154620.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576154619.08, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154619.02, "ph": "X", "cat": "fee", "dur": 1.06, "name": "_classify_pyc (<frozen importlib._bootstrap_external>:560)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154621.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576154621.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576154620.12, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154621.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576154621.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576154621.1, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154620.1, "ph": "X", "cat": "fee", "dur": 1.12, "name": "_validate_timestamp_pyc (<frozen importlib._bootstrap_external>:593)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154621.24, "ph": "X", "cat": "fee", "dur": 0.76, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154622.04, "ph": "X", "cat": "fee", "dur": 30.96, "name": "marshal.loads"}, {"pid": 20956, "tid": 2192355, "ts": 253576154653.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576154653.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154653.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp._fix_co_filename"}, {"pid": 20956, "tid": 2192355, "ts": 253576154622.02, "ph": "X", "cat": "fee", "dur": 31.12, "name": "_compile_bytecode (<frozen importlib._bootstrap_external>:645)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154591.1, "ph": "X", "cat": "fee", "dur": 62.06, "name": "get_code (<frozen importlib._bootstrap_external>:916)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154655.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576154656.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154655.0, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154657.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "SimulationLangFunction (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/runners/simulation.py:10)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154657.0, "ph": "X", "cat": "fee", "dur": 5.0, "name": "builtins.__build_class__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154663.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "property.setter"}, {"pid": 20956, "tid": 2192355, "ts": 253576154663.02, "ph": "X", "cat": "fee", "dur": 1.0, "name": "SimulationDeviceInterface (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/runners/simulation.py:54)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154663.0, "ph": "X", "cat": "fee", "dur": 7.0, "name": "builtins.__build_class__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154670.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "SimulationRunner (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/runners/simulation.py:173)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154670.02, "ph": "X", "cat": "fee", "dur": 3.98, "name": "builtins.__build_class__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154654.04, "ph": "X", "cat": "fee", "dur": 20.96, "name": "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/runners/simulation.py:1)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154654.02, "ph": "X", "cat": "fee", "dur": 21.0, "name": "builtins.exec"}, {"pid": 20956, "tid": 2192355, "ts": 253576154654.0, "ph": "X", "cat": "fee", "dur": 21.04, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154591.08, "ph": "X", "cat": "fee", "dur": 83.98, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154676.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576154676.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154582.1, "ph": "X", "cat": "fee", "dur": 93.98, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154676.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576154677.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154560.12, "ph": "X", "cat": "fee", "dur": 116.92, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154678.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576154678.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154677.08, "ph": "X", "cat": "fee", "dur": 1.0, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154677.06, "ph": "X", "cat": "fee", "dur": 1.04, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154679.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154679.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576154679.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154679.0, "ph": "X", "cat": "fee", "dur": 0.14, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154557.0, "ph": "X", "cat": "fee", "dur": 122.16, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154681.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154682.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154682.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154683.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154682.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154683.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154682.02, "ph": "X", "cat": "fee", "dur": 1.08, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154683.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576154684.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154683.12, "ph": "X", "cat": "fee", "dur": 0.92, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154682.0, "ph": "X", "cat": "fee", "dur": 2.06, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154684.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576154684.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576154685.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154685.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154685.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154686.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154686.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154686.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154686.1, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154686.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_frozen"}, {"pid": 20956, "tid": 2192355, "ts": 253576154686.18, "ph": "X", "cat": "fee", "dur": 0.06, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154687.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154687.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154687.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154687.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154687.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576154688.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154688.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154688.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576154688.16, "ph": "X", "cat": "fee", "dur": 2.84, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576154688.14, "ph": "X", "cat": "fee", "dur": 2.88, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154692.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154693.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154693.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154692.06, "ph": "X", "cat": "fee", "dur": 1.02, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154693.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154692.04, "ph": "X", "cat": "fee", "dur": 1.1, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154694.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154694.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154694.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154694.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154693.16, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154694.24, "ph": "X", "cat": "fee", "dur": 5.76, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576154694.22, "ph": "X", "cat": "fee", "dur": 5.8, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154694.2, "ph": "X", "cat": "fee", "dur": 6.8, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154694.18, "ph": "X", "cat": "fee", "dur": 6.84, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154701.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154701.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154701.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154701.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154701.04, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154702.1, "ph": "X", "cat": "fee", "dur": 1.9, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576154702.08, "ph": "X", "cat": "fee", "dur": 1.94, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154702.06, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154702.04, "ph": "X", "cat": "fee", "dur": 2.02, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154705.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154705.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154705.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154705.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154705.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154705.26, "ph": "X", "cat": "fee", "dur": 1.74, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576154705.24, "ph": "X", "cat": "fee", "dur": 1.78, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154705.22, "ph": "X", "cat": "fee", "dur": 1.82, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154705.2, "ph": "X", "cat": "fee", "dur": 1.86, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154708.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154708.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154708.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154708.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154708.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154708.26, "ph": "X", "cat": "fee", "dur": 6.74, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576154708.24, "ph": "X", "cat": "fee", "dur": 6.78, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154708.22, "ph": "X", "cat": "fee", "dur": 6.82, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154708.2, "ph": "X", "cat": "fee", "dur": 7.8, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154716.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap_external>:1006)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154716.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576154717.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:351)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154716.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "spec_from_file_location (<frozen importlib._bootstrap_external>:696)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154716.02, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_get_spec (<frozen importlib._bootstrap_external>:1500)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154688.08, "ph": "X", "cat": "fee", "dur": 29.92, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154687.18, "ph": "X", "cat": "fee", "dur": 30.84, "name": "_get_spec (<frozen importlib._bootstrap_external>:1374)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154687.16, "ph": "X", "cat": "fee", "dur": 30.88, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154718.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154718.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154685.0, "ph": "X", "cat": "fee", "dur": 33.14, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154719.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154719.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154719.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "create_module (<frozen importlib._bootstrap_external>:841)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154719.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "_new_module (<frozen importlib._bootstrap>:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154720.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154720.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154720.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154720.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154721.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154721.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "has_location (<frozen importlib._bootstrap>:406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154722.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154722.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154723.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.endswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576154724.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576154724.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rfind"}, {"pid": 20956, "tid": 2192355, "ts": 253576154724.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154724.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154724.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576154724.04, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154725.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576154725.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154726.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154726.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154727.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154726.04, "ph": "X", "cat": "fee", "dur": 1.0, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154727.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154726.02, "ph": "X", "cat": "fee", "dur": 1.08, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154723.1, "ph": "X", "cat": "fee", "dur": 4.02, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154723.04, "ph": "X", "cat": "fee", "dur": 4.1, "name": "_get_cached (<frozen importlib._bootstrap_external>:491)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154723.02, "ph": "X", "cat": "fee", "dur": 4.14, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154727.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154720.02, "ph": "X", "cat": "fee", "dur": 8.0, "name": "_init_module_attrs (<frozen importlib._bootstrap>:486)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154719.06, "ph": "X", "cat": "fee", "dur": 8.98, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154728.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "get_filename (<frozen importlib._bootstrap_external>:1031)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154728.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "_check_name_wrapper (<frozen importlib._bootstrap_external>:523)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154729.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576154729.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rfind"}, {"pid": 20956, "tid": 2192355, "ts": 253576154729.12, "ph": "X", "cat": "fee", "dur": 0.06, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154729.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154729.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576154729.08, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154730.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576154730.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154731.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154731.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154731.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154731.0, "ph": "X", "cat": "fee", "dur": 0.14, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154731.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154730.12, "ph": "X", "cat": "fee", "dur": 1.08, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154729.02, "ph": "X", "cat": "fee", "dur": 2.2, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154732.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576154732.0, "ph": "X", "cat": "fee", "dur": 2.02, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154731.24, "ph": "X", "cat": "fee", "dur": 2.8, "name": "path_stats (<frozen importlib._bootstrap_external>:1077)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154735.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576154735.06, "ph": "X", "cat": "fee", "dur": 19.94, "name": "io.open_code"}, {"pid": 20956, "tid": 2192355, "ts": 253576154755.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_io.BufferedReader.read"}, {"pid": 20956, "tid": 2192355, "ts": 253576154757.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_io.BufferedReader.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154735.0, "ph": "X", "cat": "fee", "dur": 24.02, "name": "get_data (<frozen importlib._bootstrap_external>:1036)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154759.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576154760.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576154760.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576154760.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154759.04, "ph": "X", "cat": "fee", "dur": 1.08, "name": "_classify_pyc (<frozen importlib._bootstrap_external>:560)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154761.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576154761.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576154761.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154761.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576154761.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576154761.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154761.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_validate_timestamp_pyc (<frozen importlib._bootstrap_external>:593)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154762.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154762.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "marshal.loads"}, {"pid": 20956, "tid": 2192355, "ts": 253576154763.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576154764.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154764.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp._fix_co_filename"}, {"pid": 20956, "tid": 2192355, "ts": 253576154762.08, "ph": "X", "cat": "fee", "dur": 2.0, "name": "_compile_bytecode (<frozen importlib._bootstrap_external>:645)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154728.08, "ph": "X", "cat": "fee", "dur": 36.02, "name": "get_code (<frozen importlib._bootstrap_external>:916)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154765.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/__init__.py:1)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154764.14, "ph": "X", "cat": "fee", "dur": 0.9, "name": "builtins.exec"}, {"pid": 20956, "tid": 2192355, "ts": 253576154764.12, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154728.06, "ph": "X", "cat": "fee", "dur": 37.02, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154765.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576154766.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154719.0, "ph": "X", "cat": "fee", "dur": 47.04, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154766.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576154766.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154684.12, "ph": "X", "cat": "fee", "dur": 82.02, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154767.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576154767.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154767.02, "ph": "X", "cat": "fee", "dur": 1.0, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154767.0, "ph": "X", "cat": "fee", "dur": 1.04, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154768.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154768.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576154768.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154768.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154681.0, "ph": "X", "cat": "fee", "dur": 88.02, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154769.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576154769.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154770.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.format"}, {"pid": 20956, "tid": 2192355, "ts": 253576154771.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154772.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154772.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154773.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154772.1, "ph": "X", "cat": "fee", "dur": 0.94, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154773.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154772.04, "ph": "X", "cat": "fee", "dur": 1.06, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154773.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576154774.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154773.12, "ph": "X", "cat": "fee", "dur": 0.92, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154772.02, "ph": "X", "cat": "fee", "dur": 2.04, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154774.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576154774.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576154775.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154775.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154776.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154776.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154776.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154776.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154776.12, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154776.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_frozen"}, {"pid": 20956, "tid": 2192355, "ts": 253576154776.2, "ph": "X", "cat": "fee", "dur": 0.06, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154777.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154777.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154777.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154777.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154777.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576154778.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576154779.02, "ph": "X", "cat": "fee", "dur": 4.98, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576154779.0, "ph": "X", "cat": "fee", "dur": 5.02, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154778.02, "ph": "X", "cat": "fee", "dur": 6.98, "name": "__init__ (<frozen zipimport>:63)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154786.0, "ph": "X", "cat": "fee", "dur": 2.0, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154785.06, "ph": "X", "cat": "fee", "dur": 2.96, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154785.04, "ph": "X", "cat": "fee", "dur": 3.0, "name": "_path_isdir (<frozen importlib._bootstrap_external>:159)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154789.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:1472)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154790.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:1472)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154790.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:1472)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154790.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:1472)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154789.02, "ph": "X", "cat": "fee", "dur": 1.1, "name": "list.extend"}, {"pid": 20956, "tid": 2192355, "ts": 253576154790.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "<genexpr> (<frozen importlib._bootstrap_external>:1472)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154791.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:1472)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154790.14, "ph": "X", "cat": "fee", "dur": 0.92, "name": "list.extend"}, {"pid": 20956, "tid": 2192355, "ts": 253576154791.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:1472)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154791.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:1472)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154791.08, "ph": "X", "cat": "fee", "dur": 0.1, "name": "list.extend"}, {"pid": 20956, "tid": 2192355, "ts": 253576154792.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576154792.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "_path_isabs (<frozen importlib._bootstrap_external>:175)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154789.0, "ph": "X", "cat": "fee", "dur": 3.08, "name": "__init__ (<frozen importlib._bootstrap_external>:1466)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154785.02, "ph": "X", "cat": "fee", "dur": 7.08, "name": "path_hook_for_FileFinder (<frozen importlib._bootstrap_external>:1597)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154778.0, "ph": "X", "cat": "fee", "dur": 15.0, "name": "_path_hooks (<frozen importlib._bootstrap_external>:1324)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154777.24, "ph": "X", "cat": "fee", "dur": 15.78, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154793.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154793.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576154794.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576154794.0, "ph": "X", "cat": "fee", "dur": 2.02, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154796.06, "ph": "X", "cat": "fee", "dur": 31.94, "name": "posix.listdir"}, {"pid": 20956, "tid": 2192355, "ts": 253576154828.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576154830.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576154831.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253576154831.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253576154831.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253576154832.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253576154832.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253576154832.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253576154832.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253576154832.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253576154832.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253576154832.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253576154832.28, "ph": "X", "cat": "fee", "dur": 0.72, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253576154833.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253576154833.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253576154833.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253576154833.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253576154833.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253576154833.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253576154833.26, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253576154833.3, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253576154834.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253576154834.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253576154834.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253576154834.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253576154834.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253576154834.2, "ph": "X", "cat": "fee", "dur": 0.8, "name": "str.lower"}, {"pid": 20956, "tid": 2192355, "ts": 253576154831.02, "ph": "X", "cat": "fee", "dur": 4.0, "name": "<setcomp> (<frozen importlib._bootstrap_external>:1585)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154796.04, "ph": "X", "cat": "fee", "dur": 39.0, "name": "_fill_cache (<frozen importlib._bootstrap_external>:1556)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154835.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154836.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154836.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154836.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154836.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154836.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154837.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154837.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154837.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154837.1, "ph": "X", "cat": "fee", "dur": 0.92, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154838.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154837.08, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154838.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154838.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154839.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154838.16, "ph": "X", "cat": "fee", "dur": 0.9, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154839.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154838.14, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154839.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154839.22, "ph": "X", "cat": "fee", "dur": 0.78, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154840.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154839.2, "ph": "X", "cat": "fee", "dur": 0.86, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154840.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154839.18, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154840.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154840.24, "ph": "X", "cat": "fee", "dur": 6.76, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576154840.22, "ph": "X", "cat": "fee", "dur": 6.8, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154840.2, "ph": "X", "cat": "fee", "dur": 6.84, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154840.18, "ph": "X", "cat": "fee", "dur": 6.88, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154847.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "__init__ (<frozen importlib._bootstrap_external>:1006)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154848.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576154848.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:351)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154848.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "spec_from_file_location (<frozen importlib._bootstrap_external>:696)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154847.08, "ph": "X", "cat": "fee", "dur": 1.94, "name": "_get_spec (<frozen importlib._bootstrap_external>:1500)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154793.08, "ph": "X", "cat": "fee", "dur": 55.96, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154777.18, "ph": "X", "cat": "fee", "dur": 71.88, "name": "_get_spec (<frozen importlib._bootstrap_external>:1374)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154777.16, "ph": "X", "cat": "fee", "dur": 71.92, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154849.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154849.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154775.02, "ph": "X", "cat": "fee", "dur": 75.0, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154850.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154850.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154851.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "create_module (<frozen importlib._bootstrap_external>:841)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154851.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_new_module (<frozen importlib._bootstrap>:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154851.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154851.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154852.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154852.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576154852.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154852.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154853.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "has_location (<frozen importlib._bootstrap>:406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154853.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154854.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154855.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.endswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576154855.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576154855.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154856.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154855.14, "ph": "X", "cat": "fee", "dur": 0.92, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576154855.12, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154856.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576154857.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154857.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154857.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154858.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154857.06, "ph": "X", "cat": "fee", "dur": 1.0, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154858.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154857.04, "ph": "X", "cat": "fee", "dur": 1.08, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154855.06, "ph": "X", "cat": "fee", "dur": 3.08, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154855.0, "ph": "X", "cat": "fee", "dur": 3.16, "name": "_get_cached (<frozen importlib._bootstrap_external>:491)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154854.06, "ph": "X", "cat": "fee", "dur": 4.12, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154858.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154851.08, "ph": "X", "cat": "fee", "dur": 7.16, "name": "_init_module_attrs (<frozen importlib._bootstrap>:486)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154850.1, "ph": "X", "cat": "fee", "dur": 8.9, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154859.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "get_filename (<frozen importlib._bootstrap_external>:1031)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154859.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "_check_name_wrapper (<frozen importlib._bootstrap_external>:523)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154860.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576154860.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rfind"}, {"pid": 20956, "tid": 2192355, "ts": 253576154860.1, "ph": "X", "cat": "fee", "dur": 0.06, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154860.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154860.08, "ph": "X", "cat": "fee", "dur": 0.14, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576154860.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154861.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576154861.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154861.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154862.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154862.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154861.12, "ph": "X", "cat": "fee", "dur": 0.98, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154862.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154861.1, "ph": "X", "cat": "fee", "dur": 1.06, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154860.0, "ph": "X", "cat": "fee", "dur": 2.18, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154862.24, "ph": "X", "cat": "fee", "dur": 2.76, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576154862.22, "ph": "X", "cat": "fee", "dur": 2.8, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154862.2, "ph": "X", "cat": "fee", "dur": 2.84, "name": "path_stats (<frozen importlib._bootstrap_external>:1077)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154865.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576154866.0, "ph": "X", "cat": "fee", "dur": 16.0, "name": "io.open_code"}, {"pid": 20956, "tid": 2192355, "ts": 253576154883.0, "ph": "X", "cat": "fee", "dur": 2.0, "name": "_io.BufferedReader.read"}, {"pid": 20956, "tid": 2192355, "ts": 253576154885.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_io.BufferedReader.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154865.06, "ph": "X", "cat": "fee", "dur": 21.96, "name": "get_data (<frozen importlib._bootstrap_external>:1036)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154888.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576154888.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576154888.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576154888.04, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154887.04, "ph": "X", "cat": "fee", "dur": 1.12, "name": "_classify_pyc (<frozen importlib._bootstrap_external>:560)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154889.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576154889.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576154889.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154889.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576154889.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576154889.14, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154889.0, "ph": "X", "cat": "fee", "dur": 0.26, "name": "_validate_timestamp_pyc (<frozen importlib._bootstrap_external>:593)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154890.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154890.06, "ph": "X", "cat": "fee", "dur": 4.94, "name": "marshal.loads"}, {"pid": 20956, "tid": 2192355, "ts": 253576154895.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576154896.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154896.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp._fix_co_filename"}, {"pid": 20956, "tid": 2192355, "ts": 253576154890.04, "ph": "X", "cat": "fee", "dur": 6.06, "name": "_compile_bytecode (<frozen importlib._bootstrap_external>:645)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154859.04, "ph": "X", "cat": "fee", "dur": 37.08, "name": "get_code (<frozen importlib._bootstrap_external>:916)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154898.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154898.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154898.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154899.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576154899.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154899.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154900.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576154900.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154900.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154898.0, "ph": "X", "cat": "fee", "dur": 2.14, "name": "_lock_unlock_module (<frozen importlib._bootstrap>:203)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154901.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576154901.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154901.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154897.02, "ph": "X", "cat": "fee", "dur": 4.1, "name": "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/brute_force.py:1)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154897.0, "ph": "X", "cat": "fee", "dur": 4.14, "name": "builtins.exec"}, {"pid": 20956, "tid": 2192355, "ts": 253576154896.14, "ph": "X", "cat": "fee", "dur": 5.02, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154859.02, "ph": "X", "cat": "fee", "dur": 42.98, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154902.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576154902.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154850.04, "ph": "X", "cat": "fee", "dur": 52.06, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154903.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576154903.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154774.12, "ph": "X", "cat": "fee", "dur": 128.96, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154904.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576154904.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154904.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154903.1, "ph": "X", "cat": "fee", "dur": 1.02, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154904.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154904.2, "ph": "X", "cat": "fee", "dur": 0.8, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576154905.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154904.14, "ph": "X", "cat": "fee", "dur": 0.92, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154771.02, "ph": "X", "cat": "fee", "dur": 134.06, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154905.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154906.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154905.12, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154906.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576154906.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154906.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154907.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576154907.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154907.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154905.1, "ph": "X", "cat": "fee", "dur": 2.04, "name": "_lock_unlock_module (<frozen importlib._bootstrap>:203)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154771.0, "ph": "X", "cat": "fee", "dur": 136.16, "name": "builtins.__import__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154770.06, "ph": "X", "cat": "fee", "dur": 137.12, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154908.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576154908.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154908.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "str.format"}, {"pid": 20956, "tid": 2192355, "ts": 253576154910.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154910.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154911.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154911.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154910.12, "ph": "X", "cat": "fee", "dur": 0.96, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154911.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154910.06, "ph": "X", "cat": "fee", "dur": 1.08, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154912.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576154912.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154912.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154910.04, "ph": "X", "cat": "fee", "dur": 2.08, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154912.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576154913.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576154913.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154913.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154914.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154914.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154914.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154914.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154914.12, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154914.22, "ph": "X", "cat": "fee", "dur": 0.78, "name": "_imp.is_frozen"}, {"pid": 20956, "tid": 2192355, "ts": 253576154914.2, "ph": "X", "cat": "fee", "dur": 0.82, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154915.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154915.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154915.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154915.12, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154915.24, "ph": "X", "cat": "fee", "dur": 0.76, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576154916.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154916.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154916.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576154916.18, "ph": "X", "cat": "fee", "dur": 2.82, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576154916.16, "ph": "X", "cat": "fee", "dur": 2.86, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154919.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154920.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154920.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154920.04, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154921.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154920.02, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154921.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154921.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154922.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154921.12, "ph": "X", "cat": "fee", "dur": 0.92, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154922.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154921.1, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154922.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154922.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154923.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154922.18, "ph": "X", "cat": "fee", "dur": 0.86, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154923.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154922.16, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154923.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154923.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154924.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154923.18, "ph": "X", "cat": "fee", "dur": 0.86, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154924.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154923.16, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154924.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154924.22, "ph": "X", "cat": "fee", "dur": 6.78, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576154924.2, "ph": "X", "cat": "fee", "dur": 6.82, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154924.18, "ph": "X", "cat": "fee", "dur": 6.86, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154924.16, "ph": "X", "cat": "fee", "dur": 6.9, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154931.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "__init__ (<frozen importlib._bootstrap_external>:1006)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154932.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576154932.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:351)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154932.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "spec_from_file_location (<frozen importlib._bootstrap_external>:696)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154931.08, "ph": "X", "cat": "fee", "dur": 1.94, "name": "_get_spec (<frozen importlib._bootstrap_external>:1500)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154916.1, "ph": "X", "cat": "fee", "dur": 16.94, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154915.22, "ph": "X", "cat": "fee", "dur": 17.84, "name": "_get_spec (<frozen importlib._bootstrap_external>:1374)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154915.2, "ph": "X", "cat": "fee", "dur": 17.88, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154933.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154933.1, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154913.04, "ph": "X", "cat": "fee", "dur": 20.96, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154934.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154934.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154934.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "create_module (<frozen importlib._bootstrap_external>:841)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154934.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "_new_module (<frozen importlib._bootstrap>:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154935.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154935.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154935.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154936.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576154935.16, "ph": "X", "cat": "fee", "dur": 0.88, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154936.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154937.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "has_location (<frozen importlib._bootstrap>:406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154937.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154937.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154938.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.endswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576154939.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576154939.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154939.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154939.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576154939.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154940.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576154940.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154941.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154941.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154941.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154941.02, "ph": "X", "cat": "fee", "dur": 0.14, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154941.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154941.0, "ph": "X", "cat": "fee", "dur": 0.22, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154938.1, "ph": "X", "cat": "fee", "dur": 3.9, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154938.04, "ph": "X", "cat": "fee", "dur": 3.98, "name": "_get_cached (<frozen importlib._bootstrap_external>:491)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154938.02, "ph": "X", "cat": "fee", "dur": 4.02, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154942.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154935.02, "ph": "X", "cat": "fee", "dur": 7.08, "name": "_init_module_attrs (<frozen importlib._bootstrap>:486)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154934.08, "ph": "X", "cat": "fee", "dur": 8.04, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154943.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "get_filename (<frozen importlib._bootstrap_external>:1031)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154943.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "_check_name_wrapper (<frozen importlib._bootstrap_external>:523)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154943.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576154944.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rfind"}, {"pid": 20956, "tid": 2192355, "ts": 253576154943.2, "ph": "X", "cat": "fee", "dur": 0.84, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154944.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154943.18, "ph": "X", "cat": "fee", "dur": 0.92, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576154943.16, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154944.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576154944.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154945.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154945.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154945.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576154945.02, "ph": "X", "cat": "fee", "dur": 0.14, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154945.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576154945.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154943.1, "ph": "X", "cat": "fee", "dur": 2.92, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154946.08, "ph": "X", "cat": "fee", "dur": 1.92, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576154946.06, "ph": "X", "cat": "fee", "dur": 1.96, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154946.04, "ph": "X", "cat": "fee", "dur": 2.0, "name": "path_stats (<frozen importlib._bootstrap_external>:1077)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154949.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576154949.06, "ph": "X", "cat": "fee", "dur": 20.94, "name": "io.open_code"}, {"pid": 20956, "tid": 2192355, "ts": 253576154970.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_io.BufferedReader.read"}, {"pid": 20956, "tid": 2192355, "ts": 253576154972.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_io.BufferedReader.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154949.0, "ph": "X", "cat": "fee", "dur": 25.0, "name": "get_data (<frozen importlib._bootstrap_external>:1036)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154974.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576154974.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576154975.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576154974.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154974.02, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_classify_pyc (<frozen importlib._bootstrap_external>:560)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154975.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576154975.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576154975.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154976.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576154976.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576154976.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154975.08, "ph": "X", "cat": "fee", "dur": 1.06, "name": "_validate_timestamp_pyc (<frozen importlib._bootstrap_external>:593)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154976.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154977.0, "ph": "X", "cat": "fee", "dur": 6.0, "name": "marshal.loads"}, {"pid": 20956, "tid": 2192355, "ts": 253576154983.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576154983.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154984.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp._fix_co_filename"}, {"pid": 20956, "tid": 2192355, "ts": 253576154976.2, "ph": "X", "cat": "fee", "dur": 7.84, "name": "_compile_bytecode (<frozen importlib._bootstrap_external>:645)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154943.0, "ph": "X", "cat": "fee", "dur": 41.06, "name": "get_code (<frozen importlib._bootstrap_external>:916)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154986.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154986.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154986.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154987.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576154987.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154986.14, "ph": "X", "cat": "fee", "dur": 0.94, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154987.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576154988.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154987.1, "ph": "X", "cat": "fee", "dur": 0.94, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154986.0, "ph": "X", "cat": "fee", "dur": 2.06, "name": "_lock_unlock_module (<frozen importlib._bootstrap>:203)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154988.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576154988.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154988.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154985.0, "ph": "X", "cat": "fee", "dur": 4.02, "name": "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/random_sample.py:1)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154984.1, "ph": "X", "cat": "fee", "dur": 4.94, "name": "builtins.exec"}, {"pid": 20956, "tid": 2192355, "ts": 253576154984.08, "ph": "X", "cat": "fee", "dur": 4.98, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154942.14, "ph": "X", "cat": "fee", "dur": 46.94, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154989.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576154990.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154934.02, "ph": "X", "cat": "fee", "dur": 56.02, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154990.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576154990.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154912.18, "ph": "X", "cat": "fee", "dur": 78.84, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154991.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576154991.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154991.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154991.04, "ph": "X", "cat": "fee", "dur": 0.98, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154992.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154992.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576154992.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154992.04, "ph": "X", "cat": "fee", "dur": 0.14, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154909.06, "ph": "X", "cat": "fee", "dur": 83.14, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154993.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154993.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154993.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154993.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576154994.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154993.14, "ph": "X", "cat": "fee", "dur": 0.9, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154994.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576154994.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154994.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154993.0, "ph": "X", "cat": "fee", "dur": 1.18, "name": "_lock_unlock_module (<frozen importlib._bootstrap>:203)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154909.04, "ph": "X", "cat": "fee", "dur": 85.16, "name": "builtins.__import__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154909.02, "ph": "X", "cat": "fee", "dur": 85.2, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154995.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576154995.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154995.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "str.format"}, {"pid": 20956, "tid": 2192355, "ts": 253576154997.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154997.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154997.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154998.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154997.12, "ph": "X", "cat": "fee", "dur": 0.94, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154998.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576154997.06, "ph": "X", "cat": "fee", "dur": 1.06, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154999.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576154999.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154998.14, "ph": "X", "cat": "fee", "dur": 0.94, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154997.04, "ph": "X", "cat": "fee", "dur": 2.06, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154999.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576154999.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576155000.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576155000.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155001.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155001.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576155001.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155001.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576155001.12, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155001.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_frozen"}, {"pid": 20956, "tid": 2192355, "ts": 253576155001.2, "ph": "X", "cat": "fee", "dur": 0.06, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155002.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576155002.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155002.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576155002.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155002.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576155003.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155003.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576155003.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576155003.16, "ph": "X", "cat": "fee", "dur": 2.84, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576155003.14, "ph": "X", "cat": "fee", "dur": 2.88, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155006.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155007.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576155007.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576155007.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155008.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576155007.02, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155008.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155008.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576155009.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576155008.14, "ph": "X", "cat": "fee", "dur": 0.92, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155009.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576155008.12, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155009.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155010.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576155010.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576155009.2, "ph": "X", "cat": "fee", "dur": 0.88, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155010.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576155009.18, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155010.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155011.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576155011.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576155010.22, "ph": "X", "cat": "fee", "dur": 0.86, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155011.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576155010.2, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155011.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155011.26, "ph": "X", "cat": "fee", "dur": 6.74, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576155011.24, "ph": "X", "cat": "fee", "dur": 6.78, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155011.22, "ph": "X", "cat": "fee", "dur": 6.82, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155011.2, "ph": "X", "cat": "fee", "dur": 6.86, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155019.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap_external>:1006)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155019.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576155019.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "__init__ (<frozen importlib._bootstrap>:351)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155019.06, "ph": "X", "cat": "fee", "dur": 0.96, "name": "spec_from_file_location (<frozen importlib._bootstrap_external>:696)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155019.0, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_get_spec (<frozen importlib._bootstrap_external>:1500)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155003.08, "ph": "X", "cat": "fee", "dur": 16.98, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155002.18, "ph": "X", "cat": "fee", "dur": 17.9, "name": "_get_spec (<frozen importlib._bootstrap_external>:1374)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155002.16, "ph": "X", "cat": "fee", "dur": 17.94, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155021.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576155021.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155000.02, "ph": "X", "cat": "fee", "dur": 21.06, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155021.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576155021.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576155022.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "create_module (<frozen importlib._bootstrap_external>:841)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155022.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_new_module (<frozen importlib._bootstrap>:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155022.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576155022.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576155023.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576155023.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576155023.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155023.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576155024.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "has_location (<frozen importlib._bootstrap>:406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155024.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576155025.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576155026.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.endswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576155026.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576155026.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155027.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155026.12, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576155026.1, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155027.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576155027.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576155028.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576155028.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576155028.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576155028.02, "ph": "X", "cat": "fee", "dur": 0.14, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155028.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576155028.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155026.04, "ph": "X", "cat": "fee", "dur": 3.0, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155025.08, "ph": "X", "cat": "fee", "dur": 3.98, "name": "_get_cached (<frozen importlib._bootstrap_external>:491)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155025.06, "ph": "X", "cat": "fee", "dur": 4.02, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155029.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155022.1, "ph": "X", "cat": "fee", "dur": 7.04, "name": "_init_module_attrs (<frozen importlib._bootstrap>:486)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155021.16, "ph": "X", "cat": "fee", "dur": 8.0, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155030.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "get_filename (<frozen importlib._bootstrap_external>:1031)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155030.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "_check_name_wrapper (<frozen importlib._bootstrap_external>:523)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155030.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576155031.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rfind"}, {"pid": 20956, "tid": 2192355, "ts": 253576155031.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155031.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155031.0, "ph": "X", "cat": "fee", "dur": 0.14, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576155030.18, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155031.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576155031.22, "ph": "X", "cat": "fee", "dur": 0.78, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576155032.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576155032.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576155032.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576155032.04, "ph": "X", "cat": "fee", "dur": 0.14, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155032.2, "ph": "X", "cat": "fee", "dur": 0.8, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576155032.02, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155030.12, "ph": "X", "cat": "fee", "dur": 2.92, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155033.1, "ph": "X", "cat": "fee", "dur": 1.9, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576155033.08, "ph": "X", "cat": "fee", "dur": 1.94, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155033.06, "ph": "X", "cat": "fee", "dur": 2.94, "name": "path_stats (<frozen importlib._bootstrap_external>:1077)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155036.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576155036.08, "ph": "X", "cat": "fee", "dur": 16.92, "name": "io.open_code"}, {"pid": 20956, "tid": 2192355, "ts": 253576155053.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_io.BufferedReader.read"}, {"pid": 20956, "tid": 2192355, "ts": 253576155055.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_io.BufferedReader.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576155036.02, "ph": "X", "cat": "fee", "dur": 20.0, "name": "get_data (<frozen importlib._bootstrap_external>:1036)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155057.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576155057.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576155057.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576155057.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155057.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_classify_pyc (<frozen importlib._bootstrap_external>:560)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155058.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576155058.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576155058.04, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155058.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576155059.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576155058.16, "ph": "X", "cat": "fee", "dur": 0.9, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155058.02, "ph": "X", "cat": "fee", "dur": 1.06, "name": "_validate_timestamp_pyc (<frozen importlib._bootstrap_external>:593)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155059.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155059.16, "ph": "X", "cat": "fee", "dur": 8.84, "name": "marshal.loads"}, {"pid": 20956, "tid": 2192355, "ts": 253576155068.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576155068.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155068.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp._fix_co_filename"}, {"pid": 20956, "tid": 2192355, "ts": 253576155059.14, "ph": "X", "cat": "fee", "dur": 9.0, "name": "_compile_bytecode (<frozen importlib._bootstrap_external>:645)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155030.02, "ph": "X", "cat": "fee", "dur": 38.14, "name": "get_code (<frozen importlib._bootstrap_external>:916)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155070.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155071.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576155071.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155073.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576155071.04, "ph": "X", "cat": "fee", "dur": 2.0, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155073.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576155073.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576155073.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155071.02, "ph": "X", "cat": "fee", "dur": 2.98, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155074.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576155074.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576155075.02, "ph": "X", "cat": "fee", "dur": 3291.98, "name": "builtins.__import__"}, {"pid": 20956, "tid": 2192355, "ts": 253576155075.0, "ph": "X", "cat": "fee", "dur": 3292.02, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576158368.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576158368.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253576158369.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576158369.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576158369.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253576158370.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576158370.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576158370.08, "ph": "X", "cat": "fee", "dur": 20.92, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576158391.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576158368.0, "ph": "X", "cat": "fee", "dur": 23.06, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253576158392.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576158392.04, "ph": "X", "cat": "fee", "dur": 7.96, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253576158400.02, "ph": "X", "cat": "fee", "dur": 42697.98, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201099.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576201099.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576158391.08, "ph": "X", "cat": "fee", "dur": 42708.92, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201100.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201100.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576155074.06, "ph": "X", "cat": "fee", "dur": 46026.04, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201101.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576201101.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201101.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201101.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201102.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201102.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576201102.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201102.02, "ph": "X", "cat": "fee", "dur": 0.14, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155070.0, "ph": "X", "cat": "fee", "dur": 46033.0, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201103.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576201103.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201103.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201104.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201105.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201105.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201106.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201105.04, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201107.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576201107.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201107.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201105.02, "ph": "X", "cat": "fee", "dur": 2.1, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201107.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576201108.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201109.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201110.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201110.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201110.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201110.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201111.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201111.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201111.08, "ph": "X", "cat": "fee", "dur": 28.92, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201140.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201109.0, "ph": "X", "cat": "fee", "dur": 32.02, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201141.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201141.1, "ph": "X", "cat": "fee", "dur": 7.9, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201149.02, "ph": "X", "cat": "fee", "dur": 69.98, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201219.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576201220.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201141.04, "ph": "X", "cat": "fee", "dur": 79.02, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201220.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201221.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201108.02, "ph": "X", "cat": "fee", "dur": 113.02, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201221.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576201222.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201221.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201221.06, "ph": "X", "cat": "fee", "dur": 1.0, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201222.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201222.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576201223.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201222.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201104.0, "ph": "X", "cat": "fee", "dur": 119.06, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155069.04, "ph": "X", "cat": "fee", "dur": 46154.96, "name": "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/diff_evo.py:1)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155069.02, "ph": "X", "cat": "fee", "dur": 46155.0, "name": "builtins.exec"}, {"pid": 20956, "tid": 2192355, "ts": 253576155069.0, "ph": "X", "cat": "fee", "dur": 46155.04, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155030.0, "ph": "X", "cat": "fee", "dur": 46194.06, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201225.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576201225.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576155021.1, "ph": "X", "cat": "fee", "dur": 46203.98, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201225.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201226.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576154999.16, "ph": "X", "cat": "fee", "dur": 46226.88, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201227.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576201227.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201227.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201226.06, "ph": "X", "cat": "fee", "dur": 1.06, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201227.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201228.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576201228.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201227.14, "ph": "X", "cat": "fee", "dur": 0.94, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154996.06, "ph": "X", "cat": "fee", "dur": 46232.04, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201229.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201229.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201229.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201229.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576201230.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201229.14, "ph": "X", "cat": "fee", "dur": 0.9, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201230.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576201230.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201230.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201229.0, "ph": "X", "cat": "fee", "dur": 2.0, "name": "_lock_unlock_module (<frozen importlib._bootstrap>:203)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154996.04, "ph": "X", "cat": "fee", "dur": 46234.98, "name": "builtins.__import__"}, {"pid": 20956, "tid": 2192355, "ts": 253576154996.02, "ph": "X", "cat": "fee", "dur": 46235.02, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201231.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576201231.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201231.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576201231.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201232.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.format"}, {"pid": 20956, "tid": 2192355, "ts": 253576201234.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201234.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201235.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201235.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201234.12, "ph": "X", "cat": "fee", "dur": 0.96, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201235.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201234.06, "ph": "X", "cat": "fee", "dur": 1.94, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201236.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576201236.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201236.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201234.04, "ph": "X", "cat": "fee", "dur": 2.1, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201236.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576201237.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201238.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201238.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201238.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201238.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201238.12, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201238.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201238.2, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201239.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_frozen"}, {"pid": 20956, "tid": 2192355, "ts": 253576201239.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201239.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201239.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201239.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201239.16, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201240.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576201240.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201240.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201241.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201241.08, "ph": "X", "cat": "fee", "dur": 2.92, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576201241.06, "ph": "X", "cat": "fee", "dur": 2.96, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201245.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201246.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201246.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201245.06, "ph": "X", "cat": "fee", "dur": 1.02, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201246.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201245.04, "ph": "X", "cat": "fee", "dur": 1.1, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201246.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201247.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201247.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201247.04, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201247.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201247.02, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201248.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201248.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201248.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201248.1, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201248.22, "ph": "X", "cat": "fee", "dur": 0.78, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201248.08, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201249.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201250.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201250.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201249.1, "ph": "X", "cat": "fee", "dur": 0.98, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201250.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201249.08, "ph": "X", "cat": "fee", "dur": 1.06, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201250.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201251.0, "ph": "X", "cat": "fee", "dur": 10.0, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576201250.24, "ph": "X", "cat": "fee", "dur": 10.78, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201250.22, "ph": "X", "cat": "fee", "dur": 10.82, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201250.2, "ph": "X", "cat": "fee", "dur": 10.86, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201262.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap_external>:1006)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201262.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576201262.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "__init__ (<frozen importlib._bootstrap>:351)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201262.06, "ph": "X", "cat": "fee", "dur": 0.96, "name": "spec_from_file_location (<frozen importlib._bootstrap_external>:696)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201262.0, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_get_spec (<frozen importlib._bootstrap_external>:1500)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201241.0, "ph": "X", "cat": "fee", "dur": 22.06, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201240.02, "ph": "X", "cat": "fee", "dur": 23.06, "name": "_get_spec (<frozen importlib._bootstrap_external>:1374)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201240.0, "ph": "X", "cat": "fee", "dur": 24.0, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201264.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201264.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201237.08, "ph": "X", "cat": "fee", "dur": 27.02, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201264.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201265.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201265.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "create_module (<frozen importlib._bootstrap_external>:841)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201265.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_new_module (<frozen importlib._bootstrap>:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201266.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201266.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201266.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201266.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201266.14, "ph": "X", "cat": "fee", "dur": 0.88, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201267.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201268.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "has_location (<frozen importlib._bootstrap>:406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201268.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201268.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201269.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "str.endswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576201270.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576201270.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201271.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201270.1, "ph": "X", "cat": "fee", "dur": 0.96, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576201270.08, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201271.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201272.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201272.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201273.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201273.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201272.06, "ph": "X", "cat": "fee", "dur": 1.04, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201273.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201272.04, "ph": "X", "cat": "fee", "dur": 1.12, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201270.02, "ph": "X", "cat": "fee", "dur": 3.16, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201269.04, "ph": "X", "cat": "fee", "dur": 4.16, "name": "_get_cached (<frozen importlib._bootstrap_external>:491)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201269.02, "ph": "X", "cat": "fee", "dur": 4.2, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201274.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201266.0, "ph": "X", "cat": "fee", "dur": 8.04, "name": "_init_module_attrs (<frozen importlib._bootstrap>:486)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201265.02, "ph": "X", "cat": "fee", "dur": 9.04, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201275.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "get_filename (<frozen importlib._bootstrap_external>:1031)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201274.12, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_check_name_wrapper (<frozen importlib._bootstrap_external>:523)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201275.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576201275.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "str.rfind"}, {"pid": 20956, "tid": 2192355, "ts": 253576201275.16, "ph": "X", "cat": "fee", "dur": 0.86, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201276.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201275.14, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576201275.12, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201276.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201276.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201277.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201277.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201277.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201277.02, "ph": "X", "cat": "fee", "dur": 0.14, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201277.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201277.0, "ph": "X", "cat": "fee", "dur": 0.22, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201275.06, "ph": "X", "cat": "fee", "dur": 2.18, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201278.04, "ph": "X", "cat": "fee", "dur": 1.96, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576201278.02, "ph": "X", "cat": "fee", "dur": 2.0, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201278.0, "ph": "X", "cat": "fee", "dur": 3.0, "name": "path_stats (<frozen importlib._bootstrap_external>:1077)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201281.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576201281.08, "ph": "X", "cat": "fee", "dur": 24.92, "name": "io.open_code"}, {"pid": 20956, "tid": 2192355, "ts": 253576201306.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_io.BufferedReader.read"}, {"pid": 20956, "tid": 2192355, "ts": 253576201309.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_io.BufferedReader.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201281.02, "ph": "X", "cat": "fee", "dur": 29.0, "name": "get_data (<frozen importlib._bootstrap_external>:1036)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201311.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576201311.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576201311.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576201311.04, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201310.04, "ph": "X", "cat": "fee", "dur": 1.12, "name": "_classify_pyc (<frozen importlib._bootstrap_external>:560)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201312.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576201312.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576201312.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201313.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576201313.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576201313.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201312.0, "ph": "X", "cat": "fee", "dur": 1.12, "name": "_validate_timestamp_pyc (<frozen importlib._bootstrap_external>:593)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201313.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201313.2, "ph": "X", "cat": "fee", "dur": 7.8, "name": "marshal.loads"}, {"pid": 20956, "tid": 2192355, "ts": 253576201321.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576201321.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201322.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp._fix_co_filename"}, {"pid": 20956, "tid": 2192355, "ts": 253576201313.18, "ph": "X", "cat": "fee", "dur": 8.86, "name": "_compile_bytecode (<frozen importlib._bootstrap_external>:645)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201274.1, "ph": "X", "cat": "fee", "dur": 47.96, "name": "get_code (<frozen importlib._bootstrap_external>:916)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201323.0, "ph": "X", "cat": "fee", "dur": 2.0, "name": "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/basinhopping.py:1)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201322.1, "ph": "X", "cat": "fee", "dur": 2.92, "name": "builtins.exec"}, {"pid": 20956, "tid": 2192355, "ts": 253576201322.08, "ph": "X", "cat": "fee", "dur": 2.96, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201274.08, "ph": "X", "cat": "fee", "dur": 50.98, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201326.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576201326.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201264.12, "ph": "X", "cat": "fee", "dur": 61.96, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201327.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201327.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201237.02, "ph": "X", "cat": "fee", "dur": 90.06, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201328.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576201328.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201328.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201327.1, "ph": "X", "cat": "fee", "dur": 1.02, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201329.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201329.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576201329.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201328.14, "ph": "X", "cat": "fee", "dur": 0.98, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201233.02, "ph": "X", "cat": "fee", "dur": 96.12, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201330.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201330.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201330.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201330.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576201331.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201330.14, "ph": "X", "cat": "fee", "dur": 0.9, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201331.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576201331.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201331.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201330.0, "ph": "X", "cat": "fee", "dur": 1.18, "name": "_lock_unlock_module (<frozen importlib._bootstrap>:203)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201233.0, "ph": "X", "cat": "fee", "dur": 99.0, "name": "builtins.__import__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201232.06, "ph": "X", "cat": "fee", "dur": 99.96, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201332.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576201332.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201333.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.format"}, {"pid": 20956, "tid": 2192355, "ts": 253576201334.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201334.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201335.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201335.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201335.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201336.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201334.08, "ph": "X", "cat": "fee", "dur": 1.96, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201336.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576201336.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201336.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201334.06, "ph": "X", "cat": "fee", "dur": 2.94, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201337.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576201337.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201338.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201338.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201338.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201338.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201338.12, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201339.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201339.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201339.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_frozen"}, {"pid": 20956, "tid": 2192355, "ts": 253576201339.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201339.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201339.16, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201339.26, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201339.24, "ph": "X", "cat": "fee", "dur": 0.76, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201340.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576201340.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201340.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201341.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201341.1, "ph": "X", "cat": "fee", "dur": 2.9, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576201341.08, "ph": "X", "cat": "fee", "dur": 2.94, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201344.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201345.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201345.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201345.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201346.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201345.0, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201346.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201346.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201347.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201346.12, "ph": "X", "cat": "fee", "dur": 0.94, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201347.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201346.1, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201347.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201348.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201348.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201348.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201348.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201348.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201348.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201349.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201349.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201349.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201349.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201349.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201349.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201350.06, "ph": "X", "cat": "fee", "dur": 5.94, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576201350.04, "ph": "X", "cat": "fee", "dur": 5.98, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201350.02, "ph": "X", "cat": "fee", "dur": 6.98, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201350.0, "ph": "X", "cat": "fee", "dur": 7.02, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201357.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap_external>:1006)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201357.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576201358.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:351)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201357.1, "ph": "X", "cat": "fee", "dur": 0.94, "name": "spec_from_file_location (<frozen importlib._bootstrap_external>:696)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201357.04, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_get_spec (<frozen importlib._bootstrap_external>:1500)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201341.02, "ph": "X", "cat": "fee", "dur": 17.98, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201340.04, "ph": "X", "cat": "fee", "dur": 18.98, "name": "_get_spec (<frozen importlib._bootstrap_external>:1374)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201340.02, "ph": "X", "cat": "fee", "dur": 19.02, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201359.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201359.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201337.12, "ph": "X", "cat": "fee", "dur": 22.02, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201360.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201360.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201360.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "create_module (<frozen importlib._bootstrap_external>:841)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201360.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_new_module (<frozen importlib._bootstrap>:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201361.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201361.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201361.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201361.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201361.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201362.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201362.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "has_location (<frozen importlib._bootstrap>:406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201363.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201363.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201364.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.endswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576201364.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576201365.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201365.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201365.04, "ph": "X", "cat": "fee", "dur": 0.1, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576201365.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201366.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201366.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201367.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201367.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201367.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201367.02, "ph": "X", "cat": "fee", "dur": 0.14, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201367.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201367.0, "ph": "X", "cat": "fee", "dur": 0.22, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201364.1, "ph": "X", "cat": "fee", "dur": 3.14, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201364.04, "ph": "X", "cat": "fee", "dur": 3.96, "name": "_get_cached (<frozen importlib._bootstrap_external>:491)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201364.02, "ph": "X", "cat": "fee", "dur": 4.0, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201368.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201361.0, "ph": "X", "cat": "fee", "dur": 7.08, "name": "_init_module_attrs (<frozen importlib._bootstrap>:486)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201360.04, "ph": "X", "cat": "fee", "dur": 8.06, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201369.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "get_filename (<frozen importlib._bootstrap_external>:1031)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201369.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "_check_name_wrapper (<frozen importlib._bootstrap_external>:523)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201369.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576201370.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rfind"}, {"pid": 20956, "tid": 2192355, "ts": 253576201370.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201370.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201369.18, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576201369.16, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201370.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201371.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201371.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201371.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201371.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201371.06, "ph": "X", "cat": "fee", "dur": 0.14, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201371.22, "ph": "X", "cat": "fee", "dur": 0.78, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201371.04, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201369.1, "ph": "X", "cat": "fee", "dur": 2.94, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201372.1, "ph": "X", "cat": "fee", "dur": 2.9, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576201372.08, "ph": "X", "cat": "fee", "dur": 2.94, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201372.06, "ph": "X", "cat": "fee", "dur": 2.98, "name": "path_stats (<frozen importlib._bootstrap_external>:1077)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201375.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576201375.12, "ph": "X", "cat": "fee", "dur": 18.88, "name": "io.open_code"}, {"pid": 20956, "tid": 2192355, "ts": 253576201394.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_io.BufferedReader.read"}, {"pid": 20956, "tid": 2192355, "ts": 253576201396.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_io.BufferedReader.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201375.06, "ph": "X", "cat": "fee", "dur": 22.96, "name": "get_data (<frozen importlib._bootstrap_external>:1036)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201398.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576201399.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576201399.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576201399.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201398.04, "ph": "X", "cat": "fee", "dur": 1.08, "name": "_classify_pyc (<frozen importlib._bootstrap_external>:560)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201400.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576201400.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576201400.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201400.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576201400.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576201400.12, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201399.14, "ph": "X", "cat": "fee", "dur": 1.1, "name": "_validate_timestamp_pyc (<frozen importlib._bootstrap_external>:593)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201400.26, "ph": "X", "cat": "fee", "dur": 0.74, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201401.04, "ph": "X", "cat": "fee", "dur": 25.96, "name": "marshal.loads"}, {"pid": 20956, "tid": 2192355, "ts": 253576201427.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576201427.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201428.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp._fix_co_filename"}, {"pid": 20956, "tid": 2192355, "ts": 253576201401.02, "ph": "X", "cat": "fee", "dur": 27.02, "name": "_compile_bytecode (<frozen importlib._bootstrap_external>:645)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201369.0, "ph": "X", "cat": "fee", "dur": 59.06, "name": "get_code (<frozen importlib._bootstrap_external>:916)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201431.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201431.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201430.02, "ph": "X", "cat": "fee", "dur": 1.06, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201431.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576201432.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201431.1, "ph": "X", "cat": "fee", "dur": 0.94, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201432.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576201432.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201432.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201430.0, "ph": "X", "cat": "fee", "dur": 3.02, "name": "_lock_unlock_module (<frozen importlib._bootstrap>:203)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201433.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576201433.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201433.04, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201429.0, "ph": "X", "cat": "fee", "dur": 6.0, "name": "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/genetic_algorithm.py:1)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201428.1, "ph": "X", "cat": "fee", "dur": 6.92, "name": "builtins.exec"}, {"pid": 20956, "tid": 2192355, "ts": 253576201428.08, "ph": "X", "cat": "fee", "dur": 6.96, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201368.12, "ph": "X", "cat": "fee", "dur": 66.94, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201435.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576201436.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201359.16, "ph": "X", "cat": "fee", "dur": 76.88, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201436.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201436.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201337.06, "ph": "X", "cat": "fee", "dur": 99.96, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201437.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576201437.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201437.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201437.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201438.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201438.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576201438.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201438.02, "ph": "X", "cat": "fee", "dur": 0.14, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201334.0, "ph": "X", "cat": "fee", "dur": 104.18, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201439.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201439.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201439.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201439.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576201440.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201439.14, "ph": "X", "cat": "fee", "dur": 0.9, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201440.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576201440.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201440.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201439.0, "ph": "X", "cat": "fee", "dur": 1.18, "name": "_lock_unlock_module (<frozen importlib._bootstrap>:203)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201333.08, "ph": "X", "cat": "fee", "dur": 107.12, "name": "builtins.__import__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201333.06, "ph": "X", "cat": "fee", "dur": 107.94, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201441.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576201441.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201442.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.format"}, {"pid": 20956, "tid": 2192355, "ts": 253576201443.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201443.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201444.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201444.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201444.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201445.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201443.08, "ph": "X", "cat": "fee", "dur": 1.96, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201445.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576201445.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201445.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201443.06, "ph": "X", "cat": "fee", "dur": 2.12, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201446.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576201446.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201447.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201447.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201447.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201447.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201447.12, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201447.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201447.2, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201448.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_frozen"}, {"pid": 20956, "tid": 2192355, "ts": 253576201448.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201448.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201448.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201448.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201448.16, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201449.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576201449.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201449.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201449.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201450.02, "ph": "X", "cat": "fee", "dur": 2.98, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576201450.0, "ph": "X", "cat": "fee", "dur": 3.02, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201453.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201454.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201454.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201454.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201454.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201454.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201455.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201455.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201455.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201455.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201455.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201455.04, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201456.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201456.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201456.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201456.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201456.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201456.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201457.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201457.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201457.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201457.08, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201457.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201457.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201458.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201458.12, "ph": "X", "cat": "fee", "dur": 5.88, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576201458.1, "ph": "X", "cat": "fee", "dur": 5.92, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201458.08, "ph": "X", "cat": "fee", "dur": 5.96, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201458.06, "ph": "X", "cat": "fee", "dur": 6.0, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201465.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap_external>:1006)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201465.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576201465.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "__init__ (<frozen importlib._bootstrap>:351)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201465.06, "ph": "X", "cat": "fee", "dur": 0.96, "name": "spec_from_file_location (<frozen importlib._bootstrap_external>:696)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201465.0, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_get_spec (<frozen importlib._bootstrap_external>:1500)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201449.14, "ph": "X", "cat": "fee", "dur": 16.92, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201449.0, "ph": "X", "cat": "fee", "dur": 17.08, "name": "_get_spec (<frozen importlib._bootstrap_external>:1374)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201448.24, "ph": "X", "cat": "fee", "dur": 18.76, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201467.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201467.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201446.1, "ph": "X", "cat": "fee", "dur": 21.0, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201467.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201468.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201468.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "create_module (<frozen importlib._bootstrap_external>:841)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201468.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_new_module (<frozen importlib._bootstrap>:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201468.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201469.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201469.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201469.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201469.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201469.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201470.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "has_location (<frozen importlib._bootstrap>:406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201470.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201471.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201472.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.endswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576201472.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576201472.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201473.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201472.14, "ph": "X", "cat": "fee", "dur": 0.92, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576201472.12, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201473.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201474.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201474.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201475.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201475.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201474.06, "ph": "X", "cat": "fee", "dur": 1.02, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201475.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201474.04, "ph": "X", "cat": "fee", "dur": 1.1, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201472.06, "ph": "X", "cat": "fee", "dur": 3.1, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201472.0, "ph": "X", "cat": "fee", "dur": 3.18, "name": "_get_cached (<frozen importlib._bootstrap_external>:491)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201471.06, "ph": "X", "cat": "fee", "dur": 4.14, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201475.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201468.12, "ph": "X", "cat": "fee", "dur": 7.88, "name": "_init_module_attrs (<frozen importlib._bootstrap>:486)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201467.18, "ph": "X", "cat": "fee", "dur": 8.84, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201476.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "get_filename (<frozen importlib._bootstrap_external>:1031)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201476.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_check_name_wrapper (<frozen importlib._bootstrap_external>:523)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201477.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576201477.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rfind"}, {"pid": 20956, "tid": 2192355, "ts": 253576201477.12, "ph": "X", "cat": "fee", "dur": 0.06, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201477.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201477.1, "ph": "X", "cat": "fee", "dur": 0.14, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576201477.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201478.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201478.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201479.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201479.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201479.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201478.12, "ph": "X", "cat": "fee", "dur": 1.0, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201479.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201478.1, "ph": "X", "cat": "fee", "dur": 1.08, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201477.02, "ph": "X", "cat": "fee", "dur": 2.18, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201479.26, "ph": "X", "cat": "fee", "dur": 2.74, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576201479.24, "ph": "X", "cat": "fee", "dur": 2.78, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201479.22, "ph": "X", "cat": "fee", "dur": 2.82, "name": "path_stats (<frozen importlib._bootstrap_external>:1077)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201482.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576201483.02, "ph": "X", "cat": "fee", "dur": 16.98, "name": "io.open_code"}, {"pid": 20956, "tid": 2192355, "ts": 253576201500.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_io.BufferedReader.read"}, {"pid": 20956, "tid": 2192355, "ts": 253576201502.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_io.BufferedReader.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201482.06, "ph": "X", "cat": "fee", "dur": 21.96, "name": "get_data (<frozen importlib._bootstrap_external>:1036)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201504.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576201505.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576201505.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576201505.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201504.04, "ph": "X", "cat": "fee", "dur": 1.08, "name": "_classify_pyc (<frozen importlib._bootstrap_external>:560)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201506.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576201506.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576201506.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201506.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576201506.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576201506.12, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201505.14, "ph": "X", "cat": "fee", "dur": 1.1, "name": "_validate_timestamp_pyc (<frozen importlib._bootstrap_external>:593)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201506.26, "ph": "X", "cat": "fee", "dur": 0.74, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201507.04, "ph": "X", "cat": "fee", "dur": 5.96, "name": "marshal.loads"}, {"pid": 20956, "tid": 2192355, "ts": 253576201513.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576201513.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201513.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp._fix_co_filename"}, {"pid": 20956, "tid": 2192355, "ts": 253576201507.02, "ph": "X", "cat": "fee", "dur": 6.98, "name": "_compile_bytecode (<frozen importlib._bootstrap_external>:645)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201476.06, "ph": "X", "cat": "fee", "dur": 37.96, "name": "get_code (<frozen importlib._bootstrap_external>:916)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201515.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201515.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201515.02, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201516.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576201516.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201516.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201517.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576201517.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201517.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201515.0, "ph": "X", "cat": "fee", "dur": 2.14, "name": "_lock_unlock_module (<frozen importlib._bootstrap>:203)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201518.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576201518.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201518.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201520.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201520.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201520.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201521.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201520.06, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201522.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576201522.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201522.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201520.04, "ph": "X", "cat": "fee", "dur": 2.08, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201522.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576201523.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201524.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201524.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201524.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201525.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201525.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201525.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201525.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201526.02, "ph": "X", "cat": "fee", "dur": 16.98, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201543.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201523.08, "ph": "X", "cat": "fee", "dur": 19.98, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201543.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201544.0, "ph": "X", "cat": "fee", "dur": 7.0, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201551.02, "ph": "X", "cat": "fee", "dur": 162.98, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201715.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576201715.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201543.08, "ph": "X", "cat": "fee", "dur": 172.0, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201715.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201715.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201523.02, "ph": "X", "cat": "fee", "dur": 193.0, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201716.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576201717.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201716.06, "ph": "X", "cat": "fee", "dur": 0.98, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201716.04, "ph": "X", "cat": "fee", "dur": 1.02, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201717.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201717.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576201717.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201717.08, "ph": "X", "cat": "fee", "dur": 0.14, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201519.0, "ph": "X", "cat": "fee", "dur": 199.0, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201514.08, "ph": "X", "cat": "fee", "dur": 203.94, "name": "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/mls.py:1)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201514.06, "ph": "X", "cat": "fee", "dur": 203.98, "name": "builtins.exec"}, {"pid": 20956, "tid": 2192355, "ts": 253576201514.04, "ph": "X", "cat": "fee", "dur": 204.02, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201476.04, "ph": "X", "cat": "fee", "dur": 242.96, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201719.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576201719.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201467.12, "ph": "X", "cat": "fee", "dur": 252.88, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201720.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201720.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201446.04, "ph": "X", "cat": "fee", "dur": 274.06, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201720.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576201721.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201720.14, "ph": "X", "cat": "fee", "dur": 0.9, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201720.12, "ph": "X", "cat": "fee", "dur": 0.94, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201721.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201721.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576201721.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201721.08, "ph": "X", "cat": "fee", "dur": 0.14, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201443.0, "ph": "X", "cat": "fee", "dur": 279.0, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201722.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201722.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201722.04, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201723.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576201723.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201723.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201723.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576201724.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201723.12, "ph": "X", "cat": "fee", "dur": 0.92, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201722.02, "ph": "X", "cat": "fee", "dur": 2.04, "name": "_lock_unlock_module (<frozen importlib._bootstrap>:203)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201442.06, "ph": "X", "cat": "fee", "dur": 282.02, "name": "builtins.__import__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201442.04, "ph": "X", "cat": "fee", "dur": 282.06, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201724.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576201724.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201725.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.format"}, {"pid": 20956, "tid": 2192355, "ts": 253576201726.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201727.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201727.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201727.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201727.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201728.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201727.0, "ph": "X", "cat": "fee", "dur": 1.06, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201728.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576201729.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201728.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201726.06, "ph": "X", "cat": "fee", "dur": 3.0, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201729.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576201729.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201730.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201730.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201730.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201730.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201730.14, "ph": "X", "cat": "fee", "dur": 0.88, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201731.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201731.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201731.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_frozen"}, {"pid": 20956, "tid": 2192355, "ts": 253576201731.12, "ph": "X", "cat": "fee", "dur": 0.06, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201731.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201731.2, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201732.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201732.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201732.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576201732.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201733.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201733.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201733.14, "ph": "X", "cat": "fee", "dur": 2.86, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576201733.12, "ph": "X", "cat": "fee", "dur": 2.9, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201736.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201737.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201737.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201737.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201737.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201737.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201738.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201738.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201739.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201738.1, "ph": "X", "cat": "fee", "dur": 0.94, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201739.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201738.08, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201739.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201740.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201740.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201739.18, "ph": "X", "cat": "fee", "dur": 0.9, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201740.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201739.16, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201740.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201741.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201741.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201741.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201741.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201740.2, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201741.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201742.04, "ph": "X", "cat": "fee", "dur": 5.96, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576201742.02, "ph": "X", "cat": "fee", "dur": 6.0, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201742.0, "ph": "X", "cat": "fee", "dur": 6.04, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201741.22, "ph": "X", "cat": "fee", "dur": 6.84, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201749.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap_external>:1006)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201749.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576201749.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "__init__ (<frozen importlib._bootstrap>:351)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201749.04, "ph": "X", "cat": "fee", "dur": 0.98, "name": "spec_from_file_location (<frozen importlib._bootstrap_external>:696)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201748.08, "ph": "X", "cat": "fee", "dur": 1.96, "name": "_get_spec (<frozen importlib._bootstrap_external>:1500)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201733.06, "ph": "X", "cat": "fee", "dur": 17.0, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201732.1, "ph": "X", "cat": "fee", "dur": 17.98, "name": "_get_spec (<frozen importlib._bootstrap_external>:1374)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201732.08, "ph": "X", "cat": "fee", "dur": 18.02, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201751.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201751.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201730.0, "ph": "X", "cat": "fee", "dur": 21.08, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201751.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201751.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201752.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "create_module (<frozen importlib._bootstrap_external>:841)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201752.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_new_module (<frozen importlib._bootstrap>:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201752.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201752.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201753.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201753.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201753.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201753.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201754.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "has_location (<frozen importlib._bootstrap>:406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201754.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201755.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201756.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.endswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576201756.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576201756.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201757.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201756.12, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576201756.1, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201757.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201758.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201758.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201759.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201759.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201758.06, "ph": "X", "cat": "fee", "dur": 1.02, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201759.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201758.04, "ph": "X", "cat": "fee", "dur": 1.1, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201756.04, "ph": "X", "cat": "fee", "dur": 3.12, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201755.08, "ph": "X", "cat": "fee", "dur": 4.1, "name": "_get_cached (<frozen importlib._bootstrap_external>:491)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201755.06, "ph": "X", "cat": "fee", "dur": 4.14, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201760.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201752.1, "ph": "X", "cat": "fee", "dur": 7.94, "name": "_init_module_attrs (<frozen importlib._bootstrap>:486)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201751.16, "ph": "X", "cat": "fee", "dur": 8.9, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201761.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "get_filename (<frozen importlib._bootstrap_external>:1031)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201760.12, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_check_name_wrapper (<frozen importlib._bootstrap_external>:523)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201761.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576201761.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rfind"}, {"pid": 20956, "tid": 2192355, "ts": 253576201761.16, "ph": "X", "cat": "fee", "dur": 0.06, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201762.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201761.14, "ph": "X", "cat": "fee", "dur": 0.9, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576201761.12, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201762.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201762.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201763.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201763.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201763.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201763.02, "ph": "X", "cat": "fee", "dur": 0.14, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201763.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201763.0, "ph": "X", "cat": "fee", "dur": 0.22, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201761.06, "ph": "X", "cat": "fee", "dur": 2.18, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201764.04, "ph": "X", "cat": "fee", "dur": 1.96, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576201764.02, "ph": "X", "cat": "fee", "dur": 2.0, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201764.0, "ph": "X", "cat": "fee", "dur": 2.04, "name": "path_stats (<frozen importlib._bootstrap_external>:1077)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201767.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576201767.06, "ph": "X", "cat": "fee", "dur": 20.94, "name": "io.open_code"}, {"pid": 20956, "tid": 2192355, "ts": 253576201789.0, "ph": "X", "cat": "fee", "dur": 2.0, "name": "_io.BufferedReader.read"}, {"pid": 20956, "tid": 2192355, "ts": 253576201791.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_io.BufferedReader.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201767.0, "ph": "X", "cat": "fee", "dur": 25.02, "name": "get_data (<frozen importlib._bootstrap_external>:1036)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201793.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576201793.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576201793.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576201793.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201793.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_classify_pyc (<frozen importlib._bootstrap_external>:560)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201794.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576201794.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576201794.04, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201795.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576201795.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576201795.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201794.02, "ph": "X", "cat": "fee", "dur": 1.1, "name": "_validate_timestamp_pyc (<frozen importlib._bootstrap_external>:593)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201795.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201795.2, "ph": "X", "cat": "fee", "dur": 16.8, "name": "marshal.loads"}, {"pid": 20956, "tid": 2192355, "ts": 253576201812.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576201812.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201813.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp._fix_co_filename"}, {"pid": 20956, "tid": 2192355, "ts": 253576201795.18, "ph": "X", "cat": "fee", "dur": 17.88, "name": "_compile_bytecode (<frozen importlib._bootstrap_external>:645)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201760.1, "ph": "X", "cat": "fee", "dur": 52.98, "name": "get_code (<frozen importlib._bootstrap_external>:916)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201816.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "Particle (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/pso.py:85)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201816.0, "ph": "X", "cat": "fee", "dur": 7.0, "name": "builtins.__build_class__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201814.0, "ph": "X", "cat": "fee", "dur": 9.02, "name": "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/pso.py:1)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201813.12, "ph": "X", "cat": "fee", "dur": 9.92, "name": "builtins.exec"}, {"pid": 20956, "tid": 2192355, "ts": 253576201813.1, "ph": "X", "cat": "fee", "dur": 9.96, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201760.08, "ph": "X", "cat": "fee", "dur": 63.0, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201824.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576201824.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201751.1, "ph": "X", "cat": "fee", "dur": 72.98, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201825.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201825.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201729.12, "ph": "X", "cat": "fee", "dur": 95.96, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201825.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576201826.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201825.12, "ph": "X", "cat": "fee", "dur": 0.92, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201825.1, "ph": "X", "cat": "fee", "dur": 0.96, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201826.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201826.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576201827.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201826.08, "ph": "X", "cat": "fee", "dur": 0.98, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201726.0, "ph": "X", "cat": "fee", "dur": 101.08, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201827.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201828.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201827.12, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201828.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576201828.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201828.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201829.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576201829.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201829.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201827.1, "ph": "X", "cat": "fee", "dur": 2.04, "name": "_lock_unlock_module (<frozen importlib._bootstrap>:203)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201725.08, "ph": "X", "cat": "fee", "dur": 104.08, "name": "builtins.__import__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201725.06, "ph": "X", "cat": "fee", "dur": 104.12, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201829.2, "ph": "X", "cat": "fee", "dur": 0.8, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576201830.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201830.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "str.format"}, {"pid": 20956, "tid": 2192355, "ts": 253576201832.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201832.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201832.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201833.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201832.12, "ph": "X", "cat": "fee", "dur": 0.94, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201833.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201832.06, "ph": "X", "cat": "fee", "dur": 1.06, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201834.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576201834.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201834.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201832.04, "ph": "X", "cat": "fee", "dur": 2.08, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201834.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576201834.2, "ph": "X", "cat": "fee", "dur": 0.8, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201835.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201835.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201836.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201836.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201836.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201836.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201836.12, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201836.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_frozen"}, {"pid": 20956, "tid": 2192355, "ts": 253576201836.2, "ph": "X", "cat": "fee", "dur": 0.06, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201837.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201837.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201837.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201837.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201837.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576201838.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201838.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201838.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201839.0, "ph": "X", "cat": "fee", "dur": 2.0, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576201838.14, "ph": "X", "cat": "fee", "dur": 3.86, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201842.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201843.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201843.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201843.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201843.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201842.06, "ph": "X", "cat": "fee", "dur": 1.1, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201843.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201844.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201844.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201844.04, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201844.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201844.02, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201845.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201845.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201845.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201845.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201845.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201845.04, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201846.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201846.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201846.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201846.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201846.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201846.04, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201847.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201847.1, "ph": "X", "cat": "fee", "dur": 6.9, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576201847.08, "ph": "X", "cat": "fee", "dur": 6.94, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201847.06, "ph": "X", "cat": "fee", "dur": 6.98, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201847.04, "ph": "X", "cat": "fee", "dur": 7.02, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201854.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "__init__ (<frozen importlib._bootstrap_external>:1006)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201855.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576201855.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:351)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201855.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "spec_from_file_location (<frozen importlib._bootstrap_external>:696)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201854.08, "ph": "X", "cat": "fee", "dur": 1.94, "name": "_get_spec (<frozen importlib._bootstrap_external>:1500)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201838.08, "ph": "X", "cat": "fee", "dur": 17.96, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201837.18, "ph": "X", "cat": "fee", "dur": 18.88, "name": "_get_spec (<frozen importlib._bootstrap_external>:1374)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201837.16, "ph": "X", "cat": "fee", "dur": 18.92, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201856.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201856.1, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201835.02, "ph": "X", "cat": "fee", "dur": 21.98, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201857.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201857.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201857.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "create_module (<frozen importlib._bootstrap_external>:841)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201858.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_new_module (<frozen importlib._bootstrap>:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201858.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201858.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201858.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201859.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201858.18, "ph": "X", "cat": "fee", "dur": 0.86, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201859.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201860.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "has_location (<frozen importlib._bootstrap>:406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201860.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201860.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201861.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "str.endswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576201862.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576201862.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201862.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201862.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576201862.08, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201863.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201863.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201864.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201864.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201864.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201864.02, "ph": "X", "cat": "fee", "dur": 0.14, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201864.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201864.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201862.02, "ph": "X", "cat": "fee", "dur": 3.02, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201861.04, "ph": "X", "cat": "fee", "dur": 4.02, "name": "_get_cached (<frozen importlib._bootstrap_external>:491)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201861.02, "ph": "X", "cat": "fee", "dur": 4.06, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201865.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201858.04, "ph": "X", "cat": "fee", "dur": 7.1, "name": "_init_module_attrs (<frozen importlib._bootstrap>:486)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201857.08, "ph": "X", "cat": "fee", "dur": 8.08, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201866.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "get_filename (<frozen importlib._bootstrap_external>:1031)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201866.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "_check_name_wrapper (<frozen importlib._bootstrap_external>:523)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201866.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576201867.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rfind"}, {"pid": 20956, "tid": 2192355, "ts": 253576201867.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201867.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201866.18, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576201866.16, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201867.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201868.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201868.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201868.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201868.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201868.06, "ph": "X", "cat": "fee", "dur": 0.14, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201869.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201868.04, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201866.1, "ph": "X", "cat": "fee", "dur": 2.96, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201869.12, "ph": "X", "cat": "fee", "dur": 1.88, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576201869.1, "ph": "X", "cat": "fee", "dur": 2.9, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201869.08, "ph": "X", "cat": "fee", "dur": 2.94, "name": "path_stats (<frozen importlib._bootstrap_external>:1077)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201872.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576201872.1, "ph": "X", "cat": "fee", "dur": 16.9, "name": "io.open_code"}, {"pid": 20956, "tid": 2192355, "ts": 253576201890.0, "ph": "X", "cat": "fee", "dur": 2.0, "name": "_io.BufferedReader.read"}, {"pid": 20956, "tid": 2192355, "ts": 253576201892.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_io.BufferedReader.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201872.04, "ph": "X", "cat": "fee", "dur": 20.98, "name": "get_data (<frozen importlib._bootstrap_external>:1036)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201894.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576201894.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576201895.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576201894.06, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201894.0, "ph": "X", "cat": "fee", "dur": 1.06, "name": "_classify_pyc (<frozen importlib._bootstrap_external>:560)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201895.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576201895.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576201895.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201896.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576201896.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576201896.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201895.08, "ph": "X", "cat": "fee", "dur": 1.06, "name": "_validate_timestamp_pyc (<frozen importlib._bootstrap_external>:593)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201896.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201897.0, "ph": "X", "cat": "fee", "dur": 9.0, "name": "marshal.loads"}, {"pid": 20956, "tid": 2192355, "ts": 253576201906.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576201906.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201906.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "_imp._fix_co_filename"}, {"pid": 20956, "tid": 2192355, "ts": 253576201896.2, "ph": "X", "cat": "fee", "dur": 10.82, "name": "_compile_bytecode (<frozen importlib._bootstrap_external>:645)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201866.0, "ph": "X", "cat": "fee", "dur": 41.04, "name": "get_code (<frozen importlib._bootstrap_external>:916)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201907.1, "ph": "X", "cat": "fee", "dur": 2.9, "name": "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/simulated_annealing.py:1)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201907.08, "ph": "X", "cat": "fee", "dur": 2.94, "name": "builtins.exec"}, {"pid": 20956, "tid": 2192355, "ts": 253576201907.06, "ph": "X", "cat": "fee", "dur": 2.98, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201865.18, "ph": "X", "cat": "fee", "dur": 44.88, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201910.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576201911.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201857.02, "ph": "X", "cat": "fee", "dur": 54.02, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201911.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201911.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201834.18, "ph": "X", "cat": "fee", "dur": 77.82, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201912.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576201912.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201912.04, "ph": "X", "cat": "fee", "dur": 0.1, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201912.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201913.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201913.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576201913.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201913.02, "ph": "X", "cat": "fee", "dur": 0.14, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201831.06, "ph": "X", "cat": "fee", "dur": 82.12, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201914.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201914.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201914.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201914.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576201915.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201914.14, "ph": "X", "cat": "fee", "dur": 0.9, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201915.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576201915.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201915.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201914.0, "ph": "X", "cat": "fee", "dur": 2.0, "name": "_lock_unlock_module (<frozen importlib._bootstrap>:203)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201831.04, "ph": "X", "cat": "fee", "dur": 84.98, "name": "builtins.__import__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201831.02, "ph": "X", "cat": "fee", "dur": 85.02, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201916.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576201916.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201916.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "str.format"}, {"pid": 20956, "tid": 2192355, "ts": 253576201918.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201918.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201919.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201919.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201919.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201919.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201918.08, "ph": "X", "cat": "fee", "dur": 1.08, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201920.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576201920.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201920.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201918.06, "ph": "X", "cat": "fee", "dur": 2.06, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201920.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576201920.2, "ph": "X", "cat": "fee", "dur": 0.8, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201921.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201921.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201921.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201922.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201922.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201922.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201922.1, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201922.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_frozen"}, {"pid": 20956, "tid": 2192355, "ts": 253576201922.18, "ph": "X", "cat": "fee", "dur": 0.06, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201923.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201922.26, "ph": "X", "cat": "fee", "dur": 0.78, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201923.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201923.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201923.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576201923.22, "ph": "X", "cat": "fee", "dur": 0.78, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201924.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201924.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201924.14, "ph": "X", "cat": "fee", "dur": 2.86, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576201924.12, "ph": "X", "cat": "fee", "dur": 2.9, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201927.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201928.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201928.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201928.04, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201929.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201928.02, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201929.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201929.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201929.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201929.12, "ph": "X", "cat": "fee", "dur": 0.9, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201930.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201929.1, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201930.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201930.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201930.22, "ph": "X", "cat": "fee", "dur": 0.78, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201930.16, "ph": "X", "cat": "fee", "dur": 0.86, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201931.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201930.14, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201931.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201931.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201931.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201931.16, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201932.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201931.14, "ph": "X", "cat": "fee", "dur": 0.9, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201932.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201932.16, "ph": "X", "cat": "fee", "dur": 5.84, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576201932.14, "ph": "X", "cat": "fee", "dur": 5.88, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201932.12, "ph": "X", "cat": "fee", "dur": 5.92, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201932.1, "ph": "X", "cat": "fee", "dur": 6.9, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201939.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap_external>:1006)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201939.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576201940.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:351)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201939.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "spec_from_file_location (<frozen importlib._bootstrap_external>:696)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201939.02, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_get_spec (<frozen importlib._bootstrap_external>:1500)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201924.06, "ph": "X", "cat": "fee", "dur": 16.02, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201923.16, "ph": "X", "cat": "fee", "dur": 16.94, "name": "_get_spec (<frozen importlib._bootstrap_external>:1374)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201923.14, "ph": "X", "cat": "fee", "dur": 17.86, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201941.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576201941.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201921.02, "ph": "X", "cat": "fee", "dur": 20.08, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201941.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201942.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201942.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "create_module (<frozen importlib._bootstrap_external>:841)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201942.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_new_module (<frozen importlib._bootstrap>:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201942.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201942.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201943.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201943.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201943.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201943.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201944.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "has_location (<frozen importlib._bootstrap>:406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201944.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201945.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201946.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.endswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576201946.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576201946.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201946.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201946.12, "ph": "X", "cat": "fee", "dur": 0.9, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576201946.1, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201947.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201947.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201948.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201948.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201948.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201948.02, "ph": "X", "cat": "fee", "dur": 0.14, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201948.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201948.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201946.04, "ph": "X", "cat": "fee", "dur": 2.98, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201945.06, "ph": "X", "cat": "fee", "dur": 3.98, "name": "_get_cached (<frozen importlib._bootstrap_external>:491)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201945.04, "ph": "X", "cat": "fee", "dur": 4.02, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201949.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201942.12, "ph": "X", "cat": "fee", "dur": 7.0, "name": "_init_module_attrs (<frozen importlib._bootstrap>:486)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201941.18, "ph": "X", "cat": "fee", "dur": 7.96, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201950.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "get_filename (<frozen importlib._bootstrap_external>:1031)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201950.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "_check_name_wrapper (<frozen importlib._bootstrap_external>:523)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201950.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576201951.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rfind"}, {"pid": 20956, "tid": 2192355, "ts": 253576201951.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201951.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201950.18, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576201950.16, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201951.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576201951.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201952.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201952.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201952.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576201952.02, "ph": "X", "cat": "fee", "dur": 0.14, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201952.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576201952.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201950.1, "ph": "X", "cat": "fee", "dur": 2.94, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201953.1, "ph": "X", "cat": "fee", "dur": 1.9, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576201953.08, "ph": "X", "cat": "fee", "dur": 1.94, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201953.06, "ph": "X", "cat": "fee", "dur": 2.94, "name": "path_stats (<frozen importlib._bootstrap_external>:1077)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201956.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576201956.08, "ph": "X", "cat": "fee", "dur": 15.92, "name": "io.open_code"}, {"pid": 20956, "tid": 2192355, "ts": 253576201973.0, "ph": "X", "cat": "fee", "dur": 2.0, "name": "_io.BufferedReader.read"}, {"pid": 20956, "tid": 2192355, "ts": 253576201975.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_io.BufferedReader.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201956.02, "ph": "X", "cat": "fee", "dur": 20.0, "name": "get_data (<frozen importlib._bootstrap_external>:1036)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201977.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576201977.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576201977.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576201977.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201977.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_classify_pyc (<frozen importlib._bootstrap_external>:560)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201978.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576201978.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576201978.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201978.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576201978.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576201978.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201978.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_validate_timestamp_pyc (<frozen importlib._bootstrap_external>:593)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201979.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201979.1, "ph": "X", "cat": "fee", "dur": 14.9, "name": "marshal.loads"}, {"pid": 20956, "tid": 2192355, "ts": 253576201994.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576201994.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201994.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp._fix_co_filename"}, {"pid": 20956, "tid": 2192355, "ts": 253576201979.08, "ph": "X", "cat": "fee", "dur": 15.06, "name": "_compile_bytecode (<frozen importlib._bootstrap_external>:645)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201950.0, "ph": "X", "cat": "fee", "dur": 44.16, "name": "get_code (<frozen importlib._bootstrap_external>:916)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201998.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Firefly (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/firefly_algorithm.py:93)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201997.0, "ph": "X", "cat": "fee", "dur": 9.0, "name": "builtins.__build_class__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201995.04, "ph": "X", "cat": "fee", "dur": 10.98, "name": "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/firefly_algorithm.py:1)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201995.02, "ph": "X", "cat": "fee", "dur": 11.02, "name": "builtins.exec"}, {"pid": 20956, "tid": 2192355, "ts": 253576201995.0, "ph": "X", "cat": "fee", "dur": 11.06, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201949.16, "ph": "X", "cat": "fee", "dur": 56.92, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202007.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576202007.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201941.12, "ph": "X", "cat": "fee", "dur": 65.96, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202007.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576202008.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576201920.18, "ph": "X", "cat": "fee", "dur": 87.86, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202008.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576202009.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576202008.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202008.06, "ph": "X", "cat": "fee", "dur": 1.0, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202009.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576202009.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576202009.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576202009.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201918.0, "ph": "X", "cat": "fee", "dur": 92.02, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202010.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576202010.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576202010.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202011.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576202011.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576202011.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202011.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576202012.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576202011.12, "ph": "X", "cat": "fee", "dur": 0.92, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202010.04, "ph": "X", "cat": "fee", "dur": 2.02, "name": "_lock_unlock_module (<frozen importlib._bootstrap>:203)"}, {"pid": 20956, "tid": 2192355, "ts": 253576201917.04, "ph": "X", "cat": "fee", "dur": 95.04, "name": "builtins.__import__"}, {"pid": 20956, "tid": 2192355, "ts": 253576201917.02, "ph": "X", "cat": "fee", "dur": 95.08, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202012.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576202012.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576202013.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.format"}, {"pid": 20956, "tid": 2192355, "ts": 253576202014.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202015.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576202015.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576202015.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576202015.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202016.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576202015.0, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202016.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576202016.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576202016.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202014.06, "ph": "X", "cat": "fee", "dur": 2.94, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202017.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576202017.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576202018.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576202018.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202018.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202018.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576202018.12, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202018.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576202018.2, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202019.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_frozen"}, {"pid": 20956, "tid": 2192355, "ts": 253576202019.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202019.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576202019.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202019.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576202019.16, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202020.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576202020.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202020.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576202020.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576202021.0, "ph": "X", "cat": "fee", "dur": 2.0, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576202020.2, "ph": "X", "cat": "fee", "dur": 2.82, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202024.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202025.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576202025.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576202024.06, "ph": "X", "cat": "fee", "dur": 1.02, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202025.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576202024.04, "ph": "X", "cat": "fee", "dur": 1.1, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202025.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202026.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576202026.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576202026.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202026.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576202026.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202027.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202027.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576202027.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576202027.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202027.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576202027.04, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202028.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202028.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576202028.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576202028.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202028.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576202028.04, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202028.24, "ph": "X", "cat": "fee", "dur": 0.76, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202029.08, "ph": "X", "cat": "fee", "dur": 5.92, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576202029.06, "ph": "X", "cat": "fee", "dur": 5.96, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202029.04, "ph": "X", "cat": "fee", "dur": 6.0, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202029.02, "ph": "X", "cat": "fee", "dur": 6.04, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202035.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "__init__ (<frozen importlib._bootstrap_external>:1006)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202036.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576202036.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:351)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202036.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "spec_from_file_location (<frozen importlib._bootstrap_external>:696)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202035.08, "ph": "X", "cat": "fee", "dur": 1.94, "name": "_get_spec (<frozen importlib._bootstrap_external>:1500)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202020.14, "ph": "X", "cat": "fee", "dur": 16.9, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202020.0, "ph": "X", "cat": "fee", "dur": 17.06, "name": "_get_spec (<frozen importlib._bootstrap_external>:1374)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202019.24, "ph": "X", "cat": "fee", "dur": 17.84, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202037.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576202037.1, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202017.12, "ph": "X", "cat": "fee", "dur": 20.06, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202038.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576202038.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576202038.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "create_module (<frozen importlib._bootstrap_external>:841)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202038.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "_new_module (<frozen importlib._bootstrap>:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202039.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576202039.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576202039.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576202039.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576202039.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202040.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576202040.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "has_location (<frozen importlib._bootstrap>:406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202040.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576202041.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576202042.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.endswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576202042.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576202043.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202043.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202043.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576202042.16, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202043.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576202044.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576202044.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576202045.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576202045.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576202044.06, "ph": "X", "cat": "fee", "dur": 1.02, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202045.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576202044.04, "ph": "X", "cat": "fee", "dur": 1.1, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202042.1, "ph": "X", "cat": "fee", "dur": 3.06, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202042.04, "ph": "X", "cat": "fee", "dur": 3.14, "name": "_get_cached (<frozen importlib._bootstrap_external>:491)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202042.02, "ph": "X", "cat": "fee", "dur": 3.18, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202045.22, "ph": "X", "cat": "fee", "dur": 0.78, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202039.02, "ph": "X", "cat": "fee", "dur": 7.0, "name": "_init_module_attrs (<frozen importlib._bootstrap>:486)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202038.06, "ph": "X", "cat": "fee", "dur": 7.98, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202046.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "get_filename (<frozen importlib._bootstrap_external>:1031)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202046.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "_check_name_wrapper (<frozen importlib._bootstrap_external>:523)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202047.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576202047.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rfind"}, {"pid": 20956, "tid": 2192355, "ts": 253576202047.12, "ph": "X", "cat": "fee", "dur": 0.06, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202047.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202047.1, "ph": "X", "cat": "fee", "dur": 0.14, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576202047.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202048.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576202048.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576202048.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576202049.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576202049.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576202048.12, "ph": "X", "cat": "fee", "dur": 0.98, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202049.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576202048.1, "ph": "X", "cat": "fee", "dur": 1.06, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202047.02, "ph": "X", "cat": "fee", "dur": 2.16, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202049.24, "ph": "X", "cat": "fee", "dur": 2.76, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576202049.22, "ph": "X", "cat": "fee", "dur": 2.8, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202049.2, "ph": "X", "cat": "fee", "dur": 2.84, "name": "path_stats (<frozen importlib._bootstrap_external>:1077)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202052.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576202053.0, "ph": "X", "cat": "fee", "dur": 17.0, "name": "io.open_code"}, {"pid": 20956, "tid": 2192355, "ts": 253576202070.02, "ph": "X", "cat": "fee", "dur": 3.98, "name": "_io.BufferedReader.read"}, {"pid": 20956, "tid": 2192355, "ts": 253576202074.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_io.BufferedReader.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576202052.06, "ph": "X", "cat": "fee", "dur": 22.96, "name": "get_data (<frozen importlib._bootstrap_external>:1036)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202076.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576202076.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576202076.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576202076.06, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202076.0, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_classify_pyc (<frozen importlib._bootstrap_external>:560)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202077.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576202077.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576202077.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202078.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576202078.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576202078.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202077.06, "ph": "X", "cat": "fee", "dur": 1.08, "name": "_validate_timestamp_pyc (<frozen importlib._bootstrap_external>:593)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202078.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202079.0, "ph": "X", "cat": "fee", "dur": 105.0, "name": "marshal.loads"}, {"pid": 20956, "tid": 2192355, "ts": 253576202184.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576202185.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202185.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp._fix_co_filename"}, {"pid": 20956, "tid": 2192355, "ts": 253576202078.2, "ph": "X", "cat": "fee", "dur": 106.88, "name": "_compile_bytecode (<frozen importlib._bootstrap_external>:645)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202046.08, "ph": "X", "cat": "fee", "dur": 139.02, "name": "get_code (<frozen importlib._bootstrap_external>:916)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202192.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202193.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576202193.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202194.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576202192.08, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202195.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576202195.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576202195.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202192.06, "ph": "X", "cat": "fee", "dur": 3.06, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202196.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576202196.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576202197.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202197.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202197.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202198.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202198.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202198.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202198.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202199.02, "ph": "X", "cat": "fee", "dur": 19.98, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202219.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202196.1, "ph": "X", "cat": "fee", "dur": 22.96, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202219.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576202220.02, "ph": "X", "cat": "fee", "dur": 6.98, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202227.02, "ph": "X", "cat": "fee", "dur": 89108.98, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576291338.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576291338.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202219.08, "ph": "X", "cat": "fee", "dur": 89119.92, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576291339.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576291339.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576202196.04, "ph": "X", "cat": "fee", "dur": 89143.98, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576291340.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576291341.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576291340.06, "ph": "X", "cat": "fee", "dur": 0.98, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576291340.04, "ph": "X", "cat": "fee", "dur": 1.02, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576291341.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576291341.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576291342.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576291341.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202192.0, "ph": "X", "cat": "fee", "dur": 89150.06, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576291342.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576291343.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576291342.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576291344.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576291345.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576291345.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576291346.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576291345.0, "ph": "X", "cat": "fee", "dur": 1.06, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576291346.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576291347.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576291346.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576291344.06, "ph": "X", "cat": "fee", "dur": 3.0, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576291347.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576291348.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576291348.06, "ph": "X", "cat": "fee", "dur": 12353.94, "name": "builtins.__import__"}, {"pid": 20956, "tid": 2192355, "ts": 253576291348.04, "ph": "X", "cat": "fee", "dur": 12354.96, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576303703.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576303704.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253576303704.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576303704.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576303704.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253576303705.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576303705.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576303705.1, "ph": "X", "cat": "fee", "dur": 20.9, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576303726.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576303703.02, "ph": "X", "cat": "fee", "dur": 23.04, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253576303727.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576303727.06, "ph": "X", "cat": "fee", "dur": 6.94, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253576303735.0, "ph": "X", "cat": "fee", "dur": 6447.0, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576310182.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576310182.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576303727.0, "ph": "X", "cat": "fee", "dur": 6456.0, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576310183.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576310183.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576291347.12, "ph": "X", "cat": "fee", "dur": 18835.98, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576310184.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576310184.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576310184.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576310184.0, "ph": "X", "cat": "fee", "dur": 0.14, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576310185.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576310185.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576310185.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576310185.0, "ph": "X", "cat": "fee", "dur": 0.14, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576291344.0, "ph": "X", "cat": "fee", "dur": 18841.16, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576310186.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576310186.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576310186.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576310189.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576310190.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576310190.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576310191.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576310190.02, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576310192.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576310192.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576310191.08, "ph": "X", "cat": "fee", "dur": 1.0, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576310190.0, "ph": "X", "cat": "fee", "dur": 2.1, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576310192.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576310193.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576310193.08, "ph": "X", "cat": "fee", "dur": 31468.92, "name": "builtins.__import__"}, {"pid": 20956, "tid": 2192355, "ts": 253576310193.06, "ph": "X", "cat": "fee", "dur": 31468.96, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576310193.0, "ph": "X", "cat": "fee", "dur": 31469.04, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341663.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576341663.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576341663.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341663.0, "ph": "X", "cat": "fee", "dur": 0.14, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341664.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341664.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576341664.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341664.0, "ph": "X", "cat": "fee", "dur": 0.14, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576310189.0, "ph": "X", "cat": "fee", "dur": 31475.16, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341665.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576341665.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341665.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341666.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576341667.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341666.0, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341668.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341668.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341668.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341668.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576341669.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576341668.14, "ph": "X", "cat": "fee", "dur": 0.92, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341670.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576341670.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576341670.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341668.0, "ph": "X", "cat": "fee", "dur": 2.12, "name": "_lock_unlock_module (<frozen importlib._bootstrap>:203)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341670.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576341670.2, "ph": "X", "cat": "fee", "dur": 0.8, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341670.14, "ph": "X", "cat": "fee", "dur": 0.88, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341673.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576341674.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576341675.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_type_check (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:137)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341675.0, "ph": "X", "cat": "fee", "dur": 2.02, "name": "<genexpr> (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:919)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341677.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_type_check (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:137)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341677.04, "ph": "X", "cat": "fee", "dur": 0.98, "name": "<genexpr> (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:919)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341678.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:919)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341680.0, "ph": "X", "cat": "fee", "dur": 8.0, "name": "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:738)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341679.0, "ph": "X", "cat": "fee", "dur": 9.02, "name": "copy_with (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:840)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341673.0, "ph": "X", "cat": "fee", "dur": 15.04, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:908)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341672.0, "ph": "X", "cat": "fee", "dur": 16.06, "name": "inner (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:271)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341692.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "property.setter"}, {"pid": 20956, "tid": 2192355, "ts": 253576341695.02, "ph": "X", "cat": "fee", "dur": 8.98, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:908)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341695.0, "ph": "X", "cat": "fee", "dur": 9.02, "name": "inner (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:271)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341706.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "inner (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:271)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341708.0, "ph": "X", "cat": "fee", "dur": 7.0, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:908)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341707.02, "ph": "X", "cat": "fee", "dur": 8.98, "name": "inner (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:271)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341717.02, "ph": "X", "cat": "fee", "dur": 6.98, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:908)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341717.0, "ph": "X", "cat": "fee", "dur": 8.0, "name": "inner (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:271)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341690.02, "ph": "X", "cat": "fee", "dur": 36.98, "name": "BayesianOptimization (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt.py:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341690.0, "ph": "X", "cat": "fee", "dur": 44.0, "name": "builtins.__build_class__"}, {"pid": 20956, "tid": 2192355, "ts": 253576202186.0, "ph": "X", "cat": "fee", "dur": 139548.02, "name": "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt.py:1)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202185.14, "ph": "X", "cat": "fee", "dur": 139549.86, "name": "builtins.exec"}, {"pid": 20956, "tid": 2192355, "ts": 253576202185.12, "ph": "X", "cat": "fee", "dur": 139549.9, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202046.06, "ph": "X", "cat": "fee", "dur": 139688.98, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341737.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576341737.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202038.0, "ph": "X", "cat": "fee", "dur": 139699.08, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341738.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576341738.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576202017.06, "ph": "X", "cat": "fee", "dur": 139721.96, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341740.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576341740.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576341740.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341739.04, "ph": "X", "cat": "fee", "dur": 2.0, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341741.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341741.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576341741.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341741.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202014.0, "ph": "X", "cat": "fee", "dur": 139728.02, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341743.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341743.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341743.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341743.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576341744.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576341743.12, "ph": "X", "cat": "fee", "dur": 0.92, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341744.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576341744.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576341744.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341742.04, "ph": "X", "cat": "fee", "dur": 2.14, "name": "_lock_unlock_module (<frozen importlib._bootstrap>:203)"}, {"pid": 20956, "tid": 2192355, "ts": 253576202013.08, "ph": "X", "cat": "fee", "dur": 139731.12, "name": "builtins.__import__"}, {"pid": 20956, "tid": 2192355, "ts": 253576202013.06, "ph": "X", "cat": "fee", "dur": 139731.94, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341745.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576341745.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341745.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576341745.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341746.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "str.format"}, {"pid": 20956, "tid": 2192355, "ts": 253576341748.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341748.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341749.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341749.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341749.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341750.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341748.08, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341750.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576341751.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576341750.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341748.06, "ph": "X", "cat": "fee", "dur": 3.0, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341751.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576341751.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576341752.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341752.02, "ph": "X", "cat": "fee", "dur": 1.0, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341753.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341753.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341753.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341753.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341753.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341754.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_frozen"}, {"pid": 20956, "tid": 2192355, "ts": 253576341754.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341754.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341754.1, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341754.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341754.18, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341755.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576341755.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341756.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341756.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576341756.14, "ph": "X", "cat": "fee", "dur": 9.86, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576341756.12, "ph": "X", "cat": "fee", "dur": 9.9, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341767.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341768.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341768.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341768.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341768.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576341767.04, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341769.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341770.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341770.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341769.1, "ph": "X", "cat": "fee", "dur": 0.98, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341770.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576341769.08, "ph": "X", "cat": "fee", "dur": 1.06, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341770.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341771.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341771.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341771.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341771.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576341771.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341771.2, "ph": "X", "cat": "fee", "dur": 0.8, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341772.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341772.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341772.04, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341772.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576341772.02, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341772.22, "ph": "X", "cat": "fee", "dur": 0.78, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341773.08, "ph": "X", "cat": "fee", "dur": 16.92, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576341773.06, "ph": "X", "cat": "fee", "dur": 16.96, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341773.04, "ph": "X", "cat": "fee", "dur": 17.96, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341773.02, "ph": "X", "cat": "fee", "dur": 18.0, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341791.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap_external>:1006)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341792.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576341792.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:351)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341792.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "spec_from_file_location (<frozen importlib._bootstrap_external>:696)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341791.04, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_get_spec (<frozen importlib._bootstrap_external>:1500)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341756.06, "ph": "X", "cat": "fee", "dur": 36.98, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341755.02, "ph": "X", "cat": "fee", "dur": 38.04, "name": "_get_spec (<frozen importlib._bootstrap_external>:1374)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341755.0, "ph": "X", "cat": "fee", "dur": 38.08, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341794.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341793.1, "ph": "X", "cat": "fee", "dur": 0.94, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341752.0, "ph": "X", "cat": "fee", "dur": 42.06, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341794.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341795.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341795.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "create_module (<frozen importlib._bootstrap_external>:841)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341795.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_new_module (<frozen importlib._bootstrap>:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341795.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341796.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341796.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341796.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576341796.1, "ph": "X", "cat": "fee", "dur": 0.06, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341797.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341798.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "has_location (<frozen importlib._bootstrap>:406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341798.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341798.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341799.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "str.endswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576341800.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576341800.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341801.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341800.1, "ph": "X", "cat": "fee", "dur": 0.96, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576341800.08, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341801.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576341802.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576341803.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341803.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341803.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341803.02, "ph": "X", "cat": "fee", "dur": 0.14, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341803.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576341803.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341800.02, "ph": "X", "cat": "fee", "dur": 4.0, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341799.04, "ph": "X", "cat": "fee", "dur": 5.0, "name": "_get_cached (<frozen importlib._bootstrap_external>:491)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341799.02, "ph": "X", "cat": "fee", "dur": 5.04, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341804.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341795.12, "ph": "X", "cat": "fee", "dur": 9.0, "name": "_init_module_attrs (<frozen importlib._bootstrap>:486)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341794.14, "ph": "X", "cat": "fee", "dur": 10.0, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341805.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "get_filename (<frozen importlib._bootstrap_external>:1031)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341805.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "_check_name_wrapper (<frozen importlib._bootstrap_external>:523)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341806.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576341806.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rfind"}, {"pid": 20956, "tid": 2192355, "ts": 253576341806.1, "ph": "X", "cat": "fee", "dur": 0.06, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341806.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341806.08, "ph": "X", "cat": "fee", "dur": 0.14, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576341806.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341807.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576341807.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576341808.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341808.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341808.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341808.02, "ph": "X", "cat": "fee", "dur": 0.14, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341808.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576341808.0, "ph": "X", "cat": "fee", "dur": 0.22, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341806.0, "ph": "X", "cat": "fee", "dur": 2.24, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341809.04, "ph": "X", "cat": "fee", "dur": 1.96, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576341809.02, "ph": "X", "cat": "fee", "dur": 2.98, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341809.0, "ph": "X", "cat": "fee", "dur": 3.02, "name": "path_stats (<frozen importlib._bootstrap_external>:1077)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341812.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576341813.0, "ph": "X", "cat": "fee", "dur": 26.0, "name": "io.open_code"}, {"pid": 20956, "tid": 2192355, "ts": 253576341839.02, "ph": "X", "cat": "fee", "dur": 2.98, "name": "_io.BufferedReader.read"}, {"pid": 20956, "tid": 2192355, "ts": 253576341842.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_io.BufferedReader.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576341812.04, "ph": "X", "cat": "fee", "dur": 30.98, "name": "get_data (<frozen importlib._bootstrap_external>:1036)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341844.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576341845.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576341845.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576341844.06, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341844.0, "ph": "X", "cat": "fee", "dur": 1.1, "name": "_classify_pyc (<frozen importlib._bootstrap_external>:560)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341846.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576341846.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576341846.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341846.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576341847.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576341846.14, "ph": "X", "cat": "fee", "dur": 0.9, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341846.0, "ph": "X", "cat": "fee", "dur": 1.06, "name": "_validate_timestamp_pyc (<frozen importlib._bootstrap_external>:593)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341847.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341847.14, "ph": "X", "cat": "fee", "dur": 14.86, "name": "marshal.loads"}, {"pid": 20956, "tid": 2192355, "ts": 253576341862.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576341862.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341862.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp._fix_co_filename"}, {"pid": 20956, "tid": 2192355, "ts": 253576341847.12, "ph": "X", "cat": "fee", "dur": 15.02, "name": "_compile_bytecode (<frozen importlib._bootstrap_external>:645)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341805.02, "ph": "X", "cat": "fee", "dur": 57.98, "name": "get_code (<frozen importlib._bootstrap_external>:916)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341865.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341866.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341865.02, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341866.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576341867.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576341866.06, "ph": "X", "cat": "fee", "dur": 0.98, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341867.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576341867.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576341867.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341865.0, "ph": "X", "cat": "fee", "dur": 3.0, "name": "_lock_unlock_module (<frozen importlib._bootstrap>:203)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341868.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576341868.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341868.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341864.0, "ph": "X", "cat": "fee", "dur": 7.0, "name": "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/greedy_ils.py:1)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341863.04, "ph": "X", "cat": "fee", "dur": 7.98, "name": "builtins.exec"}, {"pid": 20956, "tid": 2192355, "ts": 253576341863.02, "ph": "X", "cat": "fee", "dur": 8.02, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341805.0, "ph": "X", "cat": "fee", "dur": 66.06, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341871.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576341872.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341794.08, "ph": "X", "cat": "fee", "dur": 77.96, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341872.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576341872.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341751.12, "ph": "X", "cat": "fee", "dur": 121.9, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341873.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576341873.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576341873.06, "ph": "X", "cat": "fee", "dur": 0.96, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341873.04, "ph": "X", "cat": "fee", "dur": 1.0, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341874.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341874.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576341874.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341874.06, "ph": "X", "cat": "fee", "dur": 0.14, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341748.0, "ph": "X", "cat": "fee", "dur": 127.0, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341875.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341875.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341875.04, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341875.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576341876.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576341875.16, "ph": "X", "cat": "fee", "dur": 0.88, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341876.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576341876.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576341876.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341875.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_lock_unlock_module (<frozen importlib._bootstrap>:203)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341747.04, "ph": "X", "cat": "fee", "dur": 129.98, "name": "builtins.__import__"}, {"pid": 20956, "tid": 2192355, "ts": 253576341747.02, "ph": "X", "cat": "fee", "dur": 130.02, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341877.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576341877.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341878.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.format"}, {"pid": 20956, "tid": 2192355, "ts": 253576341879.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341879.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341880.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341880.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341880.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341881.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341879.08, "ph": "X", "cat": "fee", "dur": 1.96, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341881.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576341882.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576341881.06, "ph": "X", "cat": "fee", "dur": 0.98, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341879.06, "ph": "X", "cat": "fee", "dur": 3.0, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341882.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576341882.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576341883.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341883.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341883.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341884.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341884.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341884.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341884.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341884.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_frozen"}, {"pid": 20956, "tid": 2192355, "ts": 253576341884.16, "ph": "X", "cat": "fee", "dur": 0.06, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341885.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341885.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341885.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341885.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341885.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576341886.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341886.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341886.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576341887.02, "ph": "X", "cat": "fee", "dur": 2.98, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576341887.0, "ph": "X", "cat": "fee", "dur": 3.02, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341890.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341891.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341891.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341891.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341892.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576341891.0, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341892.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341893.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341893.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341893.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341893.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576341893.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341893.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341894.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341894.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341894.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341894.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576341894.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341894.2, "ph": "X", "cat": "fee", "dur": 0.8, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341895.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341895.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341895.04, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341895.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576341895.02, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341895.22, "ph": "X", "cat": "fee", "dur": 0.78, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341896.08, "ph": "X", "cat": "fee", "dur": 7.92, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576341896.06, "ph": "X", "cat": "fee", "dur": 7.96, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341896.04, "ph": "X", "cat": "fee", "dur": 8.0, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341896.02, "ph": "X", "cat": "fee", "dur": 8.98, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341905.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap_external>:1006)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341905.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576341906.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:351)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341905.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "spec_from_file_location (<frozen importlib._bootstrap_external>:696)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341905.02, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_get_spec (<frozen importlib._bootstrap_external>:1500)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341886.08, "ph": "X", "cat": "fee", "dur": 20.92, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341885.18, "ph": "X", "cat": "fee", "dur": 21.84, "name": "_get_spec (<frozen importlib._bootstrap_external>:1374)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341885.16, "ph": "X", "cat": "fee", "dur": 21.88, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341907.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341907.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341883.0, "ph": "X", "cat": "fee", "dur": 24.14, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341908.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341908.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341908.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "create_module (<frozen importlib._bootstrap_external>:841)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341908.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "_new_module (<frozen importlib._bootstrap>:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341909.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341909.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341909.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341910.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576341909.16, "ph": "X", "cat": "fee", "dur": 0.88, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341910.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341911.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "has_location (<frozen importlib._bootstrap>:406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341911.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341912.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341913.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.endswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576341913.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576341913.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341914.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341913.12, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576341913.1, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341914.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576341915.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576341916.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341916.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341916.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341916.0, "ph": "X", "cat": "fee", "dur": 0.14, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341916.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576341915.06, "ph": "X", "cat": "fee", "dur": 1.14, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341913.04, "ph": "X", "cat": "fee", "dur": 3.18, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341912.06, "ph": "X", "cat": "fee", "dur": 4.94, "name": "_get_cached (<frozen importlib._bootstrap_external>:491)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341912.04, "ph": "X", "cat": "fee", "dur": 4.98, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341917.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341909.02, "ph": "X", "cat": "fee", "dur": 8.06, "name": "_init_module_attrs (<frozen importlib._bootstrap>:486)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341908.06, "ph": "X", "cat": "fee", "dur": 9.04, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341918.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "get_filename (<frozen importlib._bootstrap_external>:1031)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341918.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "_check_name_wrapper (<frozen importlib._bootstrap_external>:523)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341918.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576341919.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rfind"}, {"pid": 20956, "tid": 2192355, "ts": 253576341919.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341919.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341918.16, "ph": "X", "cat": "fee", "dur": 0.96, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576341918.14, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341919.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576341920.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576341920.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341920.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341920.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341920.06, "ph": "X", "cat": "fee", "dur": 0.14, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341921.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576341920.04, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341918.08, "ph": "X", "cat": "fee", "dur": 2.98, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341921.12, "ph": "X", "cat": "fee", "dur": 2.88, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576341921.1, "ph": "X", "cat": "fee", "dur": 2.92, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341921.08, "ph": "X", "cat": "fee", "dur": 2.96, "name": "path_stats (<frozen importlib._bootstrap_external>:1077)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341924.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576341924.12, "ph": "X", "cat": "fee", "dur": 18.88, "name": "io.open_code"}, {"pid": 20956, "tid": 2192355, "ts": 253576341944.0, "ph": "X", "cat": "fee", "dur": 2.0, "name": "_io.BufferedReader.read"}, {"pid": 20956, "tid": 2192355, "ts": 253576341946.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_io.BufferedReader.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576341924.06, "ph": "X", "cat": "fee", "dur": 22.96, "name": "get_data (<frozen importlib._bootstrap_external>:1036)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341948.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576341948.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576341949.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576341948.06, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341948.0, "ph": "X", "cat": "fee", "dur": 1.06, "name": "_classify_pyc (<frozen importlib._bootstrap_external>:560)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341949.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576341950.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576341949.1, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341950.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576341950.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576341950.08, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341949.08, "ph": "X", "cat": "fee", "dur": 1.12, "name": "_validate_timestamp_pyc (<frozen importlib._bootstrap_external>:593)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341950.22, "ph": "X", "cat": "fee", "dur": 0.78, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341951.04, "ph": "X", "cat": "fee", "dur": 2.96, "name": "marshal.loads"}, {"pid": 20956, "tid": 2192355, "ts": 253576341954.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576341954.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341955.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp._fix_co_filename"}, {"pid": 20956, "tid": 2192355, "ts": 253576341951.02, "ph": "X", "cat": "fee", "dur": 4.04, "name": "_compile_bytecode (<frozen importlib._bootstrap_external>:645)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341917.14, "ph": "X", "cat": "fee", "dur": 37.94, "name": "get_code (<frozen importlib._bootstrap_external>:916)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341956.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/ordered_greedy_mls.py:1)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341955.12, "ph": "X", "cat": "fee", "dur": 1.9, "name": "builtins.exec"}, {"pid": 20956, "tid": 2192355, "ts": 253576341955.1, "ph": "X", "cat": "fee", "dur": 1.94, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341917.12, "ph": "X", "cat": "fee", "dur": 39.94, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341958.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576341958.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341908.0, "ph": "X", "cat": "fee", "dur": 50.08, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341958.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576341959.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341882.12, "ph": "X", "cat": "fee", "dur": 76.92, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341959.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576341960.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576341959.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341959.06, "ph": "X", "cat": "fee", "dur": 1.0, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341960.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341960.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576341961.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341960.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341879.0, "ph": "X", "cat": "fee", "dur": 82.06, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341961.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341962.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341961.1, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341962.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576341962.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576341962.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341962.2, "ph": "X", "cat": "fee", "dur": 0.8, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576341963.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576341962.18, "ph": "X", "cat": "fee", "dur": 0.88, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341961.08, "ph": "X", "cat": "fee", "dur": 2.0, "name": "_lock_unlock_module (<frozen importlib._bootstrap>:203)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341878.06, "ph": "X", "cat": "fee", "dur": 85.04, "name": "builtins.__import__"}, {"pid": 20956, "tid": 2192355, "ts": 253576341878.04, "ph": "X", "cat": "fee", "dur": 85.08, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341963.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576341963.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341964.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.format"}, {"pid": 20956, "tid": 2192355, "ts": 253576341965.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341966.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341966.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341967.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341966.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341967.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341966.02, "ph": "X", "cat": "fee", "dur": 1.08, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341968.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576341968.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576341968.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341966.0, "ph": "X", "cat": "fee", "dur": 2.12, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341968.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576341969.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576341970.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341969.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341970.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341970.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341970.1, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341970.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341970.18, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341971.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_frozen"}, {"pid": 20956, "tid": 2192355, "ts": 253576341971.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341971.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341971.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341971.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341971.16, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341972.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576341972.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341972.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341972.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576341973.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576341973.0, "ph": "X", "cat": "fee", "dur": 2.02, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341976.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341977.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341977.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341977.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341977.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576341976.04, "ph": "X", "cat": "fee", "dur": 1.12, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341977.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341978.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341978.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341978.04, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341978.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576341978.02, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341979.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341979.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341979.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341979.1, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341979.22, "ph": "X", "cat": "fee", "dur": 0.78, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576341979.08, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341980.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341980.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341980.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341980.1, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341980.22, "ph": "X", "cat": "fee", "dur": 0.78, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576341980.08, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341981.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341981.14, "ph": "X", "cat": "fee", "dur": 7.86, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576341981.12, "ph": "X", "cat": "fee", "dur": 7.9, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341981.1, "ph": "X", "cat": "fee", "dur": 7.94, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341981.08, "ph": "X", "cat": "fee", "dur": 8.92, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341990.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap_external>:1006)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341990.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576341991.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:351)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341990.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "spec_from_file_location (<frozen importlib._bootstrap_external>:696)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341990.02, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_get_spec (<frozen importlib._bootstrap_external>:1500)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341972.14, "ph": "X", "cat": "fee", "dur": 18.94, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341972.0, "ph": "X", "cat": "fee", "dur": 19.1, "name": "_get_spec (<frozen importlib._bootstrap_external>:1374)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341971.24, "ph": "X", "cat": "fee", "dur": 20.76, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341992.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576341992.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341969.06, "ph": "X", "cat": "fee", "dur": 23.04, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341992.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341993.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341993.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "create_module (<frozen importlib._bootstrap_external>:841)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341993.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_new_module (<frozen importlib._bootstrap>:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341993.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341994.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341994.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341994.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576341994.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341994.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341995.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "has_location (<frozen importlib._bootstrap>:406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341995.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341996.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341997.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.endswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576341997.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576341998.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341998.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341997.14, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576341997.12, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341998.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576341999.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576341999.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341999.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576342000.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576341999.06, "ph": "X", "cat": "fee", "dur": 1.0, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342000.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576341999.04, "ph": "X", "cat": "fee", "dur": 1.08, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341997.06, "ph": "X", "cat": "fee", "dur": 3.08, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341997.0, "ph": "X", "cat": "fee", "dur": 3.16, "name": "_get_cached (<frozen importlib._bootstrap_external>:491)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341996.06, "ph": "X", "cat": "fee", "dur": 4.12, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342000.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341993.14, "ph": "X", "cat": "fee", "dur": 7.1, "name": "_init_module_attrs (<frozen importlib._bootstrap>:486)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341993.0, "ph": "X", "cat": "fee", "dur": 8.0, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342001.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "get_filename (<frozen importlib._bootstrap_external>:1031)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342001.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "_check_name_wrapper (<frozen importlib._bootstrap_external>:523)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342002.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576342002.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rfind"}, {"pid": 20956, "tid": 2192355, "ts": 253576342002.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342002.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342002.06, "ph": "X", "cat": "fee", "dur": 0.14, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576342002.04, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342003.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576342003.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576342003.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576342003.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576342004.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576342003.1, "ph": "X", "cat": "fee", "dur": 0.94, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342004.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576342003.08, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342001.14, "ph": "X", "cat": "fee", "dur": 2.98, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342004.18, "ph": "X", "cat": "fee", "dur": 2.82, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576342004.16, "ph": "X", "cat": "fee", "dur": 2.86, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342004.14, "ph": "X", "cat": "fee", "dur": 2.9, "name": "path_stats (<frozen importlib._bootstrap_external>:1077)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342007.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576342008.0, "ph": "X", "cat": "fee", "dur": 24.0, "name": "io.open_code"}, {"pid": 20956, "tid": 2192355, "ts": 253576342032.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_io.BufferedReader.read"}, {"pid": 20956, "tid": 2192355, "ts": 253576342034.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_io.BufferedReader.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576342007.06, "ph": "X", "cat": "fee", "dur": 27.96, "name": "get_data (<frozen importlib._bootstrap_external>:1036)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342036.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576342036.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576342037.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576342036.06, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342036.0, "ph": "X", "cat": "fee", "dur": 1.06, "name": "_classify_pyc (<frozen importlib._bootstrap_external>:560)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342037.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576342037.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576342037.1, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342038.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576342038.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576342038.04, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342037.08, "ph": "X", "cat": "fee", "dur": 1.08, "name": "_validate_timestamp_pyc (<frozen importlib._bootstrap_external>:593)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342038.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342039.04, "ph": "X", "cat": "fee", "dur": 7.96, "name": "marshal.loads"}, {"pid": 20956, "tid": 2192355, "ts": 253576342047.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576342048.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342048.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp._fix_co_filename"}, {"pid": 20956, "tid": 2192355, "ts": 253576342039.02, "ph": "X", "cat": "fee", "dur": 9.06, "name": "_compile_bytecode (<frozen importlib._bootstrap_external>:645)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342001.04, "ph": "X", "cat": "fee", "dur": 47.06, "name": "get_code (<frozen importlib._bootstrap_external>:916)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342049.0, "ph": "X", "cat": "fee", "dur": 2.0, "name": "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/dual_annealing.py:1)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342048.14, "ph": "X", "cat": "fee", "dur": 2.88, "name": "builtins.exec"}, {"pid": 20956, "tid": 2192355, "ts": 253576342048.12, "ph": "X", "cat": "fee", "dur": 2.92, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342001.02, "ph": "X", "cat": "fee", "dur": 50.04, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342052.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576342052.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341992.12, "ph": "X", "cat": "fee", "dur": 59.96, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342053.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576342053.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576341969.0, "ph": "X", "cat": "fee", "dur": 84.08, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342053.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576342054.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576342053.12, "ph": "X", "cat": "fee", "dur": 0.92, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342053.1, "ph": "X", "cat": "fee", "dur": 0.96, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342054.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576342054.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576342055.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576342054.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341965.0, "ph": "X", "cat": "fee", "dur": 90.06, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342056.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576342056.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576342056.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342056.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576342056.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576342056.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342057.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576342057.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576342057.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342055.08, "ph": "X", "cat": "fee", "dur": 2.06, "name": "_lock_unlock_module (<frozen importlib._bootstrap>:203)"}, {"pid": 20956, "tid": 2192355, "ts": 253576341964.08, "ph": "X", "cat": "fee", "dur": 93.08, "name": "builtins.__import__"}, {"pid": 20956, "tid": 2192355, "ts": 253576341964.06, "ph": "X", "cat": "fee", "dur": 93.12, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342057.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576342058.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576342058.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.format"}, {"pid": 20956, "tid": 2192355, "ts": 253576342059.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342060.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576342060.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576342060.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576342060.08, "ph": "X", "cat": "fee", "dur": 0.94, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342061.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576342060.02, "ph": "X", "cat": "fee", "dur": 1.06, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342061.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576342062.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576342061.1, "ph": "X", "cat": "fee", "dur": 0.94, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342060.0, "ph": "X", "cat": "fee", "dur": 2.06, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342062.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576342062.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576342063.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576342063.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342063.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342064.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576342063.14, "ph": "X", "cat": "fee", "dur": 0.9, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342064.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576342064.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342064.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_frozen"}, {"pid": 20956, "tid": 2192355, "ts": 253576342064.14, "ph": "X", "cat": "fee", "dur": 0.06, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342064.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576342064.22, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342065.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576342065.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342065.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576342065.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342065.2, "ph": "X", "cat": "fee", "dur": 0.8, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576342066.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576342066.1, "ph": "X", "cat": "fee", "dur": 2.9, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576342066.08, "ph": "X", "cat": "fee", "dur": 2.94, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342069.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342070.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576342070.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576342070.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342070.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576342070.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342071.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342071.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576342071.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576342071.08, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342071.2, "ph": "X", "cat": "fee", "dur": 0.8, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576342071.06, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342072.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342072.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576342072.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576342072.1, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342073.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576342072.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342073.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342073.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576342073.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576342073.12, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342073.24, "ph": "X", "cat": "fee", "dur": 0.76, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576342073.1, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342074.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342074.14, "ph": "X", "cat": "fee", "dur": 5.86, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576342074.12, "ph": "X", "cat": "fee", "dur": 6.88, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342074.1, "ph": "X", "cat": "fee", "dur": 6.92, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342074.08, "ph": "X", "cat": "fee", "dur": 6.96, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342081.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap_external>:1006)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342082.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576342082.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:351)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342082.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "spec_from_file_location (<frozen importlib._bootstrap_external>:696)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342081.06, "ph": "X", "cat": "fee", "dur": 1.06, "name": "_get_spec (<frozen importlib._bootstrap_external>:1500)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342066.02, "ph": "X", "cat": "fee", "dur": 16.98, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342065.1, "ph": "X", "cat": "fee", "dur": 17.92, "name": "_get_spec (<frozen importlib._bootstrap_external>:1374)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342065.08, "ph": "X", "cat": "fee", "dur": 17.96, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342083.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576342083.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342063.0, "ph": "X", "cat": "fee", "dur": 20.14, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342083.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576342084.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576342084.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "create_module (<frozen importlib._bootstrap_external>:841)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342084.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_new_module (<frozen importlib._bootstrap>:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342084.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576342085.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576342085.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576342085.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576342085.1, "ph": "X", "cat": "fee", "dur": 0.06, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342085.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576342086.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "has_location (<frozen importlib._bootstrap>:406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342086.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576342087.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576342088.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.endswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576342088.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576342088.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342089.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342088.14, "ph": "X", "cat": "fee", "dur": 0.92, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576342088.12, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342089.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576342089.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576342090.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576342090.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576342091.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576342090.04, "ph": "X", "cat": "fee", "dur": 1.0, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342091.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576342090.02, "ph": "X", "cat": "fee", "dur": 1.08, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342088.06, "ph": "X", "cat": "fee", "dur": 3.06, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342088.0, "ph": "X", "cat": "fee", "dur": 3.14, "name": "_get_cached (<frozen importlib._bootstrap_external>:491)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342087.06, "ph": "X", "cat": "fee", "dur": 4.1, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342091.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342084.16, "ph": "X", "cat": "fee", "dur": 7.06, "name": "_init_module_attrs (<frozen importlib._bootstrap>:486)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342084.02, "ph": "X", "cat": "fee", "dur": 7.22, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342092.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "get_filename (<frozen importlib._bootstrap_external>:1031)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342092.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "_check_name_wrapper (<frozen importlib._bootstrap_external>:523)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342092.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576342093.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rfind"}, {"pid": 20956, "tid": 2192355, "ts": 253576342093.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342093.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342093.02, "ph": "X", "cat": "fee", "dur": 0.14, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576342093.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342093.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576342094.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576342094.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576342094.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576342094.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576342094.06, "ph": "X", "cat": "fee", "dur": 0.14, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342095.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576342094.04, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342092.12, "ph": "X", "cat": "fee", "dur": 2.94, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342095.12, "ph": "X", "cat": "fee", "dur": 1.88, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576342095.1, "ph": "X", "cat": "fee", "dur": 1.92, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342095.08, "ph": "X", "cat": "fee", "dur": 2.92, "name": "path_stats (<frozen importlib._bootstrap_external>:1077)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342098.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576342098.08, "ph": "X", "cat": "fee", "dur": 22.92, "name": "io.open_code"}, {"pid": 20956, "tid": 2192355, "ts": 253576342121.02, "ph": "X", "cat": "fee", "dur": 6.98, "name": "_io.BufferedReader.read"}, {"pid": 20956, "tid": 2192355, "ts": 253576342128.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_io.BufferedReader.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576342098.02, "ph": "X", "cat": "fee", "dur": 31.0, "name": "get_data (<frozen importlib._bootstrap_external>:1036)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342130.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576342130.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576342130.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576342130.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342130.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_classify_pyc (<frozen importlib._bootstrap_external>:560)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342131.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576342131.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576342131.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342132.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576342132.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576342132.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342131.04, "ph": "X", "cat": "fee", "dur": 1.08, "name": "_validate_timestamp_pyc (<frozen importlib._bootstrap_external>:593)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342132.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342133.02, "ph": "X", "cat": "fee", "dur": 107.98, "name": "marshal.loads"}, {"pid": 20956, "tid": 2192355, "ts": 253576342242.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576342242.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342242.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp._fix_co_filename"}, {"pid": 20956, "tid": 2192355, "ts": 253576342133.0, "ph": "X", "cat": "fee", "dur": 109.12, "name": "_compile_bytecode (<frozen importlib._bootstrap_external>:645)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342092.02, "ph": "X", "cat": "fee", "dur": 150.12, "name": "get_code (<frozen importlib._bootstrap_external>:916)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342248.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576342248.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576342248.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342249.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576342249.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576342249.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342251.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576342251.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576342251.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342252.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576342252.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576342252.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342252.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576342253.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576342252.14, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342253.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576342254.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576342253.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342254.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576342255.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576342254.06, "ph": "X", "cat": "fee", "dur": 0.98, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342252.12, "ph": "X", "cat": "fee", "dur": 2.94, "name": "_lock_unlock_module (<frozen importlib._bootstrap>:203)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342255.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576342255.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576342255.08, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342257.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "inner (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:271)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342260.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "property.setter"}, {"pid": 20956, "tid": 2192355, "ts": 253576342262.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "inner (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:271)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342263.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "inner (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:271)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342264.04, "ph": "X", "cat": "fee", "dur": 11.96, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:908)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342264.02, "ph": "X", "cat": "fee", "dur": 12.0, "name": "inner (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:271)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342277.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "inner (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:271)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342259.0, "ph": "X", "cat": "fee", "dur": 21.0, "name": "BayesianOptimization (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_old.py:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342258.0, "ph": "X", "cat": "fee", "dur": 28.0, "name": "builtins.__build_class__"}, {"pid": 20956, "tid": 2192355, "ts": 253576342243.04, "ph": "X", "cat": "fee", "dur": 42.98, "name": "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_old.py:1)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342243.02, "ph": "X", "cat": "fee", "dur": 43.02, "name": "builtins.exec"}, {"pid": 20956, "tid": 2192355, "ts": 253576342243.0, "ph": "X", "cat": "fee", "dur": 43.06, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342092.0, "ph": "X", "cat": "fee", "dur": 195.0, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342288.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576342289.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342083.16, "ph": "X", "cat": "fee", "dur": 205.88, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342289.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576342290.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576342062.12, "ph": "X", "cat": "fee", "dur": 227.94, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342290.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576342291.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576342290.1, "ph": "X", "cat": "fee", "dur": 0.94, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342290.08, "ph": "X", "cat": "fee", "dur": 0.98, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342291.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576342291.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576342292.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576342291.08, "ph": "X", "cat": "fee", "dur": 0.98, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342059.04, "ph": "X", "cat": "fee", "dur": 233.04, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342293.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576342293.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576342293.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342293.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576342294.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576342293.14, "ph": "X", "cat": "fee", "dur": 0.9, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342294.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576342294.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576342294.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342293.0, "ph": "X", "cat": "fee", "dur": 1.18, "name": "_lock_unlock_module (<frozen importlib._bootstrap>:203)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342059.02, "ph": "X", "cat": "fee", "dur": 235.18, "name": "builtins.__import__"}, {"pid": 20956, "tid": 2192355, "ts": 253576342059.0, "ph": "X", "cat": "fee", "dur": 235.22, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342295.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576342295.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576342296.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.format"}, {"pid": 20956, "tid": 2192355, "ts": 253576342297.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342297.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576342298.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576342298.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576342298.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342299.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576342297.08, "ph": "X", "cat": "fee", "dur": 1.96, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342299.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576342299.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576342299.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342297.06, "ph": "X", "cat": "fee", "dur": 2.96, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342300.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576342300.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576342301.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576342301.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342301.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342302.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576342302.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342302.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576342302.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342302.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_frozen"}, {"pid": 20956, "tid": 2192355, "ts": 253576342302.16, "ph": "X", "cat": "fee", "dur": 0.06, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342303.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576342303.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342303.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576342303.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342303.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576342304.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342304.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576342304.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576342304.16, "ph": "X", "cat": "fee", "dur": 3.84, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576342304.14, "ph": "X", "cat": "fee", "dur": 3.88, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342308.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342309.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576342309.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576342309.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342309.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576342309.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342310.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342310.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576342311.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576342310.1, "ph": "X", "cat": "fee", "dur": 0.94, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342311.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576342310.08, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342311.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342311.2, "ph": "X", "cat": "fee", "dur": 0.8, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576342312.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576342311.18, "ph": "X", "cat": "fee", "dur": 0.88, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342312.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576342311.16, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342312.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342312.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576342313.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576342312.2, "ph": "X", "cat": "fee", "dur": 0.84, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342313.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576342312.18, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342313.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342313.22, "ph": "X", "cat": "fee", "dur": 6.78, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576342313.2, "ph": "X", "cat": "fee", "dur": 6.82, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342313.18, "ph": "X", "cat": "fee", "dur": 6.86, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342313.16, "ph": "X", "cat": "fee", "dur": 6.9, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342320.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "__init__ (<frozen importlib._bootstrap_external>:1006)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342321.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576342321.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "__init__ (<frozen importlib._bootstrap>:351)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342321.02, "ph": "X", "cat": "fee", "dur": 1.0, "name": "spec_from_file_location (<frozen importlib._bootstrap_external>:696)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342320.08, "ph": "X", "cat": "fee", "dur": 1.96, "name": "_get_spec (<frozen importlib._bootstrap_external>:1500)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342304.08, "ph": "X", "cat": "fee", "dur": 17.98, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342303.18, "ph": "X", "cat": "fee", "dur": 18.9, "name": "_get_spec (<frozen importlib._bootstrap_external>:1374)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342303.16, "ph": "X", "cat": "fee", "dur": 18.94, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342323.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576342323.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342301.0, "ph": "X", "cat": "fee", "dur": 22.08, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342323.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576342324.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576342324.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "create_module (<frozen importlib._bootstrap_external>:841)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342324.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_new_module (<frozen importlib._bootstrap>:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342324.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576342325.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576342325.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576342325.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576342325.1, "ph": "X", "cat": "fee", "dur": 0.06, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342326.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576342326.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "has_location (<frozen importlib._bootstrap>:406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342326.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576342327.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576342328.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.endswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576342329.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576342329.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342329.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342329.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576342329.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342330.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576342330.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576342331.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576342331.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576342332.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576342331.02, "ph": "X", "cat": "fee", "dur": 1.02, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342332.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576342331.0, "ph": "X", "cat": "fee", "dur": 1.1, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342328.1, "ph": "X", "cat": "fee", "dur": 4.02, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342328.04, "ph": "X", "cat": "fee", "dur": 4.1, "name": "_get_cached (<frozen importlib._bootstrap_external>:491)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342328.02, "ph": "X", "cat": "fee", "dur": 4.14, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342332.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342324.14, "ph": "X", "cat": "fee", "dur": 8.08, "name": "_init_module_attrs (<frozen importlib._bootstrap>:486)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342324.0, "ph": "X", "cat": "fee", "dur": 9.0, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342333.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "get_filename (<frozen importlib._bootstrap_external>:1031)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342333.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "_check_name_wrapper (<frozen importlib._bootstrap_external>:523)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342334.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576342334.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rfind"}, {"pid": 20956, "tid": 2192355, "ts": 253576342334.1, "ph": "X", "cat": "fee", "dur": 0.06, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342334.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342334.08, "ph": "X", "cat": "fee", "dur": 0.14, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576342334.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342335.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576342335.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576342336.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576342336.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576342336.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576342336.0, "ph": "X", "cat": "fee", "dur": 0.14, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342336.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576342335.1, "ph": "X", "cat": "fee", "dur": 1.1, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342334.0, "ph": "X", "cat": "fee", "dur": 2.22, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342336.28, "ph": "X", "cat": "fee", "dur": 2.72, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576342336.26, "ph": "X", "cat": "fee", "dur": 2.76, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342336.24, "ph": "X", "cat": "fee", "dur": 2.8, "name": "path_stats (<frozen importlib._bootstrap_external>:1077)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342340.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576342340.06, "ph": "X", "cat": "fee", "dur": 20.94, "name": "io.open_code"}, {"pid": 20956, "tid": 2192355, "ts": 253576342361.02, "ph": "X", "cat": "fee", "dur": 3.98, "name": "_io.BufferedReader.read"}, {"pid": 20956, "tid": 2192355, "ts": 253576342365.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_io.BufferedReader.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576342340.0, "ph": "X", "cat": "fee", "dur": 27.0, "name": "get_data (<frozen importlib._bootstrap_external>:1036)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342367.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576342367.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576342368.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576342367.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342367.02, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_classify_pyc (<frozen importlib._bootstrap_external>:560)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342369.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576342369.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576342369.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342369.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576342369.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576342369.12, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342368.08, "ph": "X", "cat": "fee", "dur": 1.16, "name": "_validate_timestamp_pyc (<frozen importlib._bootstrap_external>:593)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342370.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342370.06, "ph": "X", "cat": "fee", "dur": 101.94, "name": "marshal.loads"}, {"pid": 20956, "tid": 2192355, "ts": 253576342472.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576342472.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342473.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp._fix_co_filename"}, {"pid": 20956, "tid": 2192355, "ts": 253576342370.04, "ph": "X", "cat": "fee", "dur": 103.02, "name": "_compile_bytecode (<frozen importlib._bootstrap_external>:645)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342333.04, "ph": "X", "cat": "fee", "dur": 140.04, "name": "get_code (<frozen importlib._bootstrap_external>:916)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342477.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576342477.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576342477.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342480.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342480.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576342481.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342482.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576342480.08, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342482.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576342483.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576342482.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342480.06, "ph": "X", "cat": "fee", "dur": 3.0, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342483.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576342484.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576342485.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342485.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342486.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342486.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342486.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342487.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342487.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342487.1, "ph": "X", "cat": "fee", "dur": 61.9, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342549.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342484.08, "ph": "X", "cat": "fee", "dur": 64.98, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342550.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576342550.04, "ph": "X", "cat": "fee", "dur": 6.96, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342558.0, "ph": "X", "cat": "fee", "dur": 24987.0, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367546.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576367547.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342549.08, "ph": "X", "cat": "fee", "dur": 24997.96, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342484.02, "ph": "X", "cat": "fee", "dur": 25063.04, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367547.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576367548.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576367547.1, "ph": "X", "cat": "fee", "dur": 0.94, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367547.08, "ph": "X", "cat": "fee", "dur": 0.98, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367548.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576367548.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576367549.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576367548.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342480.0, "ph": "X", "cat": "fee", "dur": 25069.06, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367552.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576367552.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576367552.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367553.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576367553.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576367553.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367554.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576367554.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576367554.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367555.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576367555.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576367555.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367555.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576367556.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576367555.14, "ph": "X", "cat": "fee", "dur": 0.92, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367554.0, "ph": "X", "cat": "fee", "dur": 2.08, "name": "_lock_unlock_module (<frozen importlib._bootstrap>:203)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367556.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576367556.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576367556.1, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367557.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "inner (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:271)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367559.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "ExactGPModel (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch.py:140)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367559.0, "ph": "X", "cat": "fee", "dur": 10.0, "name": "builtins.__build_class__"}, {"pid": 20956, "tid": 2192355, "ts": 253576367571.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "property.setter"}, {"pid": 20956, "tid": 2192355, "ts": 253576367573.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "inner (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:271)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367575.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "inner (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:271)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367575.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "inner (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:271)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367578.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "inner (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:271)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367569.04, "ph": "X", "cat": "fee", "dur": 10.96, "name": "BayesianOptimization (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch.py:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367569.02, "ph": "X", "cat": "fee", "dur": 16.98, "name": "builtins.__build_class__"}, {"pid": 20956, "tid": 2192355, "ts": 253576342474.04, "ph": "X", "cat": "fee", "dur": 25112.96, "name": "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch.py:1)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342474.02, "ph": "X", "cat": "fee", "dur": 25113.0, "name": "builtins.exec"}, {"pid": 20956, "tid": 2192355, "ts": 253576342474.0, "ph": "X", "cat": "fee", "dur": 25113.04, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342333.02, "ph": "X", "cat": "fee", "dur": 25254.04, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367589.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576367589.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342323.1, "ph": "X", "cat": "fee", "dur": 25266.9, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367590.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576367590.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576342300.08, "ph": "X", "cat": "fee", "dur": 25290.94, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367591.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576367591.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576367591.06, "ph": "X", "cat": "fee", "dur": 0.96, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367591.04, "ph": "X", "cat": "fee", "dur": 1.0, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367592.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576367592.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576367592.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576367592.06, "ph": "X", "cat": "fee", "dur": 0.14, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342297.0, "ph": "X", "cat": "fee", "dur": 25296.0, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367593.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576367593.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576367593.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367594.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576367594.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576367594.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367594.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576367595.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576367594.14, "ph": "X", "cat": "fee", "dur": 0.9, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367593.02, "ph": "X", "cat": "fee", "dur": 2.04, "name": "_lock_unlock_module (<frozen importlib._bootstrap>:203)"}, {"pid": 20956, "tid": 2192355, "ts": 253576342296.06, "ph": "X", "cat": "fee", "dur": 25299.02, "name": "builtins.__import__"}, {"pid": 20956, "tid": 2192355, "ts": 253576342296.04, "ph": "X", "cat": "fee", "dur": 25299.06, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367595.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576367596.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576367596.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "str.format"}, {"pid": 20956, "tid": 2192355, "ts": 253576367598.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367598.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576367599.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576367599.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576367599.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367600.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576367598.08, "ph": "X", "cat": "fee", "dur": 1.96, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367600.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576367600.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576367600.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367598.06, "ph": "X", "cat": "fee", "dur": 2.96, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367601.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576367601.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576367602.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576367602.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367602.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367603.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576367602.14, "ph": "X", "cat": "fee", "dur": 0.9, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367603.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576367603.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367603.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_frozen"}, {"pid": 20956, "tid": 2192355, "ts": 253576367603.14, "ph": "X", "cat": "fee", "dur": 0.06, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367604.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576367604.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367604.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576367604.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367604.2, "ph": "X", "cat": "fee", "dur": 0.8, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576367605.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367605.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576367605.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576367606.04, "ph": "X", "cat": "fee", "dur": 3.96, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576367606.02, "ph": "X", "cat": "fee", "dur": 4.0, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367610.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367611.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576367612.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576367611.04, "ph": "X", "cat": "fee", "dur": 1.0, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367612.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576367611.02, "ph": "X", "cat": "fee", "dur": 1.08, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367612.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367613.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576367613.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576367613.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367613.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576367613.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367614.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367614.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576367614.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576367614.08, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367614.2, "ph": "X", "cat": "fee", "dur": 0.8, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576367614.06, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367615.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367615.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576367615.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576367615.1, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367615.22, "ph": "X", "cat": "fee", "dur": 0.78, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576367615.08, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367616.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367616.14, "ph": "X", "cat": "fee", "dur": 10.86, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576367616.12, "ph": "X", "cat": "fee", "dur": 10.9, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367616.1, "ph": "X", "cat": "fee", "dur": 11.9, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367616.08, "ph": "X", "cat": "fee", "dur": 11.94, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367628.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap_external>:1006)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367629.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576367629.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:351)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367629.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "spec_from_file_location (<frozen importlib._bootstrap_external>:696)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367628.04, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_get_spec (<frozen importlib._bootstrap_external>:1500)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367605.1, "ph": "X", "cat": "fee", "dur": 24.94, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367604.18, "ph": "X", "cat": "fee", "dur": 25.88, "name": "_get_spec (<frozen importlib._bootstrap_external>:1374)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367604.16, "ph": "X", "cat": "fee", "dur": 25.92, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367631.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576367631.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367602.0, "ph": "X", "cat": "fee", "dur": 29.08, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367631.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576367632.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576367632.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "create_module (<frozen importlib._bootstrap_external>:841)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367632.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_new_module (<frozen importlib._bootstrap>:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367632.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576367633.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576367633.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576367633.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576367633.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367634.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576367634.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "has_location (<frozen importlib._bootstrap>:406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367635.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576367635.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576367636.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.endswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576367637.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576367637.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367638.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367637.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576367637.06, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367638.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576367639.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576367640.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576367640.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576367640.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576367640.0, "ph": "X", "cat": "fee", "dur": 0.14, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367640.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576367639.04, "ph": "X", "cat": "fee", "dur": 1.16, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367637.0, "ph": "X", "cat": "fee", "dur": 3.22, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367636.04, "ph": "X", "cat": "fee", "dur": 4.96, "name": "_get_cached (<frozen importlib._bootstrap_external>:491)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367636.02, "ph": "X", "cat": "fee", "dur": 5.0, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367641.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367632.12, "ph": "X", "cat": "fee", "dur": 8.96, "name": "_init_module_attrs (<frozen importlib._bootstrap>:486)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367631.16, "ph": "X", "cat": "fee", "dur": 9.94, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367642.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "get_filename (<frozen importlib._bootstrap_external>:1031)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367642.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "_check_name_wrapper (<frozen importlib._bootstrap_external>:523)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367643.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576367643.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rfind"}, {"pid": 20956, "tid": 2192355, "ts": 253576367643.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367643.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367643.06, "ph": "X", "cat": "fee", "dur": 0.14, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576367643.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367644.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576367644.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576367645.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576367645.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576367645.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576367644.12, "ph": "X", "cat": "fee", "dur": 1.0, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367645.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576367644.1, "ph": "X", "cat": "fee", "dur": 1.08, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367642.12, "ph": "X", "cat": "fee", "dur": 3.08, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367646.0, "ph": "X", "cat": "fee", "dur": 2.0, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576367645.24, "ph": "X", "cat": "fee", "dur": 2.78, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367645.22, "ph": "X", "cat": "fee", "dur": 2.82, "name": "path_stats (<frozen importlib._bootstrap_external>:1077)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367649.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576367649.06, "ph": "X", "cat": "fee", "dur": 20.94, "name": "io.open_code"}, {"pid": 20956, "tid": 2192355, "ts": 253576367670.02, "ph": "X", "cat": "fee", "dur": 7.98, "name": "_io.BufferedReader.read"}, {"pid": 20956, "tid": 2192355, "ts": 253576367678.02, "ph": "X", "cat": "fee", "dur": 2.98, "name": "_io.BufferedReader.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576367649.0, "ph": "X", "cat": "fee", "dur": 32.02, "name": "get_data (<frozen importlib._bootstrap_external>:1036)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367682.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576367682.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576367683.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576367682.06, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367682.0, "ph": "X", "cat": "fee", "dur": 1.06, "name": "_classify_pyc (<frozen importlib._bootstrap_external>:560)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367684.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576367684.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576367684.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367684.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576367684.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576367684.12, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367683.08, "ph": "X", "cat": "fee", "dur": 1.16, "name": "_validate_timestamp_pyc (<frozen importlib._bootstrap_external>:593)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367685.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367685.06, "ph": "X", "cat": "fee", "dur": 121.94, "name": "marshal.loads"}, {"pid": 20956, "tid": 2192355, "ts": 253576367807.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576367807.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367808.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp._fix_co_filename"}, {"pid": 20956, "tid": 2192355, "ts": 253576367685.04, "ph": "X", "cat": "fee", "dur": 123.02, "name": "_compile_bytecode (<frozen importlib._bootstrap_external>:645)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367642.02, "ph": "X", "cat": "fee", "dur": 166.06, "name": "get_code (<frozen importlib._bootstrap_external>:916)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367815.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576367815.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576367815.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367816.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367817.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576367818.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367819.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576367817.04, "ph": "X", "cat": "fee", "dur": 2.0, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367819.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576367820.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576367819.06, "ph": "X", "cat": "fee", "dur": 0.98, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367817.02, "ph": "X", "cat": "fee", "dur": 3.04, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367820.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576367820.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576367821.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367821.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367822.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367822.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367823.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367823.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367823.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367824.0, "ph": "X", "cat": "fee", "dur": 59.0, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367884.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367821.0, "ph": "X", "cat": "fee", "dur": 63.04, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367885.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576367885.04, "ph": "X", "cat": "fee", "dur": 7.96, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367893.02, "ph": "X", "cat": "fee", "dur": 604926.98, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972825.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576972825.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367884.06, "ph": "X", "cat": "fee", "dur": 604941.94, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367820.12, "ph": "X", "cat": "fee", "dur": 605005.9, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972826.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576972828.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576972826.06, "ph": "X", "cat": "fee", "dur": 1.98, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972826.04, "ph": "X", "cat": "fee", "dur": 2.02, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972829.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576972829.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576972829.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576972829.0, "ph": "X", "cat": "fee", "dur": 0.14, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367816.0, "ph": "X", "cat": "fee", "dur": 605014.0, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972834.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576972834.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576972834.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972837.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "ExactGPModel (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:89)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972836.0, "ph": "X", "cat": "fee", "dur": 14.0, "name": "builtins.__build_class__"}, {"pid": 20956, "tid": 2192355, "ts": 253576972856.02, "ph": "X", "cat": "fee", "dur": 11.98, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:908)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972856.0, "ph": "X", "cat": "fee", "dur": 12.02, "name": "inner (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:271)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972870.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "inner (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:271)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972872.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "inner (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:271)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972873.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "inner (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:271)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972874.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "inner (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:271)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972874.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "inner (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:271)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972875.02, "ph": "X", "cat": "fee", "dur": 7.98, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:908)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972875.0, "ph": "X", "cat": "fee", "dur": 9.0, "name": "inner (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:271)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972850.04, "ph": "X", "cat": "fee", "dur": 33.98, "name": "BayesianOptimization (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:105)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972850.02, "ph": "X", "cat": "fee", "dur": 40.98, "name": "builtins.__build_class__"}, {"pid": 20956, "tid": 2192355, "ts": 253576972892.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "CustomWarning (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:928)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972892.0, "ph": "X", "cat": "fee", "dur": 9.0, "name": "builtins.__build_class__"}, {"pid": 20956, "tid": 2192355, "ts": 253576972901.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "AvoidedLossSurgeWarning (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:942)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972901.02, "ph": "X", "cat": "fee", "dur": 10.98, "name": "builtins.__build_class__"}, {"pid": 20956, "tid": 2192355, "ts": 253576972913.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "NotPSDTrainingWarning (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:948)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972912.02, "ph": "X", "cat": "fee", "dur": 7.98, "name": "builtins.__build_class__"}, {"pid": 20956, "tid": 2192355, "ts": 253576972921.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "NaNTrainingWarning (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:954)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972920.02, "ph": "X", "cat": "fee", "dur": 5.98, "name": "builtins.__build_class__"}, {"pid": 20956, "tid": 2192355, "ts": 253576972926.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "NaNPredictionWarning (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:960)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972926.02, "ph": "X", "cat": "fee", "dur": 5.98, "name": "builtins.__build_class__"}, {"pid": 20956, "tid": 2192355, "ts": 253576972932.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "NotPSDPredictionWarning (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:966)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972932.02, "ph": "X", "cat": "fee", "dur": 4.98, "name": "builtins.__build_class__"}, {"pid": 20956, "tid": 2192355, "ts": 253576972938.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "ResetModelWarning (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:972)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972937.02, "ph": "X", "cat": "fee", "dur": 5.98, "name": "builtins.__build_class__"}, {"pid": 20956, "tid": 2192355, "ts": 253576972943.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "MultipleMinimaWarning (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:978)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972943.02, "ph": "X", "cat": "fee", "dur": 4.98, "name": "builtins.__build_class__"}, {"pid": 20956, "tid": 2192355, "ts": 253576367809.04, "ph": "X", "cat": "fee", "dur": 605139.96, "name": "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:1)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367809.02, "ph": "X", "cat": "fee", "dur": 605140.0, "name": "builtins.exec"}, {"pid": 20956, "tid": 2192355, "ts": 253576367809.0, "ph": "X", "cat": "fee", "dur": 605140.04, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367642.0, "ph": "X", "cat": "fee", "dur": 605307.06, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972953.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576972954.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367631.1, "ph": "X", "cat": "fee", "dur": 605322.94, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972955.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576972955.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576367601.08, "ph": "X", "cat": "fee", "dur": 605354.94, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972956.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576972957.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576972956.06, "ph": "X", "cat": "fee", "dur": 1.94, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972956.04, "ph": "X", "cat": "fee", "dur": 1.98, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972958.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576972958.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576972958.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576972958.04, "ph": "X", "cat": "fee", "dur": 0.14, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367598.0, "ph": "X", "cat": "fee", "dur": 605361.0, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972960.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576972961.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576972960.02, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972961.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576972962.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576972961.06, "ph": "X", "cat": "fee", "dur": 0.98, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972962.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576972963.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576972962.06, "ph": "X", "cat": "fee", "dur": 0.98, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972960.0, "ph": "X", "cat": "fee", "dur": 3.06, "name": "_lock_unlock_module (<frozen importlib._bootstrap>:203)"}, {"pid": 20956, "tid": 2192355, "ts": 253576367597.04, "ph": "X", "cat": "fee", "dur": 605366.04, "name": "builtins.__import__"}, {"pid": 20956, "tid": 2192355, "ts": 253576367597.02, "ph": "X", "cat": "fee", "dur": 605366.08, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972963.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576972964.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576972965.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.format"}, {"pid": 20956, "tid": 2192355, "ts": 253576972967.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972967.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576972968.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576972969.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.allocate_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576972968.02, "ph": "X", "cat": "fee", "dur": 1.02, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972970.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576972967.08, "ph": "X", "cat": "fee", "dur": 2.96, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972970.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576972970.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576972970.06, "ph": "X", "cat": "fee", "dur": 0.96, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972967.06, "ph": "X", "cat": "fee", "dur": 3.98, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972971.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576972971.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576972972.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576972972.02, "ph": "X", "cat": "fee", "dur": 1.0, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972973.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "find_spec (<frozen importlib._bootstrap>:736)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972973.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576972973.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972974.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576972974.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972974.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.is_frozen"}, {"pid": 20956, "tid": 2192355, "ts": 253576972974.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "find_spec (<frozen importlib._bootstrap>:811)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972974.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576972974.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972975.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576972975.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__enter__ (<frozen importlib._bootstrap>:874)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972976.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576972976.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_path_importer_cache (<frozen importlib._bootstrap_external>:1337)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972976.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576972977.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576972977.08, "ph": "X", "cat": "fee", "dur": 10.92, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576972977.06, "ph": "X", "cat": "fee", "dur": 10.96, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972988.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_relax_case (<frozen importlib._bootstrap_external>:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972990.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576972990.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576972990.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972991.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576972990.0, "ph": "X", "cat": "fee", "dur": 1.04, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972991.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972992.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576972992.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576972992.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972992.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576972992.0, "ph": "X", "cat": "fee", "dur": 0.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972993.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972993.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576972993.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576972993.06, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972993.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576972993.04, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972994.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972994.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576972994.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576972994.1, "ph": "X", "cat": "fee", "dur": 0.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972994.22, "ph": "X", "cat": "fee", "dur": 0.78, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576972994.08, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972995.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972996.02, "ph": "X", "cat": "fee", "dur": 18.98, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576972996.0, "ph": "X", "cat": "fee", "dur": 19.02, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972995.1, "ph": "X", "cat": "fee", "dur": 19.94, "name": "_path_is_mode_type (<frozen importlib._bootstrap_external>:145)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972995.08, "ph": "X", "cat": "fee", "dur": 19.98, "name": "_path_isfile (<frozen importlib._bootstrap_external>:154)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973016.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap_external>:1006)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973016.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576973017.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:351)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973016.06, "ph": "X", "cat": "fee", "dur": 1.94, "name": "spec_from_file_location (<frozen importlib._bootstrap_external>:696)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973016.0, "ph": "X", "cat": "fee", "dur": 2.02, "name": "_get_spec (<frozen importlib._bootstrap_external>:1500)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972977.0, "ph": "X", "cat": "fee", "dur": 41.04, "name": "find_spec (<frozen importlib._bootstrap_external>:1505)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972975.12, "ph": "X", "cat": "fee", "dur": 42.94, "name": "_get_spec (<frozen importlib._bootstrap_external>:1374)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972975.1, "ph": "X", "cat": "fee", "dur": 42.98, "name": "find_spec (<frozen importlib._bootstrap_external>:1406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973019.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576973019.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__exit__ (<frozen importlib._bootstrap>:878)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972972.0, "ph": "X", "cat": "fee", "dur": 47.08, "name": "_find_spec (<frozen importlib._bootstrap>:901)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973019.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576973020.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576973020.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "create_module (<frozen importlib._bootstrap_external>:841)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973020.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "_new_module (<frozen importlib._bootstrap>:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973021.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576973021.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576973021.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576973022.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576973021.16, "ph": "X", "cat": "fee", "dur": 0.88, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973022.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576973023.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "has_location (<frozen importlib._bootstrap>:406)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973023.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576973024.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576973025.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.endswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576973026.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576973026.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973027.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973026.06, "ph": "X", "cat": "fee", "dur": 1.0, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576973026.04, "ph": "X", "cat": "fee", "dur": 1.96, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973028.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576973028.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576973030.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576973030.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576973030.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576973029.02, "ph": "X", "cat": "fee", "dur": 1.1, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973030.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576973029.0, "ph": "X", "cat": "fee", "dur": 1.18, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973025.08, "ph": "X", "cat": "fee", "dur": 5.12, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973025.02, "ph": "X", "cat": "fee", "dur": 5.2, "name": "_get_cached (<frozen importlib._bootstrap_external>:491)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973025.0, "ph": "X", "cat": "fee", "dur": 6.0, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973031.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "cached (<frozen importlib._bootstrap>:385)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973021.02, "ph": "X", "cat": "fee", "dur": 10.04, "name": "_init_module_attrs (<frozen importlib._bootstrap>:486)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973020.02, "ph": "X", "cat": "fee", "dur": 11.06, "name": "module_from_spec (<frozen importlib._bootstrap>:558)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973032.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "get_filename (<frozen importlib._bootstrap_external>:1031)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973032.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_check_name_wrapper (<frozen importlib._bootstrap_external>:523)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973033.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.fspath"}, {"pid": 20956, "tid": 2192355, "ts": 253576973033.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rfind"}, {"pid": 20956, "tid": 2192355, "ts": 253576973033.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973034.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (<frozen importlib._bootstrap_external>:129)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973033.1, "ph": "X", "cat": "fee", "dur": 0.96, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576973033.08, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_path_split (<frozen importlib._bootstrap_external>:127)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973034.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576973034.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576973035.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576973035.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576973035.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rstrip"}, {"pid": 20956, "tid": 2192355, "ts": 253576973035.02, "ph": "X", "cat": "fee", "dur": 0.14, "name": "<listcomp> (<frozen importlib._bootstrap_external>:123)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973035.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576973035.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_path_join (<frozen importlib._bootstrap_external>:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973033.02, "ph": "X", "cat": "fee", "dur": 3.02, "name": "cache_from_source (<frozen importlib._bootstrap_external>:361)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973036.1, "ph": "X", "cat": "fee", "dur": 2.9, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576973036.08, "ph": "X", "cat": "fee", "dur": 2.94, "name": "_path_stat (<frozen importlib._bootstrap_external>:135)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973036.06, "ph": "X", "cat": "fee", "dur": 2.98, "name": "path_stats (<frozen importlib._bootstrap_external>:1077)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973040.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576973040.06, "ph": "X", "cat": "fee", "dur": 34.94, "name": "io.open_code"}, {"pid": 20956, "tid": 2192355, "ts": 253576973075.02, "ph": "X", "cat": "fee", "dur": 2.98, "name": "_io.BufferedReader.read"}, {"pid": 20956, "tid": 2192355, "ts": 253576973078.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_io.BufferedReader.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576973040.0, "ph": "X", "cat": "fee", "dur": 40.02, "name": "get_data (<frozen importlib._bootstrap_external>:1036)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973081.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576973081.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576973082.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576973081.06, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973081.0, "ph": "X", "cat": "fee", "dur": 1.06, "name": "_classify_pyc (<frozen importlib._bootstrap_external>:560)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973083.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576973083.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576973083.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973083.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576973083.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576973083.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "_unpack_uint32 (<frozen importlib._bootstrap_external>:79)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973083.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_validate_timestamp_pyc (<frozen importlib._bootstrap_external>:593)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973084.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973084.1, "ph": "X", "cat": "fee", "dur": 20.9, "name": "marshal.loads"}, {"pid": 20956, "tid": 2192355, "ts": 253576973106.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576973106.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973106.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp._fix_co_filename"}, {"pid": 20956, "tid": 2192355, "ts": 253576973084.08, "ph": "X", "cat": "fee", "dur": 22.04, "name": "_compile_bytecode (<frozen importlib._bootstrap_external>:645)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973032.02, "ph": "X", "cat": "fee", "dur": 74.12, "name": "get_code (<frozen importlib._bootstrap_external>:916)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973109.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576973109.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576973109.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973112.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:152)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973112.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576973113.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (<frozen importlib._bootstrap>:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973114.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576973112.06, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973114.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576973115.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576973114.06, "ph": "X", "cat": "fee", "dur": 0.98, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973112.04, "ph": "X", "cat": "fee", "dur": 3.02, "name": "__enter__ (<frozen importlib._bootstrap>:156)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973115.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576973116.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576973116.08, "ph": "X", "cat": "fee", "dur": 13386.92, "name": "builtins.__import__"}, {"pid": 20956, "tid": 2192355, "ts": 253576973116.06, "ph": "X", "cat": "fee", "dur": 13386.96, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973116.0, "ph": "X", "cat": "fee", "dur": 13387.04, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986503.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576986504.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576986503.08, "ph": "X", "cat": "fee", "dur": 0.98, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986503.06, "ph": "X", "cat": "fee", "dur": 1.02, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986504.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576986504.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576986505.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576986504.1, "ph": "X", "cat": "fee", "dur": 0.96, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973111.0, "ph": "X", "cat": "fee", "dur": 13394.08, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986505.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986506.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576986505.1, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986507.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986507.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576986507.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986507.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986508.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576986507.12, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986508.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986508.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576986508.08, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986508.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986508.26, "ph": "X", "cat": "fee", "dur": 0.74, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576986508.2, "ph": "X", "cat": "fee", "dur": 0.82, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986509.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986509.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576986509.04, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973108.0, "ph": "X", "cat": "fee", "dur": 13402.0, "name": "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_alt_BOTorch.py:1)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973107.02, "ph": "X", "cat": "fee", "dur": 13403.0, "name": "builtins.exec"}, {"pid": 20956, "tid": 2192355, "ts": 253576973107.0, "ph": "X", "cat": "fee", "dur": 13403.04, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973032.0, "ph": "X", "cat": "fee", "dur": 13478.06, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986511.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576986511.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576973019.1, "ph": "X", "cat": "fee", "dur": 13491.98, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986512.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576986512.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576972971.1, "ph": "X", "cat": "fee", "dur": 13540.98, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986513.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576986513.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576986513.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986513.0, "ph": "X", "cat": "fee", "dur": 0.14, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986514.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576986514.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576986514.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576986514.0, "ph": "X", "cat": "fee", "dur": 0.14, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972967.0, "ph": "X", "cat": "fee", "dur": 13547.16, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986515.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576986515.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576986515.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_get_module_lock (<frozen importlib._bootstrap>:166)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986516.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576986516.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576986515.14, "ph": "X", "cat": "fee", "dur": 0.94, "name": "acquire (<frozen importlib._bootstrap>:87)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986516.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576986517.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576986516.1, "ph": "X", "cat": "fee", "dur": 0.94, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986515.0, "ph": "X", "cat": "fee", "dur": 2.06, "name": "_lock_unlock_module (<frozen importlib._bootstrap>:203)"}, {"pid": 20956, "tid": 2192355, "ts": 253576972965.06, "ph": "X", "cat": "fee", "dur": 13552.02, "name": "builtins.__import__"}, {"pid": 20956, "tid": 2192355, "ts": 253576972965.04, "ph": "X", "cat": "fee", "dur": 13552.06, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576154769.04, "ph": "X", "cat": "fee", "dur": 831748.08, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986522.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Options (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:73)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986521.0, "ph": "X", "cat": "fee", "dur": 10.0, "name": "builtins.__build_class__"}, {"pid": 20956, "tid": 2192355, "ts": 253576986538.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Options.items"}, {"pid": 20956, "tid": 2192355, "ts": 253576986537.0, "ph": "X", "cat": "fee", "dur": 11.0, "name": "_get_docstring (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:380)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986549.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Options.items"}, {"pid": 20956, "tid": 2192355, "ts": 253576986549.0, "ph": "X", "cat": "fee", "dur": 8.0, "name": "_get_docstring (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:380)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986558.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Options.items"}, {"pid": 20956, "tid": 2192355, "ts": 253576986558.0, "ph": "X", "cat": "fee", "dur": 3.0, "name": "_get_docstring (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:380)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986562.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Options.items"}, {"pid": 20956, "tid": 2192355, "ts": 253576986561.02, "ph": "X", "cat": "fee", "dur": 5.98, "name": "_get_docstring (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:380)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986569.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Options.items"}, {"pid": 20956, "tid": 2192355, "ts": 253576986568.0, "ph": "X", "cat": "fee", "dur": 3.0, "name": "_get_docstring (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:380)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139273.0, "ph": "X", "cat": "fee", "dur": 847298.02, "name": "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:1)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139272.02, "ph": "X", "cat": "fee", "dur": 847299.02, "name": "builtins.exec"}, {"pid": 20956, "tid": 2192355, "ts": 253576139272.0, "ph": "X", "cat": "fee", "dur": 847299.06, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139171.1, "ph": "X", "cat": "fee", "dur": 847400.9, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986575.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576986575.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139161.06, "ph": "X", "cat": "fee", "dur": 847414.02, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986576.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.rpartition"}, {"pid": 20956, "tid": 2192355, "ts": 253576986576.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.setattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576139123.12, "ph": "X", "cat": "fee", "dur": 847452.96, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986577.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576986578.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576986577.02, "ph": "X", "cat": "fee", "dur": 1.02, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986577.0, "ph": "X", "cat": "fee", "dur": 1.06, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986578.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576986578.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576986578.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576986578.08, "ph": "X", "cat": "fee", "dur": 0.14, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253576139120.0, "ph": "X", "cat": "fee", "dur": 847459.0, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755733.04, "ph": "X", "cat": "fee", "dur": 1230846.96, "name": "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/__init__.py:2)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755733.02, "ph": "X", "cat": "fee", "dur": 1230847.0, "name": "builtins.exec"}, {"pid": 20956, "tid": 2192355, "ts": 253575755733.0, "ph": "X", "cat": "fee", "dur": 1230847.04, "name": "_call_with_frames_removed (<frozen importlib._bootstrap>:220)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755677.02, "ph": "X", "cat": "fee", "dur": 1230903.04, "name": "exec_module (<frozen importlib._bootstrap_external>:844)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986581.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576986581.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_verbose_message (<frozen importlib._bootstrap>:231)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755666.0, "ph": "X", "cat": "fee", "dur": 1230915.08, "name": "_load_unlocked (<frozen importlib._bootstrap>:659)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755496.06, "ph": "X", "cat": "fee", "dur": 1231085.04, "name": "_find_and_load_unlocked (<frozen importlib._bootstrap>:967)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986582.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.get_ident"}, {"pid": 20956, "tid": 2192355, "ts": 253576986582.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576986581.14, "ph": "X", "cat": "fee", "dur": 0.94, "name": "release (<frozen importlib._bootstrap>:112)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986581.12, "ph": "X", "cat": "fee", "dur": 0.98, "name": "__exit__ (<frozen importlib._bootstrap>:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986582.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.acquire_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576986582.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576986583.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_imp.release_lock"}, {"pid": 20956, "tid": 2192355, "ts": 253576986582.12, "ph": "X", "cat": "fee", "dur": 0.94, "name": "cb (<frozen importlib._bootstrap>:185)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755491.0, "ph": "X", "cat": "fee", "dur": 1231092.08, "name": "_find_and_load (<frozen importlib._bootstrap>:1002)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986583.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986583.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576986583.1, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986584.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986584.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576986584.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_handle_fromlist (<frozen importlib._bootstrap>:1033)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986588.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "collections.OrderedDict.values"}, {"pid": 20956, "tid": 2192355, "ts": 253576986589.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986589.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "<genexpr> (/Users/fjwillemsen/Library/CloudStorage/OneDrive-NetherlandseScienceCenter/Projects/Bayesian Optimization in Kernel Tuner/Code/cached_data_used/bootstrap_hyperparamtuning.py:63)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986589.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986589.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "<genexpr> (/Users/fjwillemsen/Library/CloudStorage/OneDrive-NetherlandseScienceCenter/Projects/Bayesian Optimization in Kernel Tuner/Code/cached_data_used/bootstrap_hyperparamtuning.py:63)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986589.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/Library/CloudStorage/OneDrive-NetherlandseScienceCenter/Projects/Bayesian Optimization in Kernel Tuner/Code/cached_data_used/bootstrap_hyperparamtuning.py:63)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986591.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_prod_dispatcher (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/fromnumeric.py:2928)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986593.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.items"}, {"pid": 20956, "tid": 2192355, "ts": 253576986593.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "<dictcomp> (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/fromnumeric.py:70)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986594.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576986595.02, "ph": "X", "cat": "fee", "dur": 9.98, "name": "numpy.ufunc.reduce"}, {"pid": 20956, "tid": 2192355, "ts": 253576986593.0, "ph": "X", "cat": "fee", "dur": 12.02, "name": "_wrapreduction (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/fromnumeric.py:69)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986592.0, "ph": "X", "cat": "fee", "dur": 13.04, "name": "prod (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/fromnumeric.py:2933)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986591.04, "ph": "X", "cat": "fee", "dur": 14.02, "name": "numpy.core._multiarray_umath.implement_array_function"}, {"pid": 20956, "tid": 2192355, "ts": 253576986590.0, "ph": "X", "cat": "fee", "dur": 15.08, "name": "prod (<__array_function__ internals>:2)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986607.0, "ph": "X", "cat": "fee", "dur": 18.0, "name": "builtins.print"}, {"pid": 20956, "tid": 2192355, "ts": 253576986626.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "DurationObserver (/Users/fjwillemsen/Library/CloudStorage/OneDrive-NetherlandseScienceCenter/Projects/Bayesian Optimization in Kernel Tuner/Code/cached_data_used/bootstrap_hyperparamtuning.py:66)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986627.04, "ph": "X", "cat": "fee", "dur": 8.96, "name": "type.__new__"}, {"pid": 20956, "tid": 2192355, "ts": 253576986636.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_abc._abc_init"}, {"pid": 20956, "tid": 2192355, "ts": 253576986627.02, "ph": "X", "cat": "fee", "dur": 11.0, "name": "__new__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/abc.py:105)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986625.02, "ph": "X", "cat": "fee", "dur": 13.02, "name": "builtins.__build_class__"}, {"pid": 20956, "tid": 2192355, "ts": 253576986641.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986641.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "__init__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/core.py:58)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986643.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.callable"}, {"pid": 20956, "tid": 2192355, "ts": 253576986645.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986646.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.RLock.acquire"}, {"pid": 20956, "tid": 2192355, "ts": 253576986646.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "_acquireLock (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:218)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986647.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576986647.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576986647.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576986647.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986647.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576986647.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576986647.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576986648.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576986648.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:771)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986649.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986649.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "_checkLevel (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:193)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986650.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.RLock.acquire"}, {"pid": 20956, "tid": 2192355, "ts": 253576986650.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "_acquireLock (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:218)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986651.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986651.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.RLock.release"}, {"pid": 20956, "tid": 2192355, "ts": 253576986651.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "_releaseLock (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:227)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986650.0, "ph": "X", "cat": "fee", "dur": 1.12, "name": "_addHandlerRef (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:838)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986652.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "RLock (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/threading.py:82)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986652.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.RLock.acquire"}, {"pid": 20956, "tid": 2192355, "ts": 253576986652.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "_acquireLock (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:218)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986653.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "set.add"}, {"pid": 20956, "tid": 2192355, "ts": 253576986653.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "add (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/_weakrefset.py:86)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986654.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.RLock.release"}, {"pid": 20956, "tid": 2192355, "ts": 253576986653.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "_releaseLock (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:227)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986652.04, "ph": "X", "cat": "fee", "dur": 2.02, "name": "_register_at_fork_reinit_lock (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:246)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986651.14, "ph": "X", "cat": "fee", "dur": 2.94, "name": "createLock (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:886)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986648.06, "ph": "X", "cat": "fee", "dur": 6.04, "name": "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:857)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986648.04, "ph": "X", "cat": "fee", "dur": 6.08, "name": "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1049)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986654.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576986654.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576986655.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576986656.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:418)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986656.06, "ph": "X", "cat": "fee", "dur": 1.94, "name": "re.Pattern.search"}, {"pid": 20956, "tid": 2192355, "ts": 253576986656.04, "ph": "X", "cat": "fee", "dur": 1.98, "name": "validate (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:424)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986655.04, "ph": "X", "cat": "fee", "dur": 3.0, "name": "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:553)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986658.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "setFormatter (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:957)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986659.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.RLock.acquire"}, {"pid": 20956, "tid": 2192355, "ts": 253576986659.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "_acquireLock (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:218)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986660.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986660.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.RLock.release"}, {"pid": 20956, "tid": 2192355, "ts": 253576986660.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "_releaseLock (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:227)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986659.02, "ph": "X", "cat": "fee", "dur": 1.1, "name": "addHandler (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1601)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986660.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.pop"}, {"pid": 20956, "tid": 2192355, "ts": 253576986660.2, "ph": "X", "cat": "fee", "dur": 0.8, "name": "_thread.RLock.release"}, {"pid": 20956, "tid": 2192355, "ts": 253576986660.18, "ph": "X", "cat": "fee", "dur": 0.84, "name": "_releaseLock (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:227)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986645.06, "ph": "X", "cat": "fee", "dur": 15.98, "name": "basicConfig (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1908)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986663.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.RLock.acquire"}, {"pid": 20956, "tid": 2192355, "ts": 253576986663.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "_acquireLock (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:218)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986664.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "disable (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1276)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986664.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "getEffectiveLevel (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1675)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986665.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.RLock.release"}, {"pid": 20956, "tid": 2192355, "ts": 253576986665.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_releaseLock (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:227)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986662.0, "ph": "X", "cat": "fee", "dur": 4.02, "name": "isEnabledFor (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1689)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986661.06, "ph": "X", "cat": "fee", "dur": 4.98, "name": "debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1424)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986645.0, "ph": "X", "cat": "fee", "dur": 21.06, "name": "debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:2099)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986667.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986668.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "isEnabledFor (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1689)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986668.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1424)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986667.02, "ph": "X", "cat": "fee", "dur": 1.06, "name": "debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:2099)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986668.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.callable"}, {"pid": 20956, "tid": 2192355, "ts": 253576986668.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986669.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986669.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "isEnabledFor (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1689)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986669.08, "ph": "X", "cat": "fee", "dur": 0.94, "name": "debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1424)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986669.02, "ph": "X", "cat": "fee", "dur": 1.02, "name": "debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:2099)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986670.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986670.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986671.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "<listcomp> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:397)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986672.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.any"}, {"pid": 20956, "tid": 2192355, "ts": 253576986673.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986673.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "isEnabledFor (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1689)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986673.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1424)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986673.0, "ph": "X", "cat": "fee", "dur": 0.14, "name": "debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:2099)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986669.0, "ph": "X", "cat": "fee", "dur": 5.0, "name": "looks_like_a_filename (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:379)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986675.02, "ph": "X", "cat": "fee", "dur": 13.98, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576986689.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_stat.S_ISREG"}, {"pid": 20956, "tid": 2192355, "ts": 253576986675.0, "ph": "X", "cat": "fee", "dur": 15.02, "name": "isfile (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/genericpath.py:27)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986717.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_locale.nl_langinfo"}, {"pid": 20956, "tid": 2192355, "ts": 253576986717.0, "ph": "X", "cat": "fee", "dur": 2.0, "name": "getpreferredencoding (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/_bootlocale.py:33)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986721.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/codecs.py:260)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986720.0, "ph": "X", "cat": "fee", "dur": 1.04, "name": "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/codecs.py:309)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986690.04, "ph": "X", "cat": "fee", "dur": 31.96, "name": "io.open"}, {"pid": 20956, "tid": 2192355, "ts": 253576986727.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_codecs.utf_8_decode"}, {"pid": 20956, "tid": 2192355, "ts": 253576986726.0, "ph": "X", "cat": "fee", "dur": 2.02, "name": "decode (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/codecs.py:319)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986723.0, "ph": "X", "cat": "fee", "dur": 6.0, "name": "_io.TextIOWrapper.read"}, {"pid": 20956, "tid": 2192355, "ts": 253576986729.02, "ph": "X", "cat": "fee", "dur": 3.98, "name": "_io.TextIOWrapper.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576986674.02, "ph": "X", "cat": "fee", "dur": 59.0, "name": "read_file (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:469)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986667.0, "ph": "X", "cat": "fee", "dur": 67.0, "name": "get_kernel_string (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:222)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986644.0, "ph": "X", "cat": "fee", "dur": 90.02, "name": "get_kernel_string (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/core.py:72)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986736.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986737.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986738.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986738.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "isstring (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_compile.py:595)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986739.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986739.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "isstring (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_compile.py:595)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986740.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986741.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986740.0, "ph": "X", "cat": "fee", "dur": 2.02, "name": "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:224)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986742.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:76)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986744.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986744.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "tell (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:286)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986745.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:111)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986747.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986747.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986748.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986748.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986748.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "append (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:172)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986748.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986748.12, "ph": "X", "cat": "fee", "dur": 0.9, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986749.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986749.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986749.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "append (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:172)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986749.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986749.16, "ph": "X", "cat": "fee", "dur": 0.86, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986750.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986750.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986750.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "append (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:172)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986750.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986750.16, "ph": "X", "cat": "fee", "dur": 0.06, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986751.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986751.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986751.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "append (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:172)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986751.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986751.12, "ph": "X", "cat": "fee", "dur": 0.06, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986751.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986752.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986752.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "append (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:172)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986752.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986752.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986752.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986753.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986752.2, "ph": "X", "cat": "fee", "dur": 0.84, "name": "append (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:172)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986753.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986753.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986753.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986753.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986753.18, "ph": "X", "cat": "fee", "dur": 0.06, "name": "append (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:172)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986754.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986754.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986754.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986754.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986754.12, "ph": "X", "cat": "fee", "dur": 0.06, "name": "append (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:172)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986755.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986754.2, "ph": "X", "cat": "fee", "dur": 0.84, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986755.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986755.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986755.1, "ph": "X", "cat": "fee", "dur": 0.06, "name": "append (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:172)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986755.2, "ph": "X", "cat": "fee", "dur": 0.8, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986755.18, "ph": "X", "cat": "fee", "dur": 0.84, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986756.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986756.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986756.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "append (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:172)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986756.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986756.16, "ph": "X", "cat": "fee", "dur": 0.06, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986757.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986757.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986757.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "append (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:172)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986757.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986757.12, "ph": "X", "cat": "fee", "dur": 0.06, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986757.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986758.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986758.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "append (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:172)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986758.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986758.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986758.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986758.22, "ph": "X", "cat": "fee", "dur": 0.78, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986758.2, "ph": "X", "cat": "fee", "dur": 0.82, "name": "append (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:172)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986759.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986759.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986759.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986759.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986759.16, "ph": "X", "cat": "fee", "dur": 0.06, "name": "append (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:172)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986760.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986759.24, "ph": "X", "cat": "fee", "dur": 0.8, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986760.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986760.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986760.1, "ph": "X", "cat": "fee", "dur": 0.06, "name": "append (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:172)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986760.2, "ph": "X", "cat": "fee", "dur": 0.8, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986760.18, "ph": "X", "cat": "fee", "dur": 0.84, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986761.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986761.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986761.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "append (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:172)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986761.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986761.16, "ph": "X", "cat": "fee", "dur": 0.06, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986762.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986762.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986762.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "append (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:172)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986762.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986762.12, "ph": "X", "cat": "fee", "dur": 0.06, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986762.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986763.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986762.24, "ph": "X", "cat": "fee", "dur": 0.8, "name": "append (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:172)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986763.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986763.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986763.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986763.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986763.18, "ph": "X", "cat": "fee", "dur": 0.06, "name": "append (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:172)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986764.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986764.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986764.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986764.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986764.12, "ph": "X", "cat": "fee", "dur": 0.06, "name": "append (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:172)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986764.22, "ph": "X", "cat": "fee", "dur": 0.78, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986764.2, "ph": "X", "cat": "fee", "dur": 0.82, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986765.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986765.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986765.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "append (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:172)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986765.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986765.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986766.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986766.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986766.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "append (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:172)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986766.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986766.14, "ph": "X", "cat": "fee", "dur": 0.06, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986766.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986767.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986767.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "append (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:172)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986767.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986767.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986767.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986767.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986767.2, "ph": "X", "cat": "fee", "dur": 0.06, "name": "append (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:172)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986768.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986768.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986768.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986768.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986768.12, "ph": "X", "cat": "fee", "dur": 0.06, "name": "append (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:172)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986769.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986768.2, "ph": "X", "cat": "fee", "dur": 0.84, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986769.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986769.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986769.1, "ph": "X", "cat": "fee", "dur": 0.06, "name": "append (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:172)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986769.2, "ph": "X", "cat": "fee", "dur": 0.8, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986769.18, "ph": "X", "cat": "fee", "dur": 0.84, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986770.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986770.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986770.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "append (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:172)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986770.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986770.16, "ph": "X", "cat": "fee", "dur": 0.06, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986770.24, "ph": "X", "cat": "fee", "dur": 0.76, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986771.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986771.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "append (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:172)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986771.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986771.1, "ph": "X", "cat": "fee", "dur": 0.06, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986771.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986771.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986771.22, "ph": "X", "cat": "fee", "dur": 0.78, "name": "append (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:172)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986772.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986772.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986772.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986772.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986772.14, "ph": "X", "cat": "fee", "dur": 0.06, "name": "append (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:172)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986773.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986772.22, "ph": "X", "cat": "fee", "dur": 0.82, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986773.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986773.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986773.1, "ph": "X", "cat": "fee", "dur": 0.06, "name": "append (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:172)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986773.2, "ph": "X", "cat": "fee", "dur": 0.8, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986773.18, "ph": "X", "cat": "fee", "dur": 0.84, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986774.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986774.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986774.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "append (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:172)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986774.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986774.16, "ph": "X", "cat": "fee", "dur": 0.06, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986775.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986775.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986775.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "append (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:172)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986775.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986775.12, "ph": "X", "cat": "fee", "dur": 0.06, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986776.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986776.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "tell (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:286)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986776.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "match (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:249)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986776.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986776.12, "ph": "X", "cat": "fee", "dur": 0.9, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986777.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986777.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "match (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:249)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986778.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986778.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986778.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986778.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986778.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "match (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:249)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986779.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986779.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986779.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986779.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986779.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "match (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:249)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986780.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986780.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986780.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986781.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "type.fromkeys"}, {"pid": 20956, "tid": 2192355, "ts": 253576986780.12, "ph": "X", "cat": "fee", "dur": 1.9, "name": "_uniq (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:432)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986782.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986782.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986782.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "append (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:172)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986783.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986783.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986784.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986783.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "tell (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:286)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986784.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986784.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__len__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986785.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986785.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:111)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986785.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986786.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986786.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__len__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986786.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986786.12, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986787.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986787.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986787.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986787.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986787.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "match (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:249)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986788.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__setitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:168)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986788.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986788.04, "ph": "X", "cat": "fee", "dur": 0.98, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986789.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576986790.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576986790.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986791.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.ord"}, {"pid": 20956, "tid": 2192355, "ts": 253576986789.04, "ph": "X", "cat": "fee", "dur": 2.0, "name": "_escape (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:355)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986791.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986791.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "append (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:172)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986792.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986792.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__len__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986792.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986793.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986793.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986793.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986793.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986794.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986793.16, "ph": "X", "cat": "fee", "dur": 0.88, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986794.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986794.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986794.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986794.14, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986794.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986794.22, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986794.32, "ph": "X", "cat": "fee", "dur": 0.68, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986794.3, "ph": "X", "cat": "fee", "dur": 0.72, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986795.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986795.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986795.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986795.12, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986795.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986795.2, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986795.3, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986795.28, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986796.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986796.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986796.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986796.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986796.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986796.16, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986796.26, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986796.24, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986797.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986797.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986797.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986797.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986797.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986797.16, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986797.26, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986797.24, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986797.34, "ph": "X", "cat": "fee", "dur": 0.66, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986797.32, "ph": "X", "cat": "fee", "dur": 0.7, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986798.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986798.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986798.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986798.12, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986798.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986798.2, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986798.3, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986798.28, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986799.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986799.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986799.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986799.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986799.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986799.16, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986799.26, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986799.24, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986800.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986800.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986800.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986800.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986800.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986800.16, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986800.26, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986800.24, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986800.34, "ph": "X", "cat": "fee", "dur": 0.66, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986800.32, "ph": "X", "cat": "fee", "dur": 0.7, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986801.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986801.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986801.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986801.12, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986745.02, "ph": "X", "cat": "fee", "dur": 56.18, "name": "_parse (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:493)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986801.22, "ph": "X", "cat": "fee", "dur": 0.78, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986802.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "match (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:249)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986802.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986743.02, "ph": "X", "cat": "fee", "dur": 59.08, "name": "_parse_sub (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:435)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986803.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986802.12, "ph": "X", "cat": "fee", "dur": 0.92, "name": "fix_flags (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:921)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986739.1, "ph": "X", "cat": "fee", "dur": 63.96, "name": "parse (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:937)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986808.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.min"}, {"pid": 20956, "tid": 2192355, "ts": 253576986809.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.min"}, {"pid": 20956, "tid": 2192355, "ts": 253576986808.0, "ph": "X", "cat": "fee", "dur": 1.04, "name": "getwidth (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:174)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986810.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.min"}, {"pid": 20956, "tid": 2192355, "ts": 253576986810.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.min"}, {"pid": 20956, "tid": 2192355, "ts": 253576986804.04, "ph": "X", "cat": "fee", "dur": 6.04, "name": "getwidth (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:174)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986811.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_get_iscased (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_compile.py:453)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986811.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986811.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986812.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986812.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986812.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986812.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986812.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986812.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986812.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986812.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986812.32, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986812.36, "ph": "X", "cat": "fee", "dur": 0.64, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986813.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986813.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986813.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986813.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986813.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986813.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986813.26, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986813.3, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986813.34, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986813.38, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986814.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986814.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986814.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986814.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986814.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986814.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986814.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986814.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986814.32, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986814.36, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986814.4, "ph": "X", "cat": "fee", "dur": 0.6, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986811.0, "ph": "X", "cat": "fee", "dur": 4.02, "name": "_get_literal_prefix (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_compile.py:461)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986815.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986815.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986815.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986816.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986816.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986816.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.min"}, {"pid": 20956, "tid": 2192355, "ts": 253576986816.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986816.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986816.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986816.24, "ph": "X", "cat": "fee", "dur": 0.76, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986817.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986817.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.extend"}, {"pid": 20956, "tid": 2192355, "ts": 253576986817.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986817.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986817.1, "ph": "X", "cat": "fee", "dur": 3.9, "name": "_generate_overlap_table (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_compile.py:432)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986821.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.extend"}, {"pid": 20956, "tid": 2192355, "ts": 253576986821.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986804.02, "ph": "X", "cat": "fee", "dur": 17.08, "name": "_compile_info (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_compile.py:536)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986822.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986823.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986823.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986823.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986823.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986823.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986823.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986823.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986824.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986824.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986824.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986824.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986824.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986824.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986824.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986824.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986824.32, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986824.36, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986824.4, "ph": "X", "cat": "fee", "dur": 0.6, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986825.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986825.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986825.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986825.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986825.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986825.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986825.26, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986825.3, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986825.34, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986826.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986826.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986826.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986826.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986826.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986826.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986826.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986826.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986826.32, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986826.36, "ph": "X", "cat": "fee", "dur": 0.64, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986827.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986827.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986827.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986827.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986827.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986827.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986827.26, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986827.3, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986827.34, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986827.38, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986827.42, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986828.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986828.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986828.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986828.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986828.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986828.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986828.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986828.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986828.32, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986828.36, "ph": "X", "cat": "fee", "dur": 0.64, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986829.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986829.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986829.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986829.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986829.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986829.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986829.26, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986830.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986830.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__len__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:160)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986830.02, "ph": "X", "cat": "fee", "dur": 0.1, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986830.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986830.14, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986830.0, "ph": "X", "cat": "fee", "dur": 0.22, "name": "_simple (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_compile.py:423)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986830.24, "ph": "X", "cat": "fee", "dur": 0.76, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986831.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986831.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986831.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986831.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986832.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986832.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986833.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "bytearray.find"}, {"pid": 20956, "tid": 2192355, "ts": 253576986834.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986834.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "bytearray.find"}, {"pid": 20956, "tid": 2192355, "ts": 253576986834.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986835.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "bytearray.find"}, {"pid": 20956, "tid": 2192355, "ts": 253576986835.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986835.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "bytearray.find"}, {"pid": 20956, "tid": 2192355, "ts": 253576986835.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986835.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "bytearray.find"}, {"pid": 20956, "tid": 2192355, "ts": 253576986836.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986836.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986836.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986836.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986832.08, "ph": "X", "cat": "fee", "dur": 4.08, "name": "_optimize_charset (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_compile.py:276)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986837.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986837.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986837.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986837.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986838.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986838.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986838.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986838.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986838.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986837.12, "ph": "X", "cat": "fee", "dur": 1.08, "name": "_compile_charset (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_compile.py:249)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986838.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986838.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986838.26, "ph": "X", "cat": "fee", "dur": 0.74, "name": "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986831.18, "ph": "X", "cat": "fee", "dur": 7.84, "name": "_compile (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_compile.py:71)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986839.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986839.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986839.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986839.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986822.0, "ph": "X", "cat": "fee", "dur": 17.2, "name": "_compile (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_compile.py:71)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986840.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986804.0, "ph": "X", "cat": "fee", "dur": 36.04, "name": "_code (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_compile.py:598)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986840.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986840.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "groups (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:81)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986841.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.items"}, {"pid": 20956, "tid": 2192355, "ts": 253576986841.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986841.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "groups (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:81)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986842.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_sre.compile"}, {"pid": 20956, "tid": 2192355, "ts": 253576986739.0, "ph": "X", "cat": "fee", "dur": 104.02, "name": "compile (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_compile.py:759)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986845.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986846.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "__new__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/enum.py:670)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986846.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "__call__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/enum.py:358)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986847.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "__new__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/enum.py:670)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986847.04, "ph": "X", "cat": "fee", "dur": 0.98, "name": "__call__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/enum.py:358)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986845.0, "ph": "X", "cat": "fee", "dur": 3.04, "name": "__and__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/enum.py:977)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986848.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986736.02, "ph": "X", "cat": "fee", "dur": 112.08, "name": "_compile (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/re.py:289)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986849.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "re.Pattern.finditer"}, {"pid": 20956, "tid": 2192355, "ts": 253576986736.0, "ph": "X", "cat": "fee", "dur": 114.0, "name": "finditer (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/re.py:243)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986851.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "re.Match.end"}, {"pid": 20956, "tid": 2192355, "ts": 253576986851.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.find"}, {"pid": 20956, "tid": 2192355, "ts": 253576986852.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.split"}, {"pid": 20956, "tid": 2192355, "ts": 253576986852.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986855.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "re.Match.end"}, {"pid": 20956, "tid": 2192355, "ts": 253576986855.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.find"}, {"pid": 20956, "tid": 2192355, "ts": 253576986855.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.split"}, {"pid": 20956, "tid": 2192355, "ts": 253576986855.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986856.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986856.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986856.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986857.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986857.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986857.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986857.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986857.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986864.0, "ph": "X", "cat": "fee", "dur": 2.0, "name": "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py:403)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986868.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986871.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py:403)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986876.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986875.02, "ph": "X", "cat": "fee", "dur": 1.02, "name": "getlines (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/linecache.py:36)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986876.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986875.0, "ph": "X", "cat": "fee", "dur": 1.1, "name": "getline (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/linecache.py:26)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986877.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.strip"}, {"pid": 20956, "tid": 2192355, "ts": 253576986871.04, "ph": "X", "cat": "fee", "dur": 6.96, "name": "_formatwarnmsg_impl (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986870.0, "ph": "X", "cat": "fee", "dur": 8.02, "name": "formatwarning (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py:15)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986868.02, "ph": "X", "cat": "fee", "dur": 10.02, "name": "_formatwarning (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/bokeh/__init__.py:98)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986868.0, "ph": "X", "cat": "fee", "dur": 10.06, "name": "_formatwarnmsg (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py:117)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986878.08, "ph": "X", "cat": "fee", "dur": 9.92, "name": "_io.TextIOWrapper.write"}, {"pid": 20956, "tid": 2192355, "ts": 253576986867.02, "ph": "X", "cat": "fee", "dur": 21.0, "name": "_showwarnmsg_impl (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py:20)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986867.0, "ph": "X", "cat": "fee", "dur": 21.04, "name": "_showwarnmsg (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py:96)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986858.0, "ph": "X", "cat": "fee", "dur": 31.0, "name": "_warnings.warn"}, {"pid": 20956, "tid": 2192355, "ts": 253576986889.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_warnings.warn"}, {"pid": 20956, "tid": 2192355, "ts": 253576986734.04, "ph": "X", "cat": "fee", "dur": 155.98, "name": "check_argument_list (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:54)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986643.0, "ph": "X", "cat": "fee", "dur": 247.04, "name": "check_argument_lists (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/core.py:182)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986891.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "check_block_size_names (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:100)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986642.02, "ph": "X", "cat": "fee", "dur": 249.02, "name": "_check_user_input (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:609)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986892.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "collections.OrderedDict.items"}, {"pid": 20956, "tid": 2192355, "ts": 253576986892.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "check_tune_params_list (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:92)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986894.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "collections.OrderedDict.keys"}, {"pid": 20956, "tid": 2192355, "ts": 253576986894.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "<listcomp> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986895.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.any"}, {"pid": 20956, "tid": 2192355, "ts": 253576986898.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py:403)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986899.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986901.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py:403)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986903.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986902.02, "ph": "X", "cat": "fee", "dur": 1.02, "name": "getlines (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/linecache.py:36)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986903.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986902.0, "ph": "X", "cat": "fee", "dur": 1.1, "name": "getline (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/linecache.py:26)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986903.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.strip"}, {"pid": 20956, "tid": 2192355, "ts": 253576986901.06, "ph": "X", "cat": "fee", "dur": 2.94, "name": "_formatwarnmsg_impl (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986901.0, "ph": "X", "cat": "fee", "dur": 3.02, "name": "formatwarning (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py:15)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986899.06, "ph": "X", "cat": "fee", "dur": 4.98, "name": "_formatwarning (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/bokeh/__init__.py:98)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986899.04, "ph": "X", "cat": "fee", "dur": 5.02, "name": "_formatwarnmsg (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py:117)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986904.08, "ph": "X", "cat": "fee", "dur": 2.92, "name": "_io.TextIOWrapper.write"}, {"pid": 20956, "tid": 2192355, "ts": 253576986899.02, "ph": "X", "cat": "fee", "dur": 8.0, "name": "_showwarnmsg_impl (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py:20)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986899.0, "ph": "X", "cat": "fee", "dur": 8.04, "name": "_showwarnmsg (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py:96)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986895.06, "ph": "X", "cat": "fee", "dur": 12.0, "name": "_warnings.warn"}, {"pid": 20956, "tid": 2192355, "ts": 253576986893.02, "ph": "X", "cat": "fee", "dur": 14.06, "name": "check_block_size_params_names_list (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:115)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986907.1, "ph": "X", "cat": "fee", "dur": 2.9, "name": "builtins.locals"}, {"pid": 20956, "tid": 2192355, "ts": 253576986911.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Options.keys"}, {"pid": 20956, "tid": 2192355, "ts": 253576986911.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "<listcomp> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:430)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986914.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Options.keys"}, {"pid": 20956, "tid": 2192355, "ts": 253576986914.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "<listcomp> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:431)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986917.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Options.keys"}, {"pid": 20956, "tid": 2192355, "ts": 253576986917.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<listcomp> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:432)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986919.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986919.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "isEnabledFor (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1689)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986919.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1424)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986918.0, "ph": "X", "cat": "fee", "dur": 1.12, "name": "debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:2099)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986920.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Options.keys"}, {"pid": 20956, "tid": 2192355, "ts": 253576986921.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Options.items"}, {"pid": 20956, "tid": 2192355, "ts": 253576986921.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986922.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986921.08, "ph": "X", "cat": "fee", "dur": 0.96, "name": "compact_number (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:176)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986922.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986922.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986923.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986923.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "compact_number (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:176)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986923.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986923.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986923.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986923.16, "ph": "X", "cat": "fee", "dur": 0.06, "name": "compact_number (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:176)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986924.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986924.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986924.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986924.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "compact_number (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:176)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986925.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986925.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986926.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986926.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "compact_number (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:176)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986926.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986926.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986926.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986926.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "compact_number (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:176)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986927.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986927.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986927.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986927.1, "ph": "X", "cat": "fee", "dur": 0.06, "name": "compact_number (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:176)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986927.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986927.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986928.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986928.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "compact_number (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:176)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986928.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986928.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986928.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986928.16, "ph": "X", "cat": "fee", "dur": 0.06, "name": "compact_number (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:176)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986929.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986929.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986929.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986929.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "compact_number (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:176)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986929.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986929.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986930.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986930.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "compact_number (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:176)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986930.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986930.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986930.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986930.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "compact_number (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:176)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986931.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986931.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576986920.0, "ph": "X", "cat": "fee", "dur": 11.1, "name": "get_config_string (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:173)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986932.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986932.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "isEnabledFor (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1689)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986932.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1424)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986932.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:2099)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986933.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Options.keys"}, {"pid": 20956, "tid": 2192355, "ts": 253576986933.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Options.items"}, {"pid": 20956, "tid": 2192355, "ts": 253576986933.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986934.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986934.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "compact_number (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:176)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986937.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986937.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986937.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986937.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "compact_number (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:176)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986937.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986938.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986938.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986938.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "compact_number (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:176)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986938.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986938.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986938.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986939.0, "ph": "X", "cat": "fee", "dur": 4.0, "name": "builtins.round"}, {"pid": 20956, "tid": 2192355, "ts": 253576986943.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "str.format"}, {"pid": 20956, "tid": 2192355, "ts": 253576986938.2, "ph": "X", "cat": "fee", "dur": 6.82, "name": "compact_number (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:176)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986945.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986945.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986946.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986946.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "compact_number (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:176)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986946.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986946.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986946.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986946.16, "ph": "X", "cat": "fee", "dur": 0.06, "name": "compact_number (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:176)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986947.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986947.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986947.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986947.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "compact_number (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:176)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986948.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986948.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986948.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986948.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "compact_number (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:176)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986949.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986949.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986949.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986949.1, "ph": "X", "cat": "fee", "dur": 0.06, "name": "compact_number (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:176)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986949.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986950.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986950.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986950.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "compact_number (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:176)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986950.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986950.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986951.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986950.2, "ph": "X", "cat": "fee", "dur": 0.84, "name": "compact_number (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:176)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986951.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986951.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986951.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986951.14, "ph": "X", "cat": "fee", "dur": 0.88, "name": "compact_number (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:176)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986952.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986952.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986952.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986952.12, "ph": "X", "cat": "fee", "dur": 0.06, "name": "compact_number (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:176)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986952.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986953.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986953.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986953.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "compact_number (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:176)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986953.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986953.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576986933.02, "ph": "X", "cat": "fee", "dur": 21.0, "name": "get_config_string (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:173)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986954.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986954.12, "ph": "X", "cat": "fee", "dur": 0.88, "name": "isEnabledFor (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1689)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986954.1, "ph": "X", "cat": "fee", "dur": 0.92, "name": "debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1424)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986954.04, "ph": "X", "cat": "fee", "dur": 1.0, "name": "debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:2099)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986955.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Options.keys"}, {"pid": 20956, "tid": 2192355, "ts": 253576986955.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Options.items"}, {"pid": 20956, "tid": 2192355, "ts": 253576986956.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986956.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986956.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "compact_number (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:176)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986956.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986956.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986957.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986957.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "compact_number (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:176)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986957.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986957.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986957.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986957.16, "ph": "X", "cat": "fee", "dur": 0.06, "name": "compact_number (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:176)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986958.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986958.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986958.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986958.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "compact_number (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:176)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986958.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986958.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986958.26, "ph": "X", "cat": "fee", "dur": 0.74, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986958.24, "ph": "X", "cat": "fee", "dur": 0.78, "name": "compact_number (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:176)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986959.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576986959.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576986955.06, "ph": "X", "cat": "fee", "dur": 4.06, "name": "get_config_string (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:173)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986959.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986960.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "isEnabledFor (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1689)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986960.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1424)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986959.14, "ph": "X", "cat": "fee", "dur": 0.94, "name": "debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:2099)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986961.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576986961.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "__getattr__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:76)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986962.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576986968.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986968.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "isEnabledFor (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1689)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986968.06, "ph": "X", "cat": "fee", "dur": 0.96, "name": "debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1424)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986968.0, "ph": "X", "cat": "fee", "dur": 1.04, "name": "debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:2099)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986969.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.upper"}, {"pid": 20956, "tid": 2192355, "ts": 253576986974.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "uname (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/platform.py:825)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986977.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576986978.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576986980.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576992708.0, "ph": "X", "cat": "fee", "dur": 6.0, "name": "__enter__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py:1014)"}, {"pid": 20956, "tid": 2192355, "ts": 253576992879.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "list.count"}, {"pid": 20956, "tid": 2192355, "ts": 253576993642.0, "ph": "X", "cat": "fee", "dur": 2.0, "name": "_codecs.utf_8_decode"}, {"pid": 20956, "tid": 2192355, "ts": 253576993638.0, "ph": "X", "cat": "fee", "dur": 18.0, "name": "decode (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/codecs.py:319)"}, {"pid": 20956, "tid": 2192355, "ts": 253576992890.0, "ph": "X", "cat": "fee", "dur": 778.0, "name": "_io.TextIOWrapper.read"}, {"pid": 20956, "tid": 2192355, "ts": 253576993669.0, "ph": "X", "cat": "fee", "dur": 12.0, "name": "_io.TextIOWrapper.close"}, {"pid": 20956, "tid": 2192355, "ts": 253576993739.0, "ph": "X", "cat": "fee", "dur": 6.0, "name": "posix.waitpid"}, {"pid": 20956, "tid": 2192355, "ts": 253576993731.0, "ph": "X", "cat": "fee", "dur": 16.0, "name": "_try_wait (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py:1872)"}, {"pid": 20956, "tid": 2192355, "ts": 253576993754.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.WIFSTOPPED"}, {"pid": 20956, "tid": 2192355, "ts": 253576993754.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "posix.waitstatus_to_exitcode"}, {"pid": 20956, "tid": 2192355, "ts": 253576993754.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "_handle_exitstatus (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py:1825)"}, {"pid": 20956, "tid": 2192355, "ts": 253576993755.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_thread.lock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576993705.0, "ph": "X", "cat": "fee", "dur": 50.08, "name": "_wait (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py:1885)"}, {"pid": 20956, "tid": 2192355, "ts": 253576993686.0, "ph": "X", "cat": "fee", "dur": 69.1, "name": "wait (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py:1184)"}, {"pid": 20956, "tid": 2192355, "ts": 253576992868.0, "ph": "X", "cat": "fee", "dur": 887.12, "name": "communicate (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py:1090)"}, {"pid": 20956, "tid": 2192355, "ts": 253576993780.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_internal_poll (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py:1837)"}, {"pid": 20956, "tid": 2192355, "ts": 253576993758.0, "ph": "X", "cat": "fee", "dur": 22.04, "name": "poll (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py:1158)"}, {"pid": 20956, "tid": 2192355, "ts": 253576993784.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_io.TextIOWrapper.close"}, {"pid": 20956, "tid": 2192355, "ts": 253576993791.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_wait (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py:1885)"}, {"pid": 20956, "tid": 2192355, "ts": 253576993791.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "wait (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py:1184)"}, {"pid": 20956, "tid": 2192355, "ts": 253576993784.0, "ph": "X", "cat": "fee", "dur": 8.02, "name": "__exit__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py:1017)"}, {"pid": 20956, "tid": 2192355, "ts": 253576993798.0, "ph": "X", "cat": "fee", "dur": 15.0, "name": "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py:439)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986984.0, "ph": "X", "cat": "fee", "dur": 6829.02, "name": "run (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py:464)"}, {"pid": 20956, "tid": 2192355, "ts": 253576993816.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_internal_poll (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py:1837)"}, {"pid": 20956, "tid": 2192355, "ts": 253576993816.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "__del__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py:1045)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986983.0, "ph": "X", "cat": "fee", "dur": 6851.0, "name": "check_output (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py:377)"}, {"pid": 20956, "tid": 2192355, "ts": 253576993836.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.strip"}, {"pid": 20956, "tid": 2192355, "ts": 253576986981.02, "ph": "X", "cat": "fee", "dur": 6855.02, "name": "from_subprocess (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/platform.py:760)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986980.0, "ph": "X", "cat": "fee", "dur": 6859.0, "name": "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/platform.py:743)"}, {"pid": 20956, "tid": 2192355, "ts": 253576993852.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_unknown_as_blank (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/platform.py:774)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986979.0, "ph": "X", "cat": "fee", "dur": 6874.0, "name": "processor (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/platform.py:792)"}, {"pid": 20956, "tid": 2192355, "ts": 253576993870.0, "ph": "X", "cat": "fee", "dur": 2.0, "name": "_thread.RLock.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576986976.0, "ph": "X", "cat": "fee", "dur": 6896.02, "name": "__get__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/functools.py:962)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986973.0, "ph": "X", "cat": "fee", "dur": 6912.0, "name": "processor (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/platform.py:960)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994166.0, "ph": "X", "cat": "fee", "dur": 7.0, "name": "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py:403)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994200.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994228.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py:403)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994257.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576994258.0, "ph": "X", "cat": "fee", "dur": 97.0, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576994357.02, "ph": "X", "cat": "fee", "dur": 64.98, "name": "io.open"}, {"pid": 20956, "tid": 2192355, "ts": 253576994438.02, "ph": "X", "cat": "fee", "dur": 7.98, "name": "_io.BufferedReader.readline"}, {"pid": 20956, "tid": 2192355, "ts": 253576994438.0, "ph": "X", "cat": "fee", "dur": 8.02, "name": "read_or_stop (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/tokenize.py:319)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994447.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "bytes.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576994449.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "bytes.decode"}, {"pid": 20956, "tid": 2192355, "ts": 253576994456.0, "ph": "X", "cat": "fee", "dur": 4.0, "name": "re.Pattern.match"}, {"pid": 20956, "tid": 2192355, "ts": 253576994449.0, "ph": "X", "cat": "fee", "dur": 11.02, "name": "find_cookie (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/tokenize.py:325)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994461.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "re.Pattern.match"}, {"pid": 20956, "tid": 2192355, "ts": 253576994425.0, "ph": "X", "cat": "fee", "dur": 37.02, "name": "detect_encoding (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/tokenize.py:295)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994463.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_io.BufferedReader.seek"}, {"pid": 20956, "tid": 2192355, "ts": 253576994473.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/codecs.py:260)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994471.0, "ph": "X", "cat": "fee", "dur": 2.04, "name": "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/codecs.py:309)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994357.0, "ph": "X", "cat": "fee", "dur": 119.0, "name": "open (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/tokenize.py:388)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994485.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_codecs.utf_8_decode"}, {"pid": 20956, "tid": 2192355, "ts": 253576994485.0, "ph": "X", "cat": "fee", "dur": 2.02, "name": "decode (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/codecs.py:319)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994518.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "_codecs.utf_8_decode"}, {"pid": 20956, "tid": 2192355, "ts": 253576994518.0, "ph": "X", "cat": "fee", "dur": 2.02, "name": "decode (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/codecs.py:319)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994536.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_codecs.utf_8_decode"}, {"pid": 20956, "tid": 2192355, "ts": 253576994536.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "decode (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/codecs.py:319)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994541.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_codecs.utf_8_decode"}, {"pid": 20956, "tid": 2192355, "ts": 253576994541.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "decode (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/codecs.py:319)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994477.0, "ph": "X", "cat": "fee", "dur": 65.02, "name": "_io.TextIOWrapper.readlines"}, {"pid": 20956, "tid": 2192355, "ts": 253576994542.04, "ph": "X", "cat": "fee", "dur": 3.96, "name": "_io.TextIOWrapper.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576994546.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "str.endswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576994255.0, "ph": "X", "cat": "fee", "dur": 295.0, "name": "updatecache (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/linecache.py:80)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994253.0, "ph": "X", "cat": "fee", "dur": 299.0, "name": "getlines (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/linecache.py:36)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994552.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576994251.0, "ph": "X", "cat": "fee", "dur": 302.02, "name": "getline (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/linecache.py:26)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994553.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "str.strip"}, {"pid": 20956, "tid": 2192355, "ts": 253576994229.02, "ph": "X", "cat": "fee", "dur": 326.98, "name": "_formatwarnmsg_impl (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994228.0, "ph": "X", "cat": "fee", "dur": 328.02, "name": "formatwarning (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py:15)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994198.0, "ph": "X", "cat": "fee", "dur": 358.04, "name": "_formatwarning (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/bokeh/__init__.py:98)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994190.0, "ph": "X", "cat": "fee", "dur": 366.06, "name": "_formatwarnmsg (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py:117)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994557.0, "ph": "X", "cat": "fee", "dur": 18.0, "name": "_io.TextIOWrapper.write"}, {"pid": 20956, "tid": 2192355, "ts": 253576994184.02, "ph": "X", "cat": "fee", "dur": 391.0, "name": "_showwarnmsg_impl (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py:20)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994184.0, "ph": "X", "cat": "fee", "dur": 391.04, "name": "_showwarnmsg (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py:96)"}, {"pid": 20956, "tid": 2192355, "ts": 253576993946.0, "ph": "X", "cat": "fee", "dur": 629.06, "name": "_warnings.warn"}, {"pid": 20956, "tid": 2192355, "ts": 253576994576.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576986971.0, "ph": "X", "cat": "fee", "dur": 7605.04, "name": "__init__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/python.py:34)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994666.0, "ph": "X", "cat": "fee", "dur": 7.0, "name": "builtins.print"}, {"pid": 20956, "tid": 2192355, "ts": 253576994674.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__enter__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/python.py:61)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986967.0, "ph": "X", "cat": "fee", "dur": 7708.0, "name": "__init__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/core.py:197)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994696.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__enter__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/core.py:266)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994708.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576994708.0, "ph": "X", "cat": "fee", "dur": 2.0, "name": "__getattr__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:76)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994729.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576994729.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getattr__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:76)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994730.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "ready_argument_list (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/python.py:67)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994730.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "ready_argument_list (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/core.py:478)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986965.0, "ph": "X", "cat": "fee", "dur": 7765.08, "name": "__init__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/runners/sequential.py:14)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994744.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__enter__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/runners/sequential.py:44)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994751.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576994751.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getattr__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:76)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994753.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "normalize_verify_function (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:503)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994765.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576994765.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "__getattr__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:76)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994766.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576994771.02, "ph": "X", "cat": "fee", "dur": 15.98, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576994789.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_stat.S_ISREG"}, {"pid": 20956, "tid": 2192355, "ts": 253576994771.0, "ph": "X", "cat": "fee", "dur": 18.04, "name": "isfile (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/genericpath.py:27)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994813.0, "ph": "X", "cat": "fee", "dur": 4.0, "name": "_locale.nl_langinfo"}, {"pid": 20956, "tid": 2192355, "ts": 253576994812.0, "ph": "X", "cat": "fee", "dur": 5.02, "name": "getpreferredencoding (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/_bootlocale.py:33)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994819.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/codecs.py:260)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994818.0, "ph": "X", "cat": "fee", "dur": 1.04, "name": "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/codecs.py:309)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994790.0, "ph": "X", "cat": "fee", "dur": 29.06, "name": "io.open"}, {"pid": 20956, "tid": 2192355, "ts": 253576994823.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_codecs.utf_8_decode"}, {"pid": 20956, "tid": 2192355, "ts": 253576994823.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "decode (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/codecs.py:319)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994820.0, "ph": "X", "cat": "fee", "dur": 4.04, "name": "_io.TextIOWrapper.read"}, {"pid": 20956, "tid": 2192355, "ts": 253576994825.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.strip"}, {"pid": 20956, "tid": 2192355, "ts": 253576994825.04, "ph": "X", "cat": "fee", "dur": 1.96, "name": "_io.TextIOWrapper.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576994843.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576994843.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576994849.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "re.Pattern.match"}, {"pid": 20956, "tid": 2192355, "ts": 253576994850.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "re.Match.end"}, {"pid": 20956, "tid": 2192355, "ts": 253576994857.0, "ph": "X", "cat": "fee", "dur": 23.0, "name": "raw_decode (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/json/decoder.py:343)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994881.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "re.Pattern.match"}, {"pid": 20956, "tid": 2192355, "ts": 253576994882.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "re.Match.end"}, {"pid": 20956, "tid": 2192355, "ts": 253576994882.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576994848.0, "ph": "X", "cat": "fee", "dur": 34.1, "name": "decode (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/json/decoder.py:332)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994843.0, "ph": "X", "cat": "fee", "dur": 39.12, "name": "loads (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/json/__init__.py:299)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994883.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576994883.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "__getattr__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:76)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994885.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576994885.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "__getattr__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:76)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994886.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "collections.OrderedDict.keys"}, {"pid": 20956, "tid": 2192355, "ts": 253576994762.0, "ph": "X", "cat": "fee", "dur": 133.0, "name": "process_cache (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:550)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994946.0, "ph": "X", "cat": "fee", "dur": 18.0, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576994944.0, "ph": "X", "cat": "fee", "dur": 20.02, "name": "is_available (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/cuda/__init__.py:74)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995067.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Options.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995067.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Options.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995068.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Options.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995081.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576995081.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getattr__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:76)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995082.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "collections.OrderedDict.values"}, {"pid": 20956, "tid": 2192355, "ts": 253576995084.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576995084.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "__getattr__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:76)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995076.0, "ph": "X", "cat": "fee", "dur": 10.0, "name": "get_valid_configs (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:263)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995087.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576995087.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.min"}, {"pid": 20956, "tid": 2192355, "ts": 253576995134.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Options.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995134.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576995133.0, "ph": "X", "cat": "fee", "dur": 1.08, "name": "get_hyperparam (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:730)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995149.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Options.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995150.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576995150.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576995149.0, "ph": "X", "cat": "fee", "dur": 1.08, "name": "get_hyperparam (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:730)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995153.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Options.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995153.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576995153.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "get_hyperparam (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:730)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995153.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "Options.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995158.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576995158.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576995153.12, "ph": "X", "cat": "fee", "dur": 4.96, "name": "get_hyperparam (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:730)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995159.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Options.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995159.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576995159.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576995159.0, "ph": "X", "cat": "fee", "dur": 0.14, "name": "get_hyperparam (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:730)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995167.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Options.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995167.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576995167.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576995167.0, "ph": "X", "cat": "fee", "dur": 0.14, "name": "get_hyperparam (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:730)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995183.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Options.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995183.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576995183.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "get_hyperparam (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:730)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995184.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Options.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995184.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576995184.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576995184.0, "ph": "X", "cat": "fee", "dur": 0.14, "name": "get_hyperparam (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:730)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995186.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Options.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995186.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576995185.0, "ph": "X", "cat": "fee", "dur": 1.08, "name": "get_hyperparam (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:730)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995198.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Options.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995198.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576995198.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "get_hyperparam (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:730)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995204.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Options.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995204.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576995204.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576995204.0, "ph": "X", "cat": "fee", "dur": 0.14, "name": "get_hyperparam (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:730)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995204.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Options.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995204.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576995204.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "get_hyperparam (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:730)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995209.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Options.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995209.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576995210.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576995209.0, "ph": "X", "cat": "fee", "dur": 1.04, "name": "get_hyperparam (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:730)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995210.06, "ph": "X", "cat": "fee", "dur": 4.94, "name": "set_acquisition_function (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:751)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995225.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576995226.0, "ph": "X", "cat": "fee", "dur": 114.0, "name": "type.arange"}, {"pid": 20956, "tid": 2192355, "ts": 253576995341.0, "ph": "X", "cat": "fee", "dur": 7.0, "name": "type.ones"}, {"pid": 20956, "tid": 2192355, "ts": 253576995355.0, "ph": "X", "cat": "fee", "dur": 23.0, "name": "Tensor.to"}, {"pid": 20956, "tid": 2192355, "ts": 253576995379.0, "ph": "X", "cat": "fee", "dur": 22.0, "name": "type.zeros"}, {"pid": 20956, "tid": 2192355, "ts": 253576995401.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Tensor.to"}, {"pid": 20956, "tid": 2192355, "ts": 253576995401.06, "ph": "X", "cat": "fee", "dur": 4.94, "name": "type.zeros"}, {"pid": 20956, "tid": 2192355, "ts": 253576995406.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Tensor.to"}, {"pid": 20956, "tid": 2192355, "ts": 253576995407.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "type.zeros"}, {"pid": 20956, "tid": 2192355, "ts": 253576995409.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Tensor.to"}, {"pid": 20956, "tid": 2192355, "ts": 253576995459.0, "ph": "X", "cat": "fee", "dur": 2.0, "name": "type.ones"}, {"pid": 20956, "tid": 2192355, "ts": 253576995461.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Tensor.to"}, {"pid": 20956, "tid": 2192355, "ts": 253576995476.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "builtins.id"}, {"pid": 20956, "tid": 2192355, "ts": 253576995477.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995478.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995480.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.id"}, {"pid": 20956, "tid": 2192355, "ts": 253576995481.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.id"}, {"pid": 20956, "tid": 2192355, "ts": 253576995481.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995482.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995485.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.id"}, {"pid": 20956, "tid": 2192355, "ts": 253576995485.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995485.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995486.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_deepcopy_atomic (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py:182)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995485.0, "ph": "X", "cat": "fee", "dur": 3.0, "name": "deepcopy (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py:128)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995489.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.id"}, {"pid": 20956, "tid": 2192355, "ts": 253576995489.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995489.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995490.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_deepcopy_atomic (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py:182)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995489.0, "ph": "X", "cat": "fee", "dur": 1.04, "name": "deepcopy (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py:128)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995484.0, "ph": "X", "cat": "fee", "dur": 6.06, "name": "<listcomp> (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py:210)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995490.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.id"}, {"pid": 20956, "tid": 2192355, "ts": 253576995483.0, "ph": "X", "cat": "fee", "dur": 9.0, "name": "_deepcopy_tuple (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py:209)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995481.0, "ph": "X", "cat": "fee", "dur": 11.02, "name": "deepcopy (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py:128)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995492.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576995480.0, "ph": "X", "cat": "fee", "dur": 13.0, "name": "_deepcopy_list (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py:200)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995493.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.id"}, {"pid": 20956, "tid": 2192355, "ts": 253576995493.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "builtins.id"}, {"pid": 20956, "tid": 2192355, "ts": 253576995493.02, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_keep_alive (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py:242)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995476.0, "ph": "X", "cat": "fee", "dur": 18.04, "name": "deepcopy (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py:128)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995494.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576995495.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "type.zeros"}, {"pid": 20956, "tid": 2192355, "ts": 253576995497.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "<listcomp> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:771)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995498.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576995498.02, "ph": "X", "cat": "fee", "dur": 1.0, "name": "__getattr__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:76)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995499.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.id"}, {"pid": 20956, "tid": 2192355, "ts": 253576995499.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995499.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995500.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.issubclass"}, {"pid": 20956, "tid": 2192355, "ts": 253576995500.04, "ph": "X", "cat": "fee", "dur": 1.96, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576995503.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995503.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576995503.08, "ph": "X", "cat": "fee", "dur": 1.92, "name": "collections.OrderedDict.__reduce_ex__"}, {"pid": 20956, "tid": 2192355, "ts": 253576995505.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576995507.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.id"}, {"pid": 20956, "tid": 2192355, "ts": 253576995508.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.id"}, {"pid": 20956, "tid": 2192355, "ts": 253576995508.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995508.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995509.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_deepcopy_atomic (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py:182)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995508.0, "ph": "X", "cat": "fee", "dur": 1.04, "name": "deepcopy (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py:128)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995509.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.id"}, {"pid": 20956, "tid": 2192355, "ts": 253576995509.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995509.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995510.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.id"}, {"pid": 20956, "tid": 2192355, "ts": 253576995510.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.id"}, {"pid": 20956, "tid": 2192355, "ts": 253576995510.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995510.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995510.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "_deepcopy_atomic (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py:182)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995510.04, "ph": "X", "cat": "fee", "dur": 0.98, "name": "deepcopy (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py:128)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995511.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576995509.2, "ph": "X", "cat": "fee", "dur": 1.88, "name": "_deepcopy_list (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py:200)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995511.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.id"}, {"pid": 20956, "tid": 2192355, "ts": 253576995511.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "builtins.id"}, {"pid": 20956, "tid": 2192355, "ts": 253576995511.1, "ph": "X", "cat": "fee", "dur": 0.92, "name": "_keep_alive (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py:242)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995509.06, "ph": "X", "cat": "fee", "dur": 2.98, "name": "deepcopy (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py:128)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995512.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.id"}, {"pid": 20956, "tid": 2192355, "ts": 253576995512.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995513.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995513.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_deepcopy_atomic (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py:182)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995512.06, "ph": "X", "cat": "fee", "dur": 1.02, "name": "deepcopy (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py:128)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995513.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.id"}, {"pid": 20956, "tid": 2192355, "ts": 253576995513.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995513.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995513.26, "ph": "X", "cat": "fee", "dur": 0.74, "name": "builtins.id"}, {"pid": 20956, "tid": 2192355, "ts": 253576995514.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.id"}, {"pid": 20956, "tid": 2192355, "ts": 253576995514.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995514.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576995514.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_deepcopy_atomic (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py:182)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995514.02, "ph": "X", "cat": "fee", "dur": 0.18, "name": "deepcopy (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py:128)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995514.22, "ph": "X", "cat": "fee", "dur": 0.78, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576995513.24, "ph": "X", "cat": "fee", "dur": 1.78, "name": "_deepcopy_list (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py:200)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995515.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.id"}, {"pid": 20956, "tid": 2192355, "ts": 253576995515.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576995515.04, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_keep_alive (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py:242)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995513.1, "ph": "X", "cat": "fee", "dur": 2.06, "name": "deepcopy (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py:128)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995506.0, "ph": "X", "cat": "fee", "dur": 9.18, "name": "_reconstruct (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py:258)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995516.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.id"}, {"pid": 20956, "tid": 2192355, "ts": 253576995516.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576995516.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "_keep_alive (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py:242)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995499.04, "ph": "X", "cat": "fee", "dur": 17.08, "name": "deepcopy (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py:128)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995517.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576995517.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getattr__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:76)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995517.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "collections.OrderedDict.items"}, {"pid": 20956, "tid": 2192355, "ts": 253576995518.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576995518.02, "ph": "X", "cat": "fee", "dur": 1.0, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:774)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995519.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:774)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995518.0, "ph": "X", "cat": "fee", "dur": 1.08, "name": "builtins.all"}, {"pid": 20956, "tid": 2192355, "ts": 253576995520.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576995519.12, "ph": "X", "cat": "fee", "dur": 0.92, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:774)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995519.1, "ph": "X", "cat": "fee", "dur": 0.96, "name": "builtins.all"}, {"pid": 20956, "tid": 2192355, "ts": 253576995520.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:774)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995550.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576995570.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "list.index"}, {"pid": 20956, "tid": 2192355, "ts": 253576995577.0, "ph": "X", "cat": "fee", "dur": 17.0, "name": "type.tensor"}, {"pid": 20956, "tid": 2192355, "ts": 253576995594.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Tensor.to"}, {"pid": 20956, "tid": 2192355, "ts": 253576995463.0, "ph": "X", "cat": "fee", "dur": 131.06, "name": "transform_nonnumerical_params (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:763)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995603.0, "ph": "X", "cat": "fee", "dur": 11.0, "name": "type.zeros_like"}, {"pid": 20956, "tid": 2192355, "ts": 253576995614.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "collections.OrderedDict.values"}, {"pid": 20956, "tid": 2192355, "ts": 253576995615.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.min"}, {"pid": 20956, "tid": 2192355, "ts": 253576995615.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576995615.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576995616.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576995616.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576995616.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.min"}, {"pid": 20956, "tid": 2192355, "ts": 253576995616.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576995616.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576995616.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576995617.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576995628.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "torch._C._has_torch_function_unary"}, {"pid": 20956, "tid": 2192355, "ts": 253576995630.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "Tensor.dim"}, {"pid": 20956, "tid": 2192355, "ts": 253576995641.0, "ph": "X", "cat": "fee", "dur": 8.0, "name": "torch._C._get_tracing_state"}, {"pid": 20956, "tid": 2192355, "ts": 253576995628.0, "ph": "X", "cat": "fee", "dur": 25.0, "name": "__len__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_tensor.py:620)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995618.0, "ph": "X", "cat": "fee", "dur": 36.0, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576995662.0, "ph": "X", "cat": "fee", "dur": 19.0, "name": "type.sub"}, {"pid": 20956, "tid": 2192355, "ts": 253576995683.0, "ph": "X", "cat": "fee", "dur": 13.0, "name": "Tensor.div"}, {"pid": 20956, "tid": 2192355, "ts": 253576995703.0, "ph": "X", "cat": "fee", "dur": 2.0, "name": "type.sub"}, {"pid": 20956, "tid": 2192355, "ts": 253576995706.0, "ph": "X", "cat": "fee", "dur": 2.0, "name": "Tensor.div"}, {"pid": 20956, "tid": 2192355, "ts": 253576995710.0, "ph": "X", "cat": "fee", "dur": 2.0, "name": "type.tensor"}, {"pid": 20956, "tid": 2192355, "ts": 253576995728.0, "ph": "X", "cat": "fee", "dur": 23.0, "name": "type.count_nonzero"}, {"pid": 20956, "tid": 2192355, "ts": 253576995752.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "torch._C._has_torch_function_unary"}, {"pid": 20956, "tid": 2192355, "ts": 253576995752.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Tensor.dim"}, {"pid": 20956, "tid": 2192355, "ts": 253576995752.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "torch._C._get_tracing_state"}, {"pid": 20956, "tid": 2192355, "ts": 253576995752.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "__len__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_tensor.py:620)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995751.02, "ph": "X", "cat": "fee", "dur": 2.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576995753.06, "ph": "X", "cat": "fee", "dur": 6.94, "name": "type.zeros"}, {"pid": 20956, "tid": 2192355, "ts": 253576995766.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Tensor.dim"}, {"pid": 20956, "tid": 2192355, "ts": 253576995766.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "torch._C._get_tracing_state"}, {"pid": 20956, "tid": 2192355, "ts": 253576995767.0, "ph": "X", "cat": "fee", "dur": 8.0, "name": "Tensor.unbind"}, {"pid": 20956, "tid": 2192355, "ts": 253576995775.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.iter"}, {"pid": 20956, "tid": 2192355, "ts": 253576995765.0, "ph": "X", "cat": "fee", "dur": 10.06, "name": "__iter__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_tensor.py:632)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995599.0, "ph": "X", "cat": "fee", "dur": 212.0, "name": "apply_scaling_to_inputs (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:694)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995875.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "<listcomp> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:289)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995876.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576995877.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576995877.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "dict.keys"}, {"pid": 20956, "tid": 2192355, "ts": 253576995878.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576995878.06, "ph": "X", "cat": "fee", "dur": 5.94, "name": "builtins.print"}, {"pid": 20956, "tid": 2192355, "ts": 253576995884.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.items"}, {"pid": 20956, "tid": 2192355, "ts": 253576995885.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.index"}, {"pid": 20956, "tid": 2192355, "ts": 253576995918.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576995931.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "isEnabledFor (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1689)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995929.0, "ph": "X", "cat": "fee", "dur": 4.0, "name": "debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1424)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995917.0, "ph": "X", "cat": "fee", "dur": 16.02, "name": "debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:2099)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995941.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576995941.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "isEnabledFor (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1689)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995941.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1424)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995940.0, "ph": "X", "cat": "fee", "dur": 1.12, "name": "debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:2099)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995942.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576995942.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getattr__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:76)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995943.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576995943.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "isEnabledFor (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1689)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995943.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1424)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995943.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:2099)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995950.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "<listcomp> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/minimize.py:77)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995951.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576995951.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576995905.0, "ph": "X", "cat": "fee", "dur": 48.0, "name": "_cost_func (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/minimize.py:59)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995895.0, "ph": "X", "cat": "fee", "dur": 58.02, "name": "objective_function (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:553)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995989.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_std_dispatcher (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3444)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996013.0, "ph": "X", "cat": "fee", "dur": 21.0, "name": "numpy.asanyarray"}, {"pid": 20956, "tid": 2192355, "ts": 253576996063.0, "ph": "X", "cat": "fee", "dur": 4.0, "name": "numpy.core._multiarray_umath.normalize_axis_index"}, {"pid": 20956, "tid": 2192355, "ts": 253576996036.0, "ph": "X", "cat": "fee", "dur": 33.0, "name": "_count_reduce_items (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/_methods.py:66)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996082.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "builtins.issubclass"}, {"pid": 20956, "tid": 2192355, "ts": 253576996084.0, "ph": "X", "cat": "fee", "dur": 14.0, "name": "numpy.ufunc.reduce"}, {"pid": 20956, "tid": 2192355, "ts": 253576996100.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576996136.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "numpy.asanyarray"}, {"pid": 20956, "tid": 2192355, "ts": 253576996139.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.issubclass"}, {"pid": 20956, "tid": 2192355, "ts": 253576996142.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "numpy.ufunc.reduce"}, {"pid": 20956, "tid": 2192355, "ts": 253576996147.0, "ph": "X", "cat": "fee", "dur": 2.0, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576996149.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576996012.02, "ph": "X", "cat": "fee", "dur": 138.98, "name": "_var (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/_methods.py:195)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996152.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "builtins.isinstance"}, {"pid": 20956, "tid": 2192355, "ts": 253576996153.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576996012.0, "ph": "X", "cat": "fee", "dur": 145.0, "name": "_std (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/_methods.py:260)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995994.0, "ph": "X", "cat": "fee", "dur": 163.02, "name": "std (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3449)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995992.0, "ph": "X", "cat": "fee", "dur": 165.04, "name": "numpy.core._multiarray_umath.implement_array_function"}, {"pid": 20956, "tid": 2192355, "ts": 253576995979.0, "ph": "X", "cat": "fee", "dur": 178.06, "name": "std (<__array_function__ internals>:2)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996157.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576996163.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576996163.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.items"}, {"pid": 20956, "tid": 2192355, "ts": 253576995953.04, "ph": "X", "cat": "fee", "dur": 210.96, "name": "register_result (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:565)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996165.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.items"}, {"pid": 20956, "tid": 2192355, "ts": 253576996166.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576996166.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getattr__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:76)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996167.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576996167.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getattr__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:76)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996168.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576996168.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getattr__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:76)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996168.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576996168.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getattr__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:76)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996169.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576996169.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getattr__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:76)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996169.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576996169.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getattr__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:76)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996170.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576996170.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getattr__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:76)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996170.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576996170.08, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__getattr__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:76)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996170.18, "ph": "X", "cat": "fee", "dur": 0.82, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576996170.16, "ph": "X", "cat": "fee", "dur": 0.86, "name": "__getattr__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:76)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996165.06, "ph": "X", "cat": "fee", "dur": 5.98, "name": "<listcomp> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:592)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996171.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576996171.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "dict.update"}, {"pid": 20956, "tid": 2192355, "ts": 253576996165.0, "ph": "X", "cat": "fee", "dur": 7.02, "name": "update_unique_results (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:588)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996172.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576995887.0, "ph": "X", "cat": "fee", "dur": 285.08, "name": "evaluate_config (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:556)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996172.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576996172.14, "ph": "X", "cat": "fee", "dur": 4.86, "name": "builtins.print"}, {"pid": 20956, "tid": 2192355, "ts": 253576995874.0, "ph": "X", "cat": "fee", "dur": 303.02, "name": "import_cached_evaluations (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:284)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996195.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "torch._C._has_torch_function_unary"}, {"pid": 20956, "tid": 2192355, "ts": 253576996195.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Tensor.dim"}, {"pid": 20956, "tid": 2192355, "ts": 253576996195.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "torch._C._get_tracing_state"}, {"pid": 20956, "tid": 2192355, "ts": 253576996195.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "__len__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_tensor.py:620)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996196.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Tensor.dim"}, {"pid": 20956, "tid": 2192355, "ts": 253576996197.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "torch._C._get_tracing_state"}, {"pid": 20956, "tid": 2192355, "ts": 253576996197.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "Tensor.unbind"}, {"pid": 20956, "tid": 2192355, "ts": 253576996198.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.iter"}, {"pid": 20956, "tid": 2192355, "ts": 253576996196.04, "ph": "X", "cat": "fee", "dur": 2.02, "name": "__iter__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_tensor.py:632)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996199.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "torch._C._has_torch_function_unary"}, {"pid": 20956, "tid": 2192355, "ts": 253576996199.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Tensor.dim"}, {"pid": 20956, "tid": 2192355, "ts": 253576996199.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "torch._C._get_tracing_state"}, {"pid": 20956, "tid": 2192355, "ts": 253576996199.0, "ph": "X", "cat": "fee", "dur": 0.14, "name": "__len__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_tensor.py:620)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996250.02, "ph": "X", "cat": "fee", "dur": 8.98, "name": "_abc._abc_subclasscheck"}, {"pid": 20956, "tid": 2192355, "ts": 253576996250.0, "ph": "X", "cat": "fee", "dur": 9.02, "name": "__subclasscheck__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/abc.py:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996239.02, "ph": "X", "cat": "fee", "dur": 20.02, "name": "_abc._abc_subclasscheck"}, {"pid": 20956, "tid": 2192355, "ts": 253576996239.0, "ph": "X", "cat": "fee", "dur": 20.06, "name": "__subclasscheck__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/abc.py:121)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996222.02, "ph": "X", "cat": "fee", "dur": 37.06, "name": "_abc._abc_instancecheck"}, {"pid": 20956, "tid": 2192355, "ts": 253576996222.0, "ph": "X", "cat": "fee", "dur": 37.1, "name": "__instancecheck__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/abc.py:117)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996272.0, "ph": "X", "cat": "fee", "dur": 4.0, "name": "posix.urandom"}, {"pid": 20956, "tid": 2192355, "ts": 253576996276.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "type.from_bytes"}, {"pid": 20956, "tid": 2192355, "ts": 253576996271.0, "ph": "X", "cat": "fee", "dur": 6.02, "name": "getrandbits (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/random.py:791)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996293.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "concatenate (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/multiarray.py:148)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996293.04, "ph": "X", "cat": "fee", "dur": 4.96, "name": "numpy.core._multiarray_umath.implement_array_function"}, {"pid": 20956, "tid": 2192355, "ts": 253576996289.0, "ph": "X", "cat": "fee", "dur": 9.02, "name": "concatenate (<__array_function__ internals>:2)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996310.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_recreate_cm (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/contextlib.py:63)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996318.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "numpy.geterrobj"}, {"pid": 20956, "tid": 2192355, "ts": 253576996319.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "numpy.geterrobj"}, {"pid": 20956, "tid": 2192355, "ts": 253576996319.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "geterr (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/_ufunc_config.py:131)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996325.0, "ph": "X", "cat": "fee", "dur": 2.0, "name": "numpy.seterrobj"}, {"pid": 20956, "tid": 2192355, "ts": 253576996316.0, "ph": "X", "cat": "fee", "dur": 11.02, "name": "seterr (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/_ufunc_config.py:32)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996313.0, "ph": "X", "cat": "fee", "dur": 18.0, "name": "__enter__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/_ufunc_config.py:429)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996331.02, "ph": "X", "cat": "fee", "dur": 13.98, "name": "numpy.random.bit_generator.SeedSequence.generate_state"}, {"pid": 20956, "tid": 2192355, "ts": 253576996352.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "numpy.geterrobj"}, {"pid": 20956, "tid": 2192355, "ts": 253576996352.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "numpy.geterrobj"}, {"pid": 20956, "tid": 2192355, "ts": 253576996352.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "geterr (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/_ufunc_config.py:131)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996353.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "numpy.seterrobj"}, {"pid": 20956, "tid": 2192355, "ts": 253576996351.02, "ph": "X", "cat": "fee", "dur": 3.0, "name": "seterr (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/_ufunc_config.py:32)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996351.0, "ph": "X", "cat": "fee", "dur": 3.04, "name": "__exit__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/_ufunc_config.py:434)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996308.0, "ph": "X", "cat": "fee", "dur": 46.06, "name": "inner (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/contextlib.py:76)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996201.0, "ph": "X", "cat": "fee", "dur": 155.0, "name": "numpy.random._generator.default_rng"}, {"pid": 20956, "tid": 2192355, "ts": 253576996363.0, "ph": "X", "cat": "fee", "dur": 20.0, "name": "numpy.random._generator.Generator.standard_normal"}, {"pid": 20956, "tid": 2192355, "ts": 253576996386.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_around_dispatcher (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3216)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996388.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_around_dispatcher (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3216)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996391.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576996392.02, "ph": "X", "cat": "fee", "dur": 1.98, "name": "numpy.ndarray.round"}, {"pid": 20956, "tid": 2192355, "ts": 253576996391.0, "ph": "X", "cat": "fee", "dur": 3.02, "name": "_wrapfunc (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/fromnumeric.py:51)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996389.0, "ph": "X", "cat": "fee", "dur": 5.04, "name": "around (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3220)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996388.04, "ph": "X", "cat": "fee", "dur": 6.02, "name": "numpy.core._multiarray_umath.implement_array_function"}, {"pid": 20956, "tid": 2192355, "ts": 253576996387.02, "ph": "X", "cat": "fee", "dur": 7.06, "name": "around (<__array_function__ internals>:2)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996387.0, "ph": "X", "cat": "fee", "dur": 8.0, "name": "round_ (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3730)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996386.06, "ph": "X", "cat": "fee", "dur": 8.96, "name": "numpy.core._multiarray_umath.implement_array_function"}, {"pid": 20956, "tid": 2192355, "ts": 253576996386.0, "ph": "X", "cat": "fee", "dur": 9.04, "name": "round_ (<__array_function__ internals>:2)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996396.0, "ph": "X", "cat": "fee", "dur": 3.0, "name": "<listcomp> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:350)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996400.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "collections.OrderedDict.values"}, {"pid": 20956, "tid": 2192355, "ts": 253576996400.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576996401.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996402.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996402.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996402.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996402.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996403.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996403.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996403.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996403.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996403.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996403.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996403.26, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996403.3, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996403.34, "ph": "X", "cat": "fee", "dur": 0.66, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996404.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996404.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996404.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996404.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996404.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996404.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996404.26, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996404.3, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996404.34, "ph": "X", "cat": "fee", "dur": 0.66, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996405.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996405.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996405.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996405.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996405.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996405.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996405.26, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996405.3, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996405.34, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996406.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996406.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996406.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996406.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996406.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996406.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996406.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996406.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996406.32, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996407.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996407.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996407.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996407.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996407.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996407.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996407.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996407.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996407.32, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996408.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996408.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996409.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996409.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996409.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996409.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996409.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996409.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996410.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996410.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996410.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996410.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996410.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996410.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996410.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996410.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996410.32, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996410.36, "ph": "X", "cat": "fee", "dur": 0.64, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996411.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996411.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996411.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996411.14, "ph": "X", "cat": "fee", "dur": 1.86, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996413.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996413.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996414.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996414.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996414.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996414.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996414.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996414.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996414.26, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996414.3, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996414.34, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996415.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996415.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996415.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996415.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996415.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996415.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996415.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996415.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996415.32, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996416.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996416.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996416.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996416.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996416.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996416.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996416.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996416.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996416.32, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996417.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996417.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996417.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996417.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996417.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996417.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996417.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996417.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996417.32, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996418.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996418.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996418.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996418.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996418.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996418.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996418.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996418.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996418.32, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996418.36, "ph": "X", "cat": "fee", "dur": 0.64, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996419.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996419.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996419.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996419.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996419.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996419.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996419.26, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996419.3, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996419.34, "ph": "X", "cat": "fee", "dur": 0.66, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996420.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996420.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996420.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996420.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996420.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996420.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996420.26, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996420.3, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996420.34, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996421.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996421.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996421.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996421.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996421.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996421.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996421.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996421.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996421.32, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996422.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996422.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996422.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996422.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996422.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996422.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996422.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996422.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996422.32, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996423.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996423.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996423.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996423.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996423.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996423.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996423.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996423.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996423.32, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996423.36, "ph": "X", "cat": "fee", "dur": 0.64, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996424.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996424.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996424.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996424.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996424.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996424.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996424.26, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996424.3, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996424.34, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996425.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996425.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996425.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996425.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996425.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996425.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996425.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996425.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996425.32, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996426.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996426.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996426.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996426.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996426.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996426.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996426.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996426.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996426.32, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996427.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996427.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996427.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996427.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996427.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996427.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996427.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996427.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576996428.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996428.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996428.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996429.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996429.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996429.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996429.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996429.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996429.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996429.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996429.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996430.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996430.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996430.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996430.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996430.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996430.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996430.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996430.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996431.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996431.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996431.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996431.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996431.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996431.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996431.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996431.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996432.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996432.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996432.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996432.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996432.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996432.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996432.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996432.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996433.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996433.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996437.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996437.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996437.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996437.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996437.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996437.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996437.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996437.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996438.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996438.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996438.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996438.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996438.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996438.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996438.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996438.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996439.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996439.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996439.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996439.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996439.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996439.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996439.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996439.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996440.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996440.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996440.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996440.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996440.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996440.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996440.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996440.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996441.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996441.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996441.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996441.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996441.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996441.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996441.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996441.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996442.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996442.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996442.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996442.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996442.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996442.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996442.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996442.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996442.32, "ph": "X", "cat": "fee", "dur": 0.68, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996443.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996443.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996443.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996443.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996443.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996443.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996443.26, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996443.3, "ph": "X", "cat": "fee", "dur": 0.7, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996444.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996444.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996444.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996444.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996444.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996444.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996444.26, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996444.3, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996445.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996445.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996445.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996445.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996445.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996445.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996445.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996445.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996446.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996446.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996446.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996446.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996446.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996446.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996446.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996446.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996447.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996447.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996447.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996447.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996447.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996447.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996447.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996447.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996448.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996448.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996448.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996448.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996448.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996448.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996448.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996448.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996449.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996449.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996449.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996449.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996449.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996449.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996449.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996449.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996450.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996450.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996450.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996450.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996450.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996450.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996450.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996450.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996450.32, "ph": "X", "cat": "fee", "dur": 0.68, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996451.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996451.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996451.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996451.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996451.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996451.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996451.26, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996451.3, "ph": "X", "cat": "fee", "dur": 0.7, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996452.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996452.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996452.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996452.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996452.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996452.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996452.26, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996452.3, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996453.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996453.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996453.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996453.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996453.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996453.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996453.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996453.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996454.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996454.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996454.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996454.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996454.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996454.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996454.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996454.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996455.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996455.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996455.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996455.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996455.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996455.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996455.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996455.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996456.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996456.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996456.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996456.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996456.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996456.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996456.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996456.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "math.ceil"}, {"pid": 20956, "tid": 2192355, "ts": 253576996457.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576996457.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996458.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996458.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996458.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996458.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996458.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996458.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996459.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996459.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996459.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996459.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996459.16, "ph": "X", "cat": "fee", "dur": 0.84, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996460.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996461.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996462.02, "ph": "X", "cat": "fee", "dur": 6.98, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996470.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996470.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996470.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996470.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996470.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996470.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996470.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996470.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996470.32, "ph": "X", "cat": "fee", "dur": 0.68, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996473.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996473.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996473.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996473.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996473.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996473.2, "ph": "X", "cat": "fee", "dur": 0.8, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996474.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996474.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996474.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996474.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996474.18, "ph": "X", "cat": "fee", "dur": 5.82, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996480.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996480.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996480.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996480.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996480.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996480.22, "ph": "X", "cat": "fee", "dur": 0.78, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996481.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996481.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996481.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996481.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996481.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996481.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996481.26, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996481.3, "ph": "X", "cat": "fee", "dur": 0.7, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996482.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996482.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996482.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996482.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996482.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996482.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996482.26, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996482.3, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996483.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996483.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996483.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996483.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996483.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996483.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996483.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996483.28, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996483.32, "ph": "X", "cat": "fee", "dur": 0.68, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996484.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996484.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996484.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996484.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996484.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996484.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996484.26, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996484.3, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996484.34, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996485.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996485.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996485.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996485.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996485.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996485.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996485.24, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996485.28, "ph": "X", "cat": "fee", "dur": 0.72, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996486.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996486.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996486.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996486.14, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996486.18, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996486.22, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996486.26, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996486.3, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996486.34, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996487.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996487.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996487.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996487.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996487.16, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996487.2, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996487.24, "ph": "X", "cat": "fee", "dur": 0.76, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996488.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996488.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996488.1, "ph": "X", "cat": "fee", "dur": 11.9, "name": "type.tensor"}, {"pid": 20956, "tid": 2192355, "ts": 253576996501.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Tensor.to"}, {"pid": 20956, "tid": 2192355, "ts": 253576996510.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "torch._C._has_torch_function_unary"}, {"pid": 20956, "tid": 2192355, "ts": 253576996536.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "torch._C._has_torch_function_unary"}, {"pid": 20956, "tid": 2192355, "ts": 253576996537.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "torch._C._has_torch_function_unary"}, {"pid": 20956, "tid": 2192355, "ts": 253576996560.0, "ph": "X", "cat": "fee", "dur": 5.0, "name": "builtins.getattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576996548.0, "ph": "X", "cat": "fee", "dur": 17.02, "name": "__getattr__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_VF.py:25)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996567.0, "ph": "X", "cat": "fee", "dur": 126.0, "name": "type.unique_dim"}, {"pid": 20956, "tid": 2192355, "ts": 253576996537.0, "ph": "X", "cat": "fee", "dur": 157.0, "name": "_unique_impl (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/functional.py:660)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996536.0, "ph": "X", "cat": "fee", "dur": 160.0, "name": "_return_output (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/functional.py:815)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996530.0, "ph": "X", "cat": "fee", "dur": 167.0, "name": "fn (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_jit_internal.py:412)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996527.0, "ph": "X", "cat": "fee", "dur": 171.0, "name": "fn (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_jit_internal.py:412)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996510.0, "ph": "X", "cat": "fee", "dur": 188.02, "name": "unique (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_tensor.py:520)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996699.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "torch._C._has_torch_function_unary"}, {"pid": 20956, "tid": 2192355, "ts": 253576996699.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Tensor.dim"}, {"pid": 20956, "tid": 2192355, "ts": 253576996699.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "torch._C._get_tracing_state"}, {"pid": 20956, "tid": 2192355, "ts": 253576996699.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "__len__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_tensor.py:620)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996698.04, "ph": "X", "cat": "fee", "dur": 2.0, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576996701.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "torch._C._has_torch_function_unary"}, {"pid": 20956, "tid": 2192355, "ts": 253576996701.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Tensor.dim"}, {"pid": 20956, "tid": 2192355, "ts": 253576996702.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "torch._C._get_tracing_state"}, {"pid": 20956, "tid": 2192355, "ts": 253576996701.02, "ph": "X", "cat": "fee", "dur": 1.02, "name": "__len__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_tensor.py:620)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996701.0, "ph": "X", "cat": "fee", "dur": 1.06, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576996702.08, "ph": "X", "cat": "fee", "dur": 0.92, "name": "builtins.round"}, {"pid": 20956, "tid": 2192355, "ts": 253576996710.0, "ph": "X", "cat": "fee", "dur": 15.0, "name": "type.full"}, {"pid": 20956, "tid": 2192355, "ts": 253576996725.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Tensor.dim"}, {"pid": 20956, "tid": 2192355, "ts": 253576996726.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "torch._C._get_tracing_state"}, {"pid": 20956, "tid": 2192355, "ts": 253576996726.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "Tensor.unbind"}, {"pid": 20956, "tid": 2192355, "ts": 253576996727.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.iter"}, {"pid": 20956, "tid": 2192355, "ts": 253576996725.02, "ph": "X", "cat": "fee", "dur": 2.04, "name": "__iter__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_tensor.py:632)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996732.0, "ph": "X", "cat": "fee", "dur": 21.0, "name": "type.count_nonzero"}, {"pid": 20956, "tid": 2192355, "ts": 253576996756.0, "ph": "X", "cat": "fee", "dur": 5.0, "name": "Tensor.count_nonzero"}, {"pid": 20956, "tid": 2192355, "ts": 253576996787.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "Tensor.item"}, {"pid": 20956, "tid": 2192355, "ts": 253576996789.0, "ph": "X", "cat": "fee", "dur": 7.0, "name": "numpy.float64.item"}, {"pid": 20956, "tid": 2192355, "ts": 253576996797.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576996797.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.min"}, {"pid": 20956, "tid": 2192355, "ts": 253576996814.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "torch._C._has_torch_function_unary"}, {"pid": 20956, "tid": 2192355, "ts": 253576996816.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "torch._C._has_torch_function_unary"}, {"pid": 20956, "tid": 2192355, "ts": 253576996816.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "torch._C._has_torch_function_unary"}, {"pid": 20956, "tid": 2192355, "ts": 253576996817.0, "ph": "X", "cat": "fee", "dur": 9.0, "name": "type._unique2"}, {"pid": 20956, "tid": 2192355, "ts": 253576996816.08, "ph": "X", "cat": "fee", "dur": 9.94, "name": "_unique_impl (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/functional.py:660)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996816.02, "ph": "X", "cat": "fee", "dur": 10.02, "name": "_return_output (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/functional.py:815)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996816.0, "ph": "X", "cat": "fee", "dur": 10.06, "name": "fn (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_jit_internal.py:412)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996815.0, "ph": "X", "cat": "fee", "dur": 11.08, "name": "fn (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_jit_internal.py:412)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996814.0, "ph": "X", "cat": "fee", "dur": 13.0, "name": "unique (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_tensor.py:520)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996835.0, "ph": "X", "cat": "fee", "dur": 4.0, "name": "Tensor.type"}, {"pid": 20956, "tid": 2192355, "ts": 253576996840.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "torch._C._has_torch_function_unary"}, {"pid": 20956, "tid": 2192355, "ts": 253576996840.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Tensor.dim"}, {"pid": 20956, "tid": 2192355, "ts": 253576996840.12, "ph": "X", "cat": "fee", "dur": 0.02, "name": "torch._C._get_tracing_state"}, {"pid": 20956, "tid": 2192355, "ts": 253576996840.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "__len__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_tensor.py:620)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996840.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576996842.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "torch._C._has_torch_function_unary"}, {"pid": 20956, "tid": 2192355, "ts": 253576996842.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Tensor.dim"}, {"pid": 20956, "tid": 2192355, "ts": 253576996842.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "torch._C._get_tracing_state"}, {"pid": 20956, "tid": 2192355, "ts": 253576996842.0, "ph": "X", "cat": "fee", "dur": 0.14, "name": "__len__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_tensor.py:620)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996841.04, "ph": "X", "cat": "fee", "dur": 1.12, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576996854.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py:403)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996857.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "parent (<frozen importlib._bootstrap>:398)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996860.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py:403)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996863.02, "ph": "X", "cat": "fee", "dur": 2.98, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576996866.02, "ph": "X", "cat": "fee", "dur": 7.98, "name": "posix.stat"}, {"pid": 20956, "tid": 2192355, "ts": 253576996874.04, "ph": "X", "cat": "fee", "dur": 39.96, "name": "io.open"}, {"pid": 20956, "tid": 2192355, "ts": 253576996915.02, "ph": "X", "cat": "fee", "dur": 2.98, "name": "_io.BufferedReader.readline"}, {"pid": 20956, "tid": 2192355, "ts": 253576996915.0, "ph": "X", "cat": "fee", "dur": 3.02, "name": "read_or_stop (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/tokenize.py:319)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996918.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "bytes.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576996919.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "bytes.decode"}, {"pid": 20956, "tid": 2192355, "ts": 253576996919.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "re.Pattern.match"}, {"pid": 20956, "tid": 2192355, "ts": 253576996919.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "find_cookie (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/tokenize.py:325)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996920.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "re.Pattern.match"}, {"pid": 20956, "tid": 2192355, "ts": 253576996914.02, "ph": "X", "cat": "fee", "dur": 6.98, "name": "detect_encoding (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/tokenize.py:295)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996921.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_io.BufferedReader.seek"}, {"pid": 20956, "tid": 2192355, "ts": 253576996923.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/codecs.py:260)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996923.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/codecs.py:309)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996874.02, "ph": "X", "cat": "fee", "dur": 49.98, "name": "open (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/tokenize.py:388)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996926.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_codecs.utf_8_decode"}, {"pid": 20956, "tid": 2192355, "ts": 253576996926.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "decode (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/codecs.py:319)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996936.02, "ph": "X", "cat": "fee", "dur": 2.98, "name": "_codecs.utf_8_decode"}, {"pid": 20956, "tid": 2192355, "ts": 253576996936.0, "ph": "X", "cat": "fee", "dur": 3.02, "name": "decode (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/codecs.py:319)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996957.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_codecs.utf_8_decode"}, {"pid": 20956, "tid": 2192355, "ts": 253576996957.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "decode (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/codecs.py:319)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996979.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_codecs.utf_8_decode"}, {"pid": 20956, "tid": 2192355, "ts": 253576996979.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "decode (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/codecs.py:319)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996990.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_codecs.utf_8_decode"}, {"pid": 20956, "tid": 2192355, "ts": 253576996990.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "decode (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/codecs.py:319)"}, {"pid": 20956, "tid": 2192355, "ts": 253576997001.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_codecs.utf_8_decode"}, {"pid": 20956, "tid": 2192355, "ts": 253576997001.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "decode (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/codecs.py:319)"}, {"pid": 20956, "tid": 2192355, "ts": 253576997011.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "_codecs.utf_8_decode"}, {"pid": 20956, "tid": 2192355, "ts": 253576997011.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "decode (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/codecs.py:319)"}, {"pid": 20956, "tid": 2192355, "ts": 253576997020.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_codecs.utf_8_decode"}, {"pid": 20956, "tid": 2192355, "ts": 253576997020.0, "ph": "X", "cat": "fee", "dur": 0.06, "name": "decode (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/codecs.py:319)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996925.0, "ph": "X", "cat": "fee", "dur": 95.08, "name": "_io.TextIOWrapper.readlines"}, {"pid": 20956, "tid": 2192355, "ts": 253576997020.1, "ph": "X", "cat": "fee", "dur": 4.9, "name": "_io.TextIOWrapper.__exit__"}, {"pid": 20956, "tid": 2192355, "ts": 253576997025.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.endswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576996863.0, "ph": "X", "cat": "fee", "dur": 163.0, "name": "updatecache (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/linecache.py:80)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996862.02, "ph": "X", "cat": "fee", "dur": 164.98, "name": "getlines (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/linecache.py:36)"}, {"pid": 20956, "tid": 2192355, "ts": 253576997027.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576996862.0, "ph": "X", "cat": "fee", "dur": 165.06, "name": "getline (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/linecache.py:26)"}, {"pid": 20956, "tid": 2192355, "ts": 253576997028.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.strip"}, {"pid": 20956, "tid": 2192355, "ts": 253576996860.04, "ph": "X", "cat": "fee", "dur": 168.96, "name": "_formatwarnmsg_impl (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py:35)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996859.0, "ph": "X", "cat": "fee", "dur": 170.02, "name": "formatwarning (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py:15)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996857.0, "ph": "X", "cat": "fee", "dur": 172.04, "name": "_formatwarning (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/bokeh/__init__.py:98)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996856.02, "ph": "X", "cat": "fee", "dur": 173.04, "name": "_formatwarnmsg (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py:117)"}, {"pid": 20956, "tid": 2192355, "ts": 253576997029.08, "ph": "X", "cat": "fee", "dur": 4.92, "name": "_io.TextIOWrapper.write"}, {"pid": 20956, "tid": 2192355, "ts": 253576996856.0, "ph": "X", "cat": "fee", "dur": 178.02, "name": "_showwarnmsg_impl (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py:20)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996855.02, "ph": "X", "cat": "fee", "dur": 179.02, "name": "_showwarnmsg (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py:96)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996845.0, "ph": "X", "cat": "fee", "dur": 190.0, "name": "_warnings.warn"}, {"pid": 20956, "tid": 2192355, "ts": 253576996395.06, "ph": "X", "cat": "fee", "dur": 639.96, "name": "get_lhs_samples (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:345)"}, {"pid": 20956, "tid": 2192355, "ts": 253576997038.0, "ph": "X", "cat": "fee", "dur": 5.0, "name": "Tensor.tolist"}, {"pid": 20956, "tid": 2192355, "ts": 253576997048.0, "ph": "X", "cat": "fee", "dur": 2.0, "name": "type.arange"}, {"pid": 20956, "tid": 2192355, "ts": 253576997058.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Tensor.dim"}, {"pid": 20956, "tid": 2192355, "ts": 253576997058.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "torch._C._get_tracing_state"}, {"pid": 20956, "tid": 2192355, "ts": 253576997059.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "Tensor.unbind"}, {"pid": 20956, "tid": 2192355, "ts": 253576997060.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.iter"}, {"pid": 20956, "tid": 2192355, "ts": 253576997058.0, "ph": "X", "cat": "fee", "dur": 2.06, "name": "__iter__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_tensor.py:632)"}, {"pid": 20956, "tid": 2192355, "ts": 253576997063.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "torch._C._has_torch_function"}, {"pid": 20956, "tid": 2192355, "ts": 253576997064.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "torch._C._has_torch_function_variadic"}, {"pid": 20956, "tid": 2192355, "ts": 253576997065.0, "ph": "X", "cat": "fee", "dur": 10.0, "name": "type.rsub"}, {"pid": 20956, "tid": 2192355, "ts": 253576997063.06, "ph": "X", "cat": "fee", "dur": 11.96, "name": "__rsub__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_tensor.py:544)"}, {"pid": 20956, "tid": 2192355, "ts": 253576997063.0, "ph": "X", "cat": "fee", "dur": 12.04, "name": "wrapped (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_tensor.py:25)"}, {"pid": 20956, "tid": 2192355, "ts": 253576997075.06, "ph": "X", "cat": "fee", "dur": 1.94, "name": "type.arange"}, {"pid": 20956, "tid": 2192355, "ts": 253576997082.0, "ph": "X", "cat": "fee", "dur": 16.0, "name": "Tensor.argmax"}, {"pid": 20956, "tid": 2192355, "ts": 253576997100.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "Tensor.item"}, {"pid": 20956, "tid": 2192355, "ts": 253576997101.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.round"}, {"pid": 20956, "tid": 2192355, "ts": 253576997047.0, "ph": "X", "cat": "fee", "dur": 60.0, "name": "get_middle_index_of_least_evaluated_region (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:410)"}, {"pid": 20956, "tid": 2192355, "ts": 253576997109.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "numpy.float64.item"}, {"pid": 20956, "tid": 2192355, "ts": 253576997122.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.max"}, {"pid": 20956, "tid": 2192355, "ts": 253576997122.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.min"}, {"pid": 20956, "tid": 2192355, "ts": 253576997122.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576997124.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576997125.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "isEnabledFor (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1689)"}, {"pid": 20956, "tid": 2192355, "ts": 253576997125.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1424)"}, {"pid": 20956, "tid": 2192355, "ts": 253576997124.02, "ph": "X", "cat": "fee", "dur": 2.02, "name": "debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:2099)"}, {"pid": 20956, "tid": 2192355, "ts": 253576997127.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576997128.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "isEnabledFor (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1689)"}, {"pid": 20956, "tid": 2192355, "ts": 253576997127.06, "ph": "X", "cat": "fee", "dur": 0.98, "name": "debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1424)"}, {"pid": 20956, "tid": 2192355, "ts": 253576997127.0, "ph": "X", "cat": "fee", "dur": 1.06, "name": "debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:2099)"}, {"pid": 20956, "tid": 2192355, "ts": 253576997128.1, "ph": "X", "cat": "fee", "dur": 0.9, "name": "str.startswith"}, {"pid": 20956, "tid": 2192355, "ts": 253576997128.08, "ph": "X", "cat": "fee", "dur": 0.94, "name": "__getattr__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:76)"}, {"pid": 20956, "tid": 2192355, "ts": 253576997130.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.len"}, {"pid": 20956, "tid": 2192355, "ts": 253576997130.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "isEnabledFor (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1689)"}, {"pid": 20956, "tid": 2192355, "ts": 253576997130.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1424)"}, {"pid": 20956, "tid": 2192355, "ts": 253576997129.04, "ph": "X", "cat": "fee", "dur": 1.08, "name": "debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:2099)"}, {"pid": 20956, "tid": 2192355, "ts": 253576997130.14, "ph": "X", "cat": "fee", "dur": 0.86, "name": "<listcomp> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/minimize.py:77)"}, {"pid": 20956, "tid": 2192355, "ts": 253576997131.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "str.join"}, {"pid": 20956, "tid": 2192355, "ts": 253576997132.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 20956, "tid": 2192355, "ts": 253576997124.0, "ph": "X", "cat": "fee", "dur": 8.04, "name": "_cost_func (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/minimize.py:59)"}, {"pid": 20956, "tid": 2192355, "ts": 253576997123.02, "ph": "X", "cat": "fee", "dur": 9.04, "name": "objective_function (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:553)"}, {"pid": 20956, "tid": 2192355, "ts": 253576997132.08, "ph": "X", "cat": "fee", "dur": 4.92, "name": "register_result (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:565)"}, {"pid": 20956, "tid": 2192355, "ts": 253576997123.0, "ph": "X", "cat": "fee", "dur": 14.02, "name": "evaluate_config (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:556)"}, {"pid": 20956, "tid": 2192355, "ts": 253576996182.0, "ph": "X", "cat": "fee", "dur": 955.04, "name": "initial_sample (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:302)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995873.0, "ph": "X", "cat": "fee", "dur": 1264.06, "name": "initialize_model (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:251)"}, {"pid": 20956, "tid": 2192355, "ts": 253576995097.0, "ph": "X", "cat": "fee", "dur": 2041.0, "name": "__init__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:107)"}, {"pid": 20956, "tid": 2192355, "ts": 253576994913.0, "ph": "X", "cat": "fee", "dur": 2225.02, "name": "tune (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:29)"}, {"pid": 20956, "tid": 2192355, "ts": 253576997141.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576997145.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "builtins.hasattr"}, {"pid": 20956, "tid": 2192355, "ts": 253576997146.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "__exit__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/python.py:64)"}, {"pid": 20956, "tid": 2192355, "ts": 253576997145.0, "ph": "X", "cat": "fee", "dur": 2.0, "name": "__exit__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/core.py:499)"}, {"pid": 20956, "tid": 2192355, "ts": 253576997141.0, "ph": "X", "cat": "fee", "dur": 6.02, "name": "__exit__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/runners/sequential.py:113)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986640.0, "ph": "X", "cat": "fee", "dur": 10507.04, "name": "tune_kernel (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:403)"}, {"pid": 20956, "tid": 2192355, "ts": 253576986587.0, "ph": "X", "cat": "fee", "dur": 10562.0, "name": "tune (/Users/fjwillemsen/Library/CloudStorage/OneDrive-NetherlandseScienceCenter/Projects/Bayesian Optimization in Kernel Tuner/Code/cached_data_used/bootstrap_hyperparamtuning.py:13)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755488.02, "ph": "X", "cat": "fee", "dur": 1241661.98, "name": "<module> (/Users/fjwillemsen/Library/CloudStorage/OneDrive-NetherlandseScienceCenter/Projects/Bayesian Optimization in Kernel Tuner/Code/cached_data_used/bootstrap_hyperparamtuning.py:2)"}, {"pid": 20956, "tid": 2192355, "ts": 253575755488.0, "ph": "X", "cat": "fee", "dur": 1241662.02, "name": "builtins.exec"}, {"pid": 20956, "tid": 2192355, "ts": 253576997215.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "collections.OrderedDict.values"}, {"pid": 20956, "tid": 2192355, "ts": 253576997216.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "collections.OrderedDict.clear"}, {"pid": 20956, "tid": 2192355, "ts": 253576997218.0, "ph": "X", "cat": "fee", "dur": 723.0, "name": "gc.collect"}, {"pid": 20956, "tid": 2192355, "ts": 253576997194.0, "ph": "X", "cat": "fee", "dur": 749.0, "name": "destroy_all (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/matplotlib/_pylab_helpers.py:78)"}, {"pid": 20956, "tid": 2192355, "ts": 253576997955.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "flush (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/progressbar/utils.py:340)"}, {"pid": 20956, "tid": 2192355, "ts": 253576997958.0, "ph": "X", "cat": "fee", "dur": 2.0, "name": "clear_first_arg_caches (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/pyopencl/tools.py:163)"}, {"pid": 20956, "tid": 2192355, "ts": 253576997966.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "_set_python_exit_flag (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/utils/data/_utils/__init__.py:45)"}, {"pid": 20956, "tid": 2192355, "ts": 253576997975.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "info (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/util.py:52)"}, {"pid": 20956, "tid": 2192355, "ts": 253576997993.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/util.py:48)"}, {"pid": 20956, "tid": 2192355, "ts": 253576997994.02, "ph": "X", "cat": "fee", "dur": 0.98, "name": "<lambda> (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/util.py:284)"}, {"pid": 20956, "tid": 2192355, "ts": 253576997994.0, "ph": "X", "cat": "fee", "dur": 1.02, "name": "<listcomp> (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/util.py:291)"}, {"pid": 20956, "tid": 2192355, "ts": 253576997996.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "list.sort"}, {"pid": 20956, "tid": 2192355, "ts": 253576997993.04, "ph": "X", "cat": "fee", "dur": 3.98, "name": "_run_finalizers (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/util.py:268)"}, {"pid": 20956, "tid": 2192355, "ts": 253576998000.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "current_process (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/process.py:37)"}, {"pid": 20956, "tid": 2192355, "ts": 253576998000.06, "ph": "X", "cat": "fee", "dur": 1.94, "name": "_cleanup (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/process.py:61)"}, {"pid": 20956, "tid": 2192355, "ts": 253576998000.04, "ph": "X", "cat": "fee", "dur": 2.96, "name": "active_children (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/process.py:43)"}, {"pid": 20956, "tid": 2192355, "ts": 253576998003.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_cleanup (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/process.py:61)"}, {"pid": 20956, "tid": 2192355, "ts": 253576998003.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "active_children (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/process.py:43)"}, {"pid": 20956, "tid": 2192355, "ts": 253576998003.1, "ph": "X", "cat": "fee", "dur": 0.02, "name": "debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/util.py:48)"}, {"pid": 20956, "tid": 2192355, "ts": 253576998004.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<lambda> (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/util.py:282)"}, {"pid": 20956, "tid": 2192355, "ts": 253576998004.02, "ph": "X", "cat": "fee", "dur": 0.06, "name": "<listcomp> (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/util.py:291)"}, {"pid": 20956, "tid": 2192355, "ts": 253576998005.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.sort"}, {"pid": 20956, "tid": 2192355, "ts": 253576998005.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 20956, "tid": 2192355, "ts": 253576998005.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "sub_debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/util.py:44)"}, {"pid": 20956, "tid": 2192355, "ts": 253576998010.0, "ph": "X", "cat": "fee", "dur": 1.0, "name": "posix.getpid"}, {"pid": 20956, "tid": 2192355, "ts": 253576998013.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "sub_debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/util.py:44)"}], "viztracer_metadata": {"overflow": false, "version": "0.14.5"}, "file_info": {"files": {"/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/jsonschema/_format.py": ["from contextlib import suppress\nfrom uuid import UUID\nimport datetime\nimport ipaddress\nimport re\n\nfrom jsonschema.exceptions import FormatError\n\n\nclass FormatChecker(object):\n    \"\"\"\n    A ``format`` property checker.\n\n    JSON Schema does not mandate that the ``format`` property actually do any\n    validation. If validation is desired however, instances of this class can\n    be hooked into validators to enable format validation.\n\n    `FormatChecker` objects always return ``True`` when asked about\n    formats that they do not know how to validate.\n\n    To check a custom format using a function that takes an instance and\n    returns a ``bool``, use the `FormatChecker.checks` or\n    `FormatChecker.cls_checks` decorators.\n\n    Arguments:\n\n        formats (~collections.abc.Iterable):\n\n            The known formats to validate. This argument can be used to\n            limit which formats will be used during validation.\n    \"\"\"\n\n    checkers = {}\n\n    def __init__(self, formats=None):\n        if formats is None:\n            self.checkers = self.checkers.copy()\n        else:\n            self.checkers = dict((k, self.checkers[k]) for k in formats)\n\n    def __repr__(self):\n        return \"<FormatChecker checkers={}>\".format(sorted(self.checkers))\n\n    def checks(self, format, raises=()):\n        \"\"\"\n        Register a decorated function as validating a new format.\n\n        Arguments:\n\n            format (str):\n\n                The format that the decorated function will check.\n\n            raises (Exception):\n\n                The exception(s) raised by the decorated function when an\n                invalid instance is found.\n\n                The exception object will be accessible as the\n                `jsonschema.exceptions.ValidationError.cause` attribute of the\n                resulting validation error.\n        \"\"\"\n\n        def _checks(func):\n            self.checkers[format] = (func, raises)\n            return func\n        return _checks\n\n    cls_checks = classmethod(checks)\n\n    def check(self, instance, format):\n        \"\"\"\n        Check whether the instance conforms to the given format.\n\n        Arguments:\n\n            instance (*any primitive type*, i.e. str, number, bool):\n\n                The instance to check\n\n            format (str):\n\n                The format that instance should conform to\n\n\n        Raises:\n\n            FormatError: if the instance does not conform to ``format``\n        \"\"\"\n\n        if format not in self.checkers:\n            return\n\n        func, raises = self.checkers[format]\n        result, cause = None, None\n        try:\n            result = func(instance)\n        except raises as e:\n            cause = e\n        if not result:\n            raise FormatError(f\"{instance!r} is not a {format!r}\", cause=cause)\n\n    def conforms(self, instance, format):\n        \"\"\"\n        Check whether the instance conforms to the given format.\n\n        Arguments:\n\n            instance (*any primitive type*, i.e. str, number, bool):\n\n                The instance to check\n\n            format (str):\n\n                The format that instance should conform to\n\n        Returns:\n\n            bool: whether it conformed\n        \"\"\"\n\n        try:\n            self.check(instance, format)\n        except FormatError:\n            return False\n        else:\n            return True\n\n\ndraft3_format_checker = FormatChecker()\ndraft4_format_checker = FormatChecker()\ndraft6_format_checker = FormatChecker()\ndraft7_format_checker = FormatChecker()\ndraft201909_format_checker = FormatChecker()\ndraft202012_format_checker = FormatChecker()\n\n_draft_checkers = dict(\n    draft3=draft3_format_checker,\n    draft4=draft4_format_checker,\n    draft6=draft6_format_checker,\n    draft7=draft7_format_checker,\n    draft201909=draft201909_format_checker,\n    draft202012=draft202012_format_checker,\n)\n\n\ndef _checks_drafts(\n    name=None,\n    draft3=None,\n    draft4=None,\n    draft6=None,\n    draft7=None,\n    draft201909=None,\n    draft202012=None,\n    raises=(),\n):\n    draft3 = draft3 or name\n    draft4 = draft4 or name\n    draft6 = draft6 or name\n    draft7 = draft7 or name\n    draft201909 = draft201909 or name\n    draft202012 = draft202012 or name\n\n    def wrap(func):\n        if draft3:\n            func = _draft_checkers[\"draft3\"].checks(draft3, raises)(func)\n        if draft4:\n            func = _draft_checkers[\"draft4\"].checks(draft4, raises)(func)\n        if draft6:\n            func = _draft_checkers[\"draft6\"].checks(draft6, raises)(func)\n        if draft7:\n            func = _draft_checkers[\"draft7\"].checks(draft7, raises)(func)\n        if draft201909:\n            func = _draft_checkers[\"draft201909\"].checks(draft201909, raises)(\n                func,\n            )\n        if draft202012:\n            func = _draft_checkers[\"draft202012\"].checks(draft202012, raises)(\n                func,\n            )\n\n        # Oy. This is bad global state, but relied upon for now, until\n        # deprecation. See https://github.com/Julian/jsonschema/issues/519\n        # and test_format_checkers_come_with_defaults\n        FormatChecker.cls_checks(\n            draft202012 or draft201909 or draft7 or draft6 or draft4 or draft3,\n            raises,\n        )(func)\n        return func\n    return wrap\n\n\n@_checks_drafts(name=\"idn-email\")\n@_checks_drafts(name=\"email\")\ndef is_email(instance):\n    if not isinstance(instance, str):\n        return True\n    return \"@\" in instance\n\n\n@_checks_drafts(\n    draft3=\"ip-address\",\n    draft4=\"ipv4\",\n    draft6=\"ipv4\",\n    draft7=\"ipv4\",\n    draft201909=\"ipv4\",\n    draft202012=\"ipv4\",\n    raises=ipaddress.AddressValueError,\n)\ndef is_ipv4(instance):\n    if not isinstance(instance, str):\n        return True\n    return ipaddress.IPv4Address(instance)\n\n\n@_checks_drafts(name=\"ipv6\", raises=ipaddress.AddressValueError)\ndef is_ipv6(instance):\n    if not isinstance(instance, str):\n        return True\n    address = ipaddress.IPv6Address(instance)\n    return not getattr(address, \"scope_id\", \"\")\n\n\nwith suppress(ImportError):\n    from fqdn import FQDN\n\n    @_checks_drafts(\n        draft3=\"host-name\",\n        draft4=\"hostname\",\n        draft6=\"hostname\",\n        draft7=\"hostname\",\n        draft201909=\"hostname\",\n        draft202012=\"hostname\",\n    )\n    def is_host_name(instance):\n        if not isinstance(instance, str):\n            return True\n        return FQDN(instance).is_valid\n\n\nwith suppress(ImportError):\n    # The built-in `idna` codec only implements RFC 3890, so we go elsewhere.\n    import idna\n\n    @_checks_drafts(\n        draft7=\"idn-hostname\",\n        draft201909=\"idn-hostname\",\n        draft202012=\"idn-hostname\",\n        raises=(idna.IDNAError, UnicodeError),\n    )\n    def is_idn_host_name(instance):\n        if not isinstance(instance, str):\n            return True\n        idna.encode(instance)\n        return True\n\n\ntry:\n    import rfc3987\nexcept ImportError:\n    with suppress(ImportError):\n        from rfc3986_validator import validate_rfc3986\n\n        @_checks_drafts(name=\"uri\")\n        def is_uri(instance):\n            if not isinstance(instance, str):\n                return True\n            return validate_rfc3986(instance, rule=\"URI\")\n\n        @_checks_drafts(\n            draft6=\"uri-reference\",\n            draft7=\"uri-reference\",\n            draft201909=\"uri-reference\",\n            draft202012=\"uri-reference\",\n            raises=ValueError,\n        )\n        def is_uri_reference(instance):\n            if not isinstance(instance, str):\n                return True\n            return validate_rfc3986(instance, rule=\"URI_reference\")\n\nelse:\n    @_checks_drafts(\n        draft7=\"iri\",\n        draft201909=\"iri\",\n        draft202012=\"iri\",\n        raises=ValueError,\n    )\n    def is_iri(instance):\n        if not isinstance(instance, str):\n            return True\n        return rfc3987.parse(instance, rule=\"IRI\")\n\n    @_checks_drafts(\n        draft7=\"iri-reference\",\n        draft201909=\"iri-reference\",\n        draft202012=\"iri-reference\",\n        raises=ValueError,\n    )\n    def is_iri_reference(instance):\n        if not isinstance(instance, str):\n            return True\n        return rfc3987.parse(instance, rule=\"IRI_reference\")\n\n    @_checks_drafts(name=\"uri\", raises=ValueError)\n    def is_uri(instance):\n        if not isinstance(instance, str):\n            return True\n        return rfc3987.parse(instance, rule=\"URI\")\n\n    @_checks_drafts(\n        draft6=\"uri-reference\",\n        draft7=\"uri-reference\",\n        draft201909=\"uri-reference\",\n        draft202012=\"uri-reference\",\n        raises=ValueError,\n    )\n    def is_uri_reference(instance):\n        if not isinstance(instance, str):\n            return True\n        return rfc3987.parse(instance, rule=\"URI_reference\")\n\nwith suppress(ImportError):\n    from rfc3339_validator import validate_rfc3339\n\n    @_checks_drafts(name=\"date-time\")\n    def is_datetime(instance):\n        if not isinstance(instance, str):\n            return True\n        return validate_rfc3339(instance.upper())\n\n    @_checks_drafts(\n        draft7=\"time\",\n        draft201909=\"time\",\n        draft202012=\"time\",\n    )\n    def is_time(instance):\n        if not isinstance(instance, str):\n            return True\n        return is_datetime(\"1970-01-01T\" + instance)\n\n\n@_checks_drafts(name=\"regex\", raises=re.error)\ndef is_regex(instance):\n    if not isinstance(instance, str):\n        return True\n    return re.compile(instance)\n\n\n@_checks_drafts(\n    draft3=\"date\",\n    draft7=\"date\",\n    draft201909=\"date\",\n    draft202012=\"date\",\n    raises=ValueError,\n)\ndef is_date(instance):\n    if not isinstance(instance, str):\n        return True\n    return instance.isascii() and datetime.date.fromisoformat(instance)\n\n\n@_checks_drafts(draft3=\"time\", raises=ValueError)\ndef is_draft3_time(instance):\n    if not isinstance(instance, str):\n        return True\n    return datetime.datetime.strptime(instance, \"%H:%M:%S\")\n\n\nwith suppress(ImportError):\n    from webcolors import CSS21_NAMES_TO_HEX\n    import webcolors\n\n    def is_css_color_code(instance):\n        return webcolors.normalize_hex(instance)\n\n    @_checks_drafts(draft3=\"color\", raises=(ValueError, TypeError))\n    def is_css21_color(instance):\n        if (\n            not isinstance(instance, str)\n            or instance.lower() in CSS21_NAMES_TO_HEX\n        ):\n            return True\n        return is_css_color_code(instance)\n\n\nwith suppress(ImportError):\n    import jsonpointer\n\n    @_checks_drafts(\n        draft6=\"json-pointer\",\n        draft7=\"json-pointer\",\n        draft201909=\"json-pointer\",\n        draft202012=\"json-pointer\",\n        raises=jsonpointer.JsonPointerException,\n    )\n    def is_json_pointer(instance):\n        if not isinstance(instance, str):\n            return True\n        return jsonpointer.JsonPointer(instance)\n\n    # TODO: I don't want to maintain this, so it\n    #       needs to go either into jsonpointer (pending\n    #       https://github.com/stefankoegl/python-json-pointer/issues/34) or\n    #       into a new external library.\n    @_checks_drafts(\n        draft7=\"relative-json-pointer\",\n        draft201909=\"relative-json-pointer\",\n        draft202012=\"relative-json-pointer\",\n        raises=jsonpointer.JsonPointerException,\n    )\n    def is_relative_json_pointer(instance):\n        # Definition taken from:\n        # https://tools.ietf.org/html/draft-handrews-relative-json-pointer-01#section-3\n        if not isinstance(instance, str):\n            return True\n        non_negative_integer, rest = [], \"\"\n        for i, character in enumerate(instance):\n            if character.isdigit():\n                # digits with a leading \"0\" are not allowed\n                if i > 0 and int(instance[i - 1]) == 0:\n                    return False\n\n                non_negative_integer.append(character)\n                continue\n\n            if not non_negative_integer:\n                return False\n\n            rest = instance[i:]\n            break\n        return (rest == \"#\") or jsonpointer.JsonPointer(rest)\n\n\nwith suppress(ImportError):\n    import uri_template\n\n    @_checks_drafts(\n        draft6=\"uri-template\",\n        draft7=\"uri-template\",\n        draft201909=\"uri-template\",\n        draft202012=\"uri-template\",\n    )\n    def is_uri_template(instance):\n        if not isinstance(instance, str):\n            return True\n        return uri_template.validate(instance)\n\n\nwith suppress(ImportError):\n    import isoduration\n\n    @_checks_drafts(\n        draft201909=\"duration\",\n        draft202012=\"duration\",\n        raises=isoduration.DurationParsingException,\n    )\n    def is_duration(instance):\n        if not isinstance(instance, str):\n            return True\n        return isoduration.parse_duration(instance)\n\n\n@_checks_drafts(\n    draft201909=\"uuid\",\n    draft202012=\"uuid\",\n    raises=ValueError,\n)\ndef is_uuid(instance):\n    if not isinstance(instance, str):\n        return True\n    UUID(instance)\n    return all(instance[position] == \"-\" for position in (8, 13, 18, 23))\n", 473], "/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/jsonschema/_types.py": ["import numbers\n\nfrom pyrsistent import pmap\nimport attr\n\nfrom jsonschema.exceptions import UndefinedTypeCheck\n\n\ndef is_array(checker, instance):\n    return isinstance(instance, list)\n\n\ndef is_bool(checker, instance):\n    return isinstance(instance, bool)\n\n\ndef is_integer(checker, instance):\n    # bool inherits from int, so ensure bools aren't reported as ints\n    if isinstance(instance, bool):\n        return False\n    return isinstance(instance, int)\n\n\ndef is_null(checker, instance):\n    return instance is None\n\n\ndef is_number(checker, instance):\n    # bool inherits from int, so ensure bools aren't reported as ints\n    if isinstance(instance, bool):\n        return False\n    return isinstance(instance, numbers.Number)\n\n\ndef is_object(checker, instance):\n    return isinstance(instance, dict)\n\n\ndef is_string(checker, instance):\n    return isinstance(instance, str)\n\n\ndef is_any(checker, instance):\n    return True\n\n\n@attr.s(frozen=True)\nclass TypeChecker(object):\n    \"\"\"\n    A ``type`` property checker.\n\n    A `TypeChecker` performs type checking for an `IValidator`. Type\n    checks to perform are updated using `TypeChecker.redefine` or\n    `TypeChecker.redefine_many` and removed via `TypeChecker.remove`.\n    Each of these return a new `TypeChecker` object.\n\n    Arguments:\n\n        type_checkers (dict):\n\n            The initial mapping of types to their checking functions.\n    \"\"\"\n    _type_checkers = attr.ib(default=pmap(), converter=pmap)\n\n    def is_type(self, instance, type):\n        \"\"\"\n        Check if the instance is of the appropriate type.\n\n        Arguments:\n\n            instance (object):\n\n                The instance to check\n\n            type (str):\n\n                The name of the type that is expected.\n\n        Returns:\n\n            bool: Whether it conformed.\n\n\n        Raises:\n\n            `jsonschema.exceptions.UndefinedTypeCheck`:\n                if type is unknown to this object.\n        \"\"\"\n        try:\n            fn = self._type_checkers[type]\n        except KeyError:\n            raise UndefinedTypeCheck(type) from None\n\n        return fn(self, instance)\n\n    def redefine(self, type, fn):\n        \"\"\"\n        Produce a new checker with the given type redefined.\n\n        Arguments:\n\n            type (str):\n\n                The name of the type to check.\n\n            fn (collections.abc.Callable):\n\n                A function taking exactly two parameters - the type\n                checker calling the function and the instance to check.\n                The function should return true if instance is of this\n                type and false otherwise.\n\n        Returns:\n\n            A new `TypeChecker` instance.\n        \"\"\"\n        return self.redefine_many({type: fn})\n\n    def redefine_many(self, definitions=()):\n        \"\"\"\n        Produce a new checker with the given types redefined.\n\n        Arguments:\n\n            definitions (dict):\n\n                A dictionary mapping types to their checking functions.\n\n        Returns:\n\n            A new `TypeChecker` instance.\n        \"\"\"\n        return attr.evolve(\n            self, type_checkers=self._type_checkers.update(definitions),\n        )\n\n    def remove(self, *types):\n        \"\"\"\n        Produce a new checker with the given types forgotten.\n\n        Arguments:\n\n            types (~collections.abc.Iterable):\n\n                the names of the types to remove.\n\n        Returns:\n\n            A new `TypeChecker` instance\n\n        Raises:\n\n            `jsonschema.exceptions.UndefinedTypeCheck`:\n\n                if any given type is unknown to this object\n        \"\"\"\n\n        checkers = self._type_checkers\n        for each in types:\n            try:\n                checkers = checkers.remove(each)\n            except KeyError:\n                raise UndefinedTypeCheck(each)\n        return attr.evolve(self, type_checkers=checkers)\n\n\ndraft3_type_checker = TypeChecker(\n    {\n        \"any\": is_any,\n        \"array\": is_array,\n        \"boolean\": is_bool,\n        \"integer\": is_integer,\n        \"object\": is_object,\n        \"null\": is_null,\n        \"number\": is_number,\n        \"string\": is_string,\n    },\n)\ndraft4_type_checker = draft3_type_checker.remove(\"any\")\ndraft6_type_checker = draft4_type_checker.redefine(\n    \"integer\",\n    lambda checker, instance: (\n        is_integer(checker, instance)\n        or isinstance(instance, float) and instance.is_integer()\n    ),\n)\ndraft7_type_checker = draft6_type_checker\ndraft201909_type_checker = draft7_type_checker\ndraft202012_type_checker = draft201909_type_checker\n", 189], "/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/jsonschema/validators.py": ["\"\"\"\nCreation and extension of validators, with implementations for existing drafts.\n\"\"\"\nfrom collections import deque\nfrom collections.abc import Sequence\nfrom functools import lru_cache\nfrom urllib.parse import unquote, urldefrag, urljoin, urlsplit\nfrom urllib.request import urlopen\nfrom warnings import warn\nimport contextlib\nimport json\nimport reprlib\nimport warnings\n\nimport attr\n\nfrom jsonschema import (\n    _legacy_validators,\n    _types,\n    _utils,\n    _validators,\n    exceptions,\n)\n\n_VALIDATORS = {}\n_META_SCHEMAS = _utils.URIDict()\n_VOCABULARIES = []\n\n\ndef __getattr__(name):\n    if name == \"ErrorTree\":\n        warnings.warn(\n            \"Importing ErrorTree from jsonschema.validators is deprecated. \"\n            \"Instead import it from jsonschema.exceptions.\",\n            DeprecationWarning,\n        )\n        from jsonschema.exceptions import ErrorTree\n        return ErrorTree\n    elif name == \"validators\":\n        warnings.warn(\n            \"Accessing jsonschema.validators.validators is deprecated. \"\n            \"Use jsonschema.validators.validator_for with a given schema.\",\n            DeprecationWarning,\n        )\n        return _VALIDATORS\n    elif name == \"meta_schemas\":\n        warnings.warn(\n            \"Accessing jsonschema.validators.meta_schemas is deprecated. \"\n            \"Use jsonschema.validators.validator_for with a given schema.\",\n            DeprecationWarning,\n        )\n        return _META_SCHEMAS\n    raise AttributeError(f\"module {__name__} has no attribute {name}\")\n\n\ndef validates(version):\n    \"\"\"\n    Register the decorated validator for a ``version`` of the specification.\n\n    Registered validators and their meta schemas will be considered when\n    parsing ``$schema`` properties' URIs.\n\n    Arguments:\n\n        version (str):\n\n            An identifier to use as the version's name\n\n    Returns:\n\n        collections.abc.Callable:\n\n            a class decorator to decorate the validator with the version\n    \"\"\"\n\n    def _validates(cls):\n        _VALIDATORS[version] = cls\n        meta_schema_id = cls.ID_OF(cls.META_SCHEMA)\n        _META_SCHEMAS[meta_schema_id] = cls\n        return cls\n    return _validates\n\n\ndef _id_of(schema):\n    \"\"\"\n    Return the ID of a schema for recent JSON Schema drafts.\n    \"\"\"\n    if schema is True or schema is False:\n        return \"\"\n    return schema.get(\"$id\", \"\")\n\n\ndef _store_schema_list():\n    if not _VOCABULARIES:\n        _VOCABULARIES.extend(_utils.load_schema(\"vocabularies\").items())\n    return [\n        (id, validator.META_SCHEMA) for id, validator in _META_SCHEMAS.items()\n    ] + _VOCABULARIES\n\n\ndef create(\n    meta_schema,\n    validators=(),\n    version=None,\n    type_checker=_types.draft7_type_checker,\n    id_of=_id_of,\n    applicable_validators=lambda schema: schema.items(),\n):\n    \"\"\"\n    Create a new validator class.\n\n    Arguments:\n\n        meta_schema (collections.abc.Mapping):\n\n            the meta schema for the new validator class\n\n        validators (collections.abc.Mapping):\n\n            a mapping from names to callables, where each callable will\n            validate the schema property with the given name.\n\n            Each callable should take 4 arguments:\n\n                1. a validator instance,\n                2. the value of the property being validated within the\n                   instance\n                3. the instance\n                4. the schema\n\n        version (str):\n\n            an identifier for the version that this validator class will\n            validate. If provided, the returned validator class will\n            have its ``__name__`` set to include the version, and also\n            will have `jsonschema.validators.validates` automatically\n            called for the given version.\n\n        type_checker (jsonschema.TypeChecker):\n\n            a type checker, used when applying the :validator:`type` validator.\n\n            If unprovided, a `jsonschema.TypeChecker` will be created\n            with a set of default types typical of JSON Schema drafts.\n\n        id_of (collections.abc.Callable):\n\n            A function that given a schema, returns its ID.\n\n        applicable_validators (collections.abc.Callable):\n\n            A function that given a schema, returns the list of applicable\n            validators (names and callables) which will be called to\n            validate the instance.\n\n    Returns:\n\n        a new `jsonschema.IValidator` class\n    \"\"\"\n\n    @attr.s\n    class Validator:\n\n        VALIDATORS = dict(validators)\n        META_SCHEMA = dict(meta_schema)\n        TYPE_CHECKER = type_checker\n        ID_OF = staticmethod(id_of)\n\n        schema = attr.ib(repr=reprlib.repr)\n        resolver = attr.ib(default=None, repr=False)\n        format_checker = attr.ib(default=None)\n\n        def __attrs_post_init__(self):\n            if self.resolver is None:\n                self.resolver = RefResolver.from_schema(\n                    self.schema,\n                    id_of=id_of,\n                )\n\n        @classmethod\n        def check_schema(cls, schema):\n            for error in cls(cls.META_SCHEMA).iter_errors(schema):\n                raise exceptions.SchemaError.create_from(error)\n\n        def evolve(self, **kwargs):\n            return attr.evolve(self, **kwargs)\n\n        def iter_errors(self, instance, _schema=None):\n            if _schema is not None:\n                warnings.warn(\n                    (\n                        \"Passing a schema to Validator.iter_errors \"\n                        \"is deprecated and will be removed in a future \"\n                        \"release. Call validator.evolve(schema=new_schema).\"\n                        \"iter_errors(...) instead.\"\n                    ),\n                    DeprecationWarning,\n                )\n            else:\n                _schema = self.schema\n\n            if _schema is True:\n                return\n            elif _schema is False:\n                yield exceptions.ValidationError(\n                    f\"False schema does not allow {instance!r}\",\n                    validator=None,\n                    validator_value=None,\n                    instance=instance,\n                    schema=_schema,\n                )\n                return\n\n            scope = id_of(_schema)\n            if scope:\n                self.resolver.push_scope(scope)\n            try:\n                for k, v in applicable_validators(_schema):\n                    validator = self.VALIDATORS.get(k)\n                    if validator is None:\n                        continue\n\n                    errors = validator(self, v, instance, _schema) or ()\n                    for error in errors:\n                        # set details if not already set by the called fn\n                        error._set(\n                            validator=k,\n                            validator_value=v,\n                            instance=instance,\n                            schema=_schema,\n                        )\n                        if k not in {\"if\", \"$ref\"}:\n                            error.schema_path.appendleft(k)\n                        yield error\n            finally:\n                if scope:\n                    self.resolver.pop_scope()\n\n        def descend(self, instance, schema, path=None, schema_path=None):\n            for error in self.evolve(schema=schema).iter_errors(instance):\n                if path is not None:\n                    error.path.appendleft(path)\n                if schema_path is not None:\n                    error.schema_path.appendleft(schema_path)\n                yield error\n\n        def validate(self, *args, **kwargs):\n            for error in self.iter_errors(*args, **kwargs):\n                raise error\n\n        def is_type(self, instance, type):\n            try:\n                return self.TYPE_CHECKER.is_type(instance, type)\n            except exceptions.UndefinedTypeCheck:\n                raise exceptions.UnknownType(type, instance, self.schema)\n\n        def is_valid(self, instance, _schema=None):\n            if _schema is not None:\n                warnings.warn(\n                    (\n                        \"Passing a schema to Validator.is_valid is deprecated \"\n                        \"and will be removed in a future release. Call \"\n                        \"validator.evolve(schema=new_schema).is_valid(...) \"\n                        \"instead.\"\n                    ),\n                    DeprecationWarning,\n                )\n                self = self.evolve(schema=_schema)\n\n            error = next(self.iter_errors(instance), None)\n            return error is None\n\n    if version is not None:\n        safe = version.title().replace(\" \", \"\").replace(\"-\", \"\")\n        Validator.__name__ = Validator.__qualname__ = f\"{safe}Validator\"\n        Validator = validates(version)(Validator)\n\n    return Validator\n\n\ndef extend(validator, validators=(), version=None, type_checker=None):\n    \"\"\"\n    Create a new validator class by extending an existing one.\n\n    Arguments:\n\n        validator (jsonschema.IValidator):\n\n            an existing validator class\n\n        validators (collections.abc.Mapping):\n\n            a mapping of new validator callables to extend with, whose\n            structure is as in `create`.\n\n            .. note::\n\n                Any validator callables with the same name as an\n                existing one will (silently) replace the old validator\n                callable entirely, effectively overriding any validation\n                done in the \"parent\" validator class.\n\n                If you wish to instead extend the behavior of a parent's\n                validator callable, delegate and call it directly in\n                the new validator function by retrieving it using\n                ``OldValidator.VALIDATORS[\"validator_name\"]``.\n\n        version (str):\n\n            a version for the new validator class\n\n        type_checker (jsonschema.TypeChecker):\n\n            a type checker, used when applying the :validator:`type` validator.\n\n            If unprovided, the type checker of the extended\n            `jsonschema.IValidator` will be carried along.\n\n    Returns:\n\n        a new `jsonschema.IValidator` class extending the one provided\n\n    .. note:: Meta Schemas\n\n        The new validator class will have its parent's meta schema.\n\n        If you wish to change or extend the meta schema in the new\n        validator class, modify ``META_SCHEMA`` directly on the returned\n        class. Note that no implicit copying is done, so a copy should\n        likely be made before modifying it, in order to not affect the\n        old validator.\n    \"\"\"\n\n    all_validators = dict(validator.VALIDATORS)\n    all_validators.update(validators)\n\n    if type_checker is None:\n        type_checker = validator.TYPE_CHECKER\n    return create(\n        meta_schema=validator.META_SCHEMA,\n        validators=all_validators,\n        version=version,\n        type_checker=type_checker,\n        id_of=validator.ID_OF,\n    )\n\n\nDraft3Validator = create(\n    meta_schema=_utils.load_schema(\"draft3\"),\n    validators={\n        \"$ref\": _validators.ref,\n        \"additionalItems\": _validators.additionalItems,\n        \"additionalProperties\": _validators.additionalProperties,\n        \"dependencies\": _legacy_validators.dependencies_draft3,\n        \"disallow\": _legacy_validators.disallow_draft3,\n        \"divisibleBy\": _validators.multipleOf,\n        \"enum\": _validators.enum,\n        \"extends\": _legacy_validators.extends_draft3,\n        \"format\": _validators.format,\n        \"items\": _legacy_validators.items_draft3_draft4,\n        \"maxItems\": _validators.maxItems,\n        \"maxLength\": _validators.maxLength,\n        \"maximum\": _legacy_validators.maximum_draft3_draft4,\n        \"minItems\": _validators.minItems,\n        \"minLength\": _validators.minLength,\n        \"minimum\": _legacy_validators.minimum_draft3_draft4,\n        \"pattern\": _validators.pattern,\n        \"patternProperties\": _validators.patternProperties,\n        \"properties\": _legacy_validators.properties_draft3,\n        \"type\": _legacy_validators.type_draft3,\n        \"uniqueItems\": _validators.uniqueItems,\n    },\n    type_checker=_types.draft3_type_checker,\n    version=\"draft3\",\n    id_of=lambda schema: schema.get(\"id\", \"\"),\n    applicable_validators=_legacy_validators.ignore_ref_siblings,\n)\n\nDraft4Validator = create(\n    meta_schema=_utils.load_schema(\"draft4\"),\n    validators={\n        \"$ref\": _validators.ref,\n        \"additionalItems\": _validators.additionalItems,\n        \"additionalProperties\": _validators.additionalProperties,\n        \"allOf\": _validators.allOf,\n        \"anyOf\": _validators.anyOf,\n        \"dependencies\": _legacy_validators.dependencies_draft4_draft6_draft7,\n        \"enum\": _validators.enum,\n        \"format\": _validators.format,\n        \"items\": _legacy_validators.items_draft3_draft4,\n        \"maxItems\": _validators.maxItems,\n        \"maxLength\": _validators.maxLength,\n        \"maxProperties\": _validators.maxProperties,\n        \"maximum\": _legacy_validators.maximum_draft3_draft4,\n        \"minItems\": _validators.minItems,\n        \"minLength\": _validators.minLength,\n        \"minProperties\": _validators.minProperties,\n        \"minimum\": _legacy_validators.minimum_draft3_draft4,\n        \"multipleOf\": _validators.multipleOf,\n        \"not\": _validators.not_,\n        \"oneOf\": _validators.oneOf,\n        \"pattern\": _validators.pattern,\n        \"patternProperties\": _validators.patternProperties,\n        \"properties\": _validators.properties,\n        \"required\": _validators.required,\n        \"type\": _validators.type,\n        \"uniqueItems\": _validators.uniqueItems,\n    },\n    type_checker=_types.draft4_type_checker,\n    version=\"draft4\",\n    id_of=lambda schema: schema.get(\"id\", \"\"),\n    applicable_validators=_legacy_validators.ignore_ref_siblings,\n)\n\nDraft6Validator = create(\n    meta_schema=_utils.load_schema(\"draft6\"),\n    validators={\n        \"$ref\": _validators.ref,\n        \"additionalItems\": _validators.additionalItems,\n        \"additionalProperties\": _validators.additionalProperties,\n        \"allOf\": _validators.allOf,\n        \"anyOf\": _validators.anyOf,\n        \"const\": _validators.const,\n        \"contains\": _legacy_validators.contains_draft6_draft7,\n        \"dependencies\": _legacy_validators.dependencies_draft4_draft6_draft7,\n        \"enum\": _validators.enum,\n        \"exclusiveMaximum\": _validators.exclusiveMaximum,\n        \"exclusiveMinimum\": _validators.exclusiveMinimum,\n        \"format\": _validators.format,\n        \"items\": _legacy_validators.items_draft6_draft7_draft201909,\n        \"maxItems\": _validators.maxItems,\n        \"maxLength\": _validators.maxLength,\n        \"maxProperties\": _validators.maxProperties,\n        \"maximum\": _validators.maximum,\n        \"minItems\": _validators.minItems,\n        \"minLength\": _validators.minLength,\n        \"minProperties\": _validators.minProperties,\n        \"minimum\": _validators.minimum,\n        \"multipleOf\": _validators.multipleOf,\n        \"not\": _validators.not_,\n        \"oneOf\": _validators.oneOf,\n        \"pattern\": _validators.pattern,\n        \"patternProperties\": _validators.patternProperties,\n        \"properties\": _validators.properties,\n        \"propertyNames\": _validators.propertyNames,\n        \"required\": _validators.required,\n        \"type\": _validators.type,\n        \"uniqueItems\": _validators.uniqueItems,\n    },\n    type_checker=_types.draft6_type_checker,\n    version=\"draft6\",\n    applicable_validators=_legacy_validators.ignore_ref_siblings,\n)\n\nDraft7Validator = create(\n    meta_schema=_utils.load_schema(\"draft7\"),\n    validators={\n        \"$ref\": _validators.ref,\n        \"additionalItems\": _validators.additionalItems,\n        \"additionalProperties\": _validators.additionalProperties,\n        \"allOf\": _validators.allOf,\n        \"anyOf\": _validators.anyOf,\n        \"const\": _validators.const,\n        \"contains\": _legacy_validators.contains_draft6_draft7,\n        \"dependencies\": _legacy_validators.dependencies_draft4_draft6_draft7,\n        \"enum\": _validators.enum,\n        \"exclusiveMaximum\": _validators.exclusiveMaximum,\n        \"exclusiveMinimum\": _validators.exclusiveMinimum,\n        \"format\": _validators.format,\n        \"if\": _validators.if_,\n        \"items\": _legacy_validators.items_draft6_draft7_draft201909,\n        \"maxItems\": _validators.maxItems,\n        \"maxLength\": _validators.maxLength,\n        \"maxProperties\": _validators.maxProperties,\n        \"maximum\": _validators.maximum,\n        \"minItems\": _validators.minItems,\n        \"minLength\": _validators.minLength,\n        \"minProperties\": _validators.minProperties,\n        \"minimum\": _validators.minimum,\n        \"multipleOf\": _validators.multipleOf,\n        \"not\": _validators.not_,\n        \"oneOf\": _validators.oneOf,\n        \"pattern\": _validators.pattern,\n        \"patternProperties\": _validators.patternProperties,\n        \"properties\": _validators.properties,\n        \"propertyNames\": _validators.propertyNames,\n        \"required\": _validators.required,\n        \"type\": _validators.type,\n        \"uniqueItems\": _validators.uniqueItems,\n    },\n    type_checker=_types.draft7_type_checker,\n    version=\"draft7\",\n    applicable_validators=_legacy_validators.ignore_ref_siblings,\n)\n\nDraft201909Validator = create(\n    meta_schema=_utils.load_schema(\"draft2019-09\"),\n    validators={\n        \"$recursiveRef\": _legacy_validators.recursiveRef,\n        \"$ref\": _validators.ref,\n        \"additionalItems\": _validators.additionalItems,\n        \"additionalProperties\": _validators.additionalProperties,\n        \"allOf\": _validators.allOf,\n        \"anyOf\": _validators.anyOf,\n        \"const\": _validators.const,\n        \"contains\": _validators.contains,\n        \"dependentRequired\": _validators.dependentRequired,\n        \"dependentSchemas\": _validators.dependentSchemas,\n        \"enum\": _validators.enum,\n        \"exclusiveMaximum\": _validators.exclusiveMaximum,\n        \"exclusiveMinimum\": _validators.exclusiveMinimum,\n        \"format\": _validators.format,\n        \"if\": _validators.if_,\n        \"items\": _legacy_validators.items_draft6_draft7_draft201909,\n        \"maxItems\": _validators.maxItems,\n        \"maxLength\": _validators.maxLength,\n        \"maxProperties\": _validators.maxProperties,\n        \"maximum\": _validators.maximum,\n        \"minItems\": _validators.minItems,\n        \"minLength\": _validators.minLength,\n        \"minProperties\": _validators.minProperties,\n        \"minimum\": _validators.minimum,\n        \"multipleOf\": _validators.multipleOf,\n        \"not\": _validators.not_,\n        \"oneOf\": _validators.oneOf,\n        \"pattern\": _validators.pattern,\n        \"patternProperties\": _validators.patternProperties,\n        \"properties\": _validators.properties,\n        \"propertyNames\": _validators.propertyNames,\n        \"required\": _validators.required,\n        \"type\": _validators.type,\n        \"unevaluatedItems\": _validators.unevaluatedItems,\n        \"unevaluatedProperties\": _validators.unevaluatedProperties,\n        \"uniqueItems\": _validators.uniqueItems,\n    },\n    type_checker=_types.draft201909_type_checker,\n    version=\"draft2019-09\",\n)\n\nDraft202012Validator = create(\n    meta_schema=_utils.load_schema(\"draft2020-12\"),\n    validators={\n        \"$dynamicRef\": _validators.dynamicRef,\n        \"$ref\": _validators.ref,\n        \"additionalItems\": _validators.additionalItems,\n        \"additionalProperties\": _validators.additionalProperties,\n        \"allOf\": _validators.allOf,\n        \"anyOf\": _validators.anyOf,\n        \"const\": _validators.const,\n        \"contains\": _validators.contains,\n        \"dependentRequired\": _validators.dependentRequired,\n        \"dependentSchemas\": _validators.dependentSchemas,\n        \"enum\": _validators.enum,\n        \"exclusiveMaximum\": _validators.exclusiveMaximum,\n        \"exclusiveMinimum\": _validators.exclusiveMinimum,\n        \"format\": _validators.format,\n        \"if\": _validators.if_,\n        \"items\": _validators.items,\n        \"maxItems\": _validators.maxItems,\n        \"maxLength\": _validators.maxLength,\n        \"maxProperties\": _validators.maxProperties,\n        \"maximum\": _validators.maximum,\n        \"minItems\": _validators.minItems,\n        \"minLength\": _validators.minLength,\n        \"minProperties\": _validators.minProperties,\n        \"minimum\": _validators.minimum,\n        \"multipleOf\": _validators.multipleOf,\n        \"not\": _validators.not_,\n        \"oneOf\": _validators.oneOf,\n        \"pattern\": _validators.pattern,\n        \"patternProperties\": _validators.patternProperties,\n        \"prefixItems\": _validators.prefixItems,\n        \"properties\": _validators.properties,\n        \"propertyNames\": _validators.propertyNames,\n        \"required\": _validators.required,\n        \"type\": _validators.type,\n        \"unevaluatedItems\": _validators.unevaluatedItems,\n        \"unevaluatedProperties\": _validators.unevaluatedProperties,\n        \"uniqueItems\": _validators.uniqueItems,\n    },\n    type_checker=_types.draft202012_type_checker,\n    version=\"draft2020-12\",\n)\n\n_LATEST_VERSION = Draft202012Validator\n\n\nclass RefResolver(object):\n    \"\"\"\n    Resolve JSON References.\n\n    Arguments:\n\n        base_uri (str):\n\n            The URI of the referring document\n\n        referrer:\n\n            The actual referring document\n\n        store (dict):\n\n            A mapping from URIs to documents to cache\n\n        cache_remote (bool):\n\n            Whether remote refs should be cached after first resolution\n\n        handlers (dict):\n\n            A mapping from URI schemes to functions that should be used\n            to retrieve them\n\n        urljoin_cache (:func:`functools.lru_cache`):\n\n            A cache that will be used for caching the results of joining\n            the resolution scope to subscopes.\n\n        remote_cache (:func:`functools.lru_cache`):\n\n            A cache that will be used for caching the results of\n            resolved remote URLs.\n\n    Attributes:\n\n        cache_remote (bool):\n\n            Whether remote refs should be cached after first resolution\n    \"\"\"\n\n    def __init__(\n        self,\n        base_uri,\n        referrer,\n        store=(),\n        cache_remote=True,\n        handlers=(),\n        urljoin_cache=None,\n        remote_cache=None,\n    ):\n        if urljoin_cache is None:\n            urljoin_cache = lru_cache(1024)(urljoin)\n        if remote_cache is None:\n            remote_cache = lru_cache(1024)(self.resolve_from_url)\n\n        self.referrer = referrer\n        self.cache_remote = cache_remote\n        self.handlers = dict(handlers)\n\n        self._scopes_stack = [base_uri]\n        self.store = _utils.URIDict(_store_schema_list())\n        self.store.update(store)\n        self.store[base_uri] = referrer\n\n        self._urljoin_cache = urljoin_cache\n        self._remote_cache = remote_cache\n\n    @classmethod\n    def from_schema(cls, schema, id_of=_id_of, *args, **kwargs):\n        \"\"\"\n        Construct a resolver from a JSON schema object.\n\n        Arguments:\n\n            schema:\n\n                the referring schema\n\n        Returns:\n\n            `RefResolver`\n        \"\"\"\n\n        return cls(base_uri=id_of(schema), referrer=schema, *args, **kwargs)\n\n    def push_scope(self, scope):\n        \"\"\"\n        Enter a given sub-scope.\n\n        Treats further dereferences as being performed underneath the\n        given scope.\n        \"\"\"\n        self._scopes_stack.append(\n            self._urljoin_cache(self.resolution_scope, scope),\n        )\n\n    def pop_scope(self):\n        \"\"\"\n        Exit the most recent entered scope.\n\n        Treats further dereferences as being performed underneath the\n        original scope.\n\n        Don't call this method more times than `push_scope` has been\n        called.\n        \"\"\"\n        try:\n            self._scopes_stack.pop()\n        except IndexError:\n            raise exceptions.RefResolutionError(\n                \"Failed to pop the scope from an empty stack. \"\n                \"`pop_scope()` should only be called once for every \"\n                \"`push_scope()`\",\n            )\n\n    @property\n    def resolution_scope(self):\n        \"\"\"\n        Retrieve the current resolution scope.\n        \"\"\"\n        return self._scopes_stack[-1]\n\n    @property\n    def base_uri(self):\n        \"\"\"\n        Retrieve the current base URI, not including any fragment.\n        \"\"\"\n        uri, _ = urldefrag(self.resolution_scope)\n        return uri\n\n    @contextlib.contextmanager\n    def in_scope(self, scope):\n        \"\"\"\n        Temporarily enter the given scope for the duration of the context.\n        \"\"\"\n        warnings.warn(\n            \"jsonschema.RefResolver.in_scope is deprecated and will be \"\n            \"removed in a future release.\",\n            DeprecationWarning,\n        )\n        self.push_scope(scope)\n        try:\n            yield\n        finally:\n            self.pop_scope()\n\n    @contextlib.contextmanager\n    def resolving(self, ref):\n        \"\"\"\n        Resolve the given ``ref`` and enter its resolution scope.\n\n        Exits the scope on exit of this context manager.\n\n        Arguments:\n\n            ref (str):\n\n                The reference to resolve\n        \"\"\"\n\n        url, resolved = self.resolve(ref)\n        self.push_scope(url)\n        try:\n            yield resolved\n        finally:\n            self.pop_scope()\n\n    def _finditem(self, schema, key):\n        values = deque([schema])\n        while values:\n            each = values.pop()\n            if not isinstance(each, dict):\n                continue\n            if key in each:\n                yield each\n            values.extendleft(each.values())\n\n    def resolve(self, ref):\n        \"\"\"\n        Resolve the given reference.\n        \"\"\"\n        url = self._urljoin_cache(self.resolution_scope, ref).rstrip(\"/\")\n\n        uri, fragment = urldefrag(url)\n\n        for subschema in self._finditem(self.referrer, \"$id\"):\n            target_uri = self._urljoin_cache(\n                self.resolution_scope, subschema[\"$id\"],\n            )\n            if target_uri.rstrip(\"/\") == uri.rstrip(\"/\"):\n                if fragment:\n                    subschema = self.resolve_fragment(subschema, fragment)\n                return url, subschema\n\n        return url, self._remote_cache(url)\n\n    def resolve_from_url(self, url):\n        \"\"\"\n        Resolve the given remote URL.\n        \"\"\"\n        url, fragment = urldefrag(url)\n        try:\n            document = self.store[url]\n        except KeyError:\n            try:\n                document = self.resolve_remote(url)\n            except Exception as exc:\n                raise exceptions.RefResolutionError(exc)\n\n        return self.resolve_fragment(document, fragment)\n\n    def resolve_fragment(self, document, fragment):\n        \"\"\"\n        Resolve a ``fragment`` within the referenced ``document``.\n\n        Arguments:\n\n            document:\n\n                The referent document\n\n            fragment (str):\n\n                a URI fragment to resolve within it\n        \"\"\"\n\n        fragment = fragment.lstrip(\"/\")\n\n        if not fragment:\n            return document\n\n        for keyword in [\"$anchor\", \"$dynamicAnchor\"]:\n            for subschema in self._finditem(document, keyword):\n                if fragment == subschema[keyword]:\n                    return subschema\n        for keyword in [\"id\", \"$id\"]:\n            for subschema in self._finditem(document, keyword):\n                if \"#\" + fragment == subschema[keyword]:\n                    return subschema\n\n        # Resolve via path\n        parts = unquote(fragment).split(\"/\") if fragment else []\n        for part in parts:\n            part = part.replace(\"~1\", \"/\").replace(\"~0\", \"~\")\n\n            if isinstance(document, Sequence):\n                # Array indexes should be turned into integers\n                try:\n                    part = int(part)\n                except ValueError:\n                    pass\n            try:\n                document = document[part]\n            except (TypeError, LookupError):\n                raise exceptions.RefResolutionError(\n                    f\"Unresolvable JSON pointer: {fragment!r}\",\n                )\n\n        return document\n\n    def resolve_remote(self, uri):\n        \"\"\"\n        Resolve a remote ``uri``.\n\n        If called directly, does not check the store first, but after\n        retrieving the document at the specified URI it will be saved in\n        the store if :attr:`cache_remote` is True.\n\n        .. note::\n\n            If the requests_ library is present, ``jsonschema`` will use it to\n            request the remote ``uri``, so that the correct encoding is\n            detected and used.\n\n            If it isn't, or if the scheme of the ``uri`` is not ``http`` or\n            ``https``, UTF-8 is assumed.\n\n        Arguments:\n\n            uri (str):\n\n                The URI to resolve\n\n        Returns:\n\n            The retrieved document\n\n        .. _requests: https://pypi.org/project/requests/\n        \"\"\"\n        try:\n            import requests\n        except ImportError:\n            requests = None\n\n        scheme = urlsplit(uri).scheme\n\n        if scheme in self.handlers:\n            result = self.handlers[scheme](uri)\n        elif scheme in [\"http\", \"https\"] and requests:\n            # Requests has support for detecting the correct encoding of\n            # json over http\n            result = requests.get(uri).json()\n        else:\n            # Otherwise, pass off to urllib and assume utf-8\n            with urlopen(uri) as url:\n                result = json.loads(url.read().decode(\"utf-8\"))\n\n        if self.cache_remote:\n            self.store[uri] = result\n        return result\n\n\ndef validate(instance, schema, cls=None, *args, **kwargs):\n    \"\"\"\n    Validate an instance under the given schema.\n\n        >>> validate([2, 3, 4], {\"maxItems\": 2})\n        Traceback (most recent call last):\n            ...\n        ValidationError: [2, 3, 4] is too long\n\n    :func:`validate` will first verify that the provided schema is\n    itself valid, since not doing so can lead to less obvious error\n    messages and fail in less obvious or consistent ways.\n\n    If you know you have a valid schema already, especially if you\n    intend to validate multiple instances with the same schema, you\n    likely would prefer using the `IValidator.validate` method directly\n    on a specific validator (e.g. ``Draft7Validator.validate``).\n\n\n    Arguments:\n\n        instance:\n\n            The instance to validate\n\n        schema:\n\n            The schema to validate with\n\n        cls (IValidator):\n\n            The class that will be used to validate the instance.\n\n    If the ``cls`` argument is not provided, two things will happen\n    in accordance with the specification. First, if the schema has a\n    :validator:`$schema` property containing a known meta-schema [#]_\n    then the proper validator will be used. The specification recommends\n    that all schemas contain :validator:`$schema` properties for this\n    reason. If no :validator:`$schema` property is found, the default\n    validator class is the latest released draft.\n\n    Any other provided positional and keyword arguments will be passed\n    on when instantiating the ``cls``.\n\n    Raises:\n\n        `jsonschema.exceptions.ValidationError` if the instance\n            is invalid\n\n        `jsonschema.exceptions.SchemaError` if the schema itself\n            is invalid\n\n    .. rubric:: Footnotes\n    .. [#] known by a validator registered with\n        `jsonschema.validators.validates`\n    \"\"\"\n    if cls is None:\n        cls = validator_for(schema)\n\n    cls.check_schema(schema)\n    validator = cls(schema, *args, **kwargs)\n    error = exceptions.best_match(validator.iter_errors(instance))\n    if error is not None:\n        raise error\n\n\ndef validator_for(schema, default=_LATEST_VERSION):\n    \"\"\"\n    Retrieve the validator class appropriate for validating the given schema.\n\n    Uses the :validator:`$schema` property that should be present in the\n    given schema to look up the appropriate validator class.\n\n    Arguments:\n\n        schema (collections.abc.Mapping or bool):\n\n            the schema to look at\n\n        default:\n\n            the default to return if the appropriate validator class\n            cannot be determined.\n\n            If unprovided, the default is to return the latest supported\n            draft.\n    \"\"\"\n    if schema is True or schema is False or \"$schema\" not in schema:\n        return default\n    if schema[\"$schema\"] not in _META_SCHEMAS:\n        warn(\n            (\n                \"The metaschema specified by $schema was not found. \"\n                \"Using the latest draft to validate, but this will raise \"\n                \"an error in the future.\"\n            ),\n            DeprecationWarning,\n            stacklevel=2,\n        )\n    return _META_SCHEMAS.get(schema[\"$schema\"], _LATEST_VERSION)\n", 1003], "/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/jsonschema/__init__.py": ["\"\"\"\nAn implementation of JSON Schema for Python\n\nThe main functionality is provided by the validator classes for each of the\nsupported JSON Schema versions.\n\nMost commonly, `validate` is the quickest way to simply validate a given\ninstance under a schema, and will create a validator for you.\n\"\"\"\nimport warnings\n\nfrom jsonschema._format import (\n    FormatChecker,\n    draft3_format_checker,\n    draft4_format_checker,\n    draft6_format_checker,\n    draft7_format_checker,\n    draft201909_format_checker,\n    draft202012_format_checker,\n)\nfrom jsonschema._types import TypeChecker\nfrom jsonschema.exceptions import (\n    ErrorTree,\n    FormatError,\n    RefResolutionError,\n    SchemaError,\n    ValidationError,\n)\nfrom jsonschema.validators import (\n    Draft3Validator,\n    Draft4Validator,\n    Draft6Validator,\n    Draft7Validator,\n    Draft201909Validator,\n    Draft202012Validator,\n    RefResolver,\n    validate,\n)\n\n\ndef __getattr__(name):\n    if name == \"__version__\":\n        warnings.warn(\n            \"Accessing jsonschema.__version__ is deprecated and will be \"\n            \"removed in a future release. Use importlib.metadata directly \"\n            \"to query for jsonschema's version.\",\n            DeprecationWarning,\n        )\n\n        try:\n            from importlib import metadata\n        except ImportError:\n            import importlib_metadata as metadata\n\n        return metadata.version(\"jsonschema\")\n    raise AttributeError(f\"module {__name__} has no attribute {name}\")\n", 56], "/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py": ["\"\"\" Module for kernel tuner utility functions \"\"\"\nimport itertools\nimport json\nfrom collections import OrderedDict\nimport os\nimport errno\nimport tempfile\nimport logging\nimport warnings\nimport re\nfrom types import FunctionType\n\nimport numpy as np\ntry:\n    import cupy as cp\nexcept ImportError:\n    cp = np\n\n\nclass TorchPlaceHolder():\n\n    def __init__(self):\n        self.Tensor = Exception    #using Exception here as a type that will never be among kernel arguments\n\n\ntry:\n    import torch\nexcept ImportError:\n    torch = TorchPlaceHolder()\n\ndefault_block_size_names = [\"block_size_x\", \"block_size_y\", \"block_size_z\"]\n\n\ndef check_argument_type(dtype, kernel_argument):\n    \"\"\"check if the numpy.dtype matches the type used in the code\"\"\"\n    types_map = {\n        \"uint8\": [\"uchar\", \"unsigned char\", \"uint8_t\"],\n        \"int8\": [\"char\", \"int8_t\"],\n        \"uint16\": [\"ushort\", \"unsigned short\", \"uint16_t\"],\n        \"int16\": [\"short\", \"int16_t\"],\n        \"uint32\": [\"uint\", \"unsigned int\", \"uint32_t\"],\n        \"int32\": [\"int\", \"int32_t\"],    # discrepancy between OpenCL and C here, long may be 32bits in C\n        \"uint64\": [\"ulong\", \"unsigned long\", \"uint64_t\"],\n        \"int64\": [\"long\", \"int64_t\"],\n        \"float16\": [\"half\"],\n        \"float32\": [\"float\"],\n        \"float64\": [\"double\"]\n    }\n    if dtype in types_map:\n        return any([substr in kernel_argument for substr in types_map[dtype]])\n    return False    # unknown dtype. do not throw exception to still allow kernel to run.\n\n\ndef check_argument_list(kernel_name, kernel_string, args):\n    \"\"\" raise an exception if a kernel arguments do not match host arguments \"\"\"\n    kernel_arguments = list()\n    collected_errors = list()\n    for iterator in re.finditer(kernel_name + \"[ \\n\\t]*\" + r\"\\(\", kernel_string):\n        kernel_start = iterator.end()\n        kernel_end = kernel_string.find(\")\", kernel_start)\n        if kernel_start != 0:\n            kernel_arguments.append(kernel_string[kernel_start:kernel_end].split(\",\"))\n    for arguments_set, arguments in enumerate(kernel_arguments):\n        collected_errors.append(list())\n        if len(arguments) != len(args):\n            collected_errors[arguments_set].append(\"Kernel and host argument lists do not match in size.\")\n            continue\n        for (i, arg) in enumerate(args):\n            kernel_argument = arguments[i]\n\n            if not isinstance(arg, (np.ndarray, np.generic, cp.ndarray, torch.Tensor)):\n                raise TypeError(\"Argument at position \" + str(i) + \" of type: \" + str(type(arg)) + \" should be of type np.ndarray or numpy scalar\")\n\n            correct = True\n            if isinstance(arg, np.ndarray) and not \"*\" in kernel_argument:\n                correct = False    # array is passed to non-pointer kernel argument\n\n            if correct and check_argument_type(str(arg.dtype), kernel_argument):\n                continue\n\n            collected_errors[arguments_set].append(\"Argument at position \" + str(i) + \" of dtype: \" + str(arg.dtype) + \" does not match \" + kernel_argument +\n                                                   \".\")\n        if not collected_errors[arguments_set]:\n            # We assume that if there is a possible list of arguments that matches with the provided one\n            # it is the right one\n            return\n    for errors in collected_errors:\n        warnings.warn(errors[0], UserWarning)\n        # raise TypeError(errors[0])\n\n\ndef check_tune_params_list(tune_params):\n    \"\"\" raise an exception if a tune parameter has a forbidden name \"\"\"\n    forbidden_names = (\"grid_size_x\", \"grid_size_y\", \"grid_size_z\", \"time\")\n    for name, param in tune_params.items():\n        if name in forbidden_names:\n            raise ValueError(\"Tune parameter \" + name + \" with value \" + str(param) + \" has a forbidden name!\")\n\n\ndef check_block_size_names(block_size_names):\n    if block_size_names is not None:\n        # do some type checks for the user input\n        if not isinstance(block_size_names, list):\n            raise ValueError(\"block_size_names should be a list of strings!\")\n        if len(block_size_names) > 3:\n            raise ValueError(\"block_size_names should not contain more than 3 names!\")\n        if not all([isinstance(name, \"\".__class__) for name in block_size_names]):\n            raise ValueError(\"block_size_names should contain only strings!\")\n        # ensure there is always at least three names\n        for i, name in enumerate(default_block_size_names):\n            if len(block_size_names) < i + 1:\n                block_size_names.append(name)\n\n\ndef check_block_size_params_names_list(block_size_names, tune_params):\n    if block_size_names is not None:\n        for name in block_size_names:\n            if name not in tune_params.keys():\n                warnings.warn(\"Block size name \" + name + \" is not specified in the tunable parameters list!\", UserWarning)\n    else:    # if default block size names are used\n        if not any([k in default_block_size_names for k in tune_params.keys()]):\n            warnings.warn(\"None of the tunable parameters specify thread block dimensions!\", UserWarning)\n\n\ndef check_restrictions(restrictions, element, keys, verbose):\n    \"\"\" check whether a specific instance meets the search space restrictions \"\"\"\n    params = OrderedDict(zip(keys, element))\n    valid = True\n    if callable(restrictions):\n        valid = restrictions(params)\n    else:\n        for restrict in restrictions:\n            try:\n                if not eval(replace_param_occurrences(restrict, params)):\n                    valid = False\n            except ZeroDivisionError:\n                pass\n    if not valid and verbose:\n        print(\"skipping config\", get_instance_string(params), \"reason: config fails restriction\")\n    return valid\n\n\ndef config_valid(config, tuning_options, max_threads):\n    \"\"\" combines restrictions and a check on the max thread block dimension to check config validity \"\"\"\n    legal = True\n    if tuning_options.restrictions:\n        legal = check_restrictions(tuning_options.restrictions, config, tuning_options.tune_params.keys(), False)\n    params = OrderedDict(zip(tuning_options.tune_params.keys(), config))\n    dims = get_thread_block_dimensions(params, tuning_options.get(\"block_size_names\", None))\n    return legal and np.prod(dims) <= max_threads\n\n\ndef delete_temp_file(filename):\n    \"\"\" delete a temporary file, don't complain if no longer exists \"\"\"\n    try:\n        os.remove(filename)\n    except OSError as e:\n        if e.errno != errno.ENOENT:\n            raise e\n\n\ndef detect_language(kernel_string):\n    \"\"\"attempt to detect language from the kernel_string\"\"\"\n    if \"__global__\" in kernel_string:\n        lang = \"CUDA\"\n    elif \"__kernel\" in kernel_string:\n        lang = \"OpenCL\"\n    else:\n        lang = \"C\"\n    return lang\n\n\ndef get_config_string(params, keys=None, units=None):\n    \"\"\" return a compact string representation of a measurement \"\"\"\n\n    def compact_number(v):\n        if isinstance(v, float):\n            return \"{:.3f}\".format(round(v, 3))\n        else:\n            return str(v)\n\n    compact_str_items = []\n    if not keys:\n        keys = params.keys()\n    # first make a list of compact strings for each parameter\n    for k, v in params.items():\n        if k in keys:\n            unit = \"\"\n            if isinstance(units, dict):    # check if not None not enough, units could be mocked which causes errors\n                unit = units.get(k, \"\")\n            compact_str_items.append(k + \"=\" + compact_number(v) + unit)\n    # and finally join them\n    compact_str = \", \".join(compact_str_items)\n    return compact_str\n\n\ndef get_grid_dimensions(current_problem_size, params, grid_div, block_size_names):\n    \"\"\"compute grid dims based on problem sizes and listed grid divisors\"\"\"\n\n    def get_dimension_divisor(divisor_list, default, params):\n        if divisor_list is None:\n            if default in params:\n                divisor_list = [default]\n            else:\n                return 1\n        if callable(divisor_list):\n            return divisor_list(params)\n        else:\n            return np.prod([int(eval(replace_param_occurrences(s, params))) for s in divisor_list])\n\n    divisors = [get_dimension_divisor(d, block_size_names[i], params) for i, d in enumerate(grid_div)]\n    return tuple(int(np.ceil(float(current_problem_size[i]) / float(d))) for i, d in enumerate(divisors))\n\n\ndef get_instance_string(params):\n    \"\"\" combine the parameters to a string mostly used for debug output\n        use of OrderedDict is advised\n    \"\"\"\n    return \"_\".join([str(i) for i in params.values()])\n\n\ndef get_kernel_string(kernel_source, params=None):\n    \"\"\" retrieve the kernel source and return as a string\n\n    This function processes the passed kernel_source argument, which could be\n    a function, a string with a filename, or just a string with code already.\n\n    If kernel_source is a function, the function is called with instance\n    parameters in 'params' as the only argument.\n\n    If kernel_source looks like filename, the file is read in, but if\n    the file does not exist, it is assumed that the string is not a filename\n    after all.\n\n    :param kernel_source: One of the sources for the kernel, could be a\n        function that generates the kernel code, a string containing a filename\n        that points to the kernel source, or just a string that contains the code.\n    :type kernel_source: string or callable\n\n    :param params: Dictionary containing the tunable parameters for this specific\n        kernel instance, only needed when kernel_source is a generator.\n    :type param: dict\n\n    :returns: A string containing the kernel code.\n    :rtype: string\n    \"\"\"\n    # logging.debug('get_kernel_string called with %s', str(kernel_source))\n    logging.debug('get_kernel_string called')\n\n    kernel_string = None\n    if callable(kernel_source):\n        kernel_string = kernel_source(params)\n    elif isinstance(kernel_source, str):\n        if looks_like_a_filename(kernel_source):\n            kernel_string = read_file(kernel_source) or kernel_source\n        else:\n            kernel_string = kernel_source\n    else:\n        raise TypeError(\"Error kernel_source is not a string nor a callable function\")\n    return kernel_string\n\n\ndef get_valid_configs(tuning_options, max_threads) -> list:\n    \"\"\" compute valid configurations in a search space based on restrictions and max_threads\"\"\"\n    parameter_space = itertools.product(*tuning_options.tune_params.values())\n    if tuning_options.restrictions is not None:\n        parameter_space = filter(lambda p: config_valid(p, tuning_options, max_threads), parameter_space)\n    return list(parameter_space)\n\n\ndef get_number_of_valid_configs(tuning_options, max_threads) -> int:\n    \"\"\"compute number of valid configurations in a search space based on restrictions and max_threads\"\"\"\n    return len(get_valid_configs(tuning_options, max_threads))\n\n\ndef get_problem_size(problem_size, params):\n    \"\"\"compute current problem size\"\"\"\n    if callable(problem_size):\n        problem_size = problem_size(params)\n    if isinstance(problem_size, (str, int, np.integer)):\n        problem_size = (problem_size, )\n    current_problem_size = [1, 1, 1]\n    for i, s in enumerate(problem_size):\n        if isinstance(s, str):\n            current_problem_size[i] = int(eval(replace_param_occurrences(s, params)))\n        elif isinstance(s, (int, np.integer)):\n            current_problem_size[i] = s\n        else:\n            raise TypeError(\"Error: problem_size should only contain strings or integers\")\n    return current_problem_size\n\n\ndef get_smem_args(smem_args, params):\n    \"\"\" return a dict with kernel instance specific size \"\"\"\n    result = smem_args.copy()\n    if 'size' in result:\n        size = result['size']\n        if callable(size):\n            size = size(params)\n        elif isinstance(size, str):\n            size = replace_param_occurrences(size, params)\n            size = int(eval(size))\n        result['size'] = size\n    return result\n\n\ndef get_temp_filename(suffix=None):\n    \"\"\" return a string in the form of temp_X, where X is a large integer \"\"\"\n    file = tempfile.mkstemp(suffix=suffix or \"\", prefix=\"temp_\", dir=os.getcwd())    # or \"\" for Python 2 compatibility\n    os.close(file[0])\n    return file[1]\n\n\ndef get_thread_block_dimensions(params, block_size_names=None):\n    \"\"\"thread block size from tuning params, currently using convention\"\"\"\n    if not block_size_names:\n        block_size_names = default_block_size_names\n\n    block_size_x = params.get(block_size_names[0], 256)\n    block_size_y = params.get(block_size_names[1], 1)\n    block_size_z = params.get(block_size_names[2], 1)\n    return (int(block_size_x), int(block_size_y), int(block_size_z))\n\n\ndef print_config_output(tune_params, params, quiet, metrics, units):\n    \"\"\"print the configuration string with tunable parameters and benchmark results\"\"\"\n    print_keys = list(tune_params.keys()) + [\"time\"]\n    if metrics:\n        print_keys += metrics.keys()\n    output_string = get_config_string(params, print_keys, units)\n    if not quiet:\n        print(output_string)\n\n\ndef process_metrics(params, metrics):\n    \"\"\" process user-defined metrics for derived benchmark results\n\n    Metrics must be an OrderedDict to support composable metrics. The dictionary keys describe\n    the name given to this user-defined metric and will be used as the key in the results dictionaries\n    return by Kernel Tuner. The values describe how to calculate the user-defined metric, using either a\n    string expression in which the tunable parameters and benchmark results can be used as variables, or\n    as a function that accepts a dictionary as argument.\n    Example:\n    metrics = OrderedDict()\n    metrics[\"x\"] = \"10000 / time\"\n    metrics[\"x2\"] = \"x*x\"\n\n    Note that the values in the metric dictionary can also be functions that accept params as argument.\n    Example:\n    metrics = OrderedDict()\n    metrics[\"GFLOP/s\"] = lambda p : 10000 / p[\"time\"]\n\n    :param params: A dictionary with tunable parameters and benchmark results.\n    :type params: dict\n\n    :param metrics: An OrderedDict with user-defined metrics that can be used to create derived benchmark results.\n    :type metrics: OrderedDict\n\n    :returns: An updated params dictionary with the derived metrics inserted along with the benchmark results.\n    :rtype: dict\n\n    \"\"\"\n    if not isinstance(metrics, OrderedDict):\n        raise ValueError(\"metrics should be an OrderedDict to preserve order and support composability\")\n    for k, v in metrics.items():\n        if isinstance(v, str):\n            value = eval(replace_param_occurrences(v, params))\n        elif callable(v):\n            value = v(params)\n        else:\n            raise ValueError(\"metric dicts values should be strings or callable\")\n        if not k in params:\n            params[k] = value\n        else:\n            raise ValueError(\"metric dicts keys should not already exist in params\")\n    return params\n\n\ndef looks_like_a_filename(kernel_source):\n    \"\"\" attempt to detect whether source code or a filename was passed \"\"\"\n    logging.debug('looks_like_a_filename called')\n    result = False\n    if isinstance(kernel_source, str):\n        result = True\n        # test if not too long\n        if len(kernel_source) > 250:\n            result = False\n        # test if not contains special characters\n        for c in \"();{}\\\\\":\n            if c in kernel_source:\n                result = False\n        # just a safeguard for stuff that looks like code\n        for s in [\"__global__ \", \"__kernel \", \"void \", \"float \"]:\n            if s in kernel_source:\n                result = False\n        # string must contain substring \".c\", \".opencl\", or \".F\"\n        result = result and any([s in kernel_source for s in (\".c\", \".opencl\", \".F\", \".py\")])\n    logging.debug('kernel_source is a filename: %s' % str(result))\n    return result\n\n\ndef prepare_kernel_string(kernel_name, kernel_string, params, grid, threads, block_size_names, lang):\n    \"\"\" prepare kernel string for compilation\n\n    Prepends the kernel with a series of C preprocessor defines specific\n    to this kernel instance:\n\n     * the thread block dimensions\n     * the grid dimensions\n     * tunable parameters\n\n    :param kernel_name: Name of the kernel.\n    :type kernel_name: string\n\n    :param kernel_string: One of the source files of the kernel as a string containing code.\n    :type kernel_string: string\n\n    :param params: A dictionary containing the tunable parameters specific to this instance.\n    :type params: dict\n\n    :param grid: A tuple with the grid dimensions for this specific instance.\n    :type grid: tuple(x,y,z)\n\n    :param threads: A tuple with the thread block dimensions for this specific instance.\n    :type threads: tuple(x,y,z)\n\n    :param block_size_names: A tuple with the names of the thread block dimensions used\n        in the code. By default this is [\"block_size_x\", ...], but the user\n        may supply different names if they prefer.\n    :type block_size_names: tuple(string)\n\n    :returns: A string containing the source code made specific to this kernel instance.\n    :rtype: string\n\n    \"\"\"\n    logging.debug('prepare_kernel_string called for %s', kernel_name)\n\n    # since we insert defines above the original kernel code, the line numbers will be incorrect\n    # the following preprocessor directive informs the compiler that lines should be counted from 1\n    kernel_string = \"#line 1\\n\" + kernel_string\n\n    grid_dim_names = [\"grid_size_x\", \"grid_size_y\", \"grid_size_z\"]\n    for i, g in enumerate(grid):\n        kernel_string = f\"#define {grid_dim_names[i]} {g}\\n\" + kernel_string\n    for i, g in enumerate(threads):\n        kernel_string = f\"#define {block_size_names[i]} {g}\\n\" + kernel_string\n    for k, v in params.items():\n        if \"loop_unroll_factor\" in k and lang == \"CUDA\":\n            # this handles the special case that in CUDA\n            # pragma unroll loop_unroll_factor, loop_unroll_factor should be a constant integer expression\n            # in OpenCL this isn't the case and we can just insert \"#define loop_unroll_factor N\"\n            # using 0 to disable specifying a loop unrolling factor for this loop\n            kernel_string = \"constexpr int \" + k + \" = \" + str(v) + \";\\n\" + kernel_string\n            if v == 0:\n                kernel_string = re.sub(r\"\\n\\s*#pragma\\s+unroll\\s+\" + k, \"\\n\", kernel_string)    # + r\"[^\\S]*\"\n        elif k not in block_size_names:\n            kernel_string = f\"#define {k} {v}\\n\" + kernel_string\n\n    name = kernel_name\n\n    # also insert kernel_tuner token\n    kernel_string = \"#define kernel_tuner 1\\n\" + kernel_string\n    # name = kernel_name + \"_\" + get_instance_string(params)\n    # kernel_string = kernel_string.replace(kernel_name, name)\n\n    return name, kernel_string\n\n\ndef read_file(filename):\n    \"\"\" return the contents of the file named filename or None if file not found \"\"\"\n    if os.path.isfile(filename):\n        with open(filename, 'r') as f:\n            return f.read()\n\n\ndef replace_param_occurrences(string, params):\n    \"\"\"replace occurrences of the tuning params with their current value\"\"\"\n    for k, v in params.items():\n        string = string.replace(k, str(v))\n    return string\n\n\ndef setup_block_and_grid(problem_size, grid_div, params, block_size_names=None):\n    \"\"\"compute problem size, thread block and grid dimensions for this kernel\"\"\"\n    threads = get_thread_block_dimensions(params, block_size_names)\n    current_problem_size = get_problem_size(problem_size, params)\n    grid = get_grid_dimensions(current_problem_size, params, grid_div, block_size_names)\n    return threads, grid\n\n\ndef write_file(filename, string):\n    \"\"\"dump the contents of string to a file called filename\"\"\"\n    import sys\n    # ugly fix, hopefully we can find a better one\n    if sys.version_info[0] >= 3:\n        with open(filename, 'w', encoding=\"utf-8\") as f:\n            f.write(string)\n    else:\n        with open(filename, 'w') as f:\n            f.write(string.encode(\"utf-8\"))\n\n\ndef normalize_verify_function(v):\n    \"\"\"Normalize a user-specified verify function.\n\n    The user-specified function has two required positional arguments (answer, result_host),\n    and an optional keyword (or keyword-only) argument atol. We normalize it to always accept\n    an atol keyword argument.\n\n    Undefined behaviour if the passed function does not match the required signatures.\n    \"\"\"\n\n    # python 3.3+\n    def _has_kw_argument_sig(func, name):\n        from inspect import signature\n        sig = signature(func)\n        return name in sig.parameters\n\n    # python 3.0+\n    def _has_kw_argument_fullarg(func, name):\n        from inspect import getfullargspec\n        spec = getfullargspec(func)\n        return (name in spec.args) or (name in spec.kwonlyargs)\n\n    # python 2.6+\n    def _has_kw_argument_arg(func, name):\n        from inspect import getargspec\n        spec = getargspec(func)\n        return name in spec.args\n\n    if v is None:\n        return None\n\n    import inspect\n\n    if hasattr(inspect, 'signature'):\n        has_kw_argument = _has_kw_argument_sig\n    elif hasattr(inspect, 'getfullargspec'):\n        has_kw_argument = _has_kw_argument_fullarg\n    elif hasattr(inspect, 'getargspec'):\n        has_kw_argument = _has_kw_argument_arg\n    else:\n        raise RuntimeError('No suitable inspect function found')\n\n    if has_kw_argument(v, 'atol'):\n        return v\n    return lambda answer, result_host, atol: v(answer, result_host)\n\n\ndef process_cache(cache, kernel_options, tuning_options, runner):\n    \"\"\"cache file for storing tuned configurations\n\n    the cache file is stored using JSON and uses the following format:\n\n    .. code-block:: python\n\n        { device_name: \"name of device\"\n          kernel_name: \"name of kernel\"\n          tune_params_keys: list\n          tune_params:\n          cache: {\n            \"x1,x2,..xN\": {\"block_size_x\": x1, ..., time=0.234342},\n            \"y1,y2,..yN\": {\"block_size_x\": y1, ..., time=0.134233},\n          }\n        }\n\n\n    The last two closing brackets are not required, and everything\n    should work as expected if these are missing. This is to allow to continue\n    from an earlier (abruptly ended) tuning session.\n\n    \"\"\"\n    # caching only works correctly if tunable_parameters are stored in a OrderedDict\n    if not isinstance(tuning_options.tune_params, OrderedDict):\n        raise ValueError(\"Caching only works correctly when tunable parameters are stored in a OrderedDict\")\n\n    # if file does not exist, create new cache\n    if not os.path.isfile(cache):\n        if tuning_options.simulation_mode:\n            raise ValueError(f\"Simulation mode requires an existing cachefile: file {cache} does not exist\")\n\n        c = OrderedDict()\n        c[\"device_name\"] = runner.dev.name\n        c[\"kernel_name\"] = kernel_options.kernel_name\n        c[\"tune_params_keys\"] = list(tuning_options.tune_params.keys())\n        c[\"tune_params\"] = tuning_options.tune_params\n        c[\"cache\"] = {}\n\n        contents = json.dumps(c, indent=\"\")[:-3]    # except the last \"}\\n}\"\n\n        # write the header to the cachefile\n        with open(cache, \"w\") as cachefile:\n            cachefile.write(contents)\n\n        tuning_options.cachefile = cache\n        tuning_options.cache = {}\n\n    # if file exists\n    else:\n        with open(cache, \"r\") as cachefile:\n            filestr = cachefile.read().strip()\n\n        # if file was not properly closed, pretend it was properly closed\n        if not filestr[-3:] == \"}\\n}\":\n            # remove the trailing comma if any, and append closing brackets\n            if filestr[-1] == \",\":\n                filestr = filestr[:-1]\n            filestr = filestr + \"}\\n}\"\n        elif not tuning_options.simulation_mode:    # don't do this in simulation mode because the cache must have no race conditions in case of parallel execution\n            # if it was properly closed, open it for appending new entries\n            with open(cache, \"w\") as cachefile:\n                cachefile.write(filestr[:-3] + \",\")\n\n        cached_data = json.loads(filestr)\n\n        # if in simulation mode, use the device name from the cache file as the runner device name\n        if runner.simulation_mode:\n            runner.dev.name = cached_data[\"device_name\"]\n\n        # check if it is safe to continue tuning from this cache\n        if cached_data[\"device_name\"] != runner.dev.name:\n            raise ValueError(\"Cannot load cache which contains results for different device\")\n        if cached_data[\"kernel_name\"] != kernel_options.kernel_name:\n            raise ValueError(\"Cannot load cache which contains results for different kernel\")\n        if cached_data[\"tune_params_keys\"] != list(tuning_options.tune_params.keys()):\n            raise ValueError(\"Cannot load cache which contains results obtained with different tunable parameters\")\n\n        tuning_options.cachefile = cache\n        tuning_options.cache = cached_data[\"cache\"]\n\n\ndef close_cache(cache):\n    if not os.path.isfile(cache):\n        raise ValueError(\"close_cache expects cache file to exist\")\n\n    with open(cache, \"r\") as fh:\n        contents = fh.read()\n\n    # close to file to make sure it can be read by JSON parsers\n    if contents[-1] == \",\":\n        with open(cache, \"w\") as fh:\n            fh.write(contents[:-1] + \"}\\n}\")\n\n\ndef store_cache(key, params, tuning_options):\n    \"\"\" stores a new entry (key, params) to the cachefile \"\"\"\n\n    # create converter for dumping numpy objects to JSON\n    def npconverter(obj):\n        if isinstance(obj, np.integer):\n            return int(obj)\n        elif isinstance(obj, np.floating):\n            return float(obj)\n        elif isinstance(obj, np.ndarray):\n            return obj.tolist()\n        else:\n            return obj.__str__()\n\n    logging.debug('store_cache called, cache=%s, cachefile=%s' % (tuning_options.cache, tuning_options.cachefile))\n    if isinstance(tuning_options.cache, dict):\n        if not key in tuning_options.cache:\n            tuning_options.cache[key] = params\n            if tuning_options.cachefile:\n                with open(tuning_options.cachefile, \"a\") as cachefile:\n                    cachefile.write(\"\\n\" + json.dumps({ key: params }, default=npconverter)[1:-1] + \",\")\n\n\ndef dump_cache(obj: str, tuning_options):\n    \"\"\" dumps a string in the cache, this omits the several checks of store_cache() to speed up the process - with great power comes great responsibility! \"\"\"\n    if isinstance(tuning_options.cache, dict) and tuning_options.cachefile:\n        with open(tuning_options.cachefile, \"a\") as cachefile:\n            cachefile.write(obj)\n\n\ndef parse_restrictions(restrictions: list):\n    \"\"\"\" parses restrictions from a list of strings into a callable function \"\"\"\n\n    regex_match_variable = r\"([a-zA-Z_$][a-zA-Z_$0-9]*)\"\n    suffix = ' and '\n    parsed_restrictions = \"\"\n    for restriction in restrictions:\n        parsed_restrictions += re.sub(regex_match_variable, r'params[\"\\1\"]', restriction) + suffix\n\n    # tidy up the code by removing the last suffix and unecessary spaces\n    parsed_restrictions = parsed_restrictions[:-len(suffix)]\n    parsed_restrictions = parsed_restrictions.strip()\n    parsed_restrictions = \" \".join(parsed_restrictions.split())\n\n    # compile into a function\n    parsed_restrictions = f\"def restrictions(params): return {parsed_restrictions} \\n\"\n    code_object = compile(parsed_restrictions, '<string>', 'exec')\n    func = FunctionType(code_object.co_consts[0], globals())\n    return func\n", 693], "/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/integration.py": ["import os\nimport re\nimport json\n\nfrom jsonschema import validate\n\nfrom kernel_tuner import util\n\n#specifies for a number of pre-defined objectives whether\n#the objective should be minimized or maximized (boolean value denotes higher is better)\nobjective_default_map = {\n    \"time\": False,\n    \"energy\": False,\n    \"GFLOP/s\": True,\n    \"TFLOP/s\": True,\n    \"GB/s\": True,\n    \"TB/s\": True,\n    \"GFLOPS/W\": True,\n    \"TFLOPS/W\": True,\n    \"GFLOP/J\": True,\n    \"TFLOP/J\": True\n}\n\ndef get_objective_defaults(objective, objective_higher_is_better):\n    \"\"\" Uses time as default objective and attempts to lookup objective_higher_is_better for known objectives \"\"\"\n    objective = objective or \"time\"\n    if objective_higher_is_better is None and objective in objective_default_map:\n        objective_higher_is_better = objective_default_map[objective]\n    else:\n        raise ValueError(f\"Please specify objective_higher_is_better for objective {objective}\")\n    return objective, objective_higher_is_better\n\nschema_v1_0 = {\n    \"$schema\": \"https://json-schema.org/draft-07/schema#\",\n    \"type\": \"object\",\n    \"properties\": {\n        \"version_number\": {\"type\": \"string\"},\n        \"tunable_parameters\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n        \"kernel_name\": {\"type\": \"string\"},\n        \"kernel_string\": {\"type\": \"string\"},\n        \"objective\": {\"type\": \"string\"},\n        \"objective_higher_is_better\": {\"type\": \"boolean\"},\n        \"data\": {\n            \"type\": \"array\",\n            \"items\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"device_name\": {\"type\": \"string\"},\n                    \"problem_size\": {\"type\": \"string\"}\n                },\n                \"required\": [\"device_name\", \"problem_size\", \"tunable_parameters\"]\n            },\n        },\n    },\n    \"required\": [\"version_number\", \"tunable_parameters\", \"kernel_name\", \"objective\", \"data\"]\n}\n\n\n\n\nclass TuneResults():\n    \"\"\" Object to represent the tuning results stored to file \"\"\"\n\n    def __init__(self, results_filename):\n        #open results file\n        if not os.path.isfile(results_filename):\n            raise ValueError(\"Error: results_filename does not exist\")\n        meta, data = _read_results_file(results_filename)\n        if len(data) < 1:\n            raise ValueError(\"results file seems to be empty or did not load correctly\")\n        self.data = data\n        self.meta = meta\n        self.objective = meta[\"objective\"]\n        self.objective_higher_is_better = meta.get(\"objective_higher_is_better\", False)\n\n    def get_best_config(self, gpu_name=\"default\", problem_size=None):\n        \"\"\" get the best config based on these tuning results\n\n            This function returns the overall best performing kernel configuration\n            based on the tuning results for a given gpu_name and problem_size.\n\n            If problem_size is not given this function will select a default configuration\n            based on the tuning results for all problem_sizes and the given gpu_name.\n\n            If gpu_name is not given this function will select a default configuration\n            based on all tuning results.\n\n            :param gpu_name: Name of the GPU for which the best configuration\n                needs to be retrieved.\n            :type gpu_name: string\n\n            :param problem_size: The problem size for which the best configuration\n                on the given gpu_name needs to be retrieved.\n            :type problem_size: tuple, int, or string\n\n            :returns: A dictionary with tunable parameters of the selected kernel\n                kernel configuration.\n            :rtype: dict\n        \"\"\"\n        gpu_name = gpu_name.replace(\"-\", \"_\").replace(\" \", \"_\")\n\n        if problem_size:\n            if not isinstance(problem_size, str):\n                if not isinstance(problem_size, (list, tuple)):\n                    problem_size = (problem_size,)\n                problem_size_str = \"x\".join(str(i) for i in problem_size)\n            else:\n                problem_size_str = problem_size\n\n        gpu_match = [result for result in self.data if result[\"device_name\"] == gpu_name]\n\n        if gpu_match:\n            gpu_ps_match = [result for result in gpu_match if problem_size and result[\"problem_size\"] == problem_size_str]\n            if gpu_ps_match:\n                return _get_best_config_from_list(gpu_ps_match, self.objective, self.objective_higher_is_better)\n            #problem size is not given or not among the results, so return a good default\n            return _select_best_common_config(gpu_match, self.objective, self.objective_higher_is_better)\n\n        #gpu is not among the results, so return a good default\n        return _select_best_common_config(self.data, self.objective, self.objective_higher_is_better)\n\n\ndef store_results(results_filename, kernel_name, kernel_string, tune_params, problem_size, results, env, top=3, objective=None, objective_higher_is_better=None):\n    \"\"\" stores tuning results to a JSON file\n\n        Stores the top (3% by default) best kernel configurations in a JSON file.\n        The results are stored for a specific device (retrieved using env['device_name'])\n        and for a specific problem_size. If the file already exists, new results for\n        this device and problem_size will be appended. Any previous results already stored\n        in the file for this specific device and problem_size will be overwritten.\n\n        :param results_filename: Filename of the JSON file in which the results will be stored.\n            Results will be appended if the file already exists. Existing results within the\n            file for the same device and problem_size will be overwritten.\n        :type results_filename: string\n\n        :param tune_params: The tunable parameters of this kernel.\n        :type tune_params: dict\n\n        :param problem_size: The problem_size this kernel was tuned for\n        :type problem_size: tuple\n\n        :param results: A list of dictionaries of all executed kernel configurations and their\n            execution times, and possibly other user-defined metrics, as returned by\n            tune_kernel().\n        :type results: list(dict)\n\n        :param env: A dictionary with information about the environment\n            in which the tuning took place. This records device name, properties,\n            version info, and so on. Typicaly this dictionary is returned by tune_kernel().\n        :type env: dict\n\n        :param top: Denotes the top percentage of results to store in the results file\n        :type top: float\n\n        :param objective: Optimization objective to sort results on, consisting of a string\n            that also occurs in results as a metric.\n        :type objective: string\n\n        :param objective_higher_is_better: A boolean that specifies whether the objective should\n            be maximized or minimized.\n        :type objective_higher_is_better: bool\n\n    \"\"\"\n\n    objective, objective_higher_is_better = get_objective_defaults(objective, objective_higher_is_better)\n\n    #filter results to only those that contain the objective\n    results_filtered = [item for item in results if objective in item]\n\n    #get top results\n    if objective_higher_is_better:\n        best_config = max(results_filtered, key=lambda x: x[objective])\n    else:\n        best_config = min(results_filtered, key=lambda x: x[objective])\n    best = best_config[objective]\n    top_range = top/100.0\n\n    def top_result(item):\n        current = item[objective]\n        if objective_higher_is_better:\n            return current > best * (1-top_range)\n        return current < best * (1+top_range)\n    top_results = [item for item in results_filtered if top_result(item)]\n\n    #filter result items to just the tunable parameters and the objective\n    filter_keys = list(tune_params.keys()) + [objective]\n    top_results = [{k:item[k] for k in filter_keys} for item in top_results]\n\n    #read existing results file\n    if os.path.isfile(results_filename):\n        meta, data = _read_results_file(results_filename)\n\n        #validate consistency between arguments and results file\n        if not kernel_name == meta[\"kernel_name\"]:\n            raise ValueError(\"Mismatch between given kernel_name and results file\")\n        if not all([param in meta[\"tunable_parameters\"] for param in tune_params]):\n            raise ValueError(\"Mismatch between tunable_parameters in results file and tune_params\")\n        if not objective == meta[\"objective\"]:\n            raise ValueError(\"Mismatch between given objective and results file\")\n    else:\n        #new file\n        meta = {}\n        meta[\"version_number\"] = \"1.0\"\n        meta[\"kernel_name\"] = kernel_name\n        if kernel_string and not callable(kernel_string) and not isinstance(kernel_string, list):\n            if util.looks_like_a_filename(kernel_string):\n                meta[\"kernel_string\"] = util.read_file(kernel_string)\n            else:\n                meta[\"kernel_string\"] = kernel_string\n        meta[\"objective\"] = objective\n        meta[\"objective_higher_is_better\"] = objective_higher_is_better\n        meta[\"tunable_parameters\"] = list(tune_params.keys())\n        data = []\n\n    #insert new results into the list\n    if not isinstance(problem_size, (list, tuple)):\n        problem_size = (problem_size,)\n    problem_size_str = \"x\".join(str(i) for i in problem_size)\n\n    #replace all non alphanumeric characters with underscore\n    dev_name = re.sub('[^0-9a-zA-Z]+', '_', env[\"device_name\"].strip())\n\n    #remove existing entries for this GPU and problem_size combination from the results if any\n    data = [d for d in data if not (d[\"device_name\"] == dev_name and d[\"problem_size\"] == problem_size_str)]\n\n    #extend the results with the top_results\n    results = []\n    for result in top_results:\n        record = {\"device_name\": dev_name, \"problem_size\": problem_size_str, \"tunable_parameters\": {}}\n        for k, v in result.items():\n            if k in tune_params:\n                record[\"tunable_parameters\"][k] = v\n        record[objective] = result[objective]\n        results.append(record)\n    data.extend(results)\n\n    #write output file\n    meta[\"data\"] = data\n    with open(results_filename, 'w') as fh:\n        fh.write(json.dumps(meta, indent=\"\"))\n\n\ndef create_device_targets(header_filename, results_filename, objective=None, objective_higher_is_better=None):\n    \"\"\" create a header with device targets\n\n        This function generates a header file with device targets for compiling\n        a kernel with different parameters on different devices. The tuning\n        results are stored in a JSON file created by store_results. Existing\n        header_filename will be overwritten.\n\n        This function only creates device targets and does not create problem_size\n        specific targets. Instead it searches for configurations that perform well\n        for different problem sizes and selects a single configuration to use\n        for the kernel.\n\n        The header file can be included in a kernel source file using:\n        ``#include \"header_filename.h\"``\n\n        The kernel can then be compiled for a specific device using:\n        ``-DTARGET_GPU=\"name_of_gpu\"``\n\n        The header will also include a default value, which is chosen to perform well\n        on different devices.\n\n        :param header_filename: Filename of the to be created header file.\n        :type header_filename: string\n\n        :param results_filename: Filename of the JSON file that stores the tuning results.\n        :type results_filename: string\n\n        :param objective: Optimization objective to sort results on, consisting of a string\n            that also occurs in results as a metric.\n        :type objective: string\n\n        :param objective_higher_is_better: A boolean that specifies whether the objective should\n            be maximized or minimized.\n        :type objective_higher_is_better: bool\n\n    \"\"\"\n    objective, objective_higher_is_better = get_objective_defaults(objective, objective_higher_is_better)\n\n    #open results file\n    results = TuneResults(results_filename)\n    data = results.data\n\n    #collect data for the if-block\n    gpu_targets = list({r[\"device_name\"] for r in data})\n    targets = {}\n    for gpu_name in gpu_targets:\n        targets[gpu_name] = results.get_best_config(gpu_name)\n\n    #select a good default from all good configs\n    default_params = results.get_best_config()\n\n    #write the header output file\n    if_block = \"\"\n    first = True\n    for gpu_name, params in targets.items():\n        if first:\n            if_block += f\"\\n#ifdef TARGET_{gpu_name}\\n\"\n            first = False\n        else:\n            if_block += f\"\\n#elif TARGET_{gpu_name}\\n\"\n        if_block += \"\\n\".join([f\"#define {k} {v}\" for k,v in params.items()])\n        if_block += \"\\n\"\n\n    default_config = \"\\n\".join([f\"#define {k} {v}\" for k,v in default_params.items()])\n\n    template_header_file = f\"\"\"/* header file generated by Kernel Tuner, do not modify by hand */\n#pragma once\n#ifndef kernel_tuner /* only use these when not tuning */\n\n{if_block}\n#else /* default configuration */\n{default_config}\n#endif /* GPU TARGETS */\n\n#endif /* kernel_tuner */\n\"\"\"\n\n    with open(header_filename, 'w') as fh:\n        fh.write(template_header_file)\n\n\n\n\ndef _select_best_common_config(results, objective, objective_higher_is_better):\n    \"\"\" return the most common config among results obtained on different problem sizes \"\"\"\n    results_table = {}\n    total_performance = {}\n\n    inverse_table = {}\n\n    #for each configuration in the list\n    for config in results:\n        params = config[\"tunable_parameters\"]\n\n        config_str = util.get_instance_string(params)\n        #count occurances\n        results_table[config_str] = results_table.get(config_str,0) + 1\n        #add to performance\n        total_performance[config_str] = total_performance.get(config_str,0) + config[objective]\n        #store mapping from config_str to the parameters\n        inverse_table[config_str] = params\n\n    #look for best config\n    top_freq = max(results_table.values())\n    best_configs = [k for k in results_table if results_table[k] == top_freq]\n\n    #intersect total_performance with the best_configs\n    total_performance = {k:total_performance[k] for k in total_performance if k in best_configs}\n\n    #get the best config from this intersection\n    if objective_higher_is_better:\n        best_config_str = max(total_performance.keys(), key=lambda x: total_performance[x])\n    else:\n        best_config_str = min(total_performance.keys(), key=lambda x: total_performance[x])\n\n    #lookup the tunable parameters of this configuration in the inverse table and return result\n    return inverse_table[best_config_str]\n\n\ndef _get_best_config_from_list(configs, objective, objective_higher_is_better):\n    \"\"\" return the tunable parameters of the best config from a list of configs \"\"\"\n    if objective_higher_is_better:\n        best_config = max(configs, key=lambda x: x[objective])\n    else:\n        best_config = min(configs, key=lambda x: x[objective])\n    best_config_params = {k:best_config[k] for k in best_config if k != objective}\n    return best_config_params\n\n\n\n\ndef _read_results_file(results_filename):\n    \"\"\" Reader for results file\n\n        File format 1.0 specifies the following metadata\n        \"version_number\": string e.g. \"1.0\"\n        \"tunable_parameters\": list of strings\n        \"kernel_name\": string\n        \"kernel_string\": string with kernel code, optional\n        \"objective\": string\n        \"objective_higher_is_better\": True or False, default False\n        \"data\": list of dicts\n            each dict consists of the following keys:\n            - \"device_name\": device name as reported by the device, with all non-alphanumeric characters replaced with \"_\"\n            - \"problem_size\": a concatenated string of problem dimensions using \"x\" as separator\n            - \"tunable_parameters\": a dict with all tunable parameters\n            - \"objective\" as specified in the \"objective\" metadata\n\n    \"\"\"\n    with open(results_filename, 'r') as fh:\n        data = json.loads(fh.read())\n\n    if \"version_number\" in data:\n        if data[\"version_number\"] == \"1.0\":\n            return _parse_results_file_version_1_0(data)\n        raise ValueError(f\"Unknown results file version_number: {data['version_number']}\")\n    raise ValueError(\"Results fileformat not recognized\")\n\n\n\ndef _parse_results_file_version_1_0(data):\n    validate(instance=data, schema=schema_v1_0)\n\n    meta_keys = [\"kernel_name\", \"tunable_parameters\", \"objective\", \"version_number\"]\n    meta = {k: v for k, v in data.items() if k in meta_keys}\n    meta[\"objective_higher_is_better\"] = data.get(\"objective_higher_is_better\", False)\n    meta[\"kernel_string\"] = data.get(\"kernel_string\", \"\")\n    entries = data[\"data\"]\n\n    #do some final checks against the metadata that cannot be handled by the JSON schema\n    entry_keys = [\"tunable_parameters\"] + [meta[\"objective\"]] + [\"device_name\", \"problem_size\"]\n    for entry in entries:\n        if not all([k in entry for k in entry_keys]):\n            raise ValueError(f\"Error while parsing results file, missing keys in: {entry}\")\n        if not all([k in entry[\"tunable_parameters\"] for k in meta[\"tunable_parameters\"]]):\n            raise ValueError(f\"Error while parsing results file, missing tunable parameter keys in: {entry}\")\n\n    return meta, entries\n", 422], "/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/pkg_resources/extern/__init__.py": ["import importlib.util\nimport sys\n\n\nclass VendorImporter:\n    \"\"\"\n    A PEP 302 meta path importer for finding optionally-vendored\n    or otherwise naturally-installed packages from root_name.\n    \"\"\"\n\n    def __init__(self, root_name, vendored_names=(), vendor_pkg=None):\n        self.root_name = root_name\n        self.vendored_names = set(vendored_names)\n        self.vendor_pkg = vendor_pkg or root_name.replace('extern', '_vendor')\n\n    @property\n    def search_path(self):\n        \"\"\"\n        Search first the vendor package then as a natural package.\n        \"\"\"\n        yield self.vendor_pkg + '.'\n        yield ''\n\n    def _module_matches_namespace(self, fullname):\n        \"\"\"Figure out if the target module is vendored.\"\"\"\n        root, base, target = fullname.partition(self.root_name + '.')\n        return not root and any(map(target.startswith, self.vendored_names))\n\n    def load_module(self, fullname):\n        \"\"\"\n        Iterate over the search path to locate and load fullname.\n        \"\"\"\n        root, base, target = fullname.partition(self.root_name + '.')\n        for prefix in self.search_path:\n            try:\n                extant = prefix + target\n                __import__(extant)\n                mod = sys.modules[extant]\n                sys.modules[fullname] = mod\n                return mod\n            except ImportError:\n                pass\n        else:\n            raise ImportError(\n                \"The '{target}' package is required; \"\n                \"normally this is bundled with this package so if you get \"\n                \"this warning, consult the packager of your \"\n                \"distribution.\".format(**locals())\n            )\n\n    def create_module(self, spec):\n        return self.load_module(spec.name)\n\n    def exec_module(self, module):\n        pass\n\n    def find_spec(self, fullname, path=None, target=None):\n        \"\"\"Return a module spec for vendored names.\"\"\"\n        return (\n            importlib.util.spec_from_loader(fullname, self)\n            if self._module_matches_namespace(fullname) else None\n        )\n\n    def install(self):\n        \"\"\"\n        Install this importer into sys.meta_path if not already present.\n        \"\"\"\n        if self not in sys.meta_path:\n            sys.meta_path.append(self)\n\n\nnames = 'packaging', 'pyparsing', 'appdirs'\nVendorImporter(__name__, names).install()\n", 73], "/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/six.py": ["# Copyright (c) 2010-2020 Benjamin Peterson\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the \"Software\"), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n\n\"\"\"Utilities for writing code that runs on Python 2 and 3\"\"\"\n\nfrom __future__ import absolute_import\n\nimport functools\nimport itertools\nimport operator\nimport sys\nimport types\n\n__author__ = \"Benjamin Peterson <benjamin@python.org>\"\n__version__ = \"1.16.0\"\n\n\n# Useful for very coarse version differentiation.\nPY2 = sys.version_info[0] == 2\nPY3 = sys.version_info[0] == 3\nPY34 = sys.version_info[0:2] >= (3, 4)\n\nif PY3:\n    string_types = str,\n    integer_types = int,\n    class_types = type,\n    text_type = str\n    binary_type = bytes\n\n    MAXSIZE = sys.maxsize\nelse:\n    string_types = basestring,\n    integer_types = (int, long)\n    class_types = (type, types.ClassType)\n    text_type = unicode\n    binary_type = str\n\n    if sys.platform.startswith(\"java\"):\n        # Jython always uses 32 bits.\n        MAXSIZE = int((1 << 31) - 1)\n    else:\n        # It's possible to have sizeof(long) != sizeof(Py_ssize_t).\n        class X(object):\n\n            def __len__(self):\n                return 1 << 31\n        try:\n            len(X())\n        except OverflowError:\n            # 32-bit\n            MAXSIZE = int((1 << 31) - 1)\n        else:\n            # 64-bit\n            MAXSIZE = int((1 << 63) - 1)\n        del X\n\nif PY34:\n    from importlib.util import spec_from_loader\nelse:\n    spec_from_loader = None\n\n\ndef _add_doc(func, doc):\n    \"\"\"Add documentation to a function.\"\"\"\n    func.__doc__ = doc\n\n\ndef _import_module(name):\n    \"\"\"Import module, returning the module after the last dot.\"\"\"\n    __import__(name)\n    return sys.modules[name]\n\n\nclass _LazyDescr(object):\n\n    def __init__(self, name):\n        self.name = name\n\n    def __get__(self, obj, tp):\n        result = self._resolve()\n        setattr(obj, self.name, result)  # Invokes __set__.\n        try:\n            # This is a bit ugly, but it avoids running this again by\n            # removing this descriptor.\n            delattr(obj.__class__, self.name)\n        except AttributeError:\n            pass\n        return result\n\n\nclass MovedModule(_LazyDescr):\n\n    def __init__(self, name, old, new=None):\n        super(MovedModule, self).__init__(name)\n        if PY3:\n            if new is None:\n                new = name\n            self.mod = new\n        else:\n            self.mod = old\n\n    def _resolve(self):\n        return _import_module(self.mod)\n\n    def __getattr__(self, attr):\n        _module = self._resolve()\n        value = getattr(_module, attr)\n        setattr(self, attr, value)\n        return value\n\n\nclass _LazyModule(types.ModuleType):\n\n    def __init__(self, name):\n        super(_LazyModule, self).__init__(name)\n        self.__doc__ = self.__class__.__doc__\n\n    def __dir__(self):\n        attrs = [\"__doc__\", \"__name__\"]\n        attrs += [attr.name for attr in self._moved_attributes]\n        return attrs\n\n    # Subclasses should override this\n    _moved_attributes = []\n\n\nclass MovedAttribute(_LazyDescr):\n\n    def __init__(self, name, old_mod, new_mod, old_attr=None, new_attr=None):\n        super(MovedAttribute, self).__init__(name)\n        if PY3:\n            if new_mod is None:\n                new_mod = name\n            self.mod = new_mod\n            if new_attr is None:\n                if old_attr is None:\n                    new_attr = name\n                else:\n                    new_attr = old_attr\n            self.attr = new_attr\n        else:\n            self.mod = old_mod\n            if old_attr is None:\n                old_attr = name\n            self.attr = old_attr\n\n    def _resolve(self):\n        module = _import_module(self.mod)\n        return getattr(module, self.attr)\n\n\nclass _SixMetaPathImporter(object):\n\n    \"\"\"\n    A meta path importer to import six.moves and its submodules.\n\n    This class implements a PEP302 finder and loader. It should be compatible\n    with Python 2.5 and all existing versions of Python3\n    \"\"\"\n\n    def __init__(self, six_module_name):\n        self.name = six_module_name\n        self.known_modules = {}\n\n    def _add_module(self, mod, *fullnames):\n        for fullname in fullnames:\n            self.known_modules[self.name + \".\" + fullname] = mod\n\n    def _get_module(self, fullname):\n        return self.known_modules[self.name + \".\" + fullname]\n\n    def find_module(self, fullname, path=None):\n        if fullname in self.known_modules:\n            return self\n        return None\n\n    def find_spec(self, fullname, path, target=None):\n        if fullname in self.known_modules:\n            return spec_from_loader(fullname, self)\n        return None\n\n    def __get_module(self, fullname):\n        try:\n            return self.known_modules[fullname]\n        except KeyError:\n            raise ImportError(\"This loader does not know module \" + fullname)\n\n    def load_module(self, fullname):\n        try:\n            # in case of a reload\n            return sys.modules[fullname]\n        except KeyError:\n            pass\n        mod = self.__get_module(fullname)\n        if isinstance(mod, MovedModule):\n            mod = mod._resolve()\n        else:\n            mod.__loader__ = self\n        sys.modules[fullname] = mod\n        return mod\n\n    def is_package(self, fullname):\n        \"\"\"\n        Return true, if the named module is a package.\n\n        We need this method to get correct spec objects with\n        Python 3.4 (see PEP451)\n        \"\"\"\n        return hasattr(self.__get_module(fullname), \"__path__\")\n\n    def get_code(self, fullname):\n        \"\"\"Return None\n\n        Required, if is_package is implemented\"\"\"\n        self.__get_module(fullname)  # eventually raises ImportError\n        return None\n    get_source = get_code  # same as get_code\n\n    def create_module(self, spec):\n        return self.load_module(spec.name)\n\n    def exec_module(self, module):\n        pass\n\n_importer = _SixMetaPathImporter(__name__)\n\n\nclass _MovedItems(_LazyModule):\n\n    \"\"\"Lazy loading of moved objects\"\"\"\n    __path__ = []  # mark as package\n\n\n_moved_attributes = [\n    MovedAttribute(\"cStringIO\", \"cStringIO\", \"io\", \"StringIO\"),\n    MovedAttribute(\"filter\", \"itertools\", \"builtins\", \"ifilter\", \"filter\"),\n    MovedAttribute(\"filterfalse\", \"itertools\", \"itertools\", \"ifilterfalse\", \"filterfalse\"),\n    MovedAttribute(\"input\", \"__builtin__\", \"builtins\", \"raw_input\", \"input\"),\n    MovedAttribute(\"intern\", \"__builtin__\", \"sys\"),\n    MovedAttribute(\"map\", \"itertools\", \"builtins\", \"imap\", \"map\"),\n    MovedAttribute(\"getcwd\", \"os\", \"os\", \"getcwdu\", \"getcwd\"),\n    MovedAttribute(\"getcwdb\", \"os\", \"os\", \"getcwd\", \"getcwdb\"),\n    MovedAttribute(\"getoutput\", \"commands\", \"subprocess\"),\n    MovedAttribute(\"range\", \"__builtin__\", \"builtins\", \"xrange\", \"range\"),\n    MovedAttribute(\"reload_module\", \"__builtin__\", \"importlib\" if PY34 else \"imp\", \"reload\"),\n    MovedAttribute(\"reduce\", \"__builtin__\", \"functools\"),\n    MovedAttribute(\"shlex_quote\", \"pipes\", \"shlex\", \"quote\"),\n    MovedAttribute(\"StringIO\", \"StringIO\", \"io\"),\n    MovedAttribute(\"UserDict\", \"UserDict\", \"collections\"),\n    MovedAttribute(\"UserList\", \"UserList\", \"collections\"),\n    MovedAttribute(\"UserString\", \"UserString\", \"collections\"),\n    MovedAttribute(\"xrange\", \"__builtin__\", \"builtins\", \"xrange\", \"range\"),\n    MovedAttribute(\"zip\", \"itertools\", \"builtins\", \"izip\", \"zip\"),\n    MovedAttribute(\"zip_longest\", \"itertools\", \"itertools\", \"izip_longest\", \"zip_longest\"),\n    MovedModule(\"builtins\", \"__builtin__\"),\n    MovedModule(\"configparser\", \"ConfigParser\"),\n    MovedModule(\"collections_abc\", \"collections\", \"collections.abc\" if sys.version_info >= (3, 3) else \"collections\"),\n    MovedModule(\"copyreg\", \"copy_reg\"),\n    MovedModule(\"dbm_gnu\", \"gdbm\", \"dbm.gnu\"),\n    MovedModule(\"dbm_ndbm\", \"dbm\", \"dbm.ndbm\"),\n    MovedModule(\"_dummy_thread\", \"dummy_thread\", \"_dummy_thread\" if sys.version_info < (3, 9) else \"_thread\"),\n    MovedModule(\"http_cookiejar\", \"cookielib\", \"http.cookiejar\"),\n    MovedModule(\"http_cookies\", \"Cookie\", \"http.cookies\"),\n    MovedModule(\"html_entities\", \"htmlentitydefs\", \"html.entities\"),\n    MovedModule(\"html_parser\", \"HTMLParser\", \"html.parser\"),\n    MovedModule(\"http_client\", \"httplib\", \"http.client\"),\n    MovedModule(\"email_mime_base\", \"email.MIMEBase\", \"email.mime.base\"),\n    MovedModule(\"email_mime_image\", \"email.MIMEImage\", \"email.mime.image\"),\n    MovedModule(\"email_mime_multipart\", \"email.MIMEMultipart\", \"email.mime.multipart\"),\n    MovedModule(\"email_mime_nonmultipart\", \"email.MIMENonMultipart\", \"email.mime.nonmultipart\"),\n    MovedModule(\"email_mime_text\", \"email.MIMEText\", \"email.mime.text\"),\n    MovedModule(\"BaseHTTPServer\", \"BaseHTTPServer\", \"http.server\"),\n    MovedModule(\"CGIHTTPServer\", \"CGIHTTPServer\", \"http.server\"),\n    MovedModule(\"SimpleHTTPServer\", \"SimpleHTTPServer\", \"http.server\"),\n    MovedModule(\"cPickle\", \"cPickle\", \"pickle\"),\n    MovedModule(\"queue\", \"Queue\"),\n    MovedModule(\"reprlib\", \"repr\"),\n    MovedModule(\"socketserver\", \"SocketServer\"),\n    MovedModule(\"_thread\", \"thread\", \"_thread\"),\n    MovedModule(\"tkinter\", \"Tkinter\"),\n    MovedModule(\"tkinter_dialog\", \"Dialog\", \"tkinter.dialog\"),\n    MovedModule(\"tkinter_filedialog\", \"FileDialog\", \"tkinter.filedialog\"),\n    MovedModule(\"tkinter_scrolledtext\", \"ScrolledText\", \"tkinter.scrolledtext\"),\n    MovedModule(\"tkinter_simpledialog\", \"SimpleDialog\", \"tkinter.simpledialog\"),\n    MovedModule(\"tkinter_tix\", \"Tix\", \"tkinter.tix\"),\n    MovedModule(\"tkinter_ttk\", \"ttk\", \"tkinter.ttk\"),\n    MovedModule(\"tkinter_constants\", \"Tkconstants\", \"tkinter.constants\"),\n    MovedModule(\"tkinter_dnd\", \"Tkdnd\", \"tkinter.dnd\"),\n    MovedModule(\"tkinter_colorchooser\", \"tkColorChooser\",\n                \"tkinter.colorchooser\"),\n    MovedModule(\"tkinter_commondialog\", \"tkCommonDialog\",\n                \"tkinter.commondialog\"),\n    MovedModule(\"tkinter_tkfiledialog\", \"tkFileDialog\", \"tkinter.filedialog\"),\n    MovedModule(\"tkinter_font\", \"tkFont\", \"tkinter.font\"),\n    MovedModule(\"tkinter_messagebox\", \"tkMessageBox\", \"tkinter.messagebox\"),\n    MovedModule(\"tkinter_tksimpledialog\", \"tkSimpleDialog\",\n                \"tkinter.simpledialog\"),\n    MovedModule(\"urllib_parse\", __name__ + \".moves.urllib_parse\", \"urllib.parse\"),\n    MovedModule(\"urllib_error\", __name__ + \".moves.urllib_error\", \"urllib.error\"),\n    MovedModule(\"urllib\", __name__ + \".moves.urllib\", __name__ + \".moves.urllib\"),\n    MovedModule(\"urllib_robotparser\", \"robotparser\", \"urllib.robotparser\"),\n    MovedModule(\"xmlrpc_client\", \"xmlrpclib\", \"xmlrpc.client\"),\n    MovedModule(\"xmlrpc_server\", \"SimpleXMLRPCServer\", \"xmlrpc.server\"),\n]\n# Add windows specific modules.\nif sys.platform == \"win32\":\n    _moved_attributes += [\n        MovedModule(\"winreg\", \"_winreg\"),\n    ]\n\nfor attr in _moved_attributes:\n    setattr(_MovedItems, attr.name, attr)\n    if isinstance(attr, MovedModule):\n        _importer._add_module(attr, \"moves.\" + attr.name)\ndel attr\n\n_MovedItems._moved_attributes = _moved_attributes\n\nmoves = _MovedItems(__name__ + \".moves\")\n_importer._add_module(moves, \"moves\")\n\n\nclass Module_six_moves_urllib_parse(_LazyModule):\n\n    \"\"\"Lazy loading of moved objects in six.moves.urllib_parse\"\"\"\n\n\n_urllib_parse_moved_attributes = [\n    MovedAttribute(\"ParseResult\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"SplitResult\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"parse_qs\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"parse_qsl\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"urldefrag\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"urljoin\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"urlparse\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"urlsplit\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"urlunparse\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"urlunsplit\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"quote\", \"urllib\", \"urllib.parse\"),\n    MovedAttribute(\"quote_plus\", \"urllib\", \"urllib.parse\"),\n    MovedAttribute(\"unquote\", \"urllib\", \"urllib.parse\"),\n    MovedAttribute(\"unquote_plus\", \"urllib\", \"urllib.parse\"),\n    MovedAttribute(\"unquote_to_bytes\", \"urllib\", \"urllib.parse\", \"unquote\", \"unquote_to_bytes\"),\n    MovedAttribute(\"urlencode\", \"urllib\", \"urllib.parse\"),\n    MovedAttribute(\"splitquery\", \"urllib\", \"urllib.parse\"),\n    MovedAttribute(\"splittag\", \"urllib\", \"urllib.parse\"),\n    MovedAttribute(\"splituser\", \"urllib\", \"urllib.parse\"),\n    MovedAttribute(\"splitvalue\", \"urllib\", \"urllib.parse\"),\n    MovedAttribute(\"uses_fragment\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"uses_netloc\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"uses_params\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"uses_query\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"uses_relative\", \"urlparse\", \"urllib.parse\"),\n]\nfor attr in _urllib_parse_moved_attributes:\n    setattr(Module_six_moves_urllib_parse, attr.name, attr)\ndel attr\n\nModule_six_moves_urllib_parse._moved_attributes = _urllib_parse_moved_attributes\n\n_importer._add_module(Module_six_moves_urllib_parse(__name__ + \".moves.urllib_parse\"),\n                      \"moves.urllib_parse\", \"moves.urllib.parse\")\n\n\nclass Module_six_moves_urllib_error(_LazyModule):\n\n    \"\"\"Lazy loading of moved objects in six.moves.urllib_error\"\"\"\n\n\n_urllib_error_moved_attributes = [\n    MovedAttribute(\"URLError\", \"urllib2\", \"urllib.error\"),\n    MovedAttribute(\"HTTPError\", \"urllib2\", \"urllib.error\"),\n    MovedAttribute(\"ContentTooShortError\", \"urllib\", \"urllib.error\"),\n]\nfor attr in _urllib_error_moved_attributes:\n    setattr(Module_six_moves_urllib_error, attr.name, attr)\ndel attr\n\nModule_six_moves_urllib_error._moved_attributes = _urllib_error_moved_attributes\n\n_importer._add_module(Module_six_moves_urllib_error(__name__ + \".moves.urllib.error\"),\n                      \"moves.urllib_error\", \"moves.urllib.error\")\n\n\nclass Module_six_moves_urllib_request(_LazyModule):\n\n    \"\"\"Lazy loading of moved objects in six.moves.urllib_request\"\"\"\n\n\n_urllib_request_moved_attributes = [\n    MovedAttribute(\"urlopen\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"install_opener\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"build_opener\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"pathname2url\", \"urllib\", \"urllib.request\"),\n    MovedAttribute(\"url2pathname\", \"urllib\", \"urllib.request\"),\n    MovedAttribute(\"getproxies\", \"urllib\", \"urllib.request\"),\n    MovedAttribute(\"Request\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"OpenerDirector\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"HTTPDefaultErrorHandler\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"HTTPRedirectHandler\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"HTTPCookieProcessor\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"ProxyHandler\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"BaseHandler\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"HTTPPasswordMgr\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"HTTPPasswordMgrWithDefaultRealm\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"AbstractBasicAuthHandler\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"HTTPBasicAuthHandler\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"ProxyBasicAuthHandler\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"AbstractDigestAuthHandler\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"HTTPDigestAuthHandler\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"ProxyDigestAuthHandler\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"HTTPHandler\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"HTTPSHandler\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"FileHandler\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"FTPHandler\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"CacheFTPHandler\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"UnknownHandler\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"HTTPErrorProcessor\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"urlretrieve\", \"urllib\", \"urllib.request\"),\n    MovedAttribute(\"urlcleanup\", \"urllib\", \"urllib.request\"),\n    MovedAttribute(\"URLopener\", \"urllib\", \"urllib.request\"),\n    MovedAttribute(\"FancyURLopener\", \"urllib\", \"urllib.request\"),\n    MovedAttribute(\"proxy_bypass\", \"urllib\", \"urllib.request\"),\n    MovedAttribute(\"parse_http_list\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"parse_keqv_list\", \"urllib2\", \"urllib.request\"),\n]\nfor attr in _urllib_request_moved_attributes:\n    setattr(Module_six_moves_urllib_request, attr.name, attr)\ndel attr\n\nModule_six_moves_urllib_request._moved_attributes = _urllib_request_moved_attributes\n\n_importer._add_module(Module_six_moves_urllib_request(__name__ + \".moves.urllib.request\"),\n                      \"moves.urllib_request\", \"moves.urllib.request\")\n\n\nclass Module_six_moves_urllib_response(_LazyModule):\n\n    \"\"\"Lazy loading of moved objects in six.moves.urllib_response\"\"\"\n\n\n_urllib_response_moved_attributes = [\n    MovedAttribute(\"addbase\", \"urllib\", \"urllib.response\"),\n    MovedAttribute(\"addclosehook\", \"urllib\", \"urllib.response\"),\n    MovedAttribute(\"addinfo\", \"urllib\", \"urllib.response\"),\n    MovedAttribute(\"addinfourl\", \"urllib\", \"urllib.response\"),\n]\nfor attr in _urllib_response_moved_attributes:\n    setattr(Module_six_moves_urllib_response, attr.name, attr)\ndel attr\n\nModule_six_moves_urllib_response._moved_attributes = _urllib_response_moved_attributes\n\n_importer._add_module(Module_six_moves_urllib_response(__name__ + \".moves.urllib.response\"),\n                      \"moves.urllib_response\", \"moves.urllib.response\")\n\n\nclass Module_six_moves_urllib_robotparser(_LazyModule):\n\n    \"\"\"Lazy loading of moved objects in six.moves.urllib_robotparser\"\"\"\n\n\n_urllib_robotparser_moved_attributes = [\n    MovedAttribute(\"RobotFileParser\", \"robotparser\", \"urllib.robotparser\"),\n]\nfor attr in _urllib_robotparser_moved_attributes:\n    setattr(Module_six_moves_urllib_robotparser, attr.name, attr)\ndel attr\n\nModule_six_moves_urllib_robotparser._moved_attributes = _urllib_robotparser_moved_attributes\n\n_importer._add_module(Module_six_moves_urllib_robotparser(__name__ + \".moves.urllib.robotparser\"),\n                      \"moves.urllib_robotparser\", \"moves.urllib.robotparser\")\n\n\nclass Module_six_moves_urllib(types.ModuleType):\n\n    \"\"\"Create a six.moves.urllib namespace that resembles the Python 3 namespace\"\"\"\n    __path__ = []  # mark as package\n    parse = _importer._get_module(\"moves.urllib_parse\")\n    error = _importer._get_module(\"moves.urllib_error\")\n    request = _importer._get_module(\"moves.urllib_request\")\n    response = _importer._get_module(\"moves.urllib_response\")\n    robotparser = _importer._get_module(\"moves.urllib_robotparser\")\n\n    def __dir__(self):\n        return ['parse', 'error', 'request', 'response', 'robotparser']\n\n_importer._add_module(Module_six_moves_urllib(__name__ + \".moves.urllib\"),\n                      \"moves.urllib\")\n\n\ndef add_move(move):\n    \"\"\"Add an item to six.moves.\"\"\"\n    setattr(_MovedItems, move.name, move)\n\n\ndef remove_move(name):\n    \"\"\"Remove item from six.moves.\"\"\"\n    try:\n        delattr(_MovedItems, name)\n    except AttributeError:\n        try:\n            del moves.__dict__[name]\n        except KeyError:\n            raise AttributeError(\"no such move, %r\" % (name,))\n\n\nif PY3:\n    _meth_func = \"__func__\"\n    _meth_self = \"__self__\"\n\n    _func_closure = \"__closure__\"\n    _func_code = \"__code__\"\n    _func_defaults = \"__defaults__\"\n    _func_globals = \"__globals__\"\nelse:\n    _meth_func = \"im_func\"\n    _meth_self = \"im_self\"\n\n    _func_closure = \"func_closure\"\n    _func_code = \"func_code\"\n    _func_defaults = \"func_defaults\"\n    _func_globals = \"func_globals\"\n\n\ntry:\n    advance_iterator = next\nexcept NameError:\n    def advance_iterator(it):\n        return it.next()\nnext = advance_iterator\n\n\ntry:\n    callable = callable\nexcept NameError:\n    def callable(obj):\n        return any(\"__call__\" in klass.__dict__ for klass in type(obj).__mro__)\n\n\nif PY3:\n    def get_unbound_function(unbound):\n        return unbound\n\n    create_bound_method = types.MethodType\n\n    def create_unbound_method(func, cls):\n        return func\n\n    Iterator = object\nelse:\n    def get_unbound_function(unbound):\n        return unbound.im_func\n\n    def create_bound_method(func, obj):\n        return types.MethodType(func, obj, obj.__class__)\n\n    def create_unbound_method(func, cls):\n        return types.MethodType(func, None, cls)\n\n    class Iterator(object):\n\n        def next(self):\n            return type(self).__next__(self)\n\n    callable = callable\n_add_doc(get_unbound_function,\n         \"\"\"Get the function out of a possibly unbound function\"\"\")\n\n\nget_method_function = operator.attrgetter(_meth_func)\nget_method_self = operator.attrgetter(_meth_self)\nget_function_closure = operator.attrgetter(_func_closure)\nget_function_code = operator.attrgetter(_func_code)\nget_function_defaults = operator.attrgetter(_func_defaults)\nget_function_globals = operator.attrgetter(_func_globals)\n\n\nif PY3:\n    def iterkeys(d, **kw):\n        return iter(d.keys(**kw))\n\n    def itervalues(d, **kw):\n        return iter(d.values(**kw))\n\n    def iteritems(d, **kw):\n        return iter(d.items(**kw))\n\n    def iterlists(d, **kw):\n        return iter(d.lists(**kw))\n\n    viewkeys = operator.methodcaller(\"keys\")\n\n    viewvalues = operator.methodcaller(\"values\")\n\n    viewitems = operator.methodcaller(\"items\")\nelse:\n    def iterkeys(d, **kw):\n        return d.iterkeys(**kw)\n\n    def itervalues(d, **kw):\n        return d.itervalues(**kw)\n\n    def iteritems(d, **kw):\n        return d.iteritems(**kw)\n\n    def iterlists(d, **kw):\n        return d.iterlists(**kw)\n\n    viewkeys = operator.methodcaller(\"viewkeys\")\n\n    viewvalues = operator.methodcaller(\"viewvalues\")\n\n    viewitems = operator.methodcaller(\"viewitems\")\n\n_add_doc(iterkeys, \"Return an iterator over the keys of a dictionary.\")\n_add_doc(itervalues, \"Return an iterator over the values of a dictionary.\")\n_add_doc(iteritems,\n         \"Return an iterator over the (key, value) pairs of a dictionary.\")\n_add_doc(iterlists,\n         \"Return an iterator over the (key, [values]) pairs of a dictionary.\")\n\n\nif PY3:\n    def b(s):\n        return s.encode(\"latin-1\")\n\n    def u(s):\n        return s\n    unichr = chr\n    import struct\n    int2byte = struct.Struct(\">B\").pack\n    del struct\n    byte2int = operator.itemgetter(0)\n    indexbytes = operator.getitem\n    iterbytes = iter\n    import io\n    StringIO = io.StringIO\n    BytesIO = io.BytesIO\n    del io\n    _assertCountEqual = \"assertCountEqual\"\n    if sys.version_info[1] <= 1:\n        _assertRaisesRegex = \"assertRaisesRegexp\"\n        _assertRegex = \"assertRegexpMatches\"\n        _assertNotRegex = \"assertNotRegexpMatches\"\n    else:\n        _assertRaisesRegex = \"assertRaisesRegex\"\n        _assertRegex = \"assertRegex\"\n        _assertNotRegex = \"assertNotRegex\"\nelse:\n    def b(s):\n        return s\n    # Workaround for standalone backslash\n\n    def u(s):\n        return unicode(s.replace(r'\\\\', r'\\\\\\\\'), \"unicode_escape\")\n    unichr = unichr\n    int2byte = chr\n\n    def byte2int(bs):\n        return ord(bs[0])\n\n    def indexbytes(buf, i):\n        return ord(buf[i])\n    iterbytes = functools.partial(itertools.imap, ord)\n    import StringIO\n    StringIO = BytesIO = StringIO.StringIO\n    _assertCountEqual = \"assertItemsEqual\"\n    _assertRaisesRegex = \"assertRaisesRegexp\"\n    _assertRegex = \"assertRegexpMatches\"\n    _assertNotRegex = \"assertNotRegexpMatches\"\n_add_doc(b, \"\"\"Byte literal\"\"\")\n_add_doc(u, \"\"\"Text literal\"\"\")\n\n\ndef assertCountEqual(self, *args, **kwargs):\n    return getattr(self, _assertCountEqual)(*args, **kwargs)\n\n\ndef assertRaisesRegex(self, *args, **kwargs):\n    return getattr(self, _assertRaisesRegex)(*args, **kwargs)\n\n\ndef assertRegex(self, *args, **kwargs):\n    return getattr(self, _assertRegex)(*args, **kwargs)\n\n\ndef assertNotRegex(self, *args, **kwargs):\n    return getattr(self, _assertNotRegex)(*args, **kwargs)\n\n\nif PY3:\n    exec_ = getattr(moves.builtins, \"exec\")\n\n    def reraise(tp, value, tb=None):\n        try:\n            if value is None:\n                value = tp()\n            if value.__traceback__ is not tb:\n                raise value.with_traceback(tb)\n            raise value\n        finally:\n            value = None\n            tb = None\n\nelse:\n    def exec_(_code_, _globs_=None, _locs_=None):\n        \"\"\"Execute code in a namespace.\"\"\"\n        if _globs_ is None:\n            frame = sys._getframe(1)\n            _globs_ = frame.f_globals\n            if _locs_ is None:\n                _locs_ = frame.f_locals\n            del frame\n        elif _locs_ is None:\n            _locs_ = _globs_\n        exec(\"\"\"exec _code_ in _globs_, _locs_\"\"\")\n\n    exec_(\"\"\"def reraise(tp, value, tb=None):\n    try:\n        raise tp, value, tb\n    finally:\n        tb = None\n\"\"\")\n\n\nif sys.version_info[:2] > (3,):\n    exec_(\"\"\"def raise_from(value, from_value):\n    try:\n        raise value from from_value\n    finally:\n        value = None\n\"\"\")\nelse:\n    def raise_from(value, from_value):\n        raise value\n\n\nprint_ = getattr(moves.builtins, \"print\", None)\nif print_ is None:\n    def print_(*args, **kwargs):\n        \"\"\"The new-style print function for Python 2.4 and 2.5.\"\"\"\n        fp = kwargs.pop(\"file\", sys.stdout)\n        if fp is None:\n            return\n\n        def write(data):\n            if not isinstance(data, basestring):\n                data = str(data)\n            # If the file has an encoding, encode unicode with it.\n            if (isinstance(fp, file) and\n                    isinstance(data, unicode) and\n                    fp.encoding is not None):\n                errors = getattr(fp, \"errors\", None)\n                if errors is None:\n                    errors = \"strict\"\n                data = data.encode(fp.encoding, errors)\n            fp.write(data)\n        want_unicode = False\n        sep = kwargs.pop(\"sep\", None)\n        if sep is not None:\n            if isinstance(sep, unicode):\n                want_unicode = True\n            elif not isinstance(sep, str):\n                raise TypeError(\"sep must be None or a string\")\n        end = kwargs.pop(\"end\", None)\n        if end is not None:\n            if isinstance(end, unicode):\n                want_unicode = True\n            elif not isinstance(end, str):\n                raise TypeError(\"end must be None or a string\")\n        if kwargs:\n            raise TypeError(\"invalid keyword arguments to print()\")\n        if not want_unicode:\n            for arg in args:\n                if isinstance(arg, unicode):\n                    want_unicode = True\n                    break\n        if want_unicode:\n            newline = unicode(\"\\n\")\n            space = unicode(\" \")\n        else:\n            newline = \"\\n\"\n            space = \" \"\n        if sep is None:\n            sep = space\n        if end is None:\n            end = newline\n        for i, arg in enumerate(args):\n            if i:\n                write(sep)\n            write(arg)\n        write(end)\nif sys.version_info[:2] < (3, 3):\n    _print = print_\n\n    def print_(*args, **kwargs):\n        fp = kwargs.get(\"file\", sys.stdout)\n        flush = kwargs.pop(\"flush\", False)\n        _print(*args, **kwargs)\n        if flush and fp is not None:\n            fp.flush()\n\n_add_doc(reraise, \"\"\"Reraise an exception.\"\"\")\n\nif sys.version_info[0:2] < (3, 4):\n    # This does exactly the same what the :func:`py3:functools.update_wrapper`\n    # function does on Python versions after 3.2. It sets the ``__wrapped__``\n    # attribute on ``wrapper`` object and it doesn't raise an error if any of\n    # the attributes mentioned in ``assigned`` and ``updated`` are missing on\n    # ``wrapped`` object.\n    def _update_wrapper(wrapper, wrapped,\n                        assigned=functools.WRAPPER_ASSIGNMENTS,\n                        updated=functools.WRAPPER_UPDATES):\n        for attr in assigned:\n            try:\n                value = getattr(wrapped, attr)\n            except AttributeError:\n                continue\n            else:\n                setattr(wrapper, attr, value)\n        for attr in updated:\n            getattr(wrapper, attr).update(getattr(wrapped, attr, {}))\n        wrapper.__wrapped__ = wrapped\n        return wrapper\n    _update_wrapper.__doc__ = functools.update_wrapper.__doc__\n\n    def wraps(wrapped, assigned=functools.WRAPPER_ASSIGNMENTS,\n              updated=functools.WRAPPER_UPDATES):\n        return functools.partial(_update_wrapper, wrapped=wrapped,\n                                 assigned=assigned, updated=updated)\n    wraps.__doc__ = functools.wraps.__doc__\n\nelse:\n    wraps = functools.wraps\n\n\ndef with_metaclass(meta, *bases):\n    \"\"\"Create a base class with a metaclass.\"\"\"\n    # This requires a bit of explanation: the basic idea is to make a dummy\n    # metaclass for one level of class instantiation that replaces itself with\n    # the actual metaclass.\n    class metaclass(type):\n\n        def __new__(cls, name, this_bases, d):\n            if sys.version_info[:2] >= (3, 7):\n                # This version introduced PEP 560 that requires a bit\n                # of extra care (we mimic what is done by __build_class__).\n                resolved_bases = types.resolve_bases(bases)\n                if resolved_bases is not bases:\n                    d['__orig_bases__'] = bases\n            else:\n                resolved_bases = bases\n            return meta(name, resolved_bases, d)\n\n        @classmethod\n        def __prepare__(cls, name, this_bases):\n            return meta.__prepare__(name, bases)\n    return type.__new__(metaclass, 'temporary_class', (), {})\n\n\ndef add_metaclass(metaclass):\n    \"\"\"Class decorator for creating a class with a metaclass.\"\"\"\n    def wrapper(cls):\n        orig_vars = cls.__dict__.copy()\n        slots = orig_vars.get('__slots__')\n        if slots is not None:\n            if isinstance(slots, str):\n                slots = [slots]\n            for slots_var in slots:\n                orig_vars.pop(slots_var)\n        orig_vars.pop('__dict__', None)\n        orig_vars.pop('__weakref__', None)\n        if hasattr(cls, '__qualname__'):\n            orig_vars['__qualname__'] = cls.__qualname__\n        return metaclass(cls.__name__, cls.__bases__, orig_vars)\n    return wrapper\n\n\ndef ensure_binary(s, encoding='utf-8', errors='strict'):\n    \"\"\"Coerce **s** to six.binary_type.\n\n    For Python 2:\n      - `unicode` -> encoded to `str`\n      - `str` -> `str`\n\n    For Python 3:\n      - `str` -> encoded to `bytes`\n      - `bytes` -> `bytes`\n    \"\"\"\n    if isinstance(s, binary_type):\n        return s\n    if isinstance(s, text_type):\n        return s.encode(encoding, errors)\n    raise TypeError(\"not expecting type '%s'\" % type(s))\n\n\ndef ensure_str(s, encoding='utf-8', errors='strict'):\n    \"\"\"Coerce *s* to `str`.\n\n    For Python 2:\n      - `unicode` -> encoded to `str`\n      - `str` -> `str`\n\n    For Python 3:\n      - `str` -> `str`\n      - `bytes` -> decoded to `str`\n    \"\"\"\n    # Optimization: Fast return for the common case.\n    if type(s) is str:\n        return s\n    if PY2 and isinstance(s, text_type):\n        return s.encode(encoding, errors)\n    elif PY3 and isinstance(s, binary_type):\n        return s.decode(encoding, errors)\n    elif not isinstance(s, (text_type, binary_type)):\n        raise TypeError(\"not expecting type '%s'\" % type(s))\n    return s\n\n\ndef ensure_text(s, encoding='utf-8', errors='strict'):\n    \"\"\"Coerce *s* to six.text_type.\n\n    For Python 2:\n      - `unicode` -> `unicode`\n      - `str` -> `unicode`\n\n    For Python 3:\n      - `str` -> `str`\n      - `bytes` -> decoded to `str`\n    \"\"\"\n    if isinstance(s, binary_type):\n        return s.decode(encoding, errors)\n    elif isinstance(s, text_type):\n        return s\n    else:\n        raise TypeError(\"not expecting type '%s'\" % type(s))\n\n\ndef python_2_unicode_compatible(klass):\n    \"\"\"\n    A class decorator that defines __unicode__ and __str__ methods under Python 2.\n    Under Python 3 it does nothing.\n\n    To support Python 2 and 3 with a single code base, define a __str__ method\n    returning text and apply this decorator to the class.\n    \"\"\"\n    if PY2:\n        if '__str__' not in klass.__dict__:\n            raise ValueError(\"@python_2_unicode_compatible cannot be applied \"\n                             \"to %s because it doesn't define __str__().\" %\n                             klass.__name__)\n        klass.__unicode__ = klass.__str__\n        klass.__str__ = lambda self: self.__unicode__().encode('utf-8')\n    return klass\n\n\n# Complete the moves implementation.\n# This code is at the end of this module to speed up module loading.\n# Turn this module into a package.\n__path__ = []  # required for PEP 302 and PEP 451\n__package__ = __name__  # see PEP 366 @ReservedAssignment\nif globals().get(\"__spec__\") is not None:\n    __spec__.submodule_search_locations = []  # PEP 451 @UndefinedVariable\n# Remove other six meta path importers, since they cause problems. This can\n# happen if six is removed from sys.modules and then reloaded. (Setuptools does\n# this for some reason.)\nif sys.meta_path:\n    for i, importer in enumerate(sys.meta_path):\n        # Here's some real nastiness: Another \"instance\" of the six module might\n        # be floating around. Therefore, we can't use isinstance() to check for\n        # the six meta path importer, since the other six instance will have\n        # inserted an importer with different class.\n        if (type(importer).__name__ == \"_SixMetaPathImporter\" and\n                importer.name == __name__):\n            del sys.meta_path[i]\n            break\n    del i, importer\n# Finally, add the importer to the meta path import hook.\nsys.meta_path.append(_importer)\n", 998], "/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/cupy.py": ["\"\"\"This module contains all Cupy specific kernel_tuner functions\"\"\"\nfrom __future__ import print_function\n\nimport logging\nimport time\nimport numpy as np\n\nfrom kernel_tuner.observers import BenchmarkObserver\n\n#embedded in try block to be able to generate documentation\n#and run tests without cupy installed\ntry:\n    import cupy as cp\nexcept ImportError:\n    cp = None\n\n\nclass CupyRuntimeObserver(BenchmarkObserver):\n    \"\"\" Observer that measures time using CUDA events during benchmarking \"\"\"\n\n    def __init__(self, dev):\n        self.dev = dev\n        self.stream = dev.stream\n        self.start = dev.start\n        self.end = dev.end\n        self.times = []\n\n    def after_finish(self):\n        self.times.append(cp.cuda.get_elapsed_time(self.start, self.end))    #ms\n\n    def get_results(self):\n        results = {\n            \"time\": np.average(self.times),\n            \"times\": self.times.copy()\n        }\n        self.times = []\n        return results\n\n\nclass CupyFunctions:\n    \"\"\"Class that groups the Cupy functions on maintains state about the device\"\"\"\n\n    def __init__(self, device=0, iterations=7, compiler_options=None, observers=None):\n        \"\"\"instantiate CudaFunctions object used for interacting with the CUDA device\n\n        Instantiating this object will inspect and store certain device properties at\n        runtime, which are used during compilation and/or execution of kernels by the\n        kernel tuner. It also maintains a reference to the most recently compiled\n        source module for copying data to constant memory before kernel launch.\n\n        :param device: Number of CUDA device to use for this context\n        :type device: int\n\n        :param iterations: Number of iterations used while benchmarking a kernel, 7 by default.\n        :type iterations: int\n        \"\"\"\n        self.allocations = []\n        self.texrefs = []\n        if not cp:\n            raise ImportError(\"Error: cupy not installed, please install e.g. \" +\n                              \"using 'pip install cupy-cuda111', please check https://github.com/cupy/cupy.\")\n\n        #select device\n        self.dev = dev = cp.cuda.Device(device).__enter__()\n\n        #inspect device properties\n        self.devprops = dev.attributes\n        self.cc = dev.compute_capability\n        self.max_threads = self.devprops['MaxThreadsPerBlock']\n\n        self.iterations = iterations\n        self.current_module = None\n        self.func = None\n        self.compiler_options = compiler_options or []\n\n        #create a stream and events\n        self.stream = cp.cuda.Stream()\n        self.start = cp.cuda.Event()\n        self.end = cp.cuda.Event()\n\n        #default dynamically allocated shared memory size, can be overwritten using smem_args\n        self.smem_size = 0\n\n        #setup observers\n        self.observers = observers or []\n        self.observers.append(CupyRuntimeObserver(self))\n        for obs in self.observers:\n            obs.register_device(self)\n\n        #collect environment information\n        env = dict()\n        cupy_info = str(cp._cupyx.get_runtime_info()).split(\"\\n\")[:-1]\n        info_dict = {s.split(\":\")[0].strip(): s.split(\":\")[1].strip()\n                     for s in cupy_info}\n        env[\"device_name\"] = info_dict[f'Device {device} Name']\n\n        env[\"cuda_version\"] = cp.cuda.runtime.driverGetVersion()\n        env[\"compute_capability\"] = self.cc\n        env[\"iterations\"] = self.iterations\n        env[\"compiler_options\"] = compiler_options\n        env[\"device_properties\"] = self.devprops\n        self.env = env\n        self.name = env[\"device_name\"]\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *exc):\n        \"\"\"destroy the device context\"\"\"\n        self.dev.__exit__()\n\n    def ready_argument_list(self, arguments):\n        \"\"\"ready argument list to be passed to the kernel, allocates gpu mem\n\n        :param arguments: List of arguments to be passed to the kernel.\n            The order should match the argument list on the CUDA kernel.\n            Allowed values are numpy.ndarray, and/or numpy.int32, numpy.float32, and so on.\n        :type arguments: list(numpy objects)\n\n        :returns: A list of arguments that can be passed to an CUDA kernel.\n        :rtype: list( cupy.ndarray, numpy.int32, ... )\n        \"\"\"\n        gpu_args = []\n        for arg in arguments:\n            # if arg i is a numpy array copy to device\n            if isinstance(arg, np.ndarray):\n                alloc = cp.array(arg)\n                self.allocations.append(alloc)\n                gpu_args.append(alloc)\n            else:    # if not a numpy array, just pass argument along\n                gpu_args.append(arg)\n        return gpu_args\n\n    def compile(self, kernel_instance):\n        \"\"\"call the CUDA compiler to compile the kernel, return the device function\n\n        :param kernel_name: The name of the kernel to be compiled, used to lookup the\n            function after compilation.\n        :type kernel_name: string\n\n        :param kernel_string: The CUDA kernel code that contains the function `kernel_name`\n        :type kernel_string: string\n\n        :returns: An CUDA kernel that can be called directly.\n        :rtype: cupy.RawKernel\n        \"\"\"\n        kernel_string = kernel_instance.kernel_string\n        kernel_name = kernel_instance.name\n\n        compiler_options = self.compiler_options\n        if not any(['--std=' in opt for opt in self.compiler_options]):\n            compiler_options = ['--std=c++11'] + self.compiler_options\n\n        options = tuple(compiler_options)\n\n        self.current_module = cp.RawModule(code=kernel_string, options=options, name_expressions=[kernel_name])\n\n        self.func = self.current_module.get_function(kernel_name)\n        return self.func\n\n    def benchmark(self, func, gpu_args, threads, grid):\n        \"\"\"runs the kernel and measures time repeatedly, returns average time\n\n        Runs the kernel and measures kernel execution time repeatedly, number of\n        iterations is set during the creation of CudaFunctions. Benchmark returns\n        a robust average, from all measurements the fastest and slowest runs are\n        discarded and the rest is included in the returned average. The reason for\n        this is to be robust against initialization artifacts and other exceptional\n        cases.\n\n        :param func: A cupy kernel compiled for this specific kernel configuration\n        :type func: cupy.RawKernel\n\n        :param gpu_args: A list of arguments to the kernel, order should match the\n            order in the code. Allowed values are either variables in global memory\n            or single values passed by value.\n        :type gpu_args: list( cupy.ndarray, numpy.int32, ...)\n\n        :param threads: A tuple listing the number of threads in each dimension of\n            the thread block\n        :type threads: tuple(int, int, int)\n\n        :param grid: A tuple listing the number of thread blocks in each dimension\n            of the grid\n        :type grid: tuple(int, int)\n\n        :returns: A dictionary with benchmark results.\n        :rtype: dict()\n        \"\"\"\n        result = dict()\n        self.dev.synchronize()\n        for _ in range(self.iterations):\n            for obs in self.observers:\n                obs.before_start()\n            self.dev.synchronize()\n            self.start.record(stream=self.stream)\n            self.run_kernel(func, gpu_args, threads, grid, stream=self.stream)\n            self.end.record(stream=self.stream)\n            for obs in self.observers:\n                obs.after_start()\n            while not self.end.done:\n                for obs in self.observers:\n                    obs.during()\n                time.sleep(1e-6)\n            for obs in self.observers:\n                obs.after_finish()\n\n        for obs in self.observers:\n            result.update(obs.get_results())\n\n        return result\n\n    def copy_constant_memory_args(self, cmem_args):\n        \"\"\"adds constant memory arguments to the most recently compiled module\n\n        :param cmem_args: A dictionary containing the data to be passed to the\n            device constant memory. The format to be used is as follows: A\n            string key is used to name the constant memory symbol to which the\n            value needs to be copied. Similar to regular arguments, these need\n            to be numpy objects, such as numpy.ndarray or numpy.int32, and so on.\n        :type cmem_args: dict( string: numpy.ndarray, ... )\n        \"\"\"\n        for k, v in cmem_args.items():\n            symbol = self.current_module.get_global(k)\n            constant_mem = cp.ndarray(v.shape, v.dtype, symbol)\n            constant_mem[:] = cp.asarray(v)\n\n    def copy_shared_memory_args(self, smem_args):\n        \"\"\"add shared memory arguments to the kernel\"\"\"\n        self.smem_size = smem_args[\"size\"]\n\n    def copy_texture_memory_args(self, texmem_args):\n        \"\"\"adds texture memory arguments to the most recently compiled module\n\n        :param texmem_args: A dictionary containing the data to be passed to the\n            device texture memory. See tune_kernel().\n        :type texmem_args: dict\n        \"\"\"\n        raise NotImplementedError('CuPy backend does not yet support texture memory')\n\n    def run_kernel(self, func, gpu_args, threads, grid, stream=None):\n        \"\"\"runs the CUDA kernel passed as 'func'\n\n        :param func: A cupy kernel compiled for this specific kernel configuration\n        :type func: cupy.RawKernel\n\n        :param gpu_args: A list of arguments to the kernel, order should match the\n            order in the code. Allowed values are either variables in global memory\n            or single values passed by value.\n        :type gpu_args: list( cupy.ndarray, numpy.int32, ...)\n\n        :param threads: A tuple listing the number of threads in each dimension of\n            the thread block\n        :type threads: tuple(int, int, int)\n\n        :param grid: A tuple listing the number of thread blocks in each dimension\n            of the grid\n        :type grid: tuple(int, int)\n        \"\"\"\n        func(grid, threads, gpu_args, stream=stream, shared_mem=self.smem_size)\n\n    def memset(self, allocation, value, size):\n        \"\"\"set the memory in allocation to the value in value\n\n        :param allocation: A GPU memory allocation unit\n        :type allocation: cupy.ndarray\n\n        :param value: The value to set the memory to\n        :type value: a single 8-bit unsigned int\n\n        :param size: The size of to the allocation unit in bytes\n        :type size: int\n\n        \"\"\"\n        allocation[:] = value\n\n    def memcpy_dtoh(self, dest, src):\n        \"\"\"perform a device to host memory copy\n\n        :param dest: A numpy array in host memory to store the data\n        :type dest: numpy.ndarray\n\n        :param src: A GPU memory allocation unit\n        :type src: cupy.ndarray\n        \"\"\"\n        if isinstance(dest, np.ndarray):\n            tmp = cp.asnumpy(src)\n            np.copyto(dest, tmp)\n        elif isinstance(dest, cp.ndarray):\n            cp.copyto(dest, src)\n        else:\n            raise ValueError(\"dest type not supported\")\n\n    def memcpy_htod(self, dest, src):\n        \"\"\"perform a host to device memory copy\n\n        :param dest: A GPU memory allocation unit\n        :type dest: cupy.ndarray\n\n        :param src: A numpy array in host memory to store the data\n        :type src: numpy.ndarray\n        \"\"\"\n        if isinstance(src, np.ndarray):\n            src = cp.asarray(src)\n        cp.copyto(dest, src)\n\n    units = {\n        'time': 'ms'\n    }\n", 309], "/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/cuda.py": ["\"\"\"This module contains all CUDA specific kernel_tuner functions\"\"\"\nfrom __future__ import print_function\n\nimport logging\nimport time\nimport numpy as np\n\nfrom kernel_tuner.observers import BenchmarkObserver\nfrom kernel_tuner.nvml import nvml\nfrom kernel_tuner.util import TorchPlaceHolder\n\n#embedded in try block to be able to generate documentation\n#and run tests without pycuda installed\ntry:\n    import pycuda.driver as drv\n    pycuda_available = True\nexcept ImportError:\n\n    class PyCudaPlaceHolder():\n\n        def __init__(self):\n            self.PointerHolderBase = object\n\n    drv = PyCudaPlaceHolder()\n    pycuda_available = False\n\ntry:\n    from pycuda.compiler import SourceModule\nexcept ImportError:\n    SourceModule = None\ntry:\n    from pycuda.compiler import DynamicSourceModule\nexcept ImportError:\n    DynamicSourceModule = None\n\ntry:\n    import torch\nexcept ImportError:\n    torch = TorchPlaceHolder()\n\n\nclass Holder(drv.PointerHolderBase):\n    \"\"\" class to interoperate torch device memory allocations with PyCUDA \"\"\"\n\n    def __init__(self, tensor):\n        super(Holder, self).__init__()\n        self.tensor = tensor\n        self.gpudata = tensor.data_ptr()\n\n    def get_pointer(self):\n        return self.t.data_ptr()\n\n\nclass CudaRuntimeObserver(BenchmarkObserver):\n    \"\"\" Observer that measures time using CUDA events during benchmarking \"\"\"\n\n    def __init__(self, dev):\n        self.dev = dev\n        self.stream = dev.stream\n        self.start = dev.start\n        self.end = dev.end\n        self.times = []\n\n    def after_finish(self):\n        self.times.append(self.end.time_since(self.start))    #ms\n\n    def get_results(self):\n        results = {\n            \"time\": np.average(self.times),\n            \"times\": self.times.copy()\n        }\n        self.times = []\n        return results\n\n\nclass CudaFunctions(object):\n    \"\"\"Class that groups the CUDA functions on maintains state about the device\"\"\"\n\n    def __init__(self, device=0, iterations=7, compiler_options=None, observers=None):\n        \"\"\"instantiate CudaFunctions object used for interacting with the CUDA device\n\n        Instantiating this object will inspect and store certain device properties at\n        runtime, which are used during compilation and/or execution of kernels by the\n        kernel tuner. It also maintains a reference to the most recently compiled\n        source module for copying data to constant memory before kernel launch.\n\n        :param device: Number of CUDA device to use for this context\n        :type device: int\n\n        :param iterations: Number of iterations used while benchmarking a kernel, 7 by default.\n        :type iterations: int\n        \"\"\"\n        self.allocations = []\n        self.texrefs = []\n        if not pycuda_available and isinstance(drv, PyCudaPlaceHolder):    #and part to allow mocking\n            raise ImportError(\"Error: pycuda not installed, please install e.g. using 'pip install pycuda'.\")\n\n        drv.init()\n        self.context = drv.Device(device).make_context()\n\n        #inspect device properties\n        devprops = {str(k): v\n                    for (k, v) in self.context.get_device().get_attributes().items()}\n        self.max_threads = devprops['MAX_THREADS_PER_BLOCK']\n        cc = str(devprops.get('COMPUTE_CAPABILITY_MAJOR', '0')) + str(devprops.get('COMPUTE_CAPABILITY_MINOR', '0'))\n        if cc == \"00\":\n            cc = self.context.get_device().compute_capability()\n        self.cc = str(cc[0]) + str(cc[1])\n        self.iterations = iterations\n        self.current_module = None\n        self.func = None\n        self.compiler_options = compiler_options or []\n\n        #select PyCUDA source module\n        if int(self.cc) >= 35:\n            self.source_mod = DynamicSourceModule\n        else:\n            self.source_mod = SourceModule\n        if not self.source_mod:\n            raise ImportError(\n                \"Error: pycuda not correctly installed, please ensure pycuda is installed on the same CUDA installation as you're using right now\")\n\n        #create a stream and events\n        self.stream = drv.Stream()\n        self.start = drv.Event()\n        self.end = drv.Event()\n\n        #default dynamically allocated shared memory size, can be overwritten using smem_args\n        self.smem_size = 0\n\n        #setup observers\n        self.observers = observers or []\n        self.observers.append(CudaRuntimeObserver(self))\n        for obs in self.observers:\n            obs.register_device(self)\n\n        #collect environment information\n        env = dict()\n        env[\"device_name\"] = self.context.get_device().name()\n        env[\"cuda_version\"] = \".\".join([str(i) for i in drv.get_version()])\n        env[\"compute_capability\"] = self.cc\n        env[\"iterations\"] = self.iterations\n        env[\"compiler_options\"] = compiler_options\n        env[\"device_properties\"] = devprops\n        self.env = env\n        self.name = env[\"device_name\"]\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *exc):\n        for gpu_mem in self.allocations:\n            if hasattr(gpu_mem, 'free'):    #if needed for when using mocks during testing\n                gpu_mem.free()\n        if hasattr(self, 'context'):\n            self.context.pop()\n\n    def ready_argument_list(self, arguments):\n        \"\"\"ready argument list to be passed to the kernel, allocates gpu mem\n\n        :param arguments: List of arguments to be passed to the kernel.\n            The order should match the argument list on the CUDA kernel.\n            Allowed values are numpy.ndarray, and/or numpy.int32, numpy.float32, and so on.\n        :type arguments: list(numpy objects)\n\n        :returns: A list of arguments that can be passed to an CUDA kernel.\n        :rtype: list( pycuda.driver.DeviceAllocation, numpy.int32, ... )\n        \"\"\"\n        gpu_args = []\n        for arg in arguments:\n            # if arg i is a numpy array copy to device\n            if isinstance(arg, np.ndarray):\n                alloc = drv.mem_alloc(arg.nbytes)\n                self.allocations.append(alloc)\n                gpu_args.append(alloc)\n                drv.memcpy_htod(gpu_args[-1], arg)\n            elif isinstance(arg, torch.Tensor):\n                if arg.is_cuda:\n                    gpu_args.append(Holder(arg))\n                else:\n                    gpu_args.append(Holder(arg.cuda()))\n            else:    # if not an array, just pass argument along\n                gpu_args.append(arg)\n        return gpu_args\n\n    def compile(self, kernel_instance):\n        \"\"\"call the CUDA compiler to compile the kernel, return the device function\n\n        :param kernel_name: The name of the kernel to be compiled, used to lookup the\n            function after compilation.\n        :type kernel_name: string\n\n        :param kernel_string: The CUDA kernel code that contains the function `kernel_name`\n        :type kernel_string: string\n\n        :returns: An CUDA kernel that can be called directly.\n        :rtype: pycuda.driver.Function\n        \"\"\"\n        kernel_string = kernel_instance.kernel_string\n        kernel_name = kernel_instance.name\n\n        try:\n            no_extern_c = 'extern \"C\"' in kernel_string\n\n            compiler_options = ['-Xcompiler=-Wall']\n            if self.compiler_options:\n                compiler_options += self.compiler_options\n\n            self.current_module = self.source_mod(kernel_string, options=compiler_options + [\"-e\", kernel_name],\n                                                  arch=('compute_' + self.cc) if self.cc != \"00\" else None, code=('sm_' + self.cc) if self.cc != \"00\" else None,\n                                                  cache_dir=False, no_extern_c=no_extern_c)\n\n            self.func = self.current_module.get_function(kernel_name)\n            return self.func\n        except drv.CompileError as e:\n            if \"uses too much shared data\" in e.stderr:\n                raise Exception(\"uses too much shared data\")\n            else:\n                raise e\n\n    def benchmark(self, func, gpu_args, threads, grid):\n        \"\"\"runs the kernel and measures time repeatedly, returns average time\n\n        Runs the kernel and measures kernel execution time repeatedly, number of\n        iterations is set during the creation of CudaFunctions. Benchmark returns\n        a robust average, from all measurements the fastest and slowest runs are\n        discarded and the rest is included in the returned average. The reason for\n        this is to be robust against initialization artifacts and other exceptional\n        cases.\n\n        :param func: A PyCuda kernel compiled for this specific kernel configuration\n        :type func: pycuda.driver.Function\n\n        :param gpu_args: A list of arguments to the kernel, order should match the\n            order in the code. Allowed values are either variables in global memory\n            or single values passed by value.\n        :type gpu_args: list( pycuda.driver.DeviceAllocation, numpy.int32, ...)\n\n        :param threads: A tuple listing the number of threads in each dimension of\n            the thread block\n        :type threads: tuple(int, int, int)\n\n        :param grid: A tuple listing the number of thread blocks in each dimension\n            of the grid\n        :type grid: tuple(int, int)\n\n        :returns: A dictionary with benchmark results.\n        :rtype: dict()\n        \"\"\"\n        result = dict()\n        self.context.synchronize()\n        for _ in range(self.iterations):\n            for obs in self.observers:\n                obs.before_start()\n            self.context.synchronize()\n            self.start.record(stream=self.stream)\n            self.run_kernel(func, gpu_args, threads, grid, stream=self.stream)\n            self.end.record(stream=self.stream)\n            for obs in self.observers:\n                obs.after_start()\n            while not self.end.query():\n                for obs in self.observers:\n                    obs.during()\n                time.sleep(1e-6)    #one microsecond\n            self.end.synchronize()\n            for obs in self.observers:\n                obs.after_finish()\n\n        for obs in self.observers:\n            result.update(obs.get_results())\n\n        return result\n\n    def copy_constant_memory_args(self, cmem_args):\n        \"\"\"adds constant memory arguments to the most recently compiled module\n\n        :param cmem_args: A dictionary containing the data to be passed to the\n            device constant memory. The format to be used is as follows: A\n            string key is used to name the constant memory symbol to which the\n            value needs to be copied. Similar to regular arguments, these need\n            to be numpy objects, such as numpy.ndarray or numpy.int32, and so on.\n        :type cmem_args: dict( string: numpy.ndarray, ... )\n        \"\"\"\n        logging.debug('copy_constant_memory_args called')\n        logging.debug('current module: ' + str(self.current_module))\n        for k, v in cmem_args.items():\n            symbol = self.current_module.get_global(k)[0]\n            logging.debug('copying to symbol: ' + str(symbol))\n            logging.debug('array to be copied: ')\n            logging.debug(v.nbytes)\n            logging.debug(v.dtype)\n            logging.debug(v.flags)\n            drv.memcpy_htod(symbol, v)\n\n    def copy_shared_memory_args(self, smem_args):\n        \"\"\"add shared memory arguments to the kernel\"\"\"\n        self.smem_size = smem_args[\"size\"]\n\n    def copy_texture_memory_args(self, texmem_args):\n        \"\"\"adds texture memory arguments to the most recently compiled module\n\n        :param texmem_args: A dictionary containing the data to be passed to the\n            device texture memory. See tune_kernel().\n        :type texmem_args: dict\n        \"\"\"\n\n        filter_mode_map = {\n            'point': drv.filter_mode.POINT,\n            'linear': drv.filter_mode.LINEAR\n        }\n        address_mode_map = {\n            'border': drv.address_mode.BORDER,\n            'clamp': drv.address_mode.CLAMP,\n            'mirror': drv.address_mode.MIRROR,\n            'wrap': drv.address_mode.WRAP\n        }\n\n        logging.debug('copy_texture_memory_args called')\n        logging.debug('current module: ' + str(self.current_module))\n        self.texrefs = []\n        for k, v in texmem_args.items():\n            tex = self.current_module.get_texref(k)\n            self.texrefs.append(tex)\n\n            logging.debug('copying to texture: ' + str(k))\n            if not isinstance(v, dict):\n                data = v\n            else:\n                data = v['array']\n            logging.debug('texture to be copied: ')\n            logging.debug(data.nbytes)\n            logging.debug(data.dtype)\n            logging.debug(data.flags)\n\n            drv.matrix_to_texref(data, tex, order=\"C\")\n\n            if isinstance(v, dict):\n                if 'address_mode' in v and v['address_mode'] is not None:\n                    # address_mode is set per axis\n                    amode = v['address_mode']\n                    if not isinstance(amode, list):\n                        amode = [amode] * data.ndim\n                    for i, m in enumerate(amode):\n                        try:\n                            if m is not None:\n                                tex.set_address_mode(i, address_mode_map[m])\n                        except KeyError:\n                            raise ValueError('Unknown address mode: ' + m)\n                if 'filter_mode' in v and v['filter_mode'] is not None:\n                    fmode = v['filter_mode']\n                    try:\n                        tex.set_filter_mode(filter_mode_map[fmode])\n                    except KeyError:\n                        raise ValueError('Unknown filter mode: ' + fmode)\n                if 'normalized_coordinates' in v and v['normalized_coordinates']:\n                    tex.set_flags(tex.get_flags() | drv.TRSF_NORMALIZED_COORDINATES)\n\n    def run_kernel(self, func, gpu_args, threads, grid, stream=None):\n        \"\"\"runs the CUDA kernel passed as 'func'\n\n        :param func: A PyCuda kernel compiled for this specific kernel configuration\n        :type func: pycuda.driver.Function\n\n        :param gpu_args: A list of arguments to the kernel, order should match the\n            order in the code. Allowed values are either variables in global memory\n            or single values passed by value.\n        :type gpu_args: list( pycuda.driver.DeviceAllocation, numpy.int32, ...)\n\n        :param threads: A tuple listing the number of threads in each dimension of\n            the thread block\n        :type threads: tuple(int, int, int)\n\n        :param grid: A tuple listing the number of thread blocks in each dimension\n            of the grid\n        :type grid: tuple(int, int)\n        \"\"\"\n        func(*gpu_args, block=threads, grid=grid, stream=stream, shared=self.smem_size, texrefs=self.texrefs)\n\n    def memset(self, allocation, value, size):\n        \"\"\"set the memory in allocation to the value in value\n\n        :param allocation: A GPU memory allocation unit\n        :type allocation: pycuda.driver.DeviceAllocation\n\n        :param value: The value to set the memory to\n        :type value: a single 8-bit unsigned int\n\n        :param size: The size of to the allocation unit in bytes\n        :type size: int\n\n        \"\"\"\n        drv.memset_d8(allocation, value, size)\n\n    def memcpy_dtoh(self, dest, src):\n        \"\"\"perform a device to host memory copy\n\n        :param dest: A numpy array in host memory to store the data\n        :type dest: numpy.ndarray\n\n        :param src: A GPU memory allocation unit\n        :type src: pycuda.driver.DeviceAllocation\n        \"\"\"\n        if isinstance(src, drv.DeviceAllocation):\n            drv.memcpy_dtoh(dest, src)\n        elif isinstance(src, torch.Tensor):\n            dest[:] = src\n        else:\n            dest = src\n\n    def memcpy_htod(self, dest, src):\n        \"\"\"perform a host to device memory copy\n\n        :param dest: A GPU memory allocation unit\n        :type dest: pycuda.driver.DeviceAllocation\n\n        :param src: A numpy array in host memory to store the data\n        :type src: numpy.ndarray\n        \"\"\"\n        if isinstance(dest, drv.DeviceAllocation):\n            drv.memcpy_htod(dest, src)\n        else:\n            dest = src\n\n    units = {\n        'time': 'ms',\n        'power': 's,mW',\n        'energy': 'J'\n    }\n", 428], "/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/opencl.py": ["\"\"\"This module contains all OpenCL specific kernel_tuner functions\"\"\"\nfrom __future__ import print_function\nimport time\nimport numpy as np\n\nfrom kernel_tuner.observers import BenchmarkObserver\n\n#embedded in try block to be able to generate documentation\ntry:\n    import pyopencl as cl\nexcept ImportError:\n    cl = None\n\n\nclass OpenCLObserver(BenchmarkObserver):\n    \"\"\" Observer that measures time using CUDA events during benchmarking \"\"\"\n    def __init__(self, dev):\n        self.dev = dev\n        self.times = []\n\n    def after_finish(self):\n        event = self.dev.event\n        self.times.append((event.profile.end - event.profile.start)*1e-6) #ms\n\n    def get_results(self):\n        results = {\"time\": np.average(self.times), \"times\": self.times.copy()}\n        self.times = []\n        return results\n\n\nclass OpenCLFunctions():\n    \"\"\"Class that groups the OpenCL functions on maintains some state about the device\"\"\"\n\n    def __init__(self, device=0, platform=0, iterations=7, compiler_options=None, observers=None):\n        \"\"\"Creates OpenCL device context and reads device properties\n\n        :param device: The ID of the OpenCL device to use for benchmarking\n        :type device: int\n\n        :param iterations: The number of iterations to run the kernel during benchmarking, 7 by default.\n        :type iterations: int\n        \"\"\"\n        if not cl:\n            raise ImportError(\"Error: pyopencl not installed, please install e.g. using 'pip install pyopencl'.\")\n\n        self.iterations = iterations\n        #setup context and queue\n        platforms = cl.get_platforms()\n        self.ctx = cl.Context(devices=[platforms[platform].get_devices()[device]])\n\n        self.queue = cl.CommandQueue(self.ctx, properties=cl.command_queue_properties.PROFILING_ENABLE)\n        self.mf = cl.mem_flags\n        #inspect device properties\n        self.max_threads = self.ctx.devices[0].get_info(cl.device_info.MAX_WORK_GROUP_SIZE)\n        self.compiler_options = compiler_options or []\n\n        #observer stuff\n        self.observers = observers or []\n        self.observers.append(OpenCLObserver(self))\n        self.event = None\n        for obs in self.observers:\n            obs.register_device(self)\n\n        #collect environment information\n        dev = self.ctx.devices[0]\n        env = dict()\n        env[\"platform_name\"] = dev.platform.name\n        env[\"platform_version\"] = dev.platform.version\n        env[\"device_name\"] = dev.name\n        env[\"device_version\"] = dev.version\n        env[\"opencl_c_version\"] = dev.opencl_c_version\n        env[\"driver_version\"] = dev.driver_version\n        env[\"iterations\"] = self.iterations\n        env[\"compiler_options\"] = compiler_options\n        self.env = env\n        self.name = dev.name\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *exc):\n        pass\n\n    def ready_argument_list(self, arguments):\n        \"\"\"ready argument list to be passed to the kernel, allocates gpu mem\n\n        :param arguments: List of arguments to be passed to the kernel.\n            The order should match the argument list on the OpenCL kernel.\n            Allowed values are numpy.ndarray, and/or numpy.int32, numpy.float32, and so on.\n        :type arguments: list(numpy objects)\n\n        :returns: A list of arguments that can be passed to an OpenCL kernel.\n        :rtype: list( pyopencl.Buffer, numpy.int32, ... )\n        \"\"\"\n        gpu_args = []\n        for arg in arguments:\n            # if arg i is a numpy array copy to device\n            if isinstance(arg, np.ndarray):\n                gpu_args.append(cl.Buffer(self.ctx, self.mf.READ_WRITE | self.mf.COPY_HOST_PTR, hostbuf=arg))\n            else: # if not an array, just pass argument along\n                gpu_args.append(arg)\n        return gpu_args\n\n    def compile(self, kernel_instance):\n        \"\"\"call the OpenCL compiler to compile the kernel, return the device function\n\n        :param kernel_name: The name of the kernel to be compiled, used to lookup the\n            function after compilation.\n        :type kernel_name: string\n\n        :param kernel_string: The OpenCL kernel code that contains the function `kernel_name`\n        :type kernel_string: string\n\n        :returns: An OpenCL kernel that can be called directly.\n        :rtype: pyopencl.Kernel\n        \"\"\"\n        prg = cl.Program(self.ctx, kernel_instance.kernel_string).build(options=self.compiler_options)\n        func = getattr(prg, kernel_instance.name)\n        return func\n\n    def benchmark(self, func, gpu_args, threads, grid):\n        \"\"\"runs the kernel and measures time repeatedly, returns average time\n\n        Runs the kernel and measures kernel execution time repeatedly, number of\n        iterations is set during the creation of OpenCLFunctions. Benchmark returns\n        a robust average, from all measurements the fastest and slowest runs are\n        discarded and the rest is included in the returned average. The reason for\n        this is to be robust against initialization artifacts and other exceptional\n        cases.\n\n        :param func: A PyOpenCL kernel compiled for this specific kernel configuration\n        :type func: pyopencl.Kernel\n\n        :param gpu_args: A list of arguments to the kernel, order should match the\n            order in the code. Allowed values are either variables in global memory\n            or single values passed by value.\n        :type gpu_args: list( pyopencl.Buffer, numpy.int32, ...)\n\n        :param threads: A tuple listing the number of work items in each dimension of\n            the work group.\n        :type threads: tuple(int, int, int)\n\n        :param grid: A tuple listing the number of work groups in each dimension\n            of the NDRange.\n        :type grid: tuple(int, int)\n\n        :returns: All benchmark results.\n        :rtype: dict()\n        \"\"\"\n        result = dict()\n        global_size = (grid[0]*threads[0], grid[1]*threads[1], grid[2]*threads[2])\n        local_size = threads\n        for _ in range(self.iterations):\n            for obs in self.observers:\n                obs.before_start()\n            self.queue.finish()\n            self.event = func(self.queue, global_size, local_size, *gpu_args)\n            for obs in self.observers:\n                obs.after_start()\n            while self.event.get_info(cl.event_info.COMMAND_EXECUTION_STATUS) != 0:\n                for obs in self.observers:\n                    obs.during()\n                time.sleep(1e-6)\n            self.event.wait()\n            for obs in self.observers:\n                obs.after_finish()\n        for obs in self.observers:\n            result.update(obs.get_results())\n        return result\n\n    def run_kernel(self, func, gpu_args, threads, grid):\n        \"\"\"runs the OpenCL kernel passed as 'func'\n\n        :param func: An OpenCL Kernel\n        :type func: pyopencl.Kernel\n\n        :param gpu_args: A list of arguments to the kernel, order should match the\n            order in the code. Allowed values are either variables in global memory\n            or single values passed by value.\n        :type gpu_args: list( pyopencl.Buffer, numpy.int32, ...)\n\n        :param threads: A tuple listing the number of work items in each dimension of\n            the work group.\n        :type threads: tuple(int, int, int)\n\n        :param grid: A tuple listing the number of work groups in each dimension\n            of the NDRange.\n        :type grid: tuple(int, int)\n        \"\"\"\n        global_size = (grid[0]*threads[0], grid[1]*threads[1], grid[2]*threads[2])\n        local_size = threads\n        event = func(self.queue, global_size, local_size, *gpu_args)\n        event.wait()\n\n    def memset(self, buffer, value, size):\n        \"\"\"set the memory in allocation to the value in value\n\n        :param allocation: An OpenCL Buffer to fill\n        :type allocation: pyopencl.Buffer\n\n        :param value: The value to set the memory to\n        :type value: a single 32-bit int\n\n        :param size: The size of to the allocation unit in bytes\n        :type size: int\n\n        \"\"\"\n        if isinstance(buffer, cl.Buffer):\n            try:\n                cl.enqueue_fill_buffer(self.queue, buffer, np.uint32(value), 0, size)\n            except AttributeError:\n                src=np.zeros(size, dtype='uint8')+np.uint8(value)\n                cl.enqueue_copy(self.queue, buffer, src)\n\n    def memcpy_dtoh(self, dest, src):\n        \"\"\"perform a device to host memory copy\n\n        :param dest: A numpy array in host memory to store the data\n        :type dest: numpy.ndarray\n\n        :param src: An OpenCL Buffer to copy data from\n        :type src: pyopencl.Buffer\n        \"\"\"\n        if isinstance(src, cl.Buffer):\n            cl.enqueue_copy(self.queue, dest, src)\n\n    def memcpy_htod(self, dest, src):\n        \"\"\"perform a host to device memory copy\n\n        :param dest: An OpenCL Buffer to copy data from\n        :type dest: pyopencl.Buffer\n\n        :param src: A numpy array in host memory to store the data\n        :type src: numpy.ndarray\n        \"\"\"\n        if isinstance(dest, cl.Buffer):\n            cl.enqueue_copy(self.queue, dest, src)\n\n    units = {'time': 'ms'}\n", 239], "/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/c.py": ["\"\"\" This module contains the functionality for running and compiling C functions \"\"\"\n\nfrom collections import namedtuple\nimport subprocess\nimport platform\nimport errno\nimport re\nimport logging\nimport ctypes as C\nimport _ctypes\n\nimport numpy\nimport numpy.ctypeslib\n\nfrom kernel_tuner.util import get_temp_filename, delete_temp_file, write_file\n\ndtype_map = {\"int8\": C.c_int8,\n             \"int16\": C.c_int16,\n             \"int32\": C.c_int32,\n             \"int64\": C.c_int64,\n             \"uint8\": C.c_uint8,\n             \"uint16\": C.c_uint16,\n             \"uint32\": C.c_uint32,\n             \"uint64\": C.c_uint64,\n             \"float32\": C.c_float,\n             \"float64\": C.c_double}\n\n# This represents an individual kernel argument.\n# It contains a numpy object (ndarray or number) and a ctypes object with a copy\n# of the argument data. For an ndarray, the ctypes object is a wrapper for the ndarray's data.\nArgument = namedtuple(\"Argument\", [\"numpy\", \"ctypes\"])\n\n\nclass CFunctions(object):\n    \"\"\"Class that groups the code for running and compiling C functions\"\"\"\n\n    def __init__(self, iterations=7, compiler_options=None, compiler=None):\n        \"\"\"instantiate CFunctions object used for interacting with C code\n\n        :param iterations: Number of iterations used while benchmarking a kernel, 7 by default.\n        :type iterations: int\n        \"\"\"\n        self.iterations = iterations\n        self.max_threads = 1024\n        self.compiler_options = compiler_options\n        self.compiler = compiler or \"g++\"  # use gcc by default\n        self.lib = None\n        self.using_openmp = False\n\n        try:\n            cc_version = str(subprocess.check_output([self.compiler, \"--version\"]))\n            cc_version = cc_version.splitlines()[0].split(\" \")[-1]\n        except OSError as e:\n            raise e\n\n        #check if nvcc is available\n        self.nvcc_available = False\n        try:\n            nvcc_version = str(subprocess.check_output([\"nvcc\", \"--version\"]))\n            nvcc_version = nvcc_version.splitlines()[-1].split(\" \")[-1]\n            self.nvcc_available = True\n        except OSError as e:\n            if e.errno != errno.ENOENT:\n                raise e\n\n        #environment info\n        env = dict()\n        env[\"CC Version\"] = cc_version\n        if self.nvcc_available:\n            env[\"NVCC Version\"] = nvcc_version\n        env[\"iterations\"] = self.iterations\n        env[\"compiler_options\"] = compiler_options\n        self.env = env\n        self.name = platform.processor()\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *exc):\n        pass\n\n    def ready_argument_list(self, arguments):\n        \"\"\"ready argument list to be passed to the C function\n\n        :param arguments: List of arguments to be passed to the C function.\n            The order should match the argument list on the C function.\n            Allowed values are numpy.ndarray, and/or numpy.int32, numpy.float32, and so on.\n        :type arguments: list(numpy objects)\n\n        :returns: A list of arguments that can be passed to the C function.\n        :rtype: list(Argument)\n        \"\"\"\n        ctype_args = [ None for _ in arguments]\n\n        for i, arg in enumerate(arguments):\n            if not isinstance(arg, (numpy.ndarray, numpy.number)):\n                raise TypeError(\"Argument is not numpy ndarray or numpy scalar %s\" % type(arg))\n            dtype_str = str(arg.dtype)\n            #data = arg.copy()\n            if isinstance(arg, numpy.ndarray):\n                if dtype_str in dtype_map.keys():\n                    # In numpy <= 1.15, ndarray.ctypes.data_as does not itself keep a reference\n                    # to its underlying array, so we need to store a reference to arg.copy()\n                    # in the Argument object manually to avoid it being deleted.\n                    # (This changed in numpy > 1.15.)\n                    #data_ctypes = data.ctypes.data_as(C.POINTER(dtype_map[dtype_str]))\n                    data_ctypes = arg.ctypes.data_as(C.POINTER(dtype_map[dtype_str]))\n                else:\n                    raise TypeError(\"unknown dtype for ndarray\")\n            elif isinstance(arg, numpy.generic):\n                data_ctypes = dtype_map[dtype_str](arg)\n            #ctype_args[i] = Argument(numpy=data, ctypes=data_ctypes)\n            ctype_args[i] = Argument(numpy=arg, ctypes=data_ctypes)\n        return ctype_args\n\n    def compile(self, kernel_instance):\n        \"\"\"call the C compiler to compile the kernel, return the function\n\n        :param kernel_instance: An object representing the specific instance of the tunable kernel\n            in the parameter space.\n        :type kernel_instance: kernel_tuner.core.KernelInstance\n\n        :returns: An ctypes function that can be called directly.\n        :rtype: ctypes._FuncPtr\n        \"\"\"\n        logging.debug('compiling ' + kernel_instance.name)\n\n        kernel_string = kernel_instance.kernel_string\n        kernel_name = kernel_instance.name\n\n        if self.lib != None:\n            self.cleanup_lib()\n\n        compiler_options = [\"-fPIC\"]\n\n        #detect openmp\n        if \"#include <omp.h>\" in kernel_string or \"use omp_lib\" in kernel_string:\n            logging.debug('set using_openmp to true')\n            self.using_openmp = True\n            if self.compiler == \"pgfortran\":\n                compiler_options.append(\"-mp\")\n            else:\n                if \"#pragma acc\" in kernel_string or \"!$acc\" in kernel_string:\n                    compiler_options.append(\"-fopenacc\")\n                else:\n                    compiler_options.append(\"-fopenmp\")\n\n        #if filename is known, use that one\n        suffix = kernel_instance.kernel_source.get_user_suffix()\n\n        #if code contains device code, suffix .cu is required\n        device_code_signals = [\"__global\", \"__syncthreads()\", \"threadIdx\"]\n        if any([snippet in kernel_string for snippet in device_code_signals]):\n            suffix = \".cu\"\n\n        #detect whether to use nvcc as default instead of g++, may overrule an explicitly passed g++\n        if (suffix == \".cu\") or (\"#include <cuda\" in kernel_string) or (\"cudaMemcpy\" in kernel_string):\n            if self.compiler == \"g++\" and self.nvcc_available:\n                self.compiler = \"nvcc\"\n\n        if suffix is None:\n            #select right suffix based on compiler\n            suffix = \".cc\"\n\n            if self.compiler in [\"gfortran\", \"pgfortran\", \"ftn\", \"ifort\"]:\n                suffix = \".F90\"\n\n        if self.compiler == \"nvcc\":\n            compiler_options = [\"-Xcompiler=\" + c for c in compiler_options]\n\n        #this basically checks if we aren't compiling Fortran\n        #at the moment any C, C++, or CUDA code is assumed to use extern \"C\" linkage\n        if \".c\" in suffix:\n            if not \"extern \\\"C\\\"\" in kernel_string:\n                kernel_string = \"extern \\\"C\\\" {\\n\" + kernel_string + \"\\n}\"\n\n        #copy user specified compiler options to current list\n        if self.compiler_options:\n            compiler_options += self.compiler_options\n\n        lib_args = []\n        if \"CL/cl.h\" in kernel_string:\n            lib_args = [\"-lOpenCL\"]\n\n        logging.debug('using compiler ' + self.compiler)\n        logging.debug('compiler_options ' + \" \".join(compiler_options))\n        logging.debug('lib_args ' + \" \".join(lib_args))\n\n        source_file = get_temp_filename(suffix=suffix)\n        filename = \".\".join(source_file.split(\".\")[:-1])\n\n        #detect Fortran modules\n        match = re.search(r\"\\s*module\\s+([a-zA-Z_]*)\", kernel_string)\n        if match:\n            if self.compiler == \"gfortran\":\n                kernel_name = \"__\" + match.group(1) + \"_MOD_\" + kernel_name\n            elif self.compiler in [\"ftn\", \"ifort\"]:\n                kernel_name = match.group(1) + \"_mp_\" + kernel_name + \"_\"\n            elif self.compiler == \"pgfortran\":\n                kernel_name = match.group(1) + \"_\" + kernel_name + \"_\"\n        else:\n            #for functions outside of modules\n            if self.compiler in [\"gfortran\", \"ftn\", \"ifort\", \"pgfortran\"]:\n                kernel_name = kernel_name + \"_\"\n\n        try:\n            write_file(source_file, kernel_string)\n\n            lib_extension = \".so\"\n            if platform.system() == \"Darwin\":\n                lib_extension = \".dylib\"\n\n            subprocess.check_call([self.compiler, \"-c\", source_file] + compiler_options + [\"-o\", filename + \".o\"])\n            subprocess.check_call([self.compiler, filename + \".o\"] + compiler_options + [\"-shared\", \"-o\", filename + lib_extension] + lib_args)\n\n            self.lib = numpy.ctypeslib.load_library(filename, '.')\n            func = getattr(self.lib, kernel_name)\n            func.restype = C.c_float\n\n        finally:\n            delete_temp_file(source_file)\n            delete_temp_file(filename+\".o\")\n            delete_temp_file(filename+\".so\")\n            delete_temp_file(filename+\".dylib\")\n\n        return func\n\n\n    def benchmark(self, func, c_args, threads, grid):\n        \"\"\"runs the kernel repeatedly, returns averaged returned value\n\n        The C function tuning is a little bit more flexible than direct CUDA\n        or OpenCL kernel tuning. The C function needs to measure time, or some\n        other quality metric you wish to tune on, on its own and should\n        therefore return a single floating-point value.\n\n        Benchmark runs the C function repeatedly and returns the average of the\n        values returned by the C function. The number of iterations is set\n        during the creation of the CFunctions object. For all measurements the\n        lowest and highest values are discarded and the rest is included in the\n        average. The reason for this is to be robust against initialization\n        artifacts and other exceptional cases.\n\n        :param func: A C function compiled for this specific configuration\n        :type func: ctypes._FuncPtr\n\n        :param c_args: A list of arguments to the function, order should match the\n            order in the code. The list should be prepared using\n            ready_argument_list().\n        :type c_args: list(Argument)\n\n        :param threads: Ignored, but left as argument for now to have the same\n            interface as CudaFunctions and OpenCLFunctions.\n        :type threads: any\n\n        :param grid: Ignored, but left as argument for now to have the same\n            interface as CudaFunctions and OpenCLFunctions.\n        :type grid: any\n\n        :returns: All execution times.\n        :rtype: dict()\n        \"\"\"\n        result = dict()\n        result[\"times\"] = []\n        for _ in range(self.iterations):\n            value = self.run_kernel(func, c_args, threads, grid)\n\n            #I would like to replace the following with actually capturing\n            #stderr and detecting the error directly in Python, it proved\n            #however that capturing stderr for non-Python functions from Python\n            #is a rather difficult thing to do\n            #\n            #The current, less than ideal, scheme uses the convention that a\n            #negative time indicates a 'too many resources requested for launch'\n            #which Kernel Tuner can silently ignore\n            if value < 0.0:\n                raise Exception(\"too many resources requested for launch\")\n\n            result[\"times\"].append(value)\n        result[\"time\"] = numpy.mean(result[\"times\"])\n        return result\n\n    def run_kernel(self, func, c_args, threads, grid):\n        \"\"\"runs the kernel once, returns whatever the kernel returns\n\n        :param func: A C function compiled for this specific configuration\n        :type func: ctypes._FuncPtr\n\n        :param c_args: A list of arguments to the function, order should match the\n            order in the code. The list should be prepared using\n            ready_argument_list().\n        :type c_args: list(Argument)\n\n        :param threads: Ignored, but left as argument for now to have the same\n            interface as CudaFunctions and OpenCLFunctions.\n        :type threads: any\n\n        :param grid: Ignored, but left as argument for now to have the same\n            interface as CudaFunctions and OpenCLFunctions.\n        :type grid: any\n\n        :returns: A robust average of values returned by the C function.\n        :rtype: float\n        \"\"\"\n        logging.debug(\"run_kernel\")\n        logging.debug(\"arguments=\" + str([str(arg.ctypes) for arg in c_args]))\n\n        time = func(*[arg.ctypes for arg in c_args])\n\n        return time\n\n    def memset(self, allocation, value, size):\n        \"\"\"set the memory in allocation to the value in value\n\n        :param allocation: An Argument for some memory allocation unit\n        :type allocation: Argument\n\n        :param value: The value to set the memory to\n        :type value: a single 8-bit unsigned int\n\n        :param size: The size of to the allocation unit in bytes\n        :type size: int\n        \"\"\"\n        C.memset(allocation.ctypes, value, size)\n\n    def memcpy_dtoh(self, dest, src):\n        \"\"\"a simple memcpy copying from an Argument to a numpy array\n\n        :param dest: A numpy array to store the data\n        :type dest: numpy.ndarray\n\n        :param src: An Argument for some memory allocation\n        :type src: Argument\n        \"\"\"\n        dest[:] = src.numpy\n\n    def memcpy_htod(self, dest, src):\n        \"\"\"a simple memcpy copying from a numpy array to an Argument\n\n        :param dest: An Argument for some memory allocation\n        :type dst: Argument\n\n        :param src: A numpy array containing the source data\n        :type src: numpy.ndarray\n        \"\"\"\n        dest.numpy[:] = src\n\n    def cleanup_lib(self):\n        \"\"\" unload the previously loaded shared library \"\"\"\n        if not self.using_openmp:\n            #this if statement is necessary because shared libraries that use\n            #OpenMP will core dump when unloaded, this is a well-known issue with OpenMP\n            logging.debug('unloading shared library')\n            _ctypes.dlclose(self.lib._handle)\n\n    units = {}\n", 356], "/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/python.py": ["\"\"\" This module contains the functionality for running Python functions \"\"\"\n\nfrom collections import namedtuple\nimport platform\nimport logging\nimport warnings\nimport importlib.util\nfrom math import ceil\nfrom time import perf_counter\nfrom typing import Tuple\n\nimport progressbar\nimport numpy as np\n\n# for parallel subprocess runs\nfrom multiprocess import Manager, cpu_count, get_context    # using Pathos as Python's multiprocessing is unable to pickle\nfrom itertools import repeat\nimport subprocess\nimport sys\nfrom os import getpid\n\nfrom kernel_tuner.util import get_temp_filename, delete_temp_file\n\n# This represents an individual kernel argument.\n# It contains a numpy object (ndarray or number) and a ctypes object with a copy\n# of the argument data. For an ndarray, the ctypes object is a wrapper for the ndarray's data.\nArgument = namedtuple(\"Argument\", [\"numpy\", \"ctypes\"])\ninvalid_value = 1e20\n\n\nclass PythonFunctions(object):\n    \"\"\"Class that groups the code for running and compiling C functions\"\"\"\n\n    def __init__(self, iterations=7, observers=None, parallel_mode=False, show_progressbar=False):\n        \"\"\"instantiate PythonFunctions object used for interacting with Python code\n\n        :param iterations: Number of iterations used while benchmarking a kernel, 7 by default.\n        :type iterations: int\n        \"\"\"\n        self.iterations = iterations\n        self.max_threads = 1024\n        self.show_progressbar = show_progressbar\n\n        #environment info\n        env = dict()\n        env[\"iterations\"] = self.iterations\n        self.env = env\n        self.name = platform.processor()\n        self.observers = observers or []\n        self.parallel_mode = parallel_mode\n\n        self.benchmark_times = []\n\n        if self.parallel_mode:\n            warnings.warn(\n                \"Be sure to check that simulation mode is true for the kernel, because parallel mode requires a completed cache file to avoid race conditions.\")\n\n        if len(self.observers) > 0 and self.parallel_mode:\n            raise NotImplementedError(\"Observers are currently not implemented for parallel execution.\")\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *exc):\n        pass\n\n    def ready_argument_list(self, arguments):\n        \"\"\"ready argument list to be passed to the Python function\n        \"\"\"\n        return arguments\n\n    def compile(self, kernel_instance):\n        \"\"\" return the function from the kernel instance \"\"\"\n\n        suffix = kernel_instance.kernel_source.get_user_suffix()\n        source_file = get_temp_filename(suffix=suffix)\n\n        spec = importlib.util.find_spec(kernel_instance.name)\n        foo = importlib.util.module_from_spec(spec)\n        spec.loader.exec_module(foo)\n        func = getattr(foo, kernel_instance.name)\n\n        self.params = kernel_instance.params\n\n        delete_temp_file(source_file)\n        return func\n\n    def benchmark(self, func, args, threads, grid):\n        \"\"\"runs the kernel repeatedly, returns averaged returned value\n\n        The C function tuning is a little bit more flexible than direct CUDA\n        or OpenCL kernel tuning. The C function needs to measure time, or some\n        other quality metric you wish to tune on, on its own and should\n        therefore return a single floating-point value.\n\n        Benchmark runs the C function repeatedly and returns the average of the\n        values returned by the C function. The number of iterations is set\n        during the creation of the CFunctions object. For all measurements the\n        lowest and highest values are discarded and the rest is included in the\n        average. The reason for this is to be robust against initialization\n        artifacts and other exceptional cases.\n\n        :param func: A C function compiled for this specific configuration\n        :type func: ctypes._FuncPtr\n\n        :param args: A list of arguments to the function, order should match the\n            order in the code. The list should be prepared using\n            ready_argument_list().\n        :type args: list(Argument)\n\n        :param threads: Ignored, but left as argument for now to have the same\n            interface as CudaFunctions and OpenCLFunctions.\n        :type threads: any\n\n        :param grid: Ignored, but left as argument for now to have the same\n            interface as CudaFunctions and OpenCLFunctions.\n        :type grid: any\n\n        :returns: All execution times.\n        :rtype: dict()\n        \"\"\"\n\n        # For reference: the following times were obtained with 35 repeats on random_sample strategy.\n        # As seen, there is a lot of overhead with subproceses; directly executing the function scales much better.\n        # time taken by sequential: 20.7 sec\n        # time taken by parallel in sequential form (subprocess overhead): 46.3 sec\n        # time taken by parallel subprocesses: 7.5 sec on 9, 9.9 sec on 8, 13.6 sec on 4, 27.8 sec on 2, 45.9 sec on 1\n        # time taken by parallel directly: 2.99 sec on 9, 4.0 sec on 8, 5.23 sec on 4, 11.3 sec on 2, 19.3 sec on 1\n\n        result = dict()\n        result[\"times\"] = []\n        min_valid_iterations = ceil(self.iterations * 0.8)\n        iterator = range(self.iterations) if not self.show_progressbar or self.parallel_mode else progressbar.progressbar(\n            range(self.iterations), min_value=0, max_value=self.iterations, redirect_stdout=True)\n\n        # new implementation\n        start_time = perf_counter()\n        if self.parallel_mode and cpu_count() > 1:\n            num_procs = max(min(cpu_count() - 1, self.iterations), 1)\n            logging.debug(f\"Running benchmark in parallel on {num_procs} processors\")\n            manager = Manager()\n            invalid_flag = manager.Value('i', int(False))\n            MNE_values = manager.list()\n            runtimes = manager.list()\n            warnings_dicts = manager.list()\n            with get_context('spawn').Pool(num_procs) as pool:    # spawn alternative is forkserver, creates a reusable server\n                args = func, args, self.params, invalid_flag\n                MNE_values, runtimes, warnings_dicts = zip(*pool.starmap(run_kernel_and_observers, zip(iterator, repeat(args))))\n                MNE_values, runtimes, warnings_dicts = list(MNE_values), list(runtimes), list(warnings_dicts)\n            result[\"strategy_time\"] = np.mean(runtimes)\n            warning_dict = warnings_dicts[0]\n            for key in warning_dict.keys():\n                warning_dict[key] = np.mean(list(warnings_dict[key] for warnings_dict in warnings_dicts))\n            result[\"warnings\"] = warning_dict\n        else:\n            raise NotImplementedError(\"Sequential mode has not been implemented yet\")\n\n        benchmark_time = perf_counter() - start_time\n        self.benchmark_times.append(benchmark_time)\n        print(f\"Time taken: {round(benchmark_time, 3)} seconds, mean: {round(np.mean(self.benchmark_times), 3)}\")\n\n        grandmean, times = get_grandmedian_and_times(MNE_values, invalid_value, min_valid_iterations)\n        result[\"times\"] = times\n        result[\"time\"] = grandmean\n        print(f\"Grandmean over kernels: {grandmean}, mean MNE per iteration: {np.mean(times)}, std MNE per iteration: {np.std(times)}\")\n        return result\n\n        start_time = perf_counter()\n        if self.parallel_mode:\n            num_procs = max(cpu_count() - 1, 1)\n            logging.debug(f\"Running benchmark in parallel on {num_procs} processors\")\n            manager = Manager()\n            MRE_values = manager.list()\n            runtimes = manager.list()\n            with get_context('spawn').Pool(num_procs) as pool:    # spawn alternative is forkserver, creates a reusable server\n                args = func, args, self.params\n                MRE_values, runtimes = zip(*pool.starmap(run_kernel_and_observers, zip(iterator, repeat(args))))\n                MRE_values, runtimes = list(MRE_values), list(runtimes)\n                print(MRE_values)\n            result[\"times\"] = values\n            result[\"strategy_time\"] = np.mean(runtimes)\n            np_results = np.array(values)\n        else:\n            # sequential implementation\n            np_results = np.array([])\n            for iter in iterator:\n                for obs in self.observers:\n                    obs.before_start()\n                value = self.run_kernel(func, args)\n                for obs in self.observers:\n                    obs.after_finish()\n\n                if value < 0.0:\n                    raise ValueError(\"Invalid benchmark result\")\n\n                result[\"times\"].append(value)\n                np_results = np.append(np_results, value)\n                if value >= invalid_value and iter >= min_valid_iterations and len(np_results[np_results < invalid_value]) < min_valid_iterations:\n                    break\n\n            # fill up the remaining iters with invalid in case of a break\n            result[\"times\"] += [invalid_value] * (self.iterations - len(result[\"times\"]))\n\n            # finish by instrumenting the results with the observers\n            for obs in self.observers:\n                result.update(obs.get_results())\n\n        benchmark_time = perf_counter() - start_time\n        self.benchmark_times.append(benchmark_time)\n        print(f\"Time taken: {round(benchmark_time, 3)} seconds, mean: {round(np.mean(self.benchmark_times), 3)}\")\n\n        # calculate the mean of the means of the Mean Relative Error over the valid results\n        valid_results = np_results[np_results < invalid_value]\n        mean_mean_MRE = np.mean(valid_results) if len(valid_results) > 0 else np.nan\n\n        # write the 'time' to the results and return\n        if np.isnan(mean_mean_MRE) or len(valid_results) < min_valid_iterations:\n            mean_mean_MRE = invalid_value\n        result[\"time\"] = mean_mean_MRE\n        return result\n\n    def run_kernel(self, func, args):\n        \"\"\"runs the kernel once, returns whatever the kernel returns\n\n        :param func: A C function compiled for this specific configuration\n        :type func: ctypes._FuncPtr\n\n        :param args: A list of arguments to the function, order should match the\n            order in the code. The list should be prepared using\n            ready_argument_list().\n        :type args: list(Argument)\n\n        :param threads: Ignored, but left as argument for now to have the same\n            interface as CudaFunctions and OpenCLFunctions.\n        :type threads: any\n\n        :param grid: Ignored, but left as argument for now to have the same\n            interface as CudaFunctions and OpenCLFunctions.\n        :type grid: any\n\n        :returns: A robust average of values returned by the C function.\n        :rtype: float\n        \"\"\"\n        logging.debug(\"run_kernel\")\n        logging.debug(\"arguments=\" + str([str(arg) for arg in args]))\n\n        time = func(*args, **self.params)\n\n        return time\n\n    units = {}\n\n\ndef run_kernel_and_observers(iter, args) -> Tuple[list, float, dict]:\n    \"\"\" Function to run a kernel directly for parallel processing. Must be outside the class to avoid pickling issues due to large scope. \"\"\"\n    PID = getpid()\n    print(f\"Iter {iter+1}, PID {PID}\", flush=True)\n    func, funcargs, params, invalid_flag = args\n    logging.debug(f\"run_kernel as subprocess {iter} (PID {PID})\")\n    logging.debug(\"arguments=\" + str([str(arg) for arg in funcargs]))\n\n    # run the kernel\n    starttime = perf_counter()\n    values, warning_dict = func(invalid_flag, *funcargs, **params)\n    runtime = perf_counter() - starttime\n    return values, runtime, warning_dict\n\n\ndef run_kernel_as_subprocess(iter, args):\n    \"\"\" Function to run a kernel as a subprocess for parallel processing. Must be outside the class to avoid pickling issues due to large scope. Significantly slower than run_kernel, but guaranteed to be a different process. Observers are not implemented.\"\"\"\n    func, args, params = args\n    PID = getpid()\n    # print(f\"Iter {iter}, PID {PID}\", flush=True)\n    logging.debug(f\"run_kernel as subprocess {iter} (PID {PID})\")\n    logging.debug(\"arguments=\" + str([str(arg) for arg in args]))\n\n    def make_kwargstrings(**kwargs) -> list:\n        return list(f\"{key}={value}\" for key, value in kwargs.items())\n\n    # Subprocess\n    args += make_kwargstrings(**params)\n    proc = subprocess.run([sys.executable or 'python', str(func.__name__ + '.py')] + args, shell=False, capture_output=True)\n    stderr = f\"subprocess {iter} with PID {PID} errors: {proc.stderr.decode('utf-8')}\" if len(proc.stderr.decode('utf-8')) > 0 else \"\"\n    stdout = f\"subprocess {iter} with PID {PID} output: {proc.stdout.decode('utf-8')}\" if len(proc.stdout.decode('utf-8')) > 0 else \"\"\n\n    if stderr != \"\":\n        logging.debug(stderr)\n        print(stderr)\n    if stdout != \"\":\n        logging.debug(stdout)\n        # print(stdout)\n\n    time = float(stdout.split(\"result_value=\")[1])\n    return time\n\n\ndef get_grandmedian_and_times(MNE_values, invalid_value, min_valid_iterations=1):\n    \"\"\" Get the grandmean (mean of median MNE per kernel) and mean MNE per iteration \"\"\"\n    MNE_values = np.array(MNE_values)\n    median_MNEs = np.array([])\n    valid_MNE_times = list()\n    # get the mean MNE per kernel\n    for i in range(len(MNE_values[0])):\n        MNE_kernel_values = MNE_values[:, i]\n        valid_MNE_mask = (MNE_kernel_values < invalid_value) & (MNE_kernel_values >= 0)\n        valid_MNE_kernel_values = MNE_kernel_values[valid_MNE_mask]\n        if len(valid_MNE_kernel_values) >= min_valid_iterations:\n            # filter outliers by keeping only values that are within two times the Median Absolute Deviation\n            AD = np.abs(valid_MNE_kernel_values - np.median(valid_MNE_kernel_values))\n            MAD = np.median(AD)\n            selected_MNE_kernel_values = valid_MNE_kernel_values[AD < MAD]\n            median_MNEs = np.append(median_MNEs, np.median(selected_MNE_kernel_values))\n        else:\n            median_MNEs = np.append(median_MNEs, invalid_value)\n\n    # get the mean MNE per iteration\n    for i in range(len(MNE_values)):\n        MNE_iteration_values = MNE_values[i]\n        valid_MNE_mask = (MNE_iteration_values < invalid_value) & (MNE_iteration_values >= 0)\n        valid_MNE_iteration_values = MNE_iteration_values[valid_MNE_mask]\n        if len(valid_MNE_iteration_values) > 0:\n            valid_MNE_times.append(np.mean(valid_MNE_iteration_values))\n        else:\n            valid_MNE_times.append(invalid_value)\n\n    # get the grandmean by taking the mean over the median MNE per iteration, invalid if one of the kernels is invalid\n    grandmean_MNE = np.mean(median_MNEs)\n    if np.isnan(grandmean_MNE) or len(median_MNEs[median_MNEs >= invalid_value]) > 0:\n        grandmean_MNE = invalid_value\n    return grandmean_MNE, valid_MNE_times\n", 330], "/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/collections/__init__.py": ["'''This module implements specialized container datatypes providing\nalternatives to Python's general purpose built-in containers, dict,\nlist, set, and tuple.\n\n* namedtuple   factory function for creating tuple subclasses with named fields\n* deque        list-like container with fast appends and pops on either end\n* ChainMap     dict-like class for creating a single view of multiple mappings\n* Counter      dict subclass for counting hashable objects\n* OrderedDict  dict subclass that remembers the order entries were added\n* defaultdict  dict subclass that calls a factory function to supply missing values\n* UserDict     wrapper around dictionary objects for easier dict subclassing\n* UserList     wrapper around list objects for easier list subclassing\n* UserString   wrapper around string objects for easier string subclassing\n\n'''\n\n__all__ = [\n    'ChainMap',\n    'Counter',\n    'OrderedDict',\n    'UserDict',\n    'UserList',\n    'UserString',\n    'defaultdict',\n    'deque',\n    'namedtuple',\n]\n\nimport _collections_abc\nimport heapq as _heapq\nimport sys as _sys\n\nfrom itertools import chain as _chain\nfrom itertools import repeat as _repeat\nfrom itertools import starmap as _starmap\nfrom keyword import iskeyword as _iskeyword\nfrom operator import eq as _eq\nfrom operator import itemgetter as _itemgetter\nfrom reprlib import recursive_repr as _recursive_repr\nfrom _weakref import proxy as _proxy\n\ntry:\n    from _collections import deque\nexcept ImportError:\n    pass\nelse:\n    _collections_abc.MutableSequence.register(deque)\n\ntry:\n    from _collections import defaultdict\nexcept ImportError:\n    pass\n\n\ndef __getattr__(name):\n    # For backwards compatibility, continue to make the collections ABCs\n    # through Python 3.6 available through the collections module.\n    # Note, no new collections ABCs were added in Python 3.7\n    if name in _collections_abc.__all__:\n        obj = getattr(_collections_abc, name)\n        import warnings\n        warnings.warn(\"Using or importing the ABCs from 'collections' instead \"\n                      \"of from 'collections.abc' is deprecated since Python 3.3, \"\n                      \"and in 3.10 it will stop working\",\n                      DeprecationWarning, stacklevel=2)\n        globals()[name] = obj\n        return obj\n    raise AttributeError(f'module {__name__!r} has no attribute {name!r}')\n\n\n################################################################################\n### OrderedDict\n################################################################################\n\nclass _OrderedDictKeysView(_collections_abc.KeysView):\n\n    def __reversed__(self):\n        yield from reversed(self._mapping)\n\nclass _OrderedDictItemsView(_collections_abc.ItemsView):\n\n    def __reversed__(self):\n        for key in reversed(self._mapping):\n            yield (key, self._mapping[key])\n\nclass _OrderedDictValuesView(_collections_abc.ValuesView):\n\n    def __reversed__(self):\n        for key in reversed(self._mapping):\n            yield self._mapping[key]\n\nclass _Link(object):\n    __slots__ = 'prev', 'next', 'key', '__weakref__'\n\nclass OrderedDict(dict):\n    'Dictionary that remembers insertion order'\n    # An inherited dict maps keys to values.\n    # The inherited dict provides __getitem__, __len__, __contains__, and get.\n    # The remaining methods are order-aware.\n    # Big-O running times for all methods are the same as regular dictionaries.\n\n    # The internal self.__map dict maps keys to links in a doubly linked list.\n    # The circular doubly linked list starts and ends with a sentinel element.\n    # The sentinel element never gets deleted (this simplifies the algorithm).\n    # The sentinel is in self.__hardroot with a weakref proxy in self.__root.\n    # The prev links are weakref proxies (to prevent circular references).\n    # Individual links are kept alive by the hard reference in self.__map.\n    # Those hard references disappear when a key is deleted from an OrderedDict.\n\n    def __init__(self, other=(), /, **kwds):\n        '''Initialize an ordered dictionary.  The signature is the same as\n        regular dictionaries.  Keyword argument order is preserved.\n        '''\n        try:\n            self.__root\n        except AttributeError:\n            self.__hardroot = _Link()\n            self.__root = root = _proxy(self.__hardroot)\n            root.prev = root.next = root\n            self.__map = {}\n        self.__update(other, **kwds)\n\n    def __setitem__(self, key, value,\n                    dict_setitem=dict.__setitem__, proxy=_proxy, Link=_Link):\n        'od.__setitem__(i, y) <==> od[i]=y'\n        # Setting a new item creates a new link at the end of the linked list,\n        # and the inherited dictionary is updated with the new key/value pair.\n        if key not in self:\n            self.__map[key] = link = Link()\n            root = self.__root\n            last = root.prev\n            link.prev, link.next, link.key = last, root, key\n            last.next = link\n            root.prev = proxy(link)\n        dict_setitem(self, key, value)\n\n    def __delitem__(self, key, dict_delitem=dict.__delitem__):\n        'od.__delitem__(y) <==> del od[y]'\n        # Deleting an existing item uses self.__map to find the link which gets\n        # removed by updating the links in the predecessor and successor nodes.\n        dict_delitem(self, key)\n        link = self.__map.pop(key)\n        link_prev = link.prev\n        link_next = link.next\n        link_prev.next = link_next\n        link_next.prev = link_prev\n        link.prev = None\n        link.next = None\n\n    def __iter__(self):\n        'od.__iter__() <==> iter(od)'\n        # Traverse the linked list in order.\n        root = self.__root\n        curr = root.next\n        while curr is not root:\n            yield curr.key\n            curr = curr.next\n\n    def __reversed__(self):\n        'od.__reversed__() <==> reversed(od)'\n        # Traverse the linked list in reverse order.\n        root = self.__root\n        curr = root.prev\n        while curr is not root:\n            yield curr.key\n            curr = curr.prev\n\n    def clear(self):\n        'od.clear() -> None.  Remove all items from od.'\n        root = self.__root\n        root.prev = root.next = root\n        self.__map.clear()\n        dict.clear(self)\n\n    def popitem(self, last=True):\n        '''Remove and return a (key, value) pair from the dictionary.\n\n        Pairs are returned in LIFO order if last is true or FIFO order if false.\n        '''\n        if not self:\n            raise KeyError('dictionary is empty')\n        root = self.__root\n        if last:\n            link = root.prev\n            link_prev = link.prev\n            link_prev.next = root\n            root.prev = link_prev\n        else:\n            link = root.next\n            link_next = link.next\n            root.next = link_next\n            link_next.prev = root\n        key = link.key\n        del self.__map[key]\n        value = dict.pop(self, key)\n        return key, value\n\n    def move_to_end(self, key, last=True):\n        '''Move an existing element to the end (or beginning if last is false).\n\n        Raise KeyError if the element does not exist.\n        '''\n        link = self.__map[key]\n        link_prev = link.prev\n        link_next = link.next\n        soft_link = link_next.prev\n        link_prev.next = link_next\n        link_next.prev = link_prev\n        root = self.__root\n        if last:\n            last = root.prev\n            link.prev = last\n            link.next = root\n            root.prev = soft_link\n            last.next = link\n        else:\n            first = root.next\n            link.prev = root\n            link.next = first\n            first.prev = soft_link\n            root.next = link\n\n    def __sizeof__(self):\n        sizeof = _sys.getsizeof\n        n = len(self) + 1                       # number of links including root\n        size = sizeof(self.__dict__)            # instance dictionary\n        size += sizeof(self.__map) * 2          # internal dict and inherited dict\n        size += sizeof(self.__hardroot) * n     # link objects\n        size += sizeof(self.__root) * n         # proxy objects\n        return size\n\n    update = __update = _collections_abc.MutableMapping.update\n\n    def keys(self):\n        \"D.keys() -> a set-like object providing a view on D's keys\"\n        return _OrderedDictKeysView(self)\n\n    def items(self):\n        \"D.items() -> a set-like object providing a view on D's items\"\n        return _OrderedDictItemsView(self)\n\n    def values(self):\n        \"D.values() -> an object providing a view on D's values\"\n        return _OrderedDictValuesView(self)\n\n    __ne__ = _collections_abc.MutableMapping.__ne__\n\n    __marker = object()\n\n    def pop(self, key, default=__marker):\n        '''od.pop(k[,d]) -> v, remove specified key and return the corresponding\n        value.  If key is not found, d is returned if given, otherwise KeyError\n        is raised.\n\n        '''\n        if key in self:\n            result = self[key]\n            del self[key]\n            return result\n        if default is self.__marker:\n            raise KeyError(key)\n        return default\n\n    def setdefault(self, key, default=None):\n        '''Insert key with a value of default if key is not in the dictionary.\n\n        Return the value for key if key is in the dictionary, else default.\n        '''\n        if key in self:\n            return self[key]\n        self[key] = default\n        return default\n\n    @_recursive_repr()\n    def __repr__(self):\n        'od.__repr__() <==> repr(od)'\n        if not self:\n            return '%s()' % (self.__class__.__name__,)\n        return '%s(%r)' % (self.__class__.__name__, list(self.items()))\n\n    def __reduce__(self):\n        'Return state information for pickling'\n        inst_dict = vars(self).copy()\n        for k in vars(OrderedDict()):\n            inst_dict.pop(k, None)\n        return self.__class__, (), inst_dict or None, None, iter(self.items())\n\n    def copy(self):\n        'od.copy() -> a shallow copy of od'\n        return self.__class__(self)\n\n    @classmethod\n    def fromkeys(cls, iterable, value=None):\n        '''Create a new ordered dictionary with keys from iterable and values set to value.\n        '''\n        self = cls()\n        for key in iterable:\n            self[key] = value\n        return self\n\n    def __eq__(self, other):\n        '''od.__eq__(y) <==> od==y.  Comparison to another OD is order-sensitive\n        while comparison to a regular mapping is order-insensitive.\n\n        '''\n        if isinstance(other, OrderedDict):\n            return dict.__eq__(self, other) and all(map(_eq, self, other))\n        return dict.__eq__(self, other)\n\n    def __ior__(self, other):\n        self.update(other)\n        return self\n\n    def __or__(self, other):\n        if not isinstance(other, dict):\n            return NotImplemented\n        new = self.__class__(self)\n        new.update(other)\n        return new\n\n    def __ror__(self, other):\n        if not isinstance(other, dict):\n            return NotImplemented\n        new = self.__class__(other)\n        new.update(self)\n        return new\n\n\ntry:\n    from _collections import OrderedDict\nexcept ImportError:\n    # Leave the pure Python version in place.\n    pass\n\n\n################################################################################\n### namedtuple\n################################################################################\n\ntry:\n    from _collections import _tuplegetter\nexcept ImportError:\n    _tuplegetter = lambda index, doc: property(_itemgetter(index), doc=doc)\n\ndef namedtuple(typename, field_names, *, rename=False, defaults=None, module=None):\n    \"\"\"Returns a new subclass of tuple with named fields.\n\n    >>> Point = namedtuple('Point', ['x', 'y'])\n    >>> Point.__doc__                   # docstring for the new class\n    'Point(x, y)'\n    >>> p = Point(11, y=22)             # instantiate with positional args or keywords\n    >>> p[0] + p[1]                     # indexable like a plain tuple\n    33\n    >>> x, y = p                        # unpack like a regular tuple\n    >>> x, y\n    (11, 22)\n    >>> p.x + p.y                       # fields also accessible by name\n    33\n    >>> d = p._asdict()                 # convert to a dictionary\n    >>> d['x']\n    11\n    >>> Point(**d)                      # convert from a dictionary\n    Point(x=11, y=22)\n    >>> p._replace(x=100)               # _replace() is like str.replace() but targets named fields\n    Point(x=100, y=22)\n\n    \"\"\"\n\n    # Validate the field names.  At the user's option, either generate an error\n    # message or automatically replace the field name with a valid name.\n    if isinstance(field_names, str):\n        field_names = field_names.replace(',', ' ').split()\n    field_names = list(map(str, field_names))\n    typename = _sys.intern(str(typename))\n\n    if rename:\n        seen = set()\n        for index, name in enumerate(field_names):\n            if (not name.isidentifier()\n                or _iskeyword(name)\n                or name.startswith('_')\n                or name in seen):\n                field_names[index] = f'_{index}'\n            seen.add(name)\n\n    for name in [typename] + field_names:\n        if type(name) is not str:\n            raise TypeError('Type names and field names must be strings')\n        if not name.isidentifier():\n            raise ValueError('Type names and field names must be valid '\n                             f'identifiers: {name!r}')\n        if _iskeyword(name):\n            raise ValueError('Type names and field names cannot be a '\n                             f'keyword: {name!r}')\n\n    seen = set()\n    for name in field_names:\n        if name.startswith('_') and not rename:\n            raise ValueError('Field names cannot start with an underscore: '\n                             f'{name!r}')\n        if name in seen:\n            raise ValueError(f'Encountered duplicate field name: {name!r}')\n        seen.add(name)\n\n    field_defaults = {}\n    if defaults is not None:\n        defaults = tuple(defaults)\n        if len(defaults) > len(field_names):\n            raise TypeError('Got more default values than field names')\n        field_defaults = dict(reversed(list(zip(reversed(field_names),\n                                                reversed(defaults)))))\n\n    # Variables used in the methods and docstrings\n    field_names = tuple(map(_sys.intern, field_names))\n    num_fields = len(field_names)\n    arg_list = ', '.join(field_names)\n    if num_fields == 1:\n        arg_list += ','\n    repr_fmt = '(' + ', '.join(f'{name}=%r' for name in field_names) + ')'\n    tuple_new = tuple.__new__\n    _dict, _tuple, _len, _map, _zip = dict, tuple, len, map, zip\n\n    # Create all the named tuple methods to be added to the class namespace\n\n    namespace = {\n        '_tuple_new': tuple_new,\n        '__builtins__': {},\n        '__name__': f'namedtuple_{typename}',\n    }\n    code = f'lambda _cls, {arg_list}: _tuple_new(_cls, ({arg_list}))'\n    __new__ = eval(code, namespace)\n    __new__.__name__ = '__new__'\n    __new__.__doc__ = f'Create new instance of {typename}({arg_list})'\n    if defaults is not None:\n        __new__.__defaults__ = defaults\n\n    @classmethod\n    def _make(cls, iterable):\n        result = tuple_new(cls, iterable)\n        if _len(result) != num_fields:\n            raise TypeError(f'Expected {num_fields} arguments, got {len(result)}')\n        return result\n\n    _make.__func__.__doc__ = (f'Make a new {typename} object from a sequence '\n                              'or iterable')\n\n    def _replace(self, /, **kwds):\n        result = self._make(_map(kwds.pop, field_names, self))\n        if kwds:\n            raise ValueError(f'Got unexpected field names: {list(kwds)!r}')\n        return result\n\n    _replace.__doc__ = (f'Return a new {typename} object replacing specified '\n                        'fields with new values')\n\n    def __repr__(self):\n        'Return a nicely formatted representation string'\n        return self.__class__.__name__ + repr_fmt % self\n\n    def _asdict(self):\n        'Return a new dict which maps field names to their values.'\n        return _dict(_zip(self._fields, self))\n\n    def __getnewargs__(self):\n        'Return self as a plain tuple.  Used by copy and pickle.'\n        return _tuple(self)\n\n    # Modify function metadata to help with introspection and debugging\n    for method in (\n        __new__,\n        _make.__func__,\n        _replace,\n        __repr__,\n        _asdict,\n        __getnewargs__,\n    ):\n        method.__qualname__ = f'{typename}.{method.__name__}'\n\n    # Build-up the class namespace dictionary\n    # and use type() to build the result class\n    class_namespace = {\n        '__doc__': f'{typename}({arg_list})',\n        '__slots__': (),\n        '_fields': field_names,\n        '_field_defaults': field_defaults,\n        '__new__': __new__,\n        '_make': _make,\n        '_replace': _replace,\n        '__repr__': __repr__,\n        '_asdict': _asdict,\n        '__getnewargs__': __getnewargs__,\n    }\n    for index, name in enumerate(field_names):\n        doc = _sys.intern(f'Alias for field number {index}')\n        class_namespace[name] = _tuplegetter(index, doc)\n\n    result = type(typename, (tuple,), class_namespace)\n\n    # For pickling to work, the __module__ variable needs to be set to the frame\n    # where the named tuple is created.  Bypass this step in environments where\n    # sys._getframe is not defined (Jython for example) or sys._getframe is not\n    # defined for arguments greater than 0 (IronPython), or where the user has\n    # specified a particular module.\n    if module is None:\n        try:\n            module = _sys._getframe(1).f_globals.get('__name__', '__main__')\n        except (AttributeError, ValueError):\n            pass\n    if module is not None:\n        result.__module__ = module\n\n    return result\n\n\n########################################################################\n###  Counter\n########################################################################\n\ndef _count_elements(mapping, iterable):\n    'Tally elements from the iterable.'\n    mapping_get = mapping.get\n    for elem in iterable:\n        mapping[elem] = mapping_get(elem, 0) + 1\n\ntry:                                    # Load C helper function if available\n    from _collections import _count_elements\nexcept ImportError:\n    pass\n\nclass Counter(dict):\n    '''Dict subclass for counting hashable items.  Sometimes called a bag\n    or multiset.  Elements are stored as dictionary keys and their counts\n    are stored as dictionary values.\n\n    >>> c = Counter('abcdeabcdabcaba')  # count elements from a string\n\n    >>> c.most_common(3)                # three most common elements\n    [('a', 5), ('b', 4), ('c', 3)]\n    >>> sorted(c)                       # list all unique elements\n    ['a', 'b', 'c', 'd', 'e']\n    >>> ''.join(sorted(c.elements()))   # list elements with repetitions\n    'aaaaabbbbcccdde'\n    >>> sum(c.values())                 # total of all counts\n    15\n\n    >>> c['a']                          # count of letter 'a'\n    5\n    >>> for elem in 'shazam':           # update counts from an iterable\n    ...     c[elem] += 1                # by adding 1 to each element's count\n    >>> c['a']                          # now there are seven 'a'\n    7\n    >>> del c['b']                      # remove all 'b'\n    >>> c['b']                          # now there are zero 'b'\n    0\n\n    >>> d = Counter('simsalabim')       # make another counter\n    >>> c.update(d)                     # add in the second counter\n    >>> c['a']                          # now there are nine 'a'\n    9\n\n    >>> c.clear()                       # empty the counter\n    >>> c\n    Counter()\n\n    Note:  If a count is set to zero or reduced to zero, it will remain\n    in the counter until the entry is deleted or the counter is cleared:\n\n    >>> c = Counter('aaabbc')\n    >>> c['b'] -= 2                     # reduce the count of 'b' by two\n    >>> c.most_common()                 # 'b' is still in, but its count is zero\n    [('a', 3), ('c', 1), ('b', 0)]\n\n    '''\n    # References:\n    #   http://en.wikipedia.org/wiki/Multiset\n    #   http://www.gnu.org/software/smalltalk/manual-base/html_node/Bag.html\n    #   http://www.demo2s.com/Tutorial/Cpp/0380__set-multiset/Catalog0380__set-multiset.htm\n    #   http://code.activestate.com/recipes/259174/\n    #   Knuth, TAOCP Vol. II section 4.6.3\n\n    def __init__(self, iterable=None, /, **kwds):\n        '''Create a new, empty Counter object.  And if given, count elements\n        from an input iterable.  Or, initialize the count from another mapping\n        of elements to their counts.\n\n        >>> c = Counter()                           # a new, empty counter\n        >>> c = Counter('gallahad')                 # a new counter from an iterable\n        >>> c = Counter({'a': 4, 'b': 2})           # a new counter from a mapping\n        >>> c = Counter(a=4, b=2)                   # a new counter from keyword args\n\n        '''\n        super().__init__()\n        self.update(iterable, **kwds)\n\n    def __missing__(self, key):\n        'The count of elements not in the Counter is zero.'\n        # Needed so that self[missing_item] does not raise KeyError\n        return 0\n\n    def most_common(self, n=None):\n        '''List the n most common elements and their counts from the most\n        common to the least.  If n is None, then list all element counts.\n\n        >>> Counter('abracadabra').most_common(3)\n        [('a', 5), ('b', 2), ('r', 2)]\n\n        '''\n        # Emulate Bag.sortedByCount from Smalltalk\n        if n is None:\n            return sorted(self.items(), key=_itemgetter(1), reverse=True)\n        return _heapq.nlargest(n, self.items(), key=_itemgetter(1))\n\n    def elements(self):\n        '''Iterator over elements repeating each as many times as its count.\n\n        >>> c = Counter('ABCABC')\n        >>> sorted(c.elements())\n        ['A', 'A', 'B', 'B', 'C', 'C']\n\n        # Knuth's example for prime factors of 1836:  2**2 * 3**3 * 17**1\n        >>> prime_factors = Counter({2: 2, 3: 3, 17: 1})\n        >>> product = 1\n        >>> for factor in prime_factors.elements():     # loop over factors\n        ...     product *= factor                       # and multiply them\n        >>> product\n        1836\n\n        Note, if an element's count has been set to zero or is a negative\n        number, elements() will ignore it.\n\n        '''\n        # Emulate Bag.do from Smalltalk and Multiset.begin from C++.\n        return _chain.from_iterable(_starmap(_repeat, self.items()))\n\n    # Override dict methods where necessary\n\n    @classmethod\n    def fromkeys(cls, iterable, v=None):\n        # There is no equivalent method for counters because the semantics\n        # would be ambiguous in cases such as Counter.fromkeys('aaabbc', v=2).\n        # Initializing counters to zero values isn't necessary because zero\n        # is already the default value for counter lookups.  Initializing\n        # to one is easily accomplished with Counter(set(iterable)).  For\n        # more exotic cases, create a dictionary first using a dictionary\n        # comprehension or dict.fromkeys().\n        raise NotImplementedError(\n            'Counter.fromkeys() is undefined.  Use Counter(iterable) instead.')\n\n    def update(self, iterable=None, /, **kwds):\n        '''Like dict.update() but add counts instead of replacing them.\n\n        Source can be an iterable, a dictionary, or another Counter instance.\n\n        >>> c = Counter('which')\n        >>> c.update('witch')           # add elements from another iterable\n        >>> d = Counter('watch')\n        >>> c.update(d)                 # add elements from another counter\n        >>> c['h']                      # four 'h' in which, witch, and watch\n        4\n\n        '''\n        # The regular dict.update() operation makes no sense here because the\n        # replace behavior results in the some of original untouched counts\n        # being mixed-in with all of the other counts for a mismash that\n        # doesn't have a straight-forward interpretation in most counting\n        # contexts.  Instead, we implement straight-addition.  Both the inputs\n        # and outputs are allowed to contain zero and negative counts.\n\n        if iterable is not None:\n            if isinstance(iterable, _collections_abc.Mapping):\n                if self:\n                    self_get = self.get\n                    for elem, count in iterable.items():\n                        self[elem] = count + self_get(elem, 0)\n                else:\n                    # fast path when counter is empty\n                    super().update(iterable)\n            else:\n                _count_elements(self, iterable)\n        if kwds:\n            self.update(kwds)\n\n    def subtract(self, iterable=None, /, **kwds):\n        '''Like dict.update() but subtracts counts instead of replacing them.\n        Counts can be reduced below zero.  Both the inputs and outputs are\n        allowed to contain zero and negative counts.\n\n        Source can be an iterable, a dictionary, or another Counter instance.\n\n        >>> c = Counter('which')\n        >>> c.subtract('witch')             # subtract elements from another iterable\n        >>> c.subtract(Counter('watch'))    # subtract elements from another counter\n        >>> c['h']                          # 2 in which, minus 1 in witch, minus 1 in watch\n        0\n        >>> c['w']                          # 1 in which, minus 1 in witch, minus 1 in watch\n        -1\n\n        '''\n        if iterable is not None:\n            self_get = self.get\n            if isinstance(iterable, _collections_abc.Mapping):\n                for elem, count in iterable.items():\n                    self[elem] = self_get(elem, 0) - count\n            else:\n                for elem in iterable:\n                    self[elem] = self_get(elem, 0) - 1\n        if kwds:\n            self.subtract(kwds)\n\n    def copy(self):\n        'Return a shallow copy.'\n        return self.__class__(self)\n\n    def __reduce__(self):\n        return self.__class__, (dict(self),)\n\n    def __delitem__(self, elem):\n        'Like dict.__delitem__() but does not raise KeyError for missing values.'\n        if elem in self:\n            super().__delitem__(elem)\n\n    def __repr__(self):\n        if not self:\n            return f'{self.__class__.__name__}()'\n        try:\n            # dict() preserves the ordering returned by most_common()\n            d = dict(self.most_common())\n        except TypeError:\n            # handle case where values are not orderable\n            d = dict(self)\n        return f'{self.__class__.__name__}({d!r})'\n\n    # Multiset-style mathematical operations discussed in:\n    #       Knuth TAOCP Volume II section 4.6.3 exercise 19\n    #       and at http://en.wikipedia.org/wiki/Multiset\n    #\n    # Outputs guaranteed to only include positive counts.\n    #\n    # To strip negative and zero counts, add-in an empty counter:\n    #       c += Counter()\n    #\n    # Rich comparison operators for multiset subset and superset tests\n    # are deliberately omitted due to semantic conflicts with the\n    # existing inherited dict equality method.  Subset and superset\n    # semantics ignore zero counts and require that p\u2264q \u2227 p\u2265q \u2192 p=q;\n    # however, that would not be the case for p=Counter(a=1, b=0)\n    # and q=Counter(a=1) where the dictionaries are not equal.\n\n    def __add__(self, other):\n        '''Add counts from two counters.\n\n        >>> Counter('abbb') + Counter('bcc')\n        Counter({'b': 4, 'c': 2, 'a': 1})\n\n        '''\n        if not isinstance(other, Counter):\n            return NotImplemented\n        result = Counter()\n        for elem, count in self.items():\n            newcount = count + other[elem]\n            if newcount > 0:\n                result[elem] = newcount\n        for elem, count in other.items():\n            if elem not in self and count > 0:\n                result[elem] = count\n        return result\n\n    def __sub__(self, other):\n        ''' Subtract count, but keep only results with positive counts.\n\n        >>> Counter('abbbc') - Counter('bccd')\n        Counter({'b': 2, 'a': 1})\n\n        '''\n        if not isinstance(other, Counter):\n            return NotImplemented\n        result = Counter()\n        for elem, count in self.items():\n            newcount = count - other[elem]\n            if newcount > 0:\n                result[elem] = newcount\n        for elem, count in other.items():\n            if elem not in self and count < 0:\n                result[elem] = 0 - count\n        return result\n\n    def __or__(self, other):\n        '''Union is the maximum of value in either of the input counters.\n\n        >>> Counter('abbb') | Counter('bcc')\n        Counter({'b': 3, 'c': 2, 'a': 1})\n\n        '''\n        if not isinstance(other, Counter):\n            return NotImplemented\n        result = Counter()\n        for elem, count in self.items():\n            other_count = other[elem]\n            newcount = other_count if count < other_count else count\n            if newcount > 0:\n                result[elem] = newcount\n        for elem, count in other.items():\n            if elem not in self and count > 0:\n                result[elem] = count\n        return result\n\n    def __and__(self, other):\n        ''' Intersection is the minimum of corresponding counts.\n\n        >>> Counter('abbb') & Counter('bcc')\n        Counter({'b': 1})\n\n        '''\n        if not isinstance(other, Counter):\n            return NotImplemented\n        result = Counter()\n        for elem, count in self.items():\n            other_count = other[elem]\n            newcount = count if count < other_count else other_count\n            if newcount > 0:\n                result[elem] = newcount\n        return result\n\n    def __pos__(self):\n        'Adds an empty counter, effectively stripping negative and zero counts'\n        result = Counter()\n        for elem, count in self.items():\n            if count > 0:\n                result[elem] = count\n        return result\n\n    def __neg__(self):\n        '''Subtracts from an empty counter.  Strips positive and zero counts,\n        and flips the sign on negative counts.\n\n        '''\n        result = Counter()\n        for elem, count in self.items():\n            if count < 0:\n                result[elem] = 0 - count\n        return result\n\n    def _keep_positive(self):\n        '''Internal method to strip elements with a negative or zero count'''\n        nonpositive = [elem for elem, count in self.items() if not count > 0]\n        for elem in nonpositive:\n            del self[elem]\n        return self\n\n    def __iadd__(self, other):\n        '''Inplace add from another counter, keeping only positive counts.\n\n        >>> c = Counter('abbb')\n        >>> c += Counter('bcc')\n        >>> c\n        Counter({'b': 4, 'c': 2, 'a': 1})\n\n        '''\n        for elem, count in other.items():\n            self[elem] += count\n        return self._keep_positive()\n\n    def __isub__(self, other):\n        '''Inplace subtract counter, but keep only results with positive counts.\n\n        >>> c = Counter('abbbc')\n        >>> c -= Counter('bccd')\n        >>> c\n        Counter({'b': 2, 'a': 1})\n\n        '''\n        for elem, count in other.items():\n            self[elem] -= count\n        return self._keep_positive()\n\n    def __ior__(self, other):\n        '''Inplace union is the maximum of value from either counter.\n\n        >>> c = Counter('abbb')\n        >>> c |= Counter('bcc')\n        >>> c\n        Counter({'b': 3, 'c': 2, 'a': 1})\n\n        '''\n        for elem, other_count in other.items():\n            count = self[elem]\n            if other_count > count:\n                self[elem] = other_count\n        return self._keep_positive()\n\n    def __iand__(self, other):\n        '''Inplace intersection is the minimum of corresponding counts.\n\n        >>> c = Counter('abbb')\n        >>> c &= Counter('bcc')\n        >>> c\n        Counter({'b': 1})\n\n        '''\n        for elem, count in self.items():\n            other_count = other[elem]\n            if other_count < count:\n                self[elem] = other_count\n        return self._keep_positive()\n\n\n########################################################################\n###  ChainMap\n########################################################################\n\nclass ChainMap(_collections_abc.MutableMapping):\n    ''' A ChainMap groups multiple dicts (or other mappings) together\n    to create a single, updateable view.\n\n    The underlying mappings are stored in a list.  That list is public and can\n    be accessed or updated using the *maps* attribute.  There is no other\n    state.\n\n    Lookups search the underlying mappings successively until a key is found.\n    In contrast, writes, updates, and deletions only operate on the first\n    mapping.\n\n    '''\n\n    def __init__(self, *maps):\n        '''Initialize a ChainMap by setting *maps* to the given mappings.\n        If no mappings are provided, a single empty dictionary is used.\n\n        '''\n        self.maps = list(maps) or [{}]          # always at least one map\n\n    def __missing__(self, key):\n        raise KeyError(key)\n\n    def __getitem__(self, key):\n        for mapping in self.maps:\n            try:\n                return mapping[key]             # can't use 'key in mapping' with defaultdict\n            except KeyError:\n                pass\n        return self.__missing__(key)            # support subclasses that define __missing__\n\n    def get(self, key, default=None):\n        return self[key] if key in self else default\n\n    def __len__(self):\n        return len(set().union(*self.maps))     # reuses stored hash values if possible\n\n    def __iter__(self):\n        d = {}\n        for mapping in reversed(self.maps):\n            d.update(dict.fromkeys(mapping))    # reuses stored hash values if possible\n        return iter(d)\n\n    def __contains__(self, key):\n        return any(key in m for m in self.maps)\n\n    def __bool__(self):\n        return any(self.maps)\n\n    @_recursive_repr()\n    def __repr__(self):\n        return f'{self.__class__.__name__}({\", \".join(map(repr, self.maps))})'\n\n    @classmethod\n    def fromkeys(cls, iterable, *args):\n        'Create a ChainMap with a single dict created from the iterable.'\n        return cls(dict.fromkeys(iterable, *args))\n\n    def copy(self):\n        'New ChainMap or subclass with a new copy of maps[0] and refs to maps[1:]'\n        return self.__class__(self.maps[0].copy(), *self.maps[1:])\n\n    __copy__ = copy\n\n    def new_child(self, m=None):                # like Django's Context.push()\n        '''New ChainMap with a new map followed by all previous maps.\n        If no map is provided, an empty dict is used.\n        '''\n        if m is None:\n            m = {}\n        return self.__class__(m, *self.maps)\n\n    @property\n    def parents(self):                          # like Django's Context.pop()\n        'New ChainMap from maps[1:].'\n        return self.__class__(*self.maps[1:])\n\n    def __setitem__(self, key, value):\n        self.maps[0][key] = value\n\n    def __delitem__(self, key):\n        try:\n            del self.maps[0][key]\n        except KeyError:\n            raise KeyError(f'Key not found in the first mapping: {key!r}')\n\n    def popitem(self):\n        'Remove and return an item pair from maps[0]. Raise KeyError is maps[0] is empty.'\n        try:\n            return self.maps[0].popitem()\n        except KeyError:\n            raise KeyError('No keys found in the first mapping.')\n\n    def pop(self, key, *args):\n        'Remove *key* from maps[0] and return its value. Raise KeyError if *key* not in maps[0].'\n        try:\n            return self.maps[0].pop(key, *args)\n        except KeyError:\n            raise KeyError(f'Key not found in the first mapping: {key!r}')\n\n    def clear(self):\n        'Clear maps[0], leaving maps[1:] intact.'\n        self.maps[0].clear()\n\n    def __ior__(self, other):\n        self.maps[0].update(other)\n        return self\n\n    def __or__(self, other):\n        if not isinstance(other, _collections_abc.Mapping):\n            return NotImplemented\n        m = self.copy()\n        m.maps[0].update(other)\n        return m\n\n    def __ror__(self, other):\n        if not isinstance(other, _collections_abc.Mapping):\n            return NotImplemented\n        m = dict(other)\n        for child in reversed(self.maps):\n            m.update(child)\n        return self.__class__(m)\n\n\n################################################################################\n### UserDict\n################################################################################\n\nclass UserDict(_collections_abc.MutableMapping):\n\n    # Start by filling-out the abstract methods\n    def __init__(self, dict=None, /, **kwargs):\n        self.data = {}\n        if dict is not None:\n            self.update(dict)\n        if kwargs:\n            self.update(kwargs)\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, key):\n        if key in self.data:\n            return self.data[key]\n        if hasattr(self.__class__, \"__missing__\"):\n            return self.__class__.__missing__(self, key)\n        raise KeyError(key)\n\n    def __setitem__(self, key, item):\n        self.data[key] = item\n\n    def __delitem__(self, key):\n        del self.data[key]\n\n    def __iter__(self):\n        return iter(self.data)\n\n    # Modify __contains__ to work correctly when __missing__ is present\n    def __contains__(self, key):\n        return key in self.data\n\n    # Now, add the methods in dicts but not in MutableMapping\n    def __repr__(self):\n        return repr(self.data)\n\n    def __or__(self, other):\n        if isinstance(other, UserDict):\n            return self.__class__(self.data | other.data)\n        if isinstance(other, dict):\n            return self.__class__(self.data | other)\n        return NotImplemented\n\n    def __ror__(self, other):\n        if isinstance(other, UserDict):\n            return self.__class__(other.data | self.data)\n        if isinstance(other, dict):\n            return self.__class__(other | self.data)\n        return NotImplemented\n\n    def __ior__(self, other):\n        if isinstance(other, UserDict):\n            self.data |= other.data\n        else:\n            self.data |= other\n        return self\n\n    def __copy__(self):\n        inst = self.__class__.__new__(self.__class__)\n        inst.__dict__.update(self.__dict__)\n        # Create a copy and avoid triggering descriptors\n        inst.__dict__[\"data\"] = self.__dict__[\"data\"].copy()\n        return inst\n\n    def copy(self):\n        if self.__class__ is UserDict:\n            return UserDict(self.data.copy())\n        import copy\n        data = self.data\n        try:\n            self.data = {}\n            c = copy.copy(self)\n        finally:\n            self.data = data\n        c.update(self)\n        return c\n\n    @classmethod\n    def fromkeys(cls, iterable, value=None):\n        d = cls()\n        for key in iterable:\n            d[key] = value\n        return d\n\n\n################################################################################\n### UserList\n################################################################################\n\nclass UserList(_collections_abc.MutableSequence):\n    \"\"\"A more or less complete user-defined wrapper around list objects.\"\"\"\n\n    def __init__(self, initlist=None):\n        self.data = []\n        if initlist is not None:\n            # XXX should this accept an arbitrary sequence?\n            if type(initlist) == type(self.data):\n                self.data[:] = initlist\n            elif isinstance(initlist, UserList):\n                self.data[:] = initlist.data[:]\n            else:\n                self.data = list(initlist)\n\n    def __repr__(self):\n        return repr(self.data)\n\n    def __lt__(self, other):\n        return self.data < self.__cast(other)\n\n    def __le__(self, other):\n        return self.data <= self.__cast(other)\n\n    def __eq__(self, other):\n        return self.data == self.__cast(other)\n\n    def __gt__(self, other):\n        return self.data > self.__cast(other)\n\n    def __ge__(self, other):\n        return self.data >= self.__cast(other)\n\n    def __cast(self, other):\n        return other.data if isinstance(other, UserList) else other\n\n    def __contains__(self, item):\n        return item in self.data\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, i):\n        if isinstance(i, slice):\n            return self.__class__(self.data[i])\n        else:\n            return self.data[i]\n\n    def __setitem__(self, i, item):\n        self.data[i] = item\n\n    def __delitem__(self, i):\n        del self.data[i]\n\n    def __add__(self, other):\n        if isinstance(other, UserList):\n            return self.__class__(self.data + other.data)\n        elif isinstance(other, type(self.data)):\n            return self.__class__(self.data + other)\n        return self.__class__(self.data + list(other))\n\n    def __radd__(self, other):\n        if isinstance(other, UserList):\n            return self.__class__(other.data + self.data)\n        elif isinstance(other, type(self.data)):\n            return self.__class__(other + self.data)\n        return self.__class__(list(other) + self.data)\n\n    def __iadd__(self, other):\n        if isinstance(other, UserList):\n            self.data += other.data\n        elif isinstance(other, type(self.data)):\n            self.data += other\n        else:\n            self.data += list(other)\n        return self\n\n    def __mul__(self, n):\n        return self.__class__(self.data * n)\n\n    __rmul__ = __mul__\n\n    def __imul__(self, n):\n        self.data *= n\n        return self\n\n    def __copy__(self):\n        inst = self.__class__.__new__(self.__class__)\n        inst.__dict__.update(self.__dict__)\n        # Create a copy and avoid triggering descriptors\n        inst.__dict__[\"data\"] = self.__dict__[\"data\"][:]\n        return inst\n\n    def append(self, item):\n        self.data.append(item)\n\n    def insert(self, i, item):\n        self.data.insert(i, item)\n\n    def pop(self, i=-1):\n        return self.data.pop(i)\n\n    def remove(self, item):\n        self.data.remove(item)\n\n    def clear(self):\n        self.data.clear()\n\n    def copy(self):\n        return self.__class__(self)\n\n    def count(self, item):\n        return self.data.count(item)\n\n    def index(self, item, *args):\n        return self.data.index(item, *args)\n\n    def reverse(self):\n        self.data.reverse()\n\n    def sort(self, /, *args, **kwds):\n        self.data.sort(*args, **kwds)\n\n    def extend(self, other):\n        if isinstance(other, UserList):\n            self.data.extend(other.data)\n        else:\n            self.data.extend(other)\n\n\n################################################################################\n### UserString\n################################################################################\n\nclass UserString(_collections_abc.Sequence):\n\n    def __init__(self, seq):\n        if isinstance(seq, str):\n            self.data = seq\n        elif isinstance(seq, UserString):\n            self.data = seq.data[:]\n        else:\n            self.data = str(seq)\n\n    def __str__(self):\n        return str(self.data)\n\n    def __repr__(self):\n        return repr(self.data)\n\n    def __int__(self):\n        return int(self.data)\n\n    def __float__(self):\n        return float(self.data)\n\n    def __complex__(self):\n        return complex(self.data)\n\n    def __hash__(self):\n        return hash(self.data)\n\n    def __getnewargs__(self):\n        return (self.data[:],)\n\n    def __eq__(self, string):\n        if isinstance(string, UserString):\n            return self.data == string.data\n        return self.data == string\n\n    def __lt__(self, string):\n        if isinstance(string, UserString):\n            return self.data < string.data\n        return self.data < string\n\n    def __le__(self, string):\n        if isinstance(string, UserString):\n            return self.data <= string.data\n        return self.data <= string\n\n    def __gt__(self, string):\n        if isinstance(string, UserString):\n            return self.data > string.data\n        return self.data > string\n\n    def __ge__(self, string):\n        if isinstance(string, UserString):\n            return self.data >= string.data\n        return self.data >= string\n\n    def __contains__(self, char):\n        if isinstance(char, UserString):\n            char = char.data\n        return char in self.data\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        return self.__class__(self.data[index])\n\n    def __add__(self, other):\n        if isinstance(other, UserString):\n            return self.__class__(self.data + other.data)\n        elif isinstance(other, str):\n            return self.__class__(self.data + other)\n        return self.__class__(self.data + str(other))\n\n    def __radd__(self, other):\n        if isinstance(other, str):\n            return self.__class__(other + self.data)\n        return self.__class__(str(other) + self.data)\n\n    def __mul__(self, n):\n        return self.__class__(self.data * n)\n\n    __rmul__ = __mul__\n\n    def __mod__(self, args):\n        return self.__class__(self.data % args)\n\n    def __rmod__(self, template):\n        return self.__class__(str(template) % self)\n\n    # the following methods are defined in alphabetical order:\n    def capitalize(self):\n        return self.__class__(self.data.capitalize())\n\n    def casefold(self):\n        return self.__class__(self.data.casefold())\n\n    def center(self, width, *args):\n        return self.__class__(self.data.center(width, *args))\n\n    def count(self, sub, start=0, end=_sys.maxsize):\n        if isinstance(sub, UserString):\n            sub = sub.data\n        return self.data.count(sub, start, end)\n\n    def removeprefix(self, prefix, /):\n        if isinstance(prefix, UserString):\n            prefix = prefix.data\n        return self.__class__(self.data.removeprefix(prefix))\n\n    def removesuffix(self, suffix, /):\n        if isinstance(suffix, UserString):\n            suffix = suffix.data\n        return self.__class__(self.data.removesuffix(suffix))\n\n    def encode(self, encoding='utf-8', errors='strict'):\n        encoding = 'utf-8' if encoding is None else encoding\n        errors = 'strict' if errors is None else errors\n        return self.data.encode(encoding, errors)\n\n    def endswith(self, suffix, start=0, end=_sys.maxsize):\n        return self.data.endswith(suffix, start, end)\n\n    def expandtabs(self, tabsize=8):\n        return self.__class__(self.data.expandtabs(tabsize))\n\n    def find(self, sub, start=0, end=_sys.maxsize):\n        if isinstance(sub, UserString):\n            sub = sub.data\n        return self.data.find(sub, start, end)\n\n    def format(self, /, *args, **kwds):\n        return self.data.format(*args, **kwds)\n\n    def format_map(self, mapping):\n        return self.data.format_map(mapping)\n\n    def index(self, sub, start=0, end=_sys.maxsize):\n        return self.data.index(sub, start, end)\n\n    def isalpha(self):\n        return self.data.isalpha()\n\n    def isalnum(self):\n        return self.data.isalnum()\n\n    def isascii(self):\n        return self.data.isascii()\n\n    def isdecimal(self):\n        return self.data.isdecimal()\n\n    def isdigit(self):\n        return self.data.isdigit()\n\n    def isidentifier(self):\n        return self.data.isidentifier()\n\n    def islower(self):\n        return self.data.islower()\n\n    def isnumeric(self):\n        return self.data.isnumeric()\n\n    def isprintable(self):\n        return self.data.isprintable()\n\n    def isspace(self):\n        return self.data.isspace()\n\n    def istitle(self):\n        return self.data.istitle()\n\n    def isupper(self):\n        return self.data.isupper()\n\n    def join(self, seq):\n        return self.data.join(seq)\n\n    def ljust(self, width, *args):\n        return self.__class__(self.data.ljust(width, *args))\n\n    def lower(self):\n        return self.__class__(self.data.lower())\n\n    def lstrip(self, chars=None):\n        return self.__class__(self.data.lstrip(chars))\n\n    maketrans = str.maketrans\n\n    def partition(self, sep):\n        return self.data.partition(sep)\n\n    def replace(self, old, new, maxsplit=-1):\n        if isinstance(old, UserString):\n            old = old.data\n        if isinstance(new, UserString):\n            new = new.data\n        return self.__class__(self.data.replace(old, new, maxsplit))\n\n    def rfind(self, sub, start=0, end=_sys.maxsize):\n        if isinstance(sub, UserString):\n            sub = sub.data\n        return self.data.rfind(sub, start, end)\n\n    def rindex(self, sub, start=0, end=_sys.maxsize):\n        return self.data.rindex(sub, start, end)\n\n    def rjust(self, width, *args):\n        return self.__class__(self.data.rjust(width, *args))\n\n    def rpartition(self, sep):\n        return self.data.rpartition(sep)\n\n    def rstrip(self, chars=None):\n        return self.__class__(self.data.rstrip(chars))\n\n    def split(self, sep=None, maxsplit=-1):\n        return self.data.split(sep, maxsplit)\n\n    def rsplit(self, sep=None, maxsplit=-1):\n        return self.data.rsplit(sep, maxsplit)\n\n    def splitlines(self, keepends=False):\n        return self.data.splitlines(keepends)\n\n    def startswith(self, prefix, start=0, end=_sys.maxsize):\n        return self.data.startswith(prefix, start, end)\n\n    def strip(self, chars=None):\n        return self.__class__(self.data.strip(chars))\n\n    def swapcase(self):\n        return self.__class__(self.data.swapcase())\n\n    def title(self):\n        return self.__class__(self.data.title())\n\n    def translate(self, *args):\n        return self.__class__(self.data.translate(*args))\n\n    def upper(self):\n        return self.__class__(self.data.upper())\n\n    def zfill(self, width):\n        return self.__class__(self.data.zfill(width))\n", 1508], "/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/core.py": ["\"\"\" Module for grouping the core functionality needed by most runners \"\"\"\nfrom __future__ import print_function\n\nimport re\nfrom collections import namedtuple\nimport resource\nimport logging\nimport numpy as np\n\ntry:\n    import cupy as cp\nexcept ImportError:\n    cp = np\n\nfrom kernel_tuner.cupy import CupyFunctions\nfrom kernel_tuner.cuda import CudaFunctions\nfrom kernel_tuner.opencl import OpenCLFunctions\nfrom kernel_tuner.c import CFunctions\nfrom kernel_tuner.python import PythonFunctions\nfrom kernel_tuner.nvml import NVMLObserver\nimport kernel_tuner.util as util\n\ntry:\n    import torch\nexcept ImportError:\n    torch = util.TorchPlaceHolder()\n\n_KernelInstance = namedtuple(\"_KernelInstance\", [\"name\", \"kernel_source\", \"kernel_string\", \"temp_files\", \"threads\", \"grid\", \"params\", \"arguments\"])\n\n\nclass KernelInstance(_KernelInstance):\n    \"\"\"Class that represents the specific parameterized instance of a kernel\"\"\"\n\n    def delete_temp_files(self):\n        \"\"\"Delete any generated temp files\"\"\"\n        for v in self.temp_files.values():\n            util.delete_temp_file(v)\n\n    def prepare_temp_files_for_error_msg(self):\n        \"\"\"Prepare temp file with source code, and return list of temp file names\"\"\"\n        temp_filename = util.get_temp_filename(suffix=self.kernel_source.get_suffix())\n        util.write_file(temp_filename, self.kernel_string)\n        ret = [temp_filename]\n        ret.extend(self.temp_files.values())\n        return ret\n\n\nclass KernelSource(object):\n    \"\"\"Class that holds the kernel sources.\n\n    There is a primary kernel source, which can be either a source string,\n    a filename (indicating a file containing the kernel source code),\n    or a callable (generating the kernel source code).\n    There can additionally be (one or multiple) secondary kernel sources, which\n    must be filenames.\n    \"\"\"\n\n    def __init__(self, kernel_name, kernel_sources, lang):\n        if not isinstance(kernel_sources, list):\n            kernel_sources = [kernel_sources]\n        self.kernel_sources = kernel_sources\n        self.kernel_name = kernel_name\n        if lang is None:\n            if callable(self.kernel_sources[0]):\n                raise TypeError(\"Please specify language when using a code generator function\")\n            kernel_string = self.get_kernel_string(0)\n            lang = util.detect_language(kernel_string)\n\n        # The validity of lang is checked later, when creating the DeviceInterface\n        self.lang = lang\n\n    def get_kernel_string(self, index=0, params=None):\n        \"\"\" retrieve the kernel source with the given index and return as a string\n\n        See util.get_kernel_string() for details.\n\n        :param index: Index of the kernel source in the list of sources.\n        :type index: int\n\n        :param params: Dictionary containing the tunable parameters for this specific\n            kernel instance, only needed when kernel_source is a generator.\n        :type param: dict\n\n        :returns: A string containing the kernel code.\n        :rtype: string\n        \"\"\"\n        #logging.debug('get_kernel_string called with %s', str(kernel_source))\n        logging.debug('get_kernel_string called')\n\n        kernel_source = self.kernel_sources[index]\n        return util.get_kernel_string(kernel_source, params)\n\n    def prepare_list_of_files(self, kernel_name, params, grid, threads, block_size_names):\n        \"\"\" prepare the kernel string along with any additional files\n\n        The first file in the list is allowed to include or read in the others\n        The files beyond the first are considered additional files that may also contain tunable parameters\n\n        For each file beyond the first this function creates a temporary file with\n        preprocessors statements inserted. Occurences of the original filenames in the\n        first file are replaced with their temporary counterparts.\n\n        :param kernel_name: A string specifying the kernel name.\n        :type kernel_name: string\n\n        :param params: A dictionary with the tunable parameters for this particular\n            instance.\n        :type params: dict()\n\n        :param grid: The grid dimensions for this instance. The grid dimensions are\n            also inserted into the code as if they are tunable parameters for\n            convenience.\n        :type grid: tuple()\n\n        :param threads: The thread block dimensions for this instance. The thread block are\n            also inserted into the code as if they are tunable parameters for\n            convenience.\n        :type threads: tuple()\n\n        :param block_size_names: A list of strings that denote the names\n            for the thread block dimensions.\n        :type block_size_names: list(string)\n\n        \"\"\"\n        temp_files = dict()\n\n        for i, f in enumerate(self.kernel_sources):\n            if i > 0 and not util.looks_like_a_filename(f):\n                raise ValueError('When passing multiple kernel sources, the secondary entries must be filenames')\n\n            ks = self.get_kernel_string(i, params)\n            # add preprocessor statements\n            n, ks = util.prepare_kernel_string(kernel_name, ks, params, grid, threads, block_size_names, self.lang)\n\n            if i == 0:\n                # primary kernel source\n                name = n\n                kernel_string = ks\n                continue\n\n            # save secondary kernel sources to temporary files\n\n            # generate temp filename with the same extension\n            temp_file = util.get_temp_filename(suffix=\".\" + f.split(\".\")[-1])\n            temp_files[f] = temp_file\n            util.write_file(temp_file, ks)\n            # replace occurences of the additional file's name in the first kernel_string with the name of the temp file\n            kernel_string = kernel_string.replace(f, temp_file)\n\n        return name, kernel_string, temp_files\n\n    def get_user_suffix(self, index=0):\n        \"\"\" Get the suffix of the kernel filename, if the user specified one. Return None otherwise.\n        \"\"\"\n        if util.looks_like_a_filename(self.kernel_sources[index]) and (\".\" in self.kernel_sources[index]):\n            return \".\" + self.kernel_sources[index].split(\".\")[-1]\n        return None\n\n    def get_suffix(self, index=0):\n        \"\"\" Return a suitable suffix for a kernel filename.\n\n        This uses the user-specified suffix if available, or one based on the\n        lang/backend otherwise.\n        \"\"\"\n\n        # TODO: Consider delegating this to the backend\n        suffix = self.get_user_suffix(index)\n        if suffix is not None:\n            return suffix\n\n        _suffixes = {\n            'CUDA': '.cu',\n            'OpenCL': '.cl',\n            'C': '.c',\n            'Python': '.py'\n        }\n        try:\n            return _suffixes[self.lang]\n        except KeyError:\n            return \".c\"\n\n    def check_argument_lists(self, kernel_name, arguments):\n        \"\"\" Check if the kernel arguments have the correct types\n\n        This is done by calling util.check_argument_list on each kernel string.\n        \"\"\"\n        for i, f in enumerate(self.kernel_sources):\n            if not callable(f):\n                util.check_argument_list(kernel_name, self.get_kernel_string(i), arguments)\n            else:\n                logging.debug(\"Checking of arguments list not supported yet for code generators.\")\n\n\nclass DeviceInterface(object):\n    \"\"\"Class that offers a High-Level Device Interface to the rest of the Kernel Tuner\"\"\"\n\n    def __init__(self, kernel_source, device=0, platform=0, quiet=False, compiler=None, compiler_options=None, iterations=7, observers=None,\n                 parallel_mode=False):\n        \"\"\" Instantiate the DeviceInterface, based on language in kernel source\n\n        :param kernel_source The kernel sources\n        :type kernel_source: kernel_tuner.core.KernelSource\n\n        :param device: CUDA/OpenCL device to use, in case you have multiple\n            CUDA-capable GPUs or OpenCL devices you may use this to select one,\n            0 by default. Ignored if you are tuning host code by passing lang=\"C\".\n        :type device: int\n\n        :param platform: OpenCL platform to use, in case you have multiple\n            OpenCL platforms you may use this to select one,\n            0 by default. Ignored if not using OpenCL.\n        :type device: int\n\n        :param lang: Specifies the language used for GPU kernels.\n            Currently supported: \"CUDA\", \"OpenCL\", or \"C\"\n        :type lang: string\n\n        :param compiler_options: The compiler options to use when compiling kernels for this device.\n        :type compiler_options: list of strings\n\n        :param iterations: Number of iterations to be used when benchmarking using this device.\n        :type iterations: int\n\n        :param times: Return the execution time of all iterations.\n        :type times: bool\n\n        \"\"\"\n        lang = kernel_source.lang\n\n        logging.debug('DeviceInterface instantiated, lang=%s', lang)\n\n        if parallel_mode and lang != \"Python\":\n            raise NotImplementedError(\"Parallel mode has not been implemented for languages other than Python\")\n\n        if lang == \"CUDA\":\n            dev = CudaFunctions(device, compiler_options=compiler_options, iterations=iterations, observers=observers)\n        elif lang.upper() == \"CUPY\":\n            dev = CupyFunctions(device, compiler_options=compiler_options, iterations=iterations, observers=observers)\n        elif lang == \"OpenCL\":\n            dev = OpenCLFunctions(device, platform, compiler_options=compiler_options, iterations=iterations, observers=observers)\n        elif lang == \"C\":\n            dev = CFunctions(compiler=compiler, compiler_options=compiler_options, iterations=iterations)\n        elif lang == \"Python\":\n            dev = PythonFunctions(iterations=iterations, observers=observers, parallel_mode=parallel_mode, show_progressbar=True)\n        else:\n            raise ValueError(\"Sorry, support for languages other than CUDA, OpenCL, or C is not implemented yet\")\n\n        #look for NVMLObserver in observers, if present, enable special tunable parameters through nvml\n        self.use_nvml = False\n        if observers:\n            for obs in observers:\n                if isinstance(obs, NVMLObserver):\n                    self.nvml = obs.nvml\n                    self.use_nvml = True\n\n        self.lang = lang\n        self.dev = dev\n        self.units = dev.units\n        self.name = dev.name\n        self.max_threads = dev.max_threads\n        if not quiet:\n            print(\"Using: \" + self.dev.name)\n\n        dev.__enter__()\n\n    def __enter__(self):\n        return self\n\n    def benchmark(self, func, gpu_args, instance, verbose):\n        \"\"\"benchmark the kernel instance\"\"\"\n        logging.debug('benchmark ' + instance.name)\n        logging.debug('thread block dimensions x,y,z=%d,%d,%d', *instance.threads)\n        logging.debug('grid dimensions x,y,z=%d,%d,%d', *instance.grid)\n\n        if self.use_nvml:\n            if \"nvml_pwr_limit\" in instance.params:\n                new_limit = int(instance.params[\"nvml_pwr_limit\"] * 1000)    #user specifies in Watt, but nvml uses milliWatt\n                if self.nvml.pwr_limit != new_limit:\n                    self.nvml.pwr_limit = new_limit\n            if \"nvml_gr_clock\" in instance.params:\n                self.nvml.gr_clock = instance.params[\"nvml_gr_clock\"]\n            if \"nvml_sm_clock\" in instance.params:\n                self.nvml.sm_clock = instance.params[\"nvml_sm_clock\"]\n            if \"nvml_mem_clock\" in instance.params:\n                self.nvml.mem_clock = instance.params[\"nvml_mem_clock\"]\n\n        result = None\n        try:\n            result = self.dev.benchmark(func, gpu_args, instance.threads, instance.grid)\n        except Exception as e:\n            #some launches may fail because too many registers are required\n            #to run the kernel given the current thread block size\n            #the desired behavior is to simply skip over this configuration\n            #and proceed to try the next one\n            skippable_exceptions = [\"too many resources requested for launch\", \"OUT_OF_RESOURCES\", \"INVALID_WORK_GROUP_SIZE\"]\n            if any([skip_str in str(e) for skip_str in skippable_exceptions]):\n                logging.debug('benchmark fails due to runtime failure too many resources required')\n                if verbose:\n                    print(f\"skipping config {util.get_instance_string(instance.params)} reason: too many resources requested for launch\")\n            else:\n                logging.debug('benchmark encountered runtime failure: ' + str(e))\n                print(\"Error while benchmarking:\", instance.name)\n                raise e\n        return result\n\n    def check_kernel_output(self, func, gpu_args, instance, answer, atol, verify, verbose):\n        \"\"\"runs the kernel once and checks the result against answer\"\"\"\n        logging.debug('check_kernel_output')\n\n        #if not using custom verify function, check if the length is the same\n        if not verify and len(instance.arguments) != len(answer):\n            raise TypeError(\"The length of argument list and provided results do not match.\")\n\n        #re-copy original contents of output arguments to GPU memory, to overwrite any changes\n        #by earlier kernel runs\n        for i, arg in enumerate(instance.arguments):\n            if (verify or answer[i] is not None) and isinstance(arg, (np.ndarray, cp.ndarray, torch.Tensor)):\n                self.dev.memcpy_htod(gpu_args[i], arg)\n\n        #run the kernel\n        check = self.run_kernel(func, gpu_args, instance)\n        if not check:\n            return True    #runtime failure occured that should be ignored, skip correctness check\n\n        #retrieve gpu results to host memory\n        result_host = []\n        for i, arg in enumerate(instance.arguments):\n            if (verify or answer[i] is not None) and isinstance(arg, (np.ndarray, cp.ndarray)):\n                result_host.append(np.zeros_like(arg))\n                self.dev.memcpy_dtoh(result_host[-1], gpu_args[i])\n            elif isinstance(arg, torch.Tensor) and isinstance(answer[i], torch.Tensor):\n                if not answer[i].is_cuda:\n                    #if the answer is on the host, copy gpu output to host as well\n                    result_host.append(torch.zeros_like(answer[i]))\n                    self.dev.memcpy_dtoh(result_host[-1], gpu_args[i].tensor)\n                else:\n                    result_host.append(gpu_args[i].tensor)\n            else:\n                result_host.append(None)\n\n        #if the user has specified a custom verify function, then call it, else use default based on numpy allclose\n        if verify:\n            correct = verify(answer, result_host, atol=atol)\n        else:\n            correct = _default_verify_function(instance, answer, result_host, atol, verbose)\n\n        if not correct:\n            raise RuntimeError(\"Kernel result verification failed for: \" + util.get_config_string(instance.params))\n        return True\n\n    def compile_and_benchmark(self, kernel_source, gpu_args, params, kernel_options, tuning_options):\n        \"\"\" Compile and benchmark a kernel instance based on kernel strings and parameters \"\"\"\n\n        instance_string = util.get_instance_string(params)\n\n        logging.debug('compile_and_benchmark ' + instance_string)\n        mem_usage = round(resource.getrusage(resource.RUSAGE_SELF).ru_maxrss / 1024.0, 1)\n        logging.debug('Memory usage : %2.2f MB', mem_usage)\n\n        verbose = tuning_options.verbose\n\n        instance = self.create_kernel_instance(kernel_source, kernel_options, params, verbose)\n        if instance is None:\n            return None\n\n        try:\n            #compile the kernel\n            func = self.compile_kernel(instance, verbose)\n            if func is None:\n                return None\n\n            #add shared memory arguments to compiled module\n            if kernel_options.smem_args is not None:\n                self.dev.copy_shared_memory_args(util.get_smem_args(kernel_options.smem_args, params))\n            #add constant memory arguments to compiled module\n            if kernel_options.cmem_args is not None:\n                self.dev.copy_constant_memory_args(kernel_options.cmem_args)\n            #add texture memory arguments to compiled module\n            if kernel_options.texmem_args is not None:\n                self.dev.copy_texture_memory_args(kernel_options.texmem_args)\n\n            #test kernel for correctness and benchmark\n            if tuning_options.answer is not None or tuning_options.verify is not None:\n                self.check_kernel_output(func, gpu_args, instance, tuning_options.answer, tuning_options.atol, tuning_options.verify, verbose)\n\n            #benchmark\n            result = self.benchmark(func, gpu_args, instance, verbose)\n\n        except Exception as e:\n            #dump kernel_string to temp file\n            temp_filenames = instance.prepare_temp_files_for_error_msg()\n            print(\"Error while compiling or benchmarking, see source files: \" + \" \".join(temp_filenames))\n            raise e\n\n        #clean up any temporary files, if no error occured\n        instance.delete_temp_files()\n\n        return result\n\n    def compile_kernel(self, instance, verbose):\n        \"\"\"compile the kernel for this specific instance\"\"\"\n        logging.debug('compile_kernel ' + instance.name)\n\n        #compile kernel_string into device func\n        func = None\n        try:\n            func = self.dev.compile(instance)\n        except Exception as e:\n            #compiles may fail because certain kernel configurations use too\n            #much shared memory for example, the desired behavior is to simply\n            #skip over this configuration and try the next one\n            shared_mem_error_messages = [\"uses too much shared data\", \"local memory limit exceeded\"]\n            if any(msg in str(e) for msg in shared_mem_error_messages):\n                logging.debug('compile_kernel failed due to kernel using too much shared memory')\n                if verbose:\n                    print(f\"skipping config {util.get_instance_string(instance.params)} reason: too much shared memory used\")\n            else:\n                logging.debug('compile_kernel failed due to error: ' + str(e))\n                print(\"Error while compiling:\", instance.name)\n                raise e\n        return func\n\n    def copy_shared_memory_args(self, smem_args):\n        \"\"\"adds shared memory arguments to the most recently compiled module, if using CUDA\"\"\"\n        if self.lang == \"CUDA\":\n            self.dev.copy_shared_memory_args(smem_args)\n        else:\n            raise RuntimeError(\"Error cannot copy shared memory arguments when language is not CUDA\")\n\n    def copy_constant_memory_args(self, cmem_args):\n        \"\"\"adds constant memory arguments to the most recently compiled module, if using CUDA\"\"\"\n        if self.lang == \"CUDA\":\n            self.dev.copy_constant_memory_args(cmem_args)\n        else:\n            raise RuntimeError(\"Error cannot copy constant memory arguments when language is not CUDA\")\n\n    def copy_texture_memory_args(self, texmem_args):\n        \"\"\"adds texture memory arguments to the most recently compiled module, if using CUDA\"\"\"\n        if self.lang == \"CUDA\":\n            self.dev.copy_texture_memory_args(texmem_args)\n        else:\n            raise RuntimeError(\"Error cannot copy texture memory arguments when language is not CUDA\")\n\n    def create_kernel_instance(self, kernel_source, kernel_options, params, verbose):\n        \"\"\"create kernel instance from kernel source, parameters, problem size, grid divisors, and so on\"\"\"\n        grid_div = (kernel_options.grid_div_x, kernel_options.grid_div_y, kernel_options.grid_div_z)\n\n        #insert default block_size_names if needed\n        if not kernel_options.block_size_names:\n            kernel_options.block_size_names = util.default_block_size_names\n\n        #setup thread block and grid dimensions\n        threads, grid = util.setup_block_and_grid(kernel_options.problem_size, grid_div, params, kernel_options.block_size_names)\n        if np.prod(threads) > self.dev.max_threads:\n            if verbose:\n                print(f\"skipping config {util.get_instance_string(params)} reason: too many threads per block\")\n            return None\n\n        #obtain the kernel_string and prepare additional files, if any\n        name, kernel_string, temp_files = kernel_source.prepare_list_of_files(kernel_options.kernel_name, params, grid, threads,\n                                                                              kernel_options.block_size_names)\n\n        #check for templated kernel\n        if kernel_source.lang == \"CUDA\" and \"<\" in name and \">\" in name:\n            kernel_string, name = wrap_templated_kernel(kernel_string, name)\n\n        #collect everything we know about this instance and return it\n        return KernelInstance(name, kernel_source, kernel_string, temp_files, threads, grid, params, kernel_options.arguments)\n\n    def get_environment(self):\n        \"\"\"Return dictionary with information about the environment\"\"\"\n        return self.dev.env\n\n    def memcpy_dtoh(self, dest, src):\n        \"\"\"perform a device to host memory copy\"\"\"\n        self.dev.memcpy_dtoh(dest, src)\n\n    def ready_argument_list(self, arguments):\n        \"\"\"ready argument list to be passed to the kernel, allocates gpu mem if necessary\"\"\"\n        return self.dev.ready_argument_list(arguments)\n\n    def run_kernel(self, func, gpu_args, instance):\n        \"\"\" Run a compiled kernel instance on a device \"\"\"\n        logging.debug('run_kernel %s', instance.name)\n        logging.debug('thread block dims (%d, %d, %d)', *instance.threads)\n        logging.debug('grid dims (%d, %d, %d)', *instance.grid)\n\n        try:\n            self.dev.run_kernel(func, gpu_args, instance.threads, instance.grid)\n        except Exception as e:\n            if \"too many resources requested for launch\" in str(e) or \"OUT_OF_RESOURCES\" in str(e):\n                logging.debug('ignoring runtime failure due to too many resources required')\n                return False\n            else:\n                logging.debug('encountered unexpected runtime failure: ' + str(e))\n                raise e\n        return True\n\n    def __exit__(self, *exc):\n        if hasattr(self, 'dev'):\n            self.dev.__exit__(*exc)\n\n\ndef _default_verify_function(instance, answer, result_host, atol, verbose):\n    \"\"\"default verify function based on np.allclose\"\"\"\n\n    #first check if the length is the same\n    if len(instance.arguments) != len(answer):\n        raise TypeError(\"The length of argument list and provided results do not match.\")\n    #for each element in the argument list, check if the types match\n    for i, arg in enumerate(instance.arguments):\n        if answer[i] is not None:    #skip None elements in the answer list\n            if isinstance(answer[i], (np.ndarray, cp.ndarray)) and isinstance(arg, (np.ndarray, cp.ndarray)):\n                if answer[i].dtype != arg.dtype:\n                    raise TypeError(f\"Element {i} of the expected results list is not of the same dtype as the kernel output: \" + str(answer[i].dtype) +\n                                    \" != \" + str(arg.dtype) + \".\")\n                if answer[i].size != arg.size:\n                    raise TypeError(f\"Element {i} of the expected results list has a size different from \" + \"the kernel argument: \" + str(answer[i].size) +\n                                    \" != \" + str(arg.size) + \".\")\n            elif isinstance(answer[i], torch.Tensor) and isinstance(arg, torch.Tensor):\n                if answer[i].dtype != arg.dtype:\n                    raise TypeError(f\"Element {i} of the expected results list is not of the same dtype as the kernel output: \" + str(answer[i].dtype) +\n                                    \" != \" + str(arg.dtype) + \".\")\n                if answer[i].size() != arg.size():\n                    raise TypeError(f\"Element {i} of the expected results list has a size different from \" + \"the kernel argument: \" + str(answer[i].size) +\n                                    \" != \" + str(arg.size) + \".\")\n\n            elif isinstance(answer[i], np.number) and isinstance(arg, np.number):\n                if answer[i].dtype != arg.dtype:\n                    raise TypeError(f\"Element {i} of the expected results list is not the same as the kernel output: \" + str(answer[i].dtype) + \" != \" +\n                                    str(arg.dtype) + \".\")\n            else:\n                #either answer[i] and argument have different types or answer[i] is not a numpy type\n                if not isinstance(answer[i], (np.ndarray, cp.ndarray, torch.Tensor)) or not isinstance(answer[i], np.number):\n                    raise TypeError(f\"Element {i} of expected results list is not a numpy/cupy ndarray, torch Tensor or numpy scalar.\")\n                else:\n                    raise TypeError(f\"Element {i} of expected results list and kernel arguments have different types.\")\n\n    def _ravel(a):\n        if hasattr(a, 'ravel') and len(a.shape) > 1:\n            return a.ravel()\n        return a\n\n    def _flatten(a):\n        if hasattr(a, 'flatten'):\n            return a.flatten()\n        return a\n\n    correct = True\n    for i, arg in enumerate(instance.arguments):\n        expected = answer[i]\n        if expected is not None:\n\n            result = _ravel(result_host[i])\n            expected = _flatten(expected)\n            if any([isinstance(array, cp.ndarray) for array in [expected, result]]):\n                output_test = cp.allclose(expected, result, atol=atol)\n            elif isinstance(expected, torch.Tensor) and isinstance(result, torch.Tensor):\n                output_test = torch.allclose(expected, result, atol=atol)\n            else:\n                output_test = np.allclose(expected, result, atol=atol)\n\n            if not output_test and verbose:\n                print(\"Error: \" + util.get_config_string(instance.params) + \" detected during correctness check\")\n                print(\"this error occured when checking value of the %oth kernel argument\" % (i, ))\n                print(\"Printing kernel output and expected result, set verbose=False to suppress this debug print\")\n                np.set_printoptions(edgeitems=50)\n                print(\"Kernel output:\")\n                print(result)\n                print(\"Expected:\")\n                print(expected)\n            correct = correct and output_test\n\n    if not correct:\n        logging.debug('correctness check has found a correctness issue')\n\n    return correct\n\n\n#these functions facilitate compiling templated kernels with PyCuda\ndef split_argument_list(argument_list):\n    \"\"\"split all arguments in a list into types and names\"\"\"\n    regex = r\"(.*[\\s*]+)(.*)?\"\n    type_list = []\n    name_list = []\n    for arg in argument_list:\n        match = re.match(regex, arg, re.S)\n        if not match:\n            raise ValueError(\"error parsing templated kernel argument list\")\n        type_list.append(re.sub(r\"\\s+\", \" \", match.group(1).strip(), re.S))\n        name_list.append(match.group(2).strip())\n    return type_list, name_list\n\n\ndef apply_template_typenames(type_list, templated_typenames):\n    \"\"\"replace the typename tokens in type_list with their templated typenames\"\"\"\n\n    def replace_typename_token(matchobj):\n        \"\"\"function for a whitespace preserving token regex replace\"\"\"\n        #replace only the match, leaving the whitespace around it as is\n        return matchobj.group(1) + templated_typenames[matchobj.group(2)] + matchobj.group(3)\n\n    for i, arg_type in enumerate(type_list):\n        for k, v in templated_typenames.items():\n            #if the templated typename occurs as a token in the string, meaning that it is enclosed in\n            #beginning of string or whitespace, and end of string, whitespace or star\n            regex = r\"(^|\\s+)(\" + k + r\")($|\\s+|\\*)\"\n            sub = re.sub(regex, replace_typename_token, arg_type, re.S)\n            type_list[i] = sub\n\n\ndef get_templated_typenames(template_parameters, template_arguments):\n    \"\"\"based on the template parameters and arguments, create dict with templated typenames\"\"\"\n    templated_typenames = {}\n    for i, param in enumerate(template_parameters):\n        if \"typename \" in param:\n            typename = param[9:]\n            templated_typenames[typename] = template_arguments[i]\n    return templated_typenames\n\n\ndef wrap_templated_kernel(kernel_string, kernel_name):\n    \"\"\"rewrite kernel_string to insert wrapper function for templated kernel\"\"\"\n    #parse kernel_name to find template_arguments and real kernel name\n    name = kernel_name.split(\"<\")[0]\n    template_arguments = re.search(r\".*?<(.*)>\", kernel_name, re.S).group(1).split(',')\n\n    #parse templated kernel definition\n    #relatively strict regex that does not allow nested template parameters like vector<TF>\n    #within the template parameter list\n    regex = r\"template\\s*<([^>]*?)>\\s*__global__\\s+void\\s+\" + name + r\"\\s*\\((.*?)\\)\\s*\\{\"\n    match = re.search(regex, kernel_string, re.S)\n    if not match:\n        raise ValueError(\"could not find templated kernel definition\")\n\n    template_parameters = match.group(1).split(',')\n    argument_list = match.group(2).split(',')\n    argument_list = [s.strip() for s in argument_list]    #remove extra whitespace around 'type name' strings\n\n    type_list, name_list = split_argument_list(argument_list)\n\n    templated_typenames = get_templated_typenames(template_parameters, template_arguments)\n    apply_template_typenames(type_list, templated_typenames)\n\n    #replace __global__ with __device__ in the templated kernel definition\n    #could do a more precise replace, but __global__ cannot be used elsewhere in the definition\n    definition = match.group(0).replace(\"__global__\", \"__device__\")\n\n    #generate code for the compile-time template instantiation\n    template_instantiation = f\"template __device__ void {kernel_name}(\" + \", \".join(type_list) + \");\\n\"\n\n    #generate code for the wrapper kernel\n    new_arg_list = \", \".join([\" \".join((a, b)) for a, b in zip(type_list, name_list)])\n    wrapper_function = \"\\nextern \\\"C\\\" __global__ void \" + name + \"_wrapper(\" + new_arg_list + \") {\\n  \" + \\\n       kernel_name + \"(\" + \", \".join(name_list) + \");\\n}\\n\"\n\n    #copy kernel_string, replace definition and append template instantiation and wrapper function\n    new_kernel_string = kernel_string[:]\n    new_kernel_string = new_kernel_string.replace(match.group(0), definition)\n    new_kernel_string += \"\\n\" + template_instantiation\n    new_kernel_string += wrapper_function\n\n    return new_kernel_string, name + \"_wrapper\"\n", 663], "/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/runners/__init__.py": ["", 0], "/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/runners/sequential.py": ["\"\"\" The default runner for sequentially tuning the parameter space \"\"\"\nfrom __future__ import print_function\n\nfrom collections import OrderedDict\nimport logging\n\nfrom kernel_tuner.util import get_config_string, store_cache, process_metrics, print_config_output\nfrom kernel_tuner.core import DeviceInterface\n\n\nclass SequentialRunner(object):\n    \"\"\" SequentialRunner is used for tuning with a single process/thread \"\"\"\n\n    def __init__(self, kernel_source, kernel_options, device_options, iterations, observers, parallel_mode=False):\n        \"\"\" Instantiate the SequentialRunner\n\n        :param kernel_source: The kernel source\n        :type kernel_source: kernel_tuner.core.KernelSource\n\n        :param kernel_options: A dictionary with all options for the kernel.\n        :type kernel_options: kernel_tuner.interface.Options\n\n        :param device_options: A dictionary with all options for the device\n            on which the kernel should be tuned.\n        :type device_options: kernel_tuner.interface.Options\n\n        :param iterations: The number of iterations used for benchmarking\n            each kernel instance.\n        :type iterations: int\n        \"\"\"\n\n        #detect language and create high-level device interface\n        self.dev = DeviceInterface(kernel_source, iterations=iterations, observers=observers, parallel_mode=parallel_mode, **device_options).__enter__()\n\n        self.units = self.dev.units\n        self.quiet = device_options.quiet\n        self.kernel_source = kernel_source\n        self.warmed_up = True if kernel_source.lang == 'Python' else False\n        self.simulation_mode = False\n\n        #move data to the GPU\n        self.gpu_args = self.dev.ready_argument_list(kernel_options.arguments)\n\n    def __enter__(self):\n        return self\n\n    def run(self, parameter_space, kernel_options, tuning_options):\n        \"\"\" Iterate through the entire parameter space using a single Python process\n\n        :param parameter_space: The parameter space as an iterable.\n        :type parameter_space: iterable\n\n        :param kernel_options: A dictionary with all options for the kernel.\n        :type kernel_options: kernel_tuner.interface.Options\n\n        :param tuning_options: A dictionary with all options regarding the tuning\n            process.\n        :type tuning_options: kernel_tuner.iterface.Options\n\n        :returns: A list of dictionaries for executed kernel configurations and their\n            execution times. And a dictionary that contains information\n            about the hardware/software environment on which the tuning took place.\n        :rtype: list(dict()), dict()\n\n        \"\"\"\n        logging.debug('sequential runner started for ' + kernel_options.kernel_name)\n\n        results = []\n\n        #iterate over parameter space\n        for element in parameter_space:\n            params = OrderedDict(zip(tuning_options.tune_params.keys(), element))\n\n            #attempt to warmup the GPU by running the first config in the parameter space and ignoring the result\n            if not self.warmed_up:\n                self.dev.compile_and_benchmark(self.kernel_source, self.gpu_args, params, kernel_options, tuning_options)\n                self.warmed_up = True\n\n            #check if element is in the cache\n            x_int = \",\".join([str(i) for i in element])\n            if tuning_options.cache and x_int in tuning_options.cache:\n                results.append(tuning_options.cache[x_int])\n                continue\n\n            result = self.dev.compile_and_benchmark(self.kernel_source, self.gpu_args, params, kernel_options, tuning_options)\n            if result is None:\n                logging.debug('received benchmark result is None, kernel configuration was skipped silently due to compile or runtime failure')\n                params.update({ \"time\": 1e20 })\n                store_cache(x_int, params, tuning_options)\n                continue\n\n            #print and append to results\n            if isinstance(result, dict):\n                time = result[\"time\"]\n            else:\n                time = result\n\n            params['time'] = time\n\n            if isinstance(result, dict):\n                params.update(result)\n\n            if tuning_options.metrics:\n                params = process_metrics(params, tuning_options.metrics)\n\n            # print_config_output(tuning_options.tune_params, params, self.quiet, tuning_options.metrics, self.units) # TODO uncomment\n\n            store_cache(x_int, params, tuning_options)\n            results.append(params)\n\n        return results, self.dev.get_environment()\n\n    def __exit__(self, *exc):\n        if hasattr(self, 'dev'):\n            self.dev.__exit__(*exc)\n", 115], "/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/runners/simulation.py": ["\"\"\" The simulation runner for sequentially tuning the parameter space based on cached data \"\"\"\nfrom __future__ import print_function\n\nfrom collections import OrderedDict\nimport logging\n\nfrom kernel_tuner.util import get_config_string, store_cache, process_metrics, print_config_output, get_instance_string\n\n\nclass SimulationLangFunction(object):\n    \"\"\"Compatibility class for supplying simulated device information based on CudaFunctions\"\"\"\n\n    def __init__(self, lang, device=0, iterations=7, compiler_options=None):\n        self.allocations = []\n        self.texrefs = []\n        self.use_nvml = False\n        self.smem_size = 0\n        cc = \"00\"\n        self.cc = str(cc[0]) + str(cc[1])\n        self.iterations = iterations\n        self.current_module = None\n        self.compiler_options = compiler_options or []\n\n        env = dict()\n        env[\"device_name\"] = \"Simulation\"\n        env[\"iterations\"] = self.iterations\n        env[\"compiler_options\"] = compiler_options\n        env[\"device_properties\"] = None\n        if lang == \"CUDA\":\n            env[\"cuda_version\"] = None\n            env[\"compute_capability\"] = self.cc\n        elif lang == \"OpenCL\":\n            env[\"platform_name\"] = None\n            env[\"platform_version\"] = None\n            env[\"device_version\"] = None\n            env[\"opencl_c_version\"] = None\n            env[\"driver_version\"] = None\n        elif lang == \"C\":\n            self.nvcc_available = False\n            self.max_threads = None\n            self.lib = None\n            self.using_openmp = False\n            env[\"CC Version\"] = None\n        self.env = env\n        self.name = env[\"device_name\"]\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *exc):\n        return\n\n\nclass SimulationDeviceInterface(object):\n    \"\"\"Compatibily class for DeviceInterface that offers a High-Level Device Interface to the rest of the Kernel Tuner\"\"\"\n\n    def __init__(self, kernel_source, device=0, platform=0, quiet=False, compiler=None, compiler_options=None, iterations=7):\n        \"\"\" Instantiate the DeviceInterface, based on language in kernel source\n\n        :param kernel_source The kernel sources\n        :type kernel_source: kernel_tuner.core.KernelSource\n\n        :param device: CUDA/OpenCL device to use, in case you have multiple\n            CUDA-capable GPUs or OpenCL devices you may use this to select one,\n            0 by default. Ignored if you are tuning host code by passing lang=\"C\".\n        :type device: int\n\n        :param platform: OpenCL platform to use, in case you have multiple\n            OpenCL platforms you may use this to select one,\n            0 by default. Ignored if not using OpenCL.\n        :type device: int\n\n        :param lang: Specifies the language used for GPU kernels.\n            Currently supported: \"CUDA\", \"OpenCL\", or \"C\"\n        :type lang: string\n\n        :param compiler_options: The compiler options to use when compiling kernels for this device.\n        :type compiler_options: list of strings\n\n        :param iterations: Number of iterations to be used when benchmarking using this device.\n        :type iterations: int\n\n        :param times: Return the execution time of all iterations.\n        :type times: bool\n\n        \"\"\"\n        lang = kernel_source.lang\n\n        logging.debug('DeviceInterface instantiated, lang=%s', lang)\n\n        if lang not in ('CUDA', 'OpenCL', 'C'):\n            raise ValueError(\"Sorry, support for languages other than CUDA, OpenCL, or C is not implemented yet\")\n        self.lang = lang\n        self.dev = SimulationLangFunction(self.lang, device, iterations, compiler_options)\n        self.max_threads = 1024\n        self.units = None\n        self._name = self.dev.name\n        self.quiet = quiet\n        self.device_access_error = SystemError(\"Device not accessible in simulation mode\")\n\n    @property\n    def name(self):\n        return self._name\n\n    @name.setter\n    def name(self, value):\n        self._name = value\n        if not self.quiet:\n            print(\"Simulating: \" + value)\n\n    def __enter__(self):\n        return self\n\n    def benchmark(self, func, gpu_args, instance, verbose):\n        \"\"\"benchmark the kernel instance\"\"\"\n        logging.debug('benchmark ' + instance.name)\n        logging.debug('thread block dimensions x,y,z=%d,%d,%d', *instance.threads)\n        logging.debug('grid dimensions x,y,z=%d,%d,%d', *instance.grid)\n        raise self.device_access_error\n\n    def check_kernel_output(self, func, gpu_args, instance, answer, atol, verify, verbose):\n        \"\"\"runs the kernel once and checks the result against answer\"\"\"\n        logging.debug('check_kernel_output')\n        raise self.device_access_error\n\n    def compile_and_benchmark(self, kernel_source, gpu_args, params, kernel_options, tuning_options):\n        \"\"\" Compile and benchmark a kernel instance based on kernel strings and parameters \"\"\"\n        instance_string = get_instance_string(params)\n        logging.debug('compile_and_benchmark ' + instance_string)\n        raise self.device_access_error\n\n    def compile_kernel(self, instance, verbose):\n        \"\"\"compile the kernel for this specific instance\"\"\"\n        logging.debug('compile_kernel ' + instance.name)\n        raise self.device_access_error\n\n    def copy_constant_memory_args(self, cmem_args):\n        \"\"\"adds constant memory arguments to the most recently compiled module, if using CUDA\"\"\"\n        raise self.device_access_error\n\n    def copy_texture_memory_args(self, texmem_args):\n        \"\"\"adds texture memory arguments to the most recently compiled module, if using CUDA\"\"\"\n        raise self.device_access_error\n\n    def create_kernel_instance(self, kernel_source, kernel_options, params, verbose):\n        \"\"\"create kernel instance from kernel source, parameters, problem size, grid divisors, and so on\"\"\"\n        raise self.device_access_error\n\n    def get_environment(self):\n        \"\"\"Return dictionary with information about the environment\"\"\"\n        return self.dev.env\n\n    def memcpy_dtoh(self, dest, src):\n        \"\"\"perform a device to host memory copy\"\"\"\n        raise self.device_access_error\n\n    def ready_argument_list(self, arguments):\n        \"\"\"ready argument list to be passed to the kernel, allocates gpu mem if necessary\"\"\"\n        raise self.device_access_error\n\n    def run_kernel(self, func, gpu_args, instance):\n        \"\"\" Run a compiled kernel instance on a device \"\"\"\n        logging.debug('run_kernel %s', instance.name)\n        logging.debug('thread block dims (%d, %d, %d)', *instance.threads)\n        logging.debug('grid dims (%d, %d, %d)', *instance.grid)\n        raise self.device_access_error\n\n    def __exit__(self, *exc):\n        if hasattr(self, 'dev'):\n            self.dev.__exit__(*exc)\n\n\nclass SimulationRunner(object):\n    \"\"\" SimulationRunner is used for tuning with a single process/thread \"\"\"\n\n    def __init__(self, kernel_source, kernel_options, device_options, iterations, observers, parallel_mode=False):\n        \"\"\" Instantiate the SimulationRunner\n\n        :param kernel_source: The kernel source\n        :type kernel_source: kernel_tuner.core.KernelSource\n\n        :param kernel_options: A dictionary with all options for the kernel.\n        :type kernel_options: kernel_tuner.interface.Options\n\n        :param device_options: A dictionary with all options for the device\n            on which the kernel should be tuned.\n        :type device_options: kernel_tuner.interface.Options\n\n        :param iterations: The number of iterations used for benchmarking\n            each kernel instance.\n        :type iterations: int\n        \"\"\"\n\n        # #detect language and create high-level device interface\n        self.dev = SimulationDeviceInterface(kernel_source, iterations=iterations, **device_options).__enter__()\n\n        self.quiet = device_options.quiet\n        self.kernel_source = kernel_source\n\n        self.simulation_mode = True\n\n    def __enter__(self):\n        return self\n\n    def run(self, parameter_space, kernel_options, tuning_options):\n        \"\"\" Iterate through the entire parameter space using a single Python process\n\n        :param parameter_space: The parameter space as an iterable.\n        :type parameter_space: iterable\n\n        :param kernel_options: A dictionary with all options for the kernel.\n        :type kernel_options: kernel_tuner.interface.Options\n\n        :param tuning_options: A dictionary with all options regarding the tuning\n            process.\n        :type tuning_options: kernel_tuner.iterface.Options\n\n        :returns: A list of dictionaries for executed kernel configurations and their\n            execution times. And a dictionary that contains information\n            about the hardware/software environment on which the tuning took place.\n        :rtype: list(dict()), dict()\n\n        \"\"\"\n        logging.debug('simulation runner started for ' + kernel_options.kernel_name)\n\n        results = []\n\n        # iterate over parameter space\n        for element in parameter_space:\n\n            # check if element is in the cache\n            x_int = \",\".join([str(i) for i in element])\n            if tuning_options.cache and x_int in tuning_options.cache:\n                results.append(tuning_options.cache[x_int])\n                continue\n\n            # if the element is not in the cache, raise an error\n            logging.debug('parameter element not in cache')\n            print(element)\n            raise ValueError(\"Parameter element not in cache - in simulation mode, all parameter elements must be present in the cache\")\n\n        return results, self.dev.get_environment()\n\n    def __exit__(self, *exc):\n        if hasattr(self, 'dev'):\n            self.dev.__exit__(*exc)\n", 246], "/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/__init__.py": ["", 0], "/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/brute_force.py": ["\"\"\" The default strategy that iterates through the whole parameter space \"\"\"\nfrom __future__ import print_function\n\nimport itertools\n\nfrom kernel_tuner import util\n\n\ndef tune(runner, kernel_options, device_options, tuning_options):\n    \"\"\" Tune all instances in the parameter space\n\n    :params runner: A runner from kernel_tuner.runners\n    :type runner: kernel_tuner.runner\n\n    :param kernel_options: A dictionary with all options for the kernel.\n    :type kernel_options: kernel_tuner.interface.Options\n\n    :param device_options: A dictionary with all options for the device\n        on which the kernel should be tuned.\n    :type device_options: kernel_tuner.interface.Options\n\n    :param tuning_options: A dictionary with all options regarding the tuning\n        process.\n    :type tuning_options: kernel_tuner.interface.Options\n\n    :returns: A list of dictionaries for executed kernel configurations and their\n        execution times. And a dictionary that contains a information\n        about the hardware/software environment on which the tuning took place.\n    :rtype: list(dict()), dict()\n\n    \"\"\"\n\n    tune_params = tuning_options.tune_params\n    restrictions = tuning_options.restrictions\n    verbose = tuning_options.verbose\n\n    # compute cartesian product of all tunable parameters\n    parameter_space = itertools.product(*tune_params.values())\n\n    # check for search space restrictions\n    if restrictions is not None:\n        parameter_space = filter(lambda p: util.check_restrictions(restrictions, p, tune_params.keys(), verbose), parameter_space)\n\n    results, env = runner.run(parameter_space, kernel_options, tuning_options)\n\n    return results, env\n", 46], "/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/random_sample.py": ["\"\"\" Iterate over a random sample of the parameter space \"\"\"\nfrom __future__ import print_function\n\nimport itertools\nimport numpy\n\nfrom kernel_tuner import util\n\n\ndef tune(runner, kernel_options, device_options, tuning_options):\n    \"\"\" Tune a random sample of sample_fraction fraction in the parameter space\n\n    :params runner: A runner from kernel_tuner.runners\n    :type runner: kernel_tuner.runner\n\n    :param kernel_options: A dictionary with all options for the kernel.\n    :type kernel_options: kernel_tuner.interface.Options\n\n    :param device_options: A dictionary with all options for the device\n        on which the kernel should be tuned.\n    :type device_options: kernel_tuner.interface.Options\n\n    :param tuning_options: A dictionary with all options regarding the tuning\n        process.\n    :type tuning_options: kernel_tuner.interface.Options\n\n    :returns: A list of dictionaries for executed kernel configurations and their\n        execution times. And a dictionary that contains a information\n        about the hardware/software environment on which the tuning took place.\n    :rtype: list(dict()), dict()\n\n    \"\"\"\n\n    tune_params = tuning_options.tune_params\n\n    fraction = tuning_options.strategy_options.get(\"fraction\", 0.1)\n\n    # compute cartesian product of all tunable parameters\n    parameter_space = itertools.product(*tune_params.values())\n\n    # check for search space restrictions\n    if tuning_options.restrictions is not None:\n        parameter_space = filter(lambda p: util.check_restrictions(tuning_options.restrictions, p, tune_params.keys(), tuning_options.verbose), parameter_space)\n\n    # reduce parameter space to a random sample using sample_fraction\n    parameter_space = numpy.array(list(parameter_space))\n    size = len(parameter_space)\n    fraction = int(numpy.ceil(size * fraction))\n    sample_indices = numpy.random.choice(range(size), size=fraction, replace=False)\n    parameter_space = parameter_space[sample_indices]\n\n    # call the runner\n    results, env = runner.run(parameter_space, kernel_options, tuning_options)\n\n    return results, env\n", 55], "/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/diff_evo.py": ["\"\"\" The differential evolution strategy that optimizes the search through the parameter space \"\"\"\nfrom __future__ import print_function\n\nfrom scipy.optimize import differential_evolution\n\nfrom kernel_tuner.strategies.minimize import get_bounds, _cost_func\n\nsupported_methods = [\"best1bin\", \"best1exp\", \"rand1exp\", \"randtobest1exp\",\n                     \"best2exp\", \"rand2exp\", \"randtobest1bin\", \"best2bin\", \"rand2bin\", \"rand1bin\"]\n\n\ndef tune(runner, kernel_options, device_options, tuning_options):\n    \"\"\" Find the best performing kernel configuration in the parameter space\n\n    :params runner: A runner from kernel_tuner.runners\n    :type runner: kernel_tuner.runner\n\n    :param kernel_options: A dictionary with all options for the kernel.\n    :type kernel_options: kernel_tuner.interface.Options\n\n    :param device_options: A dictionary with all options for the device\n        on which the kernel should be tuned.\n    :type device_options: kernel_tuner.interface.Options\n\n    :param tuning_options: A dictionary with all options regarding the tuning\n        process.\n    :type tuning_options: kernel_tuner.interface.Options\n\n    :returns: A list of dictionaries for executed kernel configurations and their\n        execution times. And a dictionary that contains a information\n        about the hardware/software environment on which the tuning took place.\n    :rtype: list(dict()), dict()\n\n    \"\"\"\n\n    results = []\n\n    method = tuning_options.strategy_options.get(\"method\", \"best1bin\")\n\n    tuning_options[\"scaling\"] = False\n    # build a bounds array as needed for the optimizer\n    bounds = get_bounds(tuning_options.tune_params)\n\n    args = (kernel_options, tuning_options, runner, results)\n\n    # call the differential evolution optimizer\n    opt_result = differential_evolution(_cost_func, bounds, args, maxiter=1,\n                                        polish=False, strategy=method, disp=tuning_options.verbose)\n\n    if tuning_options.verbose:\n        print(opt_result.message)\n\n    return results, runner.dev.get_environment()\n\n\n", 55], "/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/basinhopping.py": ["\"\"\" The strategy that uses the basinhopping global optimization method \"\"\"\nfrom __future__ import print_function\n\nimport scipy.optimize\n\nfrom kernel_tuner.strategies.minimize import _cost_func, get_bounds_x0_eps, setup_method_arguments, setup_method_options\n\nsupported_methods = [\"Nelder-Mead\", \"Powell\", \"CG\", \"BFGS\", \"L-BFGS-B\", \"TNC\", \"COBYLA\", \"SLSQP\"]\n\n\ndef tune(runner, kernel_options, device_options, tuning_options):\n    \"\"\" Find the best performing kernel configuration in the parameter space\n\n    :params runner: A runner from kernel_tuner.runners\n    :type runner: kernel_tuner.runner\n\n    :param kernel_options: A dictionary with all options for the kernel.\n    :type kernel_options: dict\n\n    :param device_options: A dictionary with all options for the device\n        on which the kernel should be tuned.\n    :type device_options: dict\n\n    :param tuning_options: A dictionary with all options regarding the tuning\n        process.\n    :type tuning_options: dict\n\n    :returns: A list of dictionaries for executed kernel configurations and their\n        execution times. And a dictionary that contains a information\n        about the hardware/software environment on which the tuning took place.\n    :rtype: list(dict()), dict()\n\n    \"\"\"\n\n    results = []\n\n    method = tuning_options.strategy_options.get(\"method\", \"L-BFGS-B\")\n    T = tuning_options.strategy_options.get(\"T\", 1.0)\n\n    #s cale variables in x to make 'eps' relevant for multiple variables\n    tuning_options[\"scaling\"] = True\n\n    bounds, x0, eps = get_bounds_x0_eps(tuning_options)\n\n    kwargs = setup_method_arguments(method, bounds)\n    options = setup_method_options(method, tuning_options)\n    kwargs['options'] = options\n\n    args = (kernel_options, tuning_options, runner, results)\n\n    minimizer_kwargs = dict(**kwargs)\n    minimizer_kwargs[\"method\"] = method\n    minimizer_kwargs[\"args\"] = args\n\n    opt_result = scipy.optimize.basinhopping(_cost_func, x0, T=T, stepsize=eps,\n                                             minimizer_kwargs=minimizer_kwargs, disp=tuning_options.verbose)\n\n    if tuning_options.verbose:\n        print(opt_result.message)\n\n    return results, runner.dev.get_environment()\n", 61], "/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/genetic_algorithm.py": ["\"\"\" A simple genetic algorithm for parameter search \"\"\"\n\nimport random\nimport numpy as np\n\nfrom kernel_tuner.strategies.minimize import _cost_func\nfrom kernel_tuner import util\n\ndef tune(runner, kernel_options, device_options, tuning_options):\n    \"\"\" Find the best performing kernel configuration in the parameter space\n\n    :params runner: A runner from kernel_tuner.runners\n    :type runner: kernel_tuner.runner\n\n    :param kernel_options: A dictionary with all options for the kernel.\n    :type kernel_options: kernel_tuner.interface.Options\n\n    :param device_options: A dictionary with all options for the device\n        on which the kernel should be tuned.\n    :type device_options: kernel_tuner.interface.Options\n\n    :param tuning_options: A dictionary with all options regarding the tuning\n        process.\n    :type tuning_options: kernel_tuner.interface.Options\n\n    :returns: A list of dictionaries for executed kernel configurations and their\n        execution times. And a dictionary that contains a information\n        about the hardware/software environment on which the tuning took place.\n    :rtype: list(dict()), dict()\n\n    \"\"\"\n\n    options = tuning_options.strategy_options\n    pop_size = options.get(\"popsize\", 20)\n    generations = options.get(\"maxiter\", 50)\n    crossover = supported_methods[options.get(\"method\", \"uniform\")]\n    mutation_chance = options.get(\"mutation_chance\", 10)\n\n    max_fevals = options.get(\"max_fevals\", 100)\n\n    # limit max_fevals to max size of the parameter space\n    max_threads = runner.dev.max_threads\n    max_fevals = min(util.get_number_of_valid_configs(tuning_options, max_threads), max_fevals)\n\n    tuning_options[\"scaling\"] = False\n    tune_params = tuning_options.tune_params\n\n    best_time = 1e20\n    all_results = []\n    unique_results = {}\n\n    population = random_population(pop_size, tune_params, tuning_options, max_threads)\n\n    for generation in range(generations):\n\n        # determine fitness of population members\n        weighted_population = []\n        for dna in population:\n            time = _cost_func(dna, kernel_options, tuning_options, runner, all_results)\n            weighted_population.append((dna, time))\n\n        # population is sorted such that better configs have higher chance of reproducing\n        weighted_population.sort(key=lambda x: x[1])\n\n        # 'best_time' is used only for printing\n        if tuning_options.verbose and all_results:\n            best_time = min(all_results, key=lambda x: x[\"time\"])[\"time\"]\n\n        if tuning_options.verbose:\n            print(\"Generation %d, best_time %f\" % (generation, best_time))\n\n        population = []\n\n        unique_results.update({\",\".join([str(i) for i in dna]): time for dna, time in weighted_population})\n        if len(unique_results) >= max_fevals:\n            break\n\n        # crossover and mutate\n        while len(population) < pop_size:\n            dna1, dna2 = weighted_choice(weighted_population, 2)\n\n            children = crossover(dna1, dna2)\n\n            for child in children:\n                child = mutate(child, tune_params, mutation_chance, tuning_options, max_threads)\n\n                if child not in population and util.config_valid(child, tuning_options, max_threads):\n                    population.append(child)\n\n                if len(population) >= pop_size:\n                    break\n\n        # could combine old + new generation here and do a selection\n\n\n\n\n\n\n\n    return all_results, runner.dev.get_environment()\n\n\ndef weighted_choice(population, n):\n    \"\"\"Randomly select n unique individuals from a weighted population, fitness determines probability of being selected\"\"\"\n\n    def random_index_betavariate(pop_size):\n        # has a higher probability of returning index of item at the head of the list\n        alpha = 1\n        beta = 2.5\n        return int(random.betavariate(alpha, beta) * pop_size)\n\n    def random_index_weighted(pop_size):\n        \"\"\"use weights to increase probability of selection\"\"\"\n        weights = [w for _, w in population]\n        # invert because lower is better\n        inverted_weights = [1.0 / w for w in weights]\n        prefix_sum = np.cumsum(inverted_weights)\n        total_weight = sum(inverted_weights)\n        randf = random.random() * total_weight\n        # return first index of prefix_sum larger than random number\n        return next(i for i, v in enumerate(prefix_sum) if v > randf)\n\n    random_index = random_index_betavariate\n\n    indices = [random_index(len(population)) for _ in range(n)]\n    chosen = []\n    for ind in indices:\n        while ind in chosen:\n            ind = random_index(len(population))\n        chosen.append(ind)\n\n    return [population[ind][0] for ind in chosen]\n\n\ndef random_population(pop_size, tune_params, tuning_options, max_threads):\n    \"\"\"create a random population of pop_size unique members\"\"\"\n    population = []\n    option_space = np.prod([len(v) for v in tune_params.values()])\n    assert pop_size < option_space\n    while len(population) < pop_size:\n        dna = [random.choice(v) for v in tune_params.values()]\n        if not dna in population and util.config_valid(dna, tuning_options, max_threads):\n            population.append(dna)\n    return population\n\n\ndef random_val(index, tune_params):\n    \"\"\"return a random value for a parameter\"\"\"\n    key = list(tune_params.keys())[index]\n    return random.choice(tune_params[key])\n\n\ndef mutate(dna, tune_params, mutation_chance, tuning_options, max_threads):\n    \"\"\"Mutate DNA with 1/mutation_chance chance\"\"\"\n    dna_out = dna[:]\n    if int(random.random() * mutation_chance) == 0:\n        attempts = 20\n        while attempts > 0:\n            #decide which parameter to mutate\n            i = random.choice(range(len(dna)))\n            dna_out = dna[:]\n            dna_out[i] = random_val(i, tune_params)\n\n            if not dna_out == dna and util.config_valid(dna_out, tuning_options, max_threads):\n                return dna_out\n            attempts = attempts - 1\n    return dna\n\n\ndef single_point_crossover(dna1, dna2):\n    \"\"\"crossover dna1 and dna2 at a random index\"\"\"\n    pos = int(random.random() * (len(dna1)))\n    return (dna1[:pos] + dna2[pos:], dna2[:pos] + dna1[pos:])\n\n\ndef two_point_crossover(dna1, dna2):\n    \"\"\"crossover dna1 and dna2 at 2 random indices\"\"\"\n    if len(dna1) < 5:\n        start, end = 0, len(dna1)\n    else:\n        start, end = 1, len(dna1)-1\n    pos1, pos2 = sorted(random.sample(list(range(start,end)), 2))\n    child1 = dna1[:pos1] + dna2[pos1:pos2] + dna1[pos2:]\n    child2 = dna2[:pos1] + dna1[pos1:pos2] + dna2[pos2:]\n    return (child1, child2)\n\n\ndef uniform_crossover(dna1, dna2):\n    \"\"\"randomly crossover genes between dna1 and dna2\"\"\"\n    ind = np.random.random(len(dna1)) > 0.5\n    child1 = [dna1[i] if ind[i] else dna2[i] for i in range(len(ind))]\n    child2 = [dna2[i] if ind[i] else dna1[i] for i in range(len(ind))]\n    return child1, child2\n\n\ndef disruptive_uniform_crossover(dna1, dna2):\n    \"\"\"disruptive uniform crossover\n\n    uniformly crossover genes between dna1 and dna2,\n    with children guaranteed to be different from parents,\n    if the number of differences between parents is larger than 1\n    \"\"\"\n    differences = sum(1 for i, j in zip(dna1, dna2) if i != j)\n    swaps = 0\n    child1 = dna1[:]\n    child2 = dna2[:]\n    while swaps < (differences + 1) // 2:\n        for ind in range(len(dna1)):\n            # if there is a difference on this index and has not been swapped yet\n            if dna1[ind] != dna2[ind] and child1[ind] != dna2[ind]:\n                p = random.random()\n                if p < 0.5 and swaps < (differences + 1) // 2:\n                    child1[ind] = dna2[ind]\n                    child2[ind] = dna1[ind]\n                    swaps += 1\n    return (child1, child2)\n\n\nsupported_methods = {\n    \"single_point\": single_point_crossover,\n    \"two_point\": two_point_crossover,\n    \"uniform\": uniform_crossover,\n    \"disruptive_uniform\": disruptive_uniform_crossover\n}\n", 225], "/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/mls.py": ["\"\"\" The strategy that uses multi-start local search \"\"\"\nimport itertools\nimport random\n\nfrom kernel_tuner import util\nfrom kernel_tuner.strategies.minimize import _cost_func\nfrom kernel_tuner.strategies.greedy_mls import tune as mls_tune\n\ndef tune(runner, kernel_options, device_options, tuning_options):\n    \"\"\" Find the best performing kernel configuration in the parameter space\n\n    :params runner: A runner from kernel_tuner.runners\n    :type runner: kernel_tuner.runner\n\n    :param kernel_options: A dictionary with all options for the kernel.\n    :type kernel_options: dict\n\n    :param device_options: A dictionary with all options for the device\n        on which the kernel should be tuned.\n    :type device_options: dict\n\n    :param tuning_options: A dictionary with all options regarding the tuning\n        process.\n    :type tuning_options: dict\n\n    :returns: A list of dictionaries for executed kernel configurations and their\n        execution times. And a dictionary that contains a information\n        about the hardware/software environment on which the tuning took place.\n    :rtype: list(dict()), dict()\n\n    \"\"\"\n\n    # Default MLS uses 'best improvement' hillclimbing, so disable greedy hillclimbing\n    options = tuning_options.strategy_options\n    options[\"restart\"] = False\n    options[\"neighbor\"] = \"Hamming\"\n    return mls_tune(runner, kernel_options, device_options, tuning_options)\n", 37], "/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/pso.py": ["\"\"\" The strategy that uses particle swarm optimization\"\"\"\n\nfrom __future__ import print_function\nfrom __future__ import division\nimport random\nimport numpy as np\n\nfrom kernel_tuner.strategies.minimize import _cost_func, get_bounds_x0_eps\n\ndef tune(runner, kernel_options, device_options, tuning_options):\n    \"\"\" Find the best performing kernel configuration in the parameter space\n\n    :params runner: A runner from kernel_tuner.runners\n    :type runner: kernel_tuner.runner\n\n    :param kernel_options: A dictionary with all options for the kernel.\n    :type kernel_options: dict\n\n    :param device_options: A dictionary with all options for the device\n        on which the kernel should be tuned.\n    :type device_options: dict\n\n    :param tuning_options: A dictionary with all options regarding the tuning\n        process.\n    :type tuning_options: dict\n\n    :returns: A list of dictionaries for executed kernel configurations and their\n        execution times. And a dictionary that contains a information\n        about the hardware/software environment on which the tuning took place.\n    :rtype: list(dict()), dict()\n\n    \"\"\"\n\n    results = []\n\n    #scale variables in x because PSO works with velocities to visit different configurations\n    tuning_options[\"scaling\"] = True\n\n    #using this instead of get_bounds because scaling is used\n    bounds, _, _ = get_bounds_x0_eps(tuning_options)\n\n    args = (kernel_options, tuning_options, runner, results)\n\n    num_particles = tuning_options.strategy_options.get(\"popsize\", 20)\n    maxiter = tuning_options.strategy_options.get(\"maxiter\", 100)\n\n    w = tuning_options.strategy_options.get(\"w\", 0.5)       # inertia constant\n    c1 = tuning_options.strategy_options.get(\"c1\", 2.0)     # cognitive constant\n    c2 = tuning_options.strategy_options.get(\"c2\", 1.0)     # social constant\n\n    best_time_global = 1e20\n    best_position_global = []\n\n    # init particle swarm\n    swarm = []\n    for i in range(0, num_particles):\n        swarm.append(Particle(bounds, args))\n\n    for i in range(maxiter):\n        if tuning_options.verbose:\n            print(\"start iteration \", i, \"best time global\", best_time_global)\n\n        # evaluate particle positions\n        for j in range(num_particles):\n            swarm[j].evaluate(_cost_func)\n\n            # update global best if needed\n            if swarm[j].time <= best_time_global:\n                best_position_global = swarm[j].position\n                best_time_global = swarm[j].time\n\n        # update particle velocities and positions\n        for j in range(0, num_particles):\n            swarm[j].update_velocity(best_position_global, w, c1, c2)\n            swarm[j].update_position(bounds)\n\n    if tuning_options.verbose:\n        print('Final result:')\n        print(best_position_global)\n        print(best_time_global)\n\n    return results, runner.dev.get_environment()\n\n\nclass Particle:\n    def __init__(self, bounds, args):\n        self.ndim = len(bounds)\n        self.args = args\n\n        self.velocity = np.random.uniform(-1, 1, self.ndim)\n        self.position = np.random.uniform([b[0] for b in bounds], [b[1] for b in bounds])\n        self.best_pos = self.position\n        self.best_time = 1e20\n        self.time = 1e20\n\n    def evaluate(self, cost_func):\n        self.time = cost_func(self.position, *self.args)\n        # update best_pos if needed\n        if self.time < self.best_time:\n            self.best_pos = self.position\n            self.best_time = self.time\n\n    def update_velocity(self, best_position_global, w, c1, c2):\n        r1 = random.random()\n        r2 = random.random()\n        vc = c1 * r1 * (self.best_pos - self.position)\n        vs = c2 * r2 * (best_position_global - self.position)\n        self.velocity = w * self.velocity + vc + vs\n\n    def update_position(self, bounds):\n        self.position = self.position + self.velocity\n        self.position = np.minimum(self.position, [b[1] for b in bounds])\n        self.position = np.maximum(self.position, [b[0] for b in bounds])\n", 113], "/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/simulated_annealing.py": ["\"\"\" The strategy that uses particle swarm optimization\"\"\"\n\nfrom __future__ import print_function\nimport random\nimport numpy as np\n\nfrom kernel_tuner.strategies.minimize import _cost_func\nfrom kernel_tuner.strategies.genetic_algorithm import random_val\n\n\ndef tune(runner, kernel_options, device_options, tuning_options):\n    \"\"\" Find the best performing kernel configuration in the parameter space\n\n    :params runner: A runner from kernel_tuner.runners\n    :type runner: kernel_tuner.runner\n\n    :param kernel_options: A dictionary with all options for the kernel.\n    :type kernel_options: dict\n\n    :param device_options: A dictionary with all options for the device\n        on which the kernel should be tuned.\n    :type device_options: dict\n\n    :param tuning_options: A dictionary with all options regarding the tuning\n        process.\n    :type tuning_options: dict\n\n    :returns: A list of dictionaries for executed kernel configurations and their\n        execution times. And a dictionary that contains a information\n        about the hardware/software environment on which the tuning took place.\n    :rtype: list(dict()), dict()\n\n    \"\"\"\n\n    results = []\n\n    # SA works with real parameter values and does not need scaling\n    tuning_options[\"scaling\"] = False\n    args = (kernel_options, tuning_options, runner, results)\n    tune_params = tuning_options.tune_params\n\n    # optimization parameters\n    T = tuning_options.strategy_options.get(\"T\", 1.0)\n    T_min = tuning_options.strategy_options.get(\"T_min\", 0.001)\n    alpha = tuning_options.strategy_options.get(\"alpha\", 0.9)\n    niter = tuning_options.strategy_options.get(\"maxiter\", 20)\n\n    # generate random starting point and evaluate cost\n    pos = []\n    for i, _ in enumerate(tune_params.keys()):\n        pos.append(random_val(i, tune_params))\n    old_cost = _cost_func(pos, *args)\n\n    if tuning_options.verbose:\n        c = 0\n    # main optimization loop\n    while T > T_min:\n        if tuning_options.verbose:\n            print(\"iteration: \", c, \"T\", T, \"cost: \", old_cost)\n            c += 1\n\n        for i in range(niter):\n\n            new_pos = neighbor(pos, tune_params)\n            new_cost = _cost_func(new_pos, *args)\n\n            ap = acceptance_prob(old_cost, new_cost, T)\n            r = random.random()\n\n            if ap > r:\n                if tuning_options.verbose:\n                    print(\"new position accepted\", new_pos, new_cost, 'old:', pos, old_cost, 'ap', ap, 'r', r, 'T', T)\n                pos = new_pos\n                old_cost = new_cost\n\n        T = T * alpha\n\n    return results, runner.dev.get_environment()\n\n\ndef acceptance_prob(old_cost, new_cost, T):\n    \"\"\"annealing equation, with modifications to work towards a lower value\"\"\"\n    # if start pos is not valid, always move\n    if old_cost == 1e20:\n        return 1.0\n    # if we have found a valid ps before, never move to nonvalid pos\n    if new_cost == 1e20:\n        return 0.0\n    # always move if new cost is better\n    if new_cost < old_cost:\n        return 1.0\n    # maybe move if old cost is better than new cost depending on T and random value\n    return np.exp(((old_cost-new_cost)/old_cost)/T)\n\n\ndef neighbor(pos, tune_params):\n    \"\"\"return a random neighbor of pos\"\"\"\n    size = len(pos)\n    pos_out = []\n    # random mutation\n    # expected value is set that values all dimensions attempt to get mutated\n    for i in range(size):\n        key = list(tune_params.keys())[i]\n        values = tune_params[key]\n\n        if random.random() < 0.2:  # replace with random value\n            new_value = random_val(i, tune_params)\n        else:  # adjacent value\n            ind = values.index(pos[i])\n            if random.random() > 0.5:\n                ind += 1\n            else:\n                ind -= 1\n            ind = min(max(ind, 0), len(values)-1)\n            new_value = values[ind]\n\n        pos_out.append(new_value)\n    return pos_out\n", 118], "/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/firefly_algorithm.py": ["\"\"\" The strategy that uses the firefly algorithm for optimization\"\"\"\nfrom __future__ import print_function\nimport numpy as np\n\nfrom kernel_tuner.strategies.minimize import _cost_func, get_bounds_x0_eps\nfrom kernel_tuner.strategies.pso import Particle\n\n\ndef tune(runner, kernel_options, device_options, tuning_options):\n    \"\"\" Find the best performing kernel configuration in the parameter space\n\n    :params runner: A runner from kernel_tuner.runners\n    :type runner: kernel_tuner.runner\n\n    :param kernel_options: A dictionary with all options for the kernel.\n    :type kernel_options: dict\n\n    :param device_options: A dictionary with all options for the device\n        on which the kernel should be tuned.\n    :type device_options: dict\n\n    :param tuning_options: A dictionary with all options regarding the tuning\n        process.\n    :type tuning_options: dict\n\n    :returns: A list of dictionaries for executed kernel configurations and their\n        execution times. And a dictionary that contains a information\n        about the hardware/software environment on which the tuning took place.\n    :rtype: list(dict()), dict()\n\n    \"\"\"\n\n    results = []\n\n    # scale variables in x because PSO works with velocities to visit different configurations\n    tuning_options[\"scaling\"] = True\n\n    # using this instead of get_bounds because scaling is used\n    bounds, _, _ = get_bounds_x0_eps(tuning_options)\n\n    args = (kernel_options, tuning_options, runner, results)\n\n    num_particles = tuning_options.strategy_options.get(\"popsize\", 20)\n    maxiter = tuning_options.strategy_options.get(\"maxiter\", 100)\n\n    # parameters needed by the Firefly Algorithm\n    B0 = tuning_options.strategy_options.get(\"B0\", 1.0)\n    gamma = tuning_options.strategy_options.get(\"gamma\", 1.0)\n    alpha = tuning_options.strategy_options.get(\"alpha\", 0.2)\n\n    best_time_global = 1e20\n    best_position_global = []\n\n    # init particle swarm\n    swarm = []\n    for i in range(0, num_particles):\n        swarm.append(Firefly(bounds, args))\n\n    # compute initial intensities\n    for j in range(num_particles):\n        swarm[j].compute_intensity(_cost_func)\n\n    for c in range(maxiter):\n        if tuning_options.verbose:\n            print(\"start iteration \", c, \"best time global\", best_time_global)\n\n        # compare all to all and compute attractiveness\n        for i in range(num_particles):\n            for j in range(num_particles):\n\n                if swarm[i].intensity < swarm[j].intensity:\n                    dist = swarm[i].distance_to(swarm[j])\n                    beta = B0 * np.exp(-gamma * dist * dist)\n\n                    swarm[i].move_towards(swarm[j], beta, alpha)\n                    swarm[i].compute_intensity(_cost_func)\n\n                    # update global best if needed, actually only used for printing\n                    if swarm[i].time <= best_time_global:\n                        best_position_global = swarm[i].position\n                        best_time_global = swarm[i].time\n\n        swarm.sort(key=lambda x: x.time)\n\n    if tuning_options.verbose:\n        print('Final result:')\n        print(best_position_global)\n        print(best_time_global)\n\n    return results, runner.dev.get_environment()\n\n\nclass Firefly(Particle):\n    \"\"\"Firefly object for use in the Firefly Algorithm\"\"\"\n\n    def __init__(self, bounds, args):\n        \"\"\"Create Firefly at random position within bounds\"\"\"\n        super().__init__(bounds, args)\n        self.bounds = bounds\n        self.intensity = 1 / self.time\n\n    def distance_to(self, other):\n        \"\"\"Return Euclidian distance between self and other Firefly\"\"\"\n        return np.linalg.norm(self.position-other.position)\n\n    def compute_intensity(self, _cost_func):\n        \"\"\"Evaluate cost function and compute intensity at this position\"\"\"\n        self.evaluate(_cost_func)\n        self.intensity = 1 / self.time\n\n    def move_towards(self, other, beta, alpha):\n        \"\"\"Move firefly towards another given beta and alpha values\"\"\"\n        self.position += beta * (other.position - self.position)\n        self.position += alpha * (np.random.uniform(-0.5, 0.5, len(self.position)))\n        self.position = np.minimum(self.position, [b[1] for b in self.bounds])\n        self.position = np.maximum(self.position, [b[0] for b in self.bounds])\n", 116], "/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py": ["\"\"\"\nThe typing module: Support for gradual typing as defined by PEP 484.\n\nAt large scale, the structure of the module is following:\n* Imports and exports, all public names should be explicitly added to __all__.\n* Internal helper functions: these should never be used in code outside this module.\n* _SpecialForm and its instances (special forms): Any, NoReturn, ClassVar, Union, Optional\n* Two classes whose instances can be type arguments in addition to types: ForwardRef and TypeVar\n* The core of internal generics API: _GenericAlias and _VariadicGenericAlias, the latter is\n  currently only used by Tuple and Callable. All subscripted types like X[int], Union[int, str],\n  etc., are instances of either of these classes.\n* The public counterpart of the generics API consists of two classes: Generic and Protocol.\n* Public helper functions: get_type_hints, overload, cast, no_type_check,\n  no_type_check_decorator.\n* Generic aliases for collections.abc ABCs and few additional protocols.\n* Special types: NewType, NamedTuple, TypedDict.\n* Wrapper submodules for re and io related types.\n\"\"\"\n\nfrom abc import abstractmethod, ABCMeta\nimport collections\nimport collections.abc\nimport contextlib\nimport functools\nimport operator\nimport re as stdlib_re  # Avoid confusion with the re we export.\nimport sys\nimport types\nfrom types import WrapperDescriptorType, MethodWrapperType, MethodDescriptorType, GenericAlias\n\n# Please keep __all__ alphabetized within each category.\n__all__ = [\n    # Super-special typing primitives.\n    'Annotated',\n    'Any',\n    'Callable',\n    'ClassVar',\n    'Final',\n    'ForwardRef',\n    'Generic',\n    'Literal',\n    'Optional',\n    'Protocol',\n    'Tuple',\n    'Type',\n    'TypeVar',\n    'Union',\n\n    # ABCs (from collections.abc).\n    'AbstractSet',  # collections.abc.Set.\n    'ByteString',\n    'Container',\n    'ContextManager',\n    'Hashable',\n    'ItemsView',\n    'Iterable',\n    'Iterator',\n    'KeysView',\n    'Mapping',\n    'MappingView',\n    'MutableMapping',\n    'MutableSequence',\n    'MutableSet',\n    'Sequence',\n    'Sized',\n    'ValuesView',\n    'Awaitable',\n    'AsyncIterator',\n    'AsyncIterable',\n    'Coroutine',\n    'Collection',\n    'AsyncGenerator',\n    'AsyncContextManager',\n\n    # Structural checks, a.k.a. protocols.\n    'Reversible',\n    'SupportsAbs',\n    'SupportsBytes',\n    'SupportsComplex',\n    'SupportsFloat',\n    'SupportsIndex',\n    'SupportsInt',\n    'SupportsRound',\n\n    # Concrete collection types.\n    'ChainMap',\n    'Counter',\n    'Deque',\n    'Dict',\n    'DefaultDict',\n    'List',\n    'OrderedDict',\n    'Set',\n    'FrozenSet',\n    'NamedTuple',  # Not really a type.\n    'TypedDict',  # Not really a type.\n    'Generator',\n\n    # Other concrete types.\n    'BinaryIO',\n    'IO',\n    'Match',\n    'Pattern',\n    'TextIO',\n\n    # One-off things.\n    'AnyStr',\n    'cast',\n    'final',\n    'get_args',\n    'get_origin',\n    'get_type_hints',\n    'NewType',\n    'no_type_check',\n    'no_type_check_decorator',\n    'NoReturn',\n    'overload',\n    'runtime_checkable',\n    'Text',\n    'TYPE_CHECKING',\n]\n\n# The pseudo-submodules 're' and 'io' are part of the public\n# namespace, but excluded from __all__ because they might stomp on\n# legitimate imports of those modules.\n\n\ndef _type_convert(arg, module=None):\n    \"\"\"For converting None to type(None), and strings to ForwardRef.\"\"\"\n    if arg is None:\n        return type(None)\n    if isinstance(arg, str):\n        return ForwardRef(arg, module=module)\n    return arg\n\n\ndef _type_check(arg, msg, is_argument=True, module=None, *, is_class=False):\n    \"\"\"Check that the argument is a type, and return it (internal helper).\n\n    As a special case, accept None and return type(None) instead. Also wrap strings\n    into ForwardRef instances. Consider several corner cases, for example plain\n    special forms like Union are not valid, while Union[int, str] is OK, etc.\n    The msg argument is a human-readable error message, e.g::\n\n        \"Union[arg, ...]: arg should be a type.\"\n\n    We append the repr() of the actual value (truncated to 100 chars).\n    \"\"\"\n    invalid_generic_forms = (Generic, Protocol)\n    if not is_class:\n        invalid_generic_forms += (ClassVar,)\n        if is_argument:\n            invalid_generic_forms += (Final,)\n\n    arg = _type_convert(arg, module=module)\n    if (isinstance(arg, _GenericAlias) and\n            arg.__origin__ in invalid_generic_forms):\n        raise TypeError(f\"{arg} is not valid as type argument\")\n    if arg in (Any, NoReturn, Final):\n        return arg\n    if isinstance(arg, _SpecialForm) or arg in (Generic, Protocol):\n        raise TypeError(f\"Plain {arg} is not valid as type argument\")\n    if isinstance(arg, (type, TypeVar, ForwardRef)):\n        return arg\n    if not callable(arg):\n        raise TypeError(f\"{msg} Got {arg!r:.100}.\")\n    return arg\n\n\ndef _type_repr(obj):\n    \"\"\"Return the repr() of an object, special-casing types (internal helper).\n\n    If obj is a type, we return a shorter version than the default\n    type.__repr__, based on the module and qualified name, which is\n    typically enough to uniquely identify a type.  For everything\n    else, we fall back on repr(obj).\n    \"\"\"\n    if isinstance(obj, types.GenericAlias):\n        return repr(obj)\n    if isinstance(obj, type):\n        if obj.__module__ == 'builtins':\n            return obj.__qualname__\n        return f'{obj.__module__}.{obj.__qualname__}'\n    if obj is ...:\n        return('...')\n    if isinstance(obj, types.FunctionType):\n        return obj.__name__\n    return repr(obj)\n\n\ndef _collect_type_vars(types):\n    \"\"\"Collect all type variable contained in types in order of\n    first appearance (lexicographic order). For example::\n\n        _collect_type_vars((T, List[S, T])) == (T, S)\n    \"\"\"\n    tvars = []\n    for t in types:\n        if isinstance(t, TypeVar) and t not in tvars:\n            tvars.append(t)\n        if isinstance(t, (_GenericAlias, GenericAlias)):\n            tvars.extend([t for t in t.__parameters__ if t not in tvars])\n    return tuple(tvars)\n\n\ndef _check_generic(cls, parameters, elen):\n    \"\"\"Check correct count for parameters of a generic cls (internal helper).\n    This gives a nice error message in case of count mismatch.\n    \"\"\"\n    if not elen:\n        raise TypeError(f\"{cls} is not a generic class\")\n    alen = len(parameters)\n    if alen != elen:\n        raise TypeError(f\"Too {'many' if alen > elen else 'few'} parameters for {cls};\"\n                        f\" actual {alen}, expected {elen}\")\n\n\ndef _deduplicate(params):\n    # Weed out strict duplicates, preserving the first of each occurrence.\n    all_params = set(params)\n    if len(all_params) < len(params):\n        new_params = []\n        for t in params:\n            if t in all_params:\n                new_params.append(t)\n                all_params.remove(t)\n        params = new_params\n        assert not all_params, all_params\n    return params\n\n\ndef _remove_dups_flatten(parameters):\n    \"\"\"An internal helper for Union creation and substitution: flatten Unions\n    among parameters, then remove duplicates.\n    \"\"\"\n    # Flatten out Union[Union[...], ...].\n    params = []\n    for p in parameters:\n        if isinstance(p, _UnionGenericAlias):\n            params.extend(p.__args__)\n        elif isinstance(p, tuple) and len(p) > 0 and p[0] is Union:\n            params.extend(p[1:])\n        else:\n            params.append(p)\n\n    return tuple(_deduplicate(params))\n\n\ndef _flatten_literal_params(parameters):\n    \"\"\"An internal helper for Literal creation: flatten Literals among parameters\"\"\"\n    params = []\n    for p in parameters:\n        if isinstance(p, _LiteralGenericAlias):\n            params.extend(p.__args__)\n        else:\n            params.append(p)\n    return tuple(params)\n\n\n_cleanups = []\n\n\ndef _tp_cache(func=None, /, *, typed=False):\n    \"\"\"Internal wrapper caching __getitem__ of generic types with a fallback to\n    original function for non-hashable arguments.\n    \"\"\"\n    def decorator(func):\n        cached = functools.lru_cache(typed=typed)(func)\n        _cleanups.append(cached.cache_clear)\n\n        @functools.wraps(func)\n        def inner(*args, **kwds):\n            try:\n                return cached(*args, **kwds)\n            except TypeError:\n                pass  # All real errors (not unhashable args) are raised below.\n            return func(*args, **kwds)\n        return inner\n\n    if func is not None:\n        return decorator(func)\n\n    return decorator\n\ndef _eval_type(t, globalns, localns, recursive_guard=frozenset()):\n    \"\"\"Evaluate all forward references in the given type t.\n    For use of globalns and localns see the docstring for get_type_hints().\n    recursive_guard is used to prevent prevent infinite recursion\n    with recursive ForwardRef.\n    \"\"\"\n    if isinstance(t, ForwardRef):\n        return t._evaluate(globalns, localns, recursive_guard)\n    if isinstance(t, (_GenericAlias, GenericAlias)):\n        ev_args = tuple(_eval_type(a, globalns, localns, recursive_guard) for a in t.__args__)\n        if ev_args == t.__args__:\n            return t\n        if isinstance(t, GenericAlias):\n            return GenericAlias(t.__origin__, ev_args)\n        else:\n            return t.copy_with(ev_args)\n    return t\n\n\nclass _Final:\n    \"\"\"Mixin to prohibit subclassing\"\"\"\n\n    __slots__ = ('__weakref__',)\n\n    def __init_subclass__(self, /, *args, **kwds):\n        if '_root' not in kwds:\n            raise TypeError(\"Cannot subclass special typing classes\")\n\nclass _Immutable:\n    \"\"\"Mixin to indicate that object should not be copied.\"\"\"\n    __slots__ = ()\n\n    def __copy__(self):\n        return self\n\n    def __deepcopy__(self, memo):\n        return self\n\n\n# Internal indicator of special typing constructs.\n# See __doc__ instance attribute for specific docs.\nclass _SpecialForm(_Final, _root=True):\n    __slots__ = ('_name', '__doc__', '_getitem')\n\n    def __init__(self, getitem):\n        self._getitem = getitem\n        self._name = getitem.__name__\n        self.__doc__ = getitem.__doc__\n\n    def __mro_entries__(self, bases):\n        raise TypeError(f\"Cannot subclass {self!r}\")\n\n    def __repr__(self):\n        return 'typing.' + self._name\n\n    def __reduce__(self):\n        return self._name\n\n    def __call__(self, *args, **kwds):\n        raise TypeError(f\"Cannot instantiate {self!r}\")\n\n    def __instancecheck__(self, obj):\n        raise TypeError(f\"{self} cannot be used with isinstance()\")\n\n    def __subclasscheck__(self, cls):\n        raise TypeError(f\"{self} cannot be used with issubclass()\")\n\n    @_tp_cache\n    def __getitem__(self, parameters):\n        return self._getitem(self, parameters)\n\n\nclass _LiteralSpecialForm(_SpecialForm, _root=True):\n    def __getitem__(self, parameters):\n        if not isinstance(parameters, tuple):\n            parameters = (parameters,)\n        return self._getitem(self, *parameters)\n\n\n@_SpecialForm\ndef Any(self, parameters):\n    \"\"\"Special type indicating an unconstrained type.\n\n    - Any is compatible with every type.\n    - Any assumed to have all methods.\n    - All values assumed to be instances of Any.\n\n    Note that all the above statements are true from the point of view of\n    static type checkers. At runtime, Any should not be used with instance\n    or class checks.\n    \"\"\"\n    raise TypeError(f\"{self} is not subscriptable\")\n\n@_SpecialForm\ndef NoReturn(self, parameters):\n    \"\"\"Special type indicating functions that never return.\n    Example::\n\n      from typing import NoReturn\n\n      def stop() -> NoReturn:\n          raise Exception('no way')\n\n    This type is invalid in other positions, e.g., ``List[NoReturn]``\n    will fail in static type checkers.\n    \"\"\"\n    raise TypeError(f\"{self} is not subscriptable\")\n\n@_SpecialForm\ndef ClassVar(self, parameters):\n    \"\"\"Special type construct to mark class variables.\n\n    An annotation wrapped in ClassVar indicates that a given\n    attribute is intended to be used as a class variable and\n    should not be set on instances of that class. Usage::\n\n      class Starship:\n          stats: ClassVar[Dict[str, int]] = {} # class variable\n          damage: int = 10                     # instance variable\n\n    ClassVar accepts only types and cannot be further subscribed.\n\n    Note that ClassVar is not a class itself, and should not\n    be used with isinstance() or issubclass().\n    \"\"\"\n    item = _type_check(parameters, f'{self} accepts only single type.')\n    return _GenericAlias(self, (item,))\n\n@_SpecialForm\ndef Final(self, parameters):\n    \"\"\"Special typing construct to indicate final names to type checkers.\n\n    A final name cannot be re-assigned or overridden in a subclass.\n    For example:\n\n      MAX_SIZE: Final = 9000\n      MAX_SIZE += 1  # Error reported by type checker\n\n      class Connection:\n          TIMEOUT: Final[int] = 10\n\n      class FastConnector(Connection):\n          TIMEOUT = 1  # Error reported by type checker\n\n    There is no runtime checking of these properties.\n    \"\"\"\n    item = _type_check(parameters, f'{self} accepts only single type.')\n    return _GenericAlias(self, (item,))\n\n@_SpecialForm\ndef Union(self, parameters):\n    \"\"\"Union type; Union[X, Y] means either X or Y.\n\n    To define a union, use e.g. Union[int, str].  Details:\n    - The arguments must be types and there must be at least one.\n    - None as an argument is a special case and is replaced by\n      type(None).\n    - Unions of unions are flattened, e.g.::\n\n        Union[Union[int, str], float] == Union[int, str, float]\n\n    - Unions of a single argument vanish, e.g.::\n\n        Union[int] == int  # The constructor actually returns int\n\n    - Redundant arguments are skipped, e.g.::\n\n        Union[int, str, int] == Union[int, str]\n\n    - When comparing unions, the argument order is ignored, e.g.::\n\n        Union[int, str] == Union[str, int]\n\n    - You cannot subclass or instantiate a union.\n    - You can use Optional[X] as a shorthand for Union[X, None].\n    \"\"\"\n    if parameters == ():\n        raise TypeError(\"Cannot take a Union of no types.\")\n    if not isinstance(parameters, tuple):\n        parameters = (parameters,)\n    msg = \"Union[arg, ...]: each arg must be a type.\"\n    parameters = tuple(_type_check(p, msg) for p in parameters)\n    parameters = _remove_dups_flatten(parameters)\n    if len(parameters) == 1:\n        return parameters[0]\n    return _UnionGenericAlias(self, parameters)\n\n@_SpecialForm\ndef Optional(self, parameters):\n    \"\"\"Optional type.\n\n    Optional[X] is equivalent to Union[X, None].\n    \"\"\"\n    arg = _type_check(parameters, f\"{self} requires a single type.\")\n    return Union[arg, type(None)]\n\n@_LiteralSpecialForm\n@_tp_cache(typed=True)\ndef Literal(self, *parameters):\n    \"\"\"Special typing form to define literal types (a.k.a. value types).\n\n    This form can be used to indicate to type checkers that the corresponding\n    variable or function parameter has a value equivalent to the provided\n    literal (or one of several literals):\n\n      def validate_simple(data: Any) -> Literal[True]:  # always returns True\n          ...\n\n      MODE = Literal['r', 'rb', 'w', 'wb']\n      def open_helper(file: str, mode: MODE) -> str:\n          ...\n\n      open_helper('/some/path', 'r')  # Passes type check\n      open_helper('/other/path', 'typo')  # Error in type checker\n\n    Literal[...] cannot be subclassed. At runtime, an arbitrary value\n    is allowed as type argument to Literal[...], but type checkers may\n    impose restrictions.\n    \"\"\"\n    # There is no '_type_check' call because arguments to Literal[...] are\n    # values, not types.\n    parameters = _flatten_literal_params(parameters)\n\n    try:\n        parameters = tuple(p for p, _ in _deduplicate(list(_value_and_type_iter(parameters))))\n    except TypeError:  # unhashable parameters\n        pass\n\n    return _LiteralGenericAlias(self, parameters)\n\n\nclass ForwardRef(_Final, _root=True):\n    \"\"\"Internal wrapper to hold a forward reference.\"\"\"\n\n    __slots__ = ('__forward_arg__', '__forward_code__',\n                 '__forward_evaluated__', '__forward_value__',\n                 '__forward_is_argument__', '__forward_is_class__',\n                 '__forward_module__')\n\n    def __init__(self, arg, is_argument=True, module=None, *, is_class=False):\n        if not isinstance(arg, str):\n            raise TypeError(f\"Forward reference must be a string -- got {arg!r}\")\n        try:\n            code = compile(arg, '<string>', 'eval')\n        except SyntaxError:\n            raise SyntaxError(f\"Forward reference must be an expression -- got {arg!r}\")\n        self.__forward_arg__ = arg\n        self.__forward_code__ = code\n        self.__forward_evaluated__ = False\n        self.__forward_value__ = None\n        self.__forward_is_argument__ = is_argument\n        self.__forward_is_class__ = is_class\n        self.__forward_module__ = module\n\n    def _evaluate(self, globalns, localns, recursive_guard):\n        if self.__forward_arg__ in recursive_guard:\n            return self\n        if not self.__forward_evaluated__ or localns is not globalns:\n            if globalns is None and localns is None:\n                globalns = localns = {}\n            elif globalns is None:\n                globalns = localns\n            elif localns is None:\n                localns = globalns\n            if self.__forward_module__ is not None:\n                globalns = getattr(\n                    sys.modules.get(self.__forward_module__, None), '__dict__', globalns\n                )\n            type_ = _type_check(\n                eval(self.__forward_code__, globalns, localns),\n                \"Forward references must evaluate to types.\",\n                is_argument=self.__forward_is_argument__,\n                is_class=self.__forward_is_class__,\n            )\n            self.__forward_value__ = _eval_type(\n                type_, globalns, localns, recursive_guard | {self.__forward_arg__}\n            )\n            self.__forward_evaluated__ = True\n        return self.__forward_value__\n\n    def __eq__(self, other):\n        if not isinstance(other, ForwardRef):\n            return NotImplemented\n        if self.__forward_evaluated__ and other.__forward_evaluated__:\n            return (self.__forward_arg__ == other.__forward_arg__ and\n                    self.__forward_value__ == other.__forward_value__)\n        return self.__forward_arg__ == other.__forward_arg__\n\n    def __hash__(self):\n        return hash(self.__forward_arg__)\n\n    def __repr__(self):\n        return f'ForwardRef({self.__forward_arg__!r})'\n\n\nclass TypeVar(_Final, _Immutable, _root=True):\n    \"\"\"Type variable.\n\n    Usage::\n\n      T = TypeVar('T')  # Can be anything\n      A = TypeVar('A', str, bytes)  # Must be str or bytes\n\n    Type variables exist primarily for the benefit of static type\n    checkers.  They serve as the parameters for generic types as well\n    as for generic function definitions.  See class Generic for more\n    information on generic types.  Generic functions work as follows:\n\n      def repeat(x: T, n: int) -> List[T]:\n          '''Return a list containing n references to x.'''\n          return [x]*n\n\n      def longest(x: A, y: A) -> A:\n          '''Return the longest of two strings.'''\n          return x if len(x) >= len(y) else y\n\n    The latter example's signature is essentially the overloading\n    of (str, str) -> str and (bytes, bytes) -> bytes.  Also note\n    that if the arguments are instances of some subclass of str,\n    the return type is still plain str.\n\n    At runtime, isinstance(x, T) and issubclass(C, T) will raise TypeError.\n\n    Type variables defined with covariant=True or contravariant=True\n    can be used to declare covariant or contravariant generic types.\n    See PEP 484 for more details. By default generic types are invariant\n    in all type variables.\n\n    Type variables can be introspected. e.g.:\n\n      T.__name__ == 'T'\n      T.__constraints__ == ()\n      T.__covariant__ == False\n      T.__contravariant__ = False\n      A.__constraints__ == (str, bytes)\n\n    Note that only type variables defined in global scope can be pickled.\n    \"\"\"\n\n    __slots__ = ('__name__', '__bound__', '__constraints__',\n                 '__covariant__', '__contravariant__', '__dict__')\n\n    def __init__(self, name, *constraints, bound=None,\n                 covariant=False, contravariant=False):\n        self.__name__ = name\n        if covariant and contravariant:\n            raise ValueError(\"Bivariant types are not supported.\")\n        self.__covariant__ = bool(covariant)\n        self.__contravariant__ = bool(contravariant)\n        if constraints and bound is not None:\n            raise TypeError(\"Constraints cannot be combined with bound=...\")\n        if constraints and len(constraints) == 1:\n            raise TypeError(\"A single constraint is not allowed\")\n        msg = \"TypeVar(name, constraint, ...): constraints must be types.\"\n        self.__constraints__ = tuple(_type_check(t, msg) for t in constraints)\n        if bound:\n            self.__bound__ = _type_check(bound, \"Bound must be a type.\")\n        else:\n            self.__bound__ = None\n        try:\n            def_mod = sys._getframe(1).f_globals.get('__name__', '__main__')  # for pickling\n        except (AttributeError, ValueError):\n            def_mod = None\n        if def_mod != 'typing':\n            self.__module__ = def_mod\n\n    def __repr__(self):\n        if self.__covariant__:\n            prefix = '+'\n        elif self.__contravariant__:\n            prefix = '-'\n        else:\n            prefix = '~'\n        return prefix + self.__name__\n\n    def __reduce__(self):\n        return self.__name__\n\n\ndef _is_dunder(attr):\n    return attr.startswith('__') and attr.endswith('__')\n\nclass _BaseGenericAlias(_Final, _root=True):\n    \"\"\"The central part of internal API.\n\n    This represents a generic version of type 'origin' with type arguments 'params'.\n    There are two kind of these aliases: user defined and special. The special ones\n    are wrappers around builtin collections and ABCs in collections.abc. These must\n    have 'name' always set. If 'inst' is False, then the alias can't be instantiated,\n    this is used by e.g. typing.List and typing.Dict.\n    \"\"\"\n    def __init__(self, origin, *, inst=True, name=None):\n        self._inst = inst\n        self._name = name\n        self.__origin__ = origin\n        self.__slots__ = None  # This is not documented.\n\n    def __call__(self, *args, **kwargs):\n        if not self._inst:\n            raise TypeError(f\"Type {self._name} cannot be instantiated; \"\n                            f\"use {self.__origin__.__name__}() instead\")\n        result = self.__origin__(*args, **kwargs)\n        try:\n            result.__orig_class__ = self\n        except AttributeError:\n            pass\n        return result\n\n    def __mro_entries__(self, bases):\n        res = []\n        if self.__origin__ not in bases:\n            res.append(self.__origin__)\n        i = bases.index(self)\n        for b in bases[i+1:]:\n            if isinstance(b, _BaseGenericAlias) or issubclass(b, Generic):\n                break\n        else:\n            res.append(Generic)\n        return tuple(res)\n\n    def __getattr__(self, attr):\n        # We are careful for copy and pickle.\n        # Also for simplicity we just don't relay all dunder names\n        if '__origin__' in self.__dict__ and not _is_dunder(attr):\n            return getattr(self.__origin__, attr)\n        raise AttributeError(attr)\n\n    def __setattr__(self, attr, val):\n        if _is_dunder(attr) or attr in ('_name', '_inst', '_nparams'):\n            super().__setattr__(attr, val)\n        else:\n            setattr(self.__origin__, attr, val)\n\n    def __instancecheck__(self, obj):\n        return self.__subclasscheck__(type(obj))\n\n    def __subclasscheck__(self, cls):\n        raise TypeError(\"Subscripted generics cannot be used with\"\n                        \" class and instance checks\")\n\n\n# Special typing constructs Union, Optional, Generic, Callable and Tuple\n# use three special attributes for internal bookkeeping of generic types:\n# * __parameters__ is a tuple of unique free type parameters of a generic\n#   type, for example, Dict[T, T].__parameters__ == (T,);\n# * __origin__ keeps a reference to a type that was subscripted,\n#   e.g., Union[T, int].__origin__ == Union, or the non-generic version of\n#   the type.\n# * __args__ is a tuple of all arguments used in subscripting,\n#   e.g., Dict[T, int].__args__ == (T, int).\n\n\nclass _GenericAlias(_BaseGenericAlias, _root=True):\n    def __init__(self, origin, params, *, inst=True, name=None):\n        super().__init__(origin, inst=inst, name=name)\n        if not isinstance(params, tuple):\n            params = (params,)\n        self.__args__ = tuple(... if a is _TypingEllipsis else\n                              () if a is _TypingEmpty else\n                              a for a in params)\n        self.__parameters__ = _collect_type_vars(params)\n        if not name:\n            self.__module__ = origin.__module__\n\n    def __eq__(self, other):\n        if not isinstance(other, _GenericAlias):\n            return NotImplemented\n        return (self.__origin__ == other.__origin__\n                and self.__args__ == other.__args__)\n\n    def __hash__(self):\n        return hash((self.__origin__, self.__args__))\n\n    @_tp_cache\n    def __getitem__(self, params):\n        if self.__origin__ in (Generic, Protocol):\n            # Can't subscript Generic[...] or Protocol[...].\n            raise TypeError(f\"Cannot subscript already-subscripted {self}\")\n        if not isinstance(params, tuple):\n            params = (params,)\n        msg = \"Parameters to generic types must be types.\"\n        params = tuple(_type_check(p, msg) for p in params)\n        _check_generic(self, params, len(self.__parameters__))\n\n        subst = dict(zip(self.__parameters__, params))\n        new_args = []\n        for arg in self.__args__:\n            if isinstance(arg, TypeVar):\n                arg = subst[arg]\n            elif isinstance(arg, (_GenericAlias, GenericAlias)):\n                subparams = arg.__parameters__\n                if subparams:\n                    subargs = tuple(subst[x] for x in subparams)\n                    arg = arg[subargs]\n            new_args.append(arg)\n        return self.copy_with(tuple(new_args))\n\n    def copy_with(self, params):\n        return self.__class__(self.__origin__, params, name=self._name, inst=self._inst)\n\n    def __repr__(self):\n        if self._name:\n            name = 'typing.' + self._name\n        else:\n            name = _type_repr(self.__origin__)\n        args = \", \".join([_type_repr(a) for a in self.__args__])\n        return f'{name}[{args}]'\n\n    def __reduce__(self):\n        if self._name:\n            origin = globals()[self._name]\n        else:\n            origin = self.__origin__\n        args = tuple(self.__args__)\n        if len(args) == 1 and not isinstance(args[0], tuple):\n            args, = args\n        return operator.getitem, (origin, args)\n\n    def __mro_entries__(self, bases):\n        if self._name:  # generic version of an ABC or built-in class\n            return super().__mro_entries__(bases)\n        if self.__origin__ is Generic:\n            if Protocol in bases:\n                return ()\n            i = bases.index(self)\n            for b in bases[i+1:]:\n                if isinstance(b, _BaseGenericAlias) and b is not self:\n                    return ()\n        return (self.__origin__,)\n\n\n# _nparams is the number of accepted parameters, e.g. 0 for Hashable,\n# 1 for List and 2 for Dict.  It may be -1 if variable number of\n# parameters are accepted (needs custom __getitem__).\n\nclass _SpecialGenericAlias(_BaseGenericAlias, _root=True):\n    def __init__(self, origin, nparams, *, inst=True, name=None):\n        if name is None:\n            name = origin.__name__\n        super().__init__(origin, inst=inst, name=name)\n        self._nparams = nparams\n        if origin.__module__ == 'builtins':\n            self.__doc__ = f'A generic version of {origin.__qualname__}.'\n        else:\n            self.__doc__ = f'A generic version of {origin.__module__}.{origin.__qualname__}.'\n\n    @_tp_cache\n    def __getitem__(self, params):\n        if not isinstance(params, tuple):\n            params = (params,)\n        msg = \"Parameters to generic types must be types.\"\n        params = tuple(_type_check(p, msg) for p in params)\n        _check_generic(self, params, self._nparams)\n        return self.copy_with(params)\n\n    def copy_with(self, params):\n        return _GenericAlias(self.__origin__, params,\n                             name=self._name, inst=self._inst)\n\n    def __repr__(self):\n        return 'typing.' + self._name\n\n    def __subclasscheck__(self, cls):\n        if isinstance(cls, _SpecialGenericAlias):\n            return issubclass(cls.__origin__, self.__origin__)\n        if not isinstance(cls, _GenericAlias):\n            return issubclass(cls, self.__origin__)\n        return super().__subclasscheck__(cls)\n\n    def __reduce__(self):\n        return self._name\n\n\nclass _CallableGenericAlias(_GenericAlias, _root=True):\n    def __repr__(self):\n        assert self._name == 'Callable'\n        if len(self.__args__) == 2 and self.__args__[0] is Ellipsis:\n            return super().__repr__()\n        return (f'typing.Callable'\n                f'[[{\", \".join([_type_repr(a) for a in self.__args__[:-1]])}], '\n                f'{_type_repr(self.__args__[-1])}]')\n\n    def __reduce__(self):\n        args = self.__args__\n        if not (len(args) == 2 and args[0] is ...):\n            args = list(args[:-1]), args[-1]\n        return operator.getitem, (Callable, args)\n\n\nclass _CallableType(_SpecialGenericAlias, _root=True):\n    def copy_with(self, params):\n        return _CallableGenericAlias(self.__origin__, params,\n                                     name=self._name, inst=self._inst)\n\n    def __getitem__(self, params):\n        if not isinstance(params, tuple) or len(params) != 2:\n            raise TypeError(\"Callable must be used as \"\n                            \"Callable[[arg, ...], result].\")\n        args, result = params\n        # This relaxes what args can be on purpose to allow things like\n        # PEP 612 ParamSpec.  Responsibility for whether a user is using\n        # Callable[...] properly is deferred to static type checkers.\n        if isinstance(args, list):\n            params = (tuple(args), result)\n        else:\n            params = (args, result)\n        return self.__getitem_inner__(params)\n\n    @_tp_cache\n    def __getitem_inner__(self, params):\n        args, result = params\n        msg = \"Callable[args, result]: result must be a type.\"\n        result = _type_check(result, msg)\n        if args is Ellipsis:\n            return self.copy_with((_TypingEllipsis, result))\n        if not isinstance(args, tuple):\n            args = (args,)\n        args = tuple(_type_convert(arg) for arg in args)\n        params = args + (result,)\n        return self.copy_with(params)\n\n\nclass _TupleType(_SpecialGenericAlias, _root=True):\n    @_tp_cache\n    def __getitem__(self, params):\n        if params == ():\n            return self.copy_with((_TypingEmpty,))\n        if not isinstance(params, tuple):\n            params = (params,)\n        if len(params) == 2 and params[1] is ...:\n            msg = \"Tuple[t, ...]: t must be a type.\"\n            p = _type_check(params[0], msg)\n            return self.copy_with((p, _TypingEllipsis))\n        msg = \"Tuple[t0, t1, ...]: each t must be a type.\"\n        params = tuple(_type_check(p, msg) for p in params)\n        return self.copy_with(params)\n\n\nclass _UnionGenericAlias(_GenericAlias, _root=True):\n    def copy_with(self, params):\n        return Union[params]\n\n    def __eq__(self, other):\n        if not isinstance(other, _UnionGenericAlias):\n            return NotImplemented\n        return set(self.__args__) == set(other.__args__)\n\n    def __hash__(self):\n        return hash(frozenset(self.__args__))\n\n    def __repr__(self):\n        args = self.__args__\n        if len(args) == 2:\n            if args[0] is type(None):\n                return f'typing.Optional[{_type_repr(args[1])}]'\n            elif args[1] is type(None):\n                return f'typing.Optional[{_type_repr(args[0])}]'\n        return super().__repr__()\n\n\ndef _value_and_type_iter(parameters):\n    return ((p, type(p)) for p in parameters)\n\n\nclass _LiteralGenericAlias(_GenericAlias, _root=True):\n\n    def __eq__(self, other):\n        if not isinstance(other, _LiteralGenericAlias):\n            return NotImplemented\n\n        return set(_value_and_type_iter(self.__args__)) == set(_value_and_type_iter(other.__args__))\n\n    def __hash__(self):\n        return hash(frozenset(_value_and_type_iter(self.__args__)))\n\n\nclass Generic:\n    \"\"\"Abstract base class for generic types.\n\n    A generic type is typically declared by inheriting from\n    this class parameterized with one or more type variables.\n    For example, a generic mapping type might be defined as::\n\n      class Mapping(Generic[KT, VT]):\n          def __getitem__(self, key: KT) -> VT:\n              ...\n          # Etc.\n\n    This class can then be used as follows::\n\n      def lookup_name(mapping: Mapping[KT, VT], key: KT, default: VT) -> VT:\n          try:\n              return mapping[key]\n          except KeyError:\n              return default\n    \"\"\"\n    __slots__ = ()\n    _is_protocol = False\n\n    @_tp_cache\n    def __class_getitem__(cls, params):\n        if not isinstance(params, tuple):\n            params = (params,)\n        if not params and cls is not Tuple:\n            raise TypeError(\n                f\"Parameter list to {cls.__qualname__}[...] cannot be empty\")\n        msg = \"Parameters to generic types must be types.\"\n        params = tuple(_type_check(p, msg) for p in params)\n        if cls in (Generic, Protocol):\n            # Generic and Protocol can only be subscripted with unique type variables.\n            if not all(isinstance(p, TypeVar) for p in params):\n                raise TypeError(\n                    f\"Parameters to {cls.__name__}[...] must all be type variables\")\n            if len(set(params)) != len(params):\n                raise TypeError(\n                    f\"Parameters to {cls.__name__}[...] must all be unique\")\n        else:\n            # Subscripting a regular Generic subclass.\n            _check_generic(cls, params, len(cls.__parameters__))\n        return _GenericAlias(cls, params)\n\n    def __init_subclass__(cls, *args, **kwargs):\n        super().__init_subclass__(*args, **kwargs)\n        tvars = []\n        if '__orig_bases__' in cls.__dict__:\n            error = Generic in cls.__orig_bases__\n        else:\n            error = Generic in cls.__bases__ and cls.__name__ != 'Protocol'\n        if error:\n            raise TypeError(\"Cannot inherit from plain Generic\")\n        if '__orig_bases__' in cls.__dict__:\n            tvars = _collect_type_vars(cls.__orig_bases__)\n            # Look for Generic[T1, ..., Tn].\n            # If found, tvars must be a subset of it.\n            # If not found, tvars is it.\n            # Also check for and reject plain Generic,\n            # and reject multiple Generic[...].\n            gvars = None\n            for base in cls.__orig_bases__:\n                if (isinstance(base, _GenericAlias) and\n                        base.__origin__ is Generic):\n                    if gvars is not None:\n                        raise TypeError(\n                            \"Cannot inherit from Generic[...] multiple types.\")\n                    gvars = base.__parameters__\n            if gvars is not None:\n                tvarset = set(tvars)\n                gvarset = set(gvars)\n                if not tvarset <= gvarset:\n                    s_vars = ', '.join(str(t) for t in tvars if t not in gvarset)\n                    s_args = ', '.join(str(g) for g in gvars)\n                    raise TypeError(f\"Some type variables ({s_vars}) are\"\n                                    f\" not listed in Generic[{s_args}]\")\n                tvars = gvars\n        cls.__parameters__ = tuple(tvars)\n\n\nclass _TypingEmpty:\n    \"\"\"Internal placeholder for () or []. Used by TupleMeta and CallableMeta\n    to allow empty list/tuple in specific places, without allowing them\n    to sneak in where prohibited.\n    \"\"\"\n\n\nclass _TypingEllipsis:\n    \"\"\"Internal placeholder for ... (ellipsis).\"\"\"\n\n\n_TYPING_INTERNALS = ['__parameters__', '__orig_bases__',  '__orig_class__',\n                     '_is_protocol', '_is_runtime_protocol']\n\n_SPECIAL_NAMES = ['__abstractmethods__', '__annotations__', '__dict__', '__doc__',\n                  '__init__', '__module__', '__new__', '__slots__',\n                  '__subclasshook__', '__weakref__', '__class_getitem__']\n\n# These special attributes will be not collected as protocol members.\nEXCLUDED_ATTRIBUTES = _TYPING_INTERNALS + _SPECIAL_NAMES + ['_MutableMapping__marker']\n\n\ndef _get_protocol_attrs(cls):\n    \"\"\"Collect protocol members from a protocol class objects.\n\n    This includes names actually defined in the class dictionary, as well\n    as names that appear in annotations. Special names (above) are skipped.\n    \"\"\"\n    attrs = set()\n    for base in cls.__mro__[:-1]:  # without object\n        if base.__name__ in ('Protocol', 'Generic'):\n            continue\n        annotations = getattr(base, '__annotations__', {})\n        for attr in list(base.__dict__.keys()) + list(annotations.keys()):\n            if not attr.startswith('_abc_') and attr not in EXCLUDED_ATTRIBUTES:\n                attrs.add(attr)\n    return attrs\n\n\ndef _is_callable_members_only(cls):\n    # PEP 544 prohibits using issubclass() with protocols that have non-method members.\n    return all(callable(getattr(cls, attr, None)) for attr in _get_protocol_attrs(cls))\n\n\ndef _no_init_or_replace_init(self, *args, **kwargs):\n    cls = type(self)\n\n    if cls._is_protocol:\n        raise TypeError('Protocols cannot be instantiated')\n\n    # Already using a custom `__init__`. No need to calculate correct\n    # `__init__` to call. This can lead to RecursionError. See bpo-45121.\n    if cls.__init__ is not _no_init_or_replace_init:\n        return\n\n    # Initially, `__init__` of a protocol subclass is set to `_no_init_or_replace_init`.\n    # The first instantiation of the subclass will call `_no_init_or_replace_init` which\n    # searches for a proper new `__init__` in the MRO. The new `__init__`\n    # replaces the subclass' old `__init__` (ie `_no_init_or_replace_init`). Subsequent\n    # instantiation of the protocol subclass will thus use the new\n    # `__init__` and no longer call `_no_init_or_replace_init`.\n    for base in cls.__mro__:\n        init = base.__dict__.get('__init__', _no_init_or_replace_init)\n        if init is not _no_init_or_replace_init:\n            cls.__init__ = init\n            break\n    else:\n        # should not happen\n        cls.__init__ = object.__init__\n\n    cls.__init__(self, *args, **kwargs)\n\n\n\ndef _allow_reckless_class_cheks():\n    \"\"\"Allow instance and class checks for special stdlib modules.\n\n    The abc and functools modules indiscriminately call isinstance() and\n    issubclass() on the whole MRO of a user class, which may contain protocols.\n    \"\"\"\n    try:\n        return sys._getframe(3).f_globals['__name__'] in ['abc', 'functools']\n    except (AttributeError, ValueError):  # For platforms without _getframe().\n        return True\n\n\n_PROTO_WHITELIST = {\n    'collections.abc': [\n        'Callable', 'Awaitable', 'Iterable', 'Iterator', 'AsyncIterable',\n        'Hashable', 'Sized', 'Container', 'Collection', 'Reversible',\n    ],\n    'contextlib': ['AbstractContextManager', 'AbstractAsyncContextManager'],\n}\n\n\nclass _ProtocolMeta(ABCMeta):\n    # This metaclass is really unfortunate and exists only because of\n    # the lack of __instancehook__.\n    def __instancecheck__(cls, instance):\n        # We need this method for situations where attributes are\n        # assigned in __init__.\n        if ((not getattr(cls, '_is_protocol', False) or\n                _is_callable_members_only(cls)) and\n                issubclass(instance.__class__, cls)):\n            return True\n        if cls._is_protocol:\n            if all(hasattr(instance, attr) and\n                    # All *methods* can be blocked by setting them to None.\n                    (not callable(getattr(cls, attr, None)) or\n                     getattr(instance, attr) is not None)\n                    for attr in _get_protocol_attrs(cls)):\n                return True\n        return super().__instancecheck__(instance)\n\n\nclass Protocol(Generic, metaclass=_ProtocolMeta):\n    \"\"\"Base class for protocol classes.\n\n    Protocol classes are defined as::\n\n        class Proto(Protocol):\n            def meth(self) -> int:\n                ...\n\n    Such classes are primarily used with static type checkers that recognize\n    structural subtyping (static duck-typing), for example::\n\n        class C:\n            def meth(self) -> int:\n                return 0\n\n        def func(x: Proto) -> int:\n            return x.meth()\n\n        func(C())  # Passes static type check\n\n    See PEP 544 for details. Protocol classes decorated with\n    @typing.runtime_checkable act as simple-minded runtime protocols that check\n    only the presence of given attributes, ignoring their type signatures.\n    Protocol classes can be generic, they are defined as::\n\n        class GenProto(Protocol[T]):\n            def meth(self) -> T:\n                ...\n    \"\"\"\n    __slots__ = ()\n    _is_protocol = True\n    _is_runtime_protocol = False\n\n    def __init_subclass__(cls, *args, **kwargs):\n        super().__init_subclass__(*args, **kwargs)\n\n        # Determine if this is a protocol or a concrete subclass.\n        if not cls.__dict__.get('_is_protocol', False):\n            cls._is_protocol = any(b is Protocol for b in cls.__bases__)\n\n        # Set (or override) the protocol subclass hook.\n        def _proto_hook(other):\n            if not cls.__dict__.get('_is_protocol', False):\n                return NotImplemented\n\n            # First, perform various sanity checks.\n            if not getattr(cls, '_is_runtime_protocol', False):\n                if _allow_reckless_class_cheks():\n                    return NotImplemented\n                raise TypeError(\"Instance and class checks can only be used with\"\n                                \" @runtime_checkable protocols\")\n            if not _is_callable_members_only(cls):\n                if _allow_reckless_class_cheks():\n                    return NotImplemented\n                raise TypeError(\"Protocols with non-method members\"\n                                \" don't support issubclass()\")\n            if not isinstance(other, type):\n                # Same error message as for issubclass(1, int).\n                raise TypeError('issubclass() arg 1 must be a class')\n\n            # Second, perform the actual structural compatibility check.\n            for attr in _get_protocol_attrs(cls):\n                for base in other.__mro__:\n                    # Check if the members appears in the class dictionary...\n                    if attr in base.__dict__:\n                        if base.__dict__[attr] is None:\n                            return NotImplemented\n                        break\n\n                    # ...or in annotations, if it is a sub-protocol.\n                    annotations = getattr(base, '__annotations__', {})\n                    if (isinstance(annotations, collections.abc.Mapping) and\n                            attr in annotations and\n                            issubclass(other, Generic) and other._is_protocol):\n                        break\n                else:\n                    return NotImplemented\n            return True\n\n        if '__subclasshook__' not in cls.__dict__:\n            cls.__subclasshook__ = _proto_hook\n\n        # We have nothing more to do for non-protocols...\n        if not cls._is_protocol:\n            return\n\n        # ... otherwise check consistency of bases, and prohibit instantiation.\n        for base in cls.__bases__:\n            if not (base in (object, Generic) or\n                    base.__module__ in _PROTO_WHITELIST and\n                    base.__name__ in _PROTO_WHITELIST[base.__module__] or\n                    issubclass(base, Generic) and base._is_protocol):\n                raise TypeError('Protocols can only inherit from other'\n                                ' protocols, got %r' % base)\n        cls.__init__ = _no_init_or_replace_init\n\n\nclass _AnnotatedAlias(_GenericAlias, _root=True):\n    \"\"\"Runtime representation of an annotated type.\n\n    At its core 'Annotated[t, dec1, dec2, ...]' is an alias for the type 't'\n    with extra annotations. The alias behaves like a normal typing alias,\n    instantiating is the same as instantiating the underlying type, binding\n    it to types is also the same.\n    \"\"\"\n    def __init__(self, origin, metadata):\n        if isinstance(origin, _AnnotatedAlias):\n            metadata = origin.__metadata__ + metadata\n            origin = origin.__origin__\n        super().__init__(origin, origin)\n        self.__metadata__ = metadata\n\n    def copy_with(self, params):\n        assert len(params) == 1\n        new_type = params[0]\n        return _AnnotatedAlias(new_type, self.__metadata__)\n\n    def __repr__(self):\n        return \"typing.Annotated[{}, {}]\".format(\n            _type_repr(self.__origin__),\n            \", \".join(repr(a) for a in self.__metadata__)\n        )\n\n    def __reduce__(self):\n        return operator.getitem, (\n            Annotated, (self.__origin__,) + self.__metadata__\n        )\n\n    def __eq__(self, other):\n        if not isinstance(other, _AnnotatedAlias):\n            return NotImplemented\n        return (self.__origin__ == other.__origin__\n                and self.__metadata__ == other.__metadata__)\n\n    def __hash__(self):\n        return hash((self.__origin__, self.__metadata__))\n\n\nclass Annotated:\n    \"\"\"Add context specific metadata to a type.\n\n    Example: Annotated[int, runtime_check.Unsigned] indicates to the\n    hypothetical runtime_check module that this type is an unsigned int.\n    Every other consumer of this type can ignore this metadata and treat\n    this type as int.\n\n    The first argument to Annotated must be a valid type.\n\n    Details:\n\n    - It's an error to call `Annotated` with less than two arguments.\n    - Nested Annotated are flattened::\n\n        Annotated[Annotated[T, Ann1, Ann2], Ann3] == Annotated[T, Ann1, Ann2, Ann3]\n\n    - Instantiating an annotated type is equivalent to instantiating the\n    underlying type::\n\n        Annotated[C, Ann1](5) == C(5)\n\n    - Annotated can be used as a generic type alias::\n\n        Optimized = Annotated[T, runtime.Optimize()]\n        Optimized[int] == Annotated[int, runtime.Optimize()]\n\n        OptimizedList = Annotated[List[T], runtime.Optimize()]\n        OptimizedList[int] == Annotated[List[int], runtime.Optimize()]\n    \"\"\"\n\n    __slots__ = ()\n\n    def __new__(cls, *args, **kwargs):\n        raise TypeError(\"Type Annotated cannot be instantiated.\")\n\n    @_tp_cache\n    def __class_getitem__(cls, params):\n        if not isinstance(params, tuple) or len(params) < 2:\n            raise TypeError(\"Annotated[...] should be used \"\n                            \"with at least two arguments (a type and an \"\n                            \"annotation).\")\n        msg = \"Annotated[t, ...]: t must be a type.\"\n        origin = _type_check(params[0], msg)\n        metadata = tuple(params[1:])\n        return _AnnotatedAlias(origin, metadata)\n\n    def __init_subclass__(cls, *args, **kwargs):\n        raise TypeError(\n            \"Cannot subclass {}.Annotated\".format(cls.__module__)\n        )\n\n\ndef runtime_checkable(cls):\n    \"\"\"Mark a protocol class as a runtime protocol.\n\n    Such protocol can be used with isinstance() and issubclass().\n    Raise TypeError if applied to a non-protocol class.\n    This allows a simple-minded structural check very similar to\n    one trick ponies in collections.abc such as Iterable.\n    For example::\n\n        @runtime_checkable\n        class Closable(Protocol):\n            def close(self): ...\n\n        assert isinstance(open('/some/file'), Closable)\n\n    Warning: this will check only the presence of the required methods,\n    not their type signatures!\n    \"\"\"\n    if not issubclass(cls, Generic) or not cls._is_protocol:\n        raise TypeError('@runtime_checkable can be only applied to protocol classes,'\n                        ' got %r' % cls)\n    cls._is_runtime_protocol = True\n    return cls\n\n\ndef cast(typ, val):\n    \"\"\"Cast a value to a type.\n\n    This returns the value unchanged.  To the type checker this\n    signals that the return value has the designated type, but at\n    runtime we intentionally don't check anything (we want this\n    to be as fast as possible).\n    \"\"\"\n    return val\n\n\ndef _get_defaults(func):\n    \"\"\"Internal helper to extract the default arguments, by name.\"\"\"\n    try:\n        code = func.__code__\n    except AttributeError:\n        # Some built-in functions don't have __code__, __defaults__, etc.\n        return {}\n    pos_count = code.co_argcount\n    arg_names = code.co_varnames\n    arg_names = arg_names[:pos_count]\n    defaults = func.__defaults__ or ()\n    kwdefaults = func.__kwdefaults__\n    res = dict(kwdefaults) if kwdefaults else {}\n    pos_offset = pos_count - len(defaults)\n    for name, value in zip(arg_names[pos_offset:], defaults):\n        assert name not in res\n        res[name] = value\n    return res\n\n\n_allowed_types = (types.FunctionType, types.BuiltinFunctionType,\n                  types.MethodType, types.ModuleType,\n                  WrapperDescriptorType, MethodWrapperType, MethodDescriptorType)\n\n\ndef get_type_hints(obj, globalns=None, localns=None, include_extras=False):\n    \"\"\"Return type hints for an object.\n\n    This is often the same as obj.__annotations__, but it handles\n    forward references encoded as string literals, adds Optional[t] if a\n    default value equal to None is set and recursively replaces all\n    'Annotated[T, ...]' with 'T' (unless 'include_extras=True').\n\n    The argument may be a module, class, method, or function. The annotations\n    are returned as a dictionary. For classes, annotations include also\n    inherited members.\n\n    TypeError is raised if the argument is not of a type that can contain\n    annotations, and an empty dictionary is returned if no annotations are\n    present.\n\n    BEWARE -- the behavior of globalns and localns is counterintuitive\n    (unless you are familiar with how eval() and exec() work).  The\n    search order is locals first, then globals.\n\n    - If no dict arguments are passed, an attempt is made to use the\n      globals from obj (or the respective module's globals for classes),\n      and these are also used as the locals.  If the object does not appear\n      to have globals, an empty dictionary is used.\n\n    - If one dict argument is passed, it is used for both globals and\n      locals.\n\n    - If two dict arguments are passed, they specify globals and\n      locals, respectively.\n    \"\"\"\n\n    if getattr(obj, '__no_type_check__', None):\n        return {}\n    # Classes require a special treatment.\n    if isinstance(obj, type):\n        hints = {}\n        for base in reversed(obj.__mro__):\n            if globalns is None:\n                base_globals = sys.modules[base.__module__].__dict__\n            else:\n                base_globals = globalns\n            ann = base.__dict__.get('__annotations__', {})\n            for name, value in ann.items():\n                if value is None:\n                    value = type(None)\n                if isinstance(value, str):\n                    value = ForwardRef(value, is_argument=False, is_class=True)\n                value = _eval_type(value, base_globals, localns)\n                hints[name] = value\n        return hints if include_extras else {k: _strip_annotations(t) for k, t in hints.items()}\n\n    if globalns is None:\n        if isinstance(obj, types.ModuleType):\n            globalns = obj.__dict__\n        else:\n            nsobj = obj\n            # Find globalns for the unwrapped object.\n            while hasattr(nsobj, '__wrapped__'):\n                nsobj = nsobj.__wrapped__\n            globalns = getattr(nsobj, '__globals__', {})\n        if localns is None:\n            localns = globalns\n    elif localns is None:\n        localns = globalns\n    hints = getattr(obj, '__annotations__', None)\n    if hints is None:\n        # Return empty annotations for something that _could_ have them.\n        if isinstance(obj, _allowed_types):\n            return {}\n        else:\n            raise TypeError('{!r} is not a module, class, method, '\n                            'or function.'.format(obj))\n    defaults = _get_defaults(obj)\n    hints = dict(hints)\n    for name, value in hints.items():\n        if value is None:\n            value = type(None)\n        if isinstance(value, str):\n            # class-level forward refs were handled above, this must be either\n            # a module-level annotation or a function argument annotation\n            value = ForwardRef(\n                value,\n                is_argument=not isinstance(obj, types.ModuleType),\n                is_class=False,\n            )\n        value = _eval_type(value, globalns, localns)\n        if name in defaults and defaults[name] is None:\n            value = Optional[value]\n        hints[name] = value\n    return hints if include_extras else {k: _strip_annotations(t) for k, t in hints.items()}\n\n\ndef _strip_annotations(t):\n    \"\"\"Strips the annotations from a given type.\n    \"\"\"\n    if isinstance(t, _AnnotatedAlias):\n        return _strip_annotations(t.__origin__)\n    if isinstance(t, _GenericAlias):\n        stripped_args = tuple(_strip_annotations(a) for a in t.__args__)\n        if stripped_args == t.__args__:\n            return t\n        return t.copy_with(stripped_args)\n    if isinstance(t, GenericAlias):\n        stripped_args = tuple(_strip_annotations(a) for a in t.__args__)\n        if stripped_args == t.__args__:\n            return t\n        return GenericAlias(t.__origin__, stripped_args)\n    return t\n\n\ndef get_origin(tp):\n    \"\"\"Get the unsubscripted version of a type.\n\n    This supports generic types, Callable, Tuple, Union, Literal, Final, ClassVar\n    and Annotated. Return None for unsupported types. Examples::\n\n        get_origin(Literal[42]) is Literal\n        get_origin(int) is None\n        get_origin(ClassVar[int]) is ClassVar\n        get_origin(Generic) is Generic\n        get_origin(Generic[T]) is Generic\n        get_origin(Union[T, int]) is Union\n        get_origin(List[Tuple[T, T]][int]) == list\n    \"\"\"\n    if isinstance(tp, _AnnotatedAlias):\n        return Annotated\n    if isinstance(tp, (_BaseGenericAlias, GenericAlias)):\n        return tp.__origin__\n    if tp is Generic:\n        return Generic\n    return None\n\n\ndef get_args(tp):\n    \"\"\"Get type arguments with all substitutions performed.\n\n    For unions, basic simplifications used by Union constructor are performed.\n    Examples::\n        get_args(Dict[str, int]) == (str, int)\n        get_args(int) == ()\n        get_args(Union[int, Union[T, int], str][int]) == (int, str)\n        get_args(Union[int, Tuple[T, int]][str]) == (int, Tuple[str, int])\n        get_args(Callable[[], T][int]) == ([], int)\n    \"\"\"\n    if isinstance(tp, _AnnotatedAlias):\n        return (tp.__origin__,) + tp.__metadata__\n    if isinstance(tp, (_GenericAlias, GenericAlias)):\n        res = tp.__args__\n        if tp.__origin__ is collections.abc.Callable and res[0] is not Ellipsis:\n            res = (list(res[:-1]), res[-1])\n        return res\n    return ()\n\n\ndef no_type_check(arg):\n    \"\"\"Decorator to indicate that annotations are not type hints.\n\n    The argument must be a class or function; if it is a class, it\n    applies recursively to all methods and classes defined in that class\n    (but not to methods defined in its superclasses or subclasses).\n\n    This mutates the function(s) or class(es) in place.\n    \"\"\"\n    if isinstance(arg, type):\n        arg_attrs = arg.__dict__.copy()\n        for attr, val in arg.__dict__.items():\n            if val in arg.__bases__ + (arg,):\n                arg_attrs.pop(attr)\n        for obj in arg_attrs.values():\n            if isinstance(obj, types.FunctionType):\n                obj.__no_type_check__ = True\n            if isinstance(obj, type):\n                no_type_check(obj)\n    try:\n        arg.__no_type_check__ = True\n    except TypeError:  # built-in classes\n        pass\n    return arg\n\n\ndef no_type_check_decorator(decorator):\n    \"\"\"Decorator to give another decorator the @no_type_check effect.\n\n    This wraps the decorator with something that wraps the decorated\n    function in @no_type_check.\n    \"\"\"\n\n    @functools.wraps(decorator)\n    def wrapped_decorator(*args, **kwds):\n        func = decorator(*args, **kwds)\n        func = no_type_check(func)\n        return func\n\n    return wrapped_decorator\n\n\ndef _overload_dummy(*args, **kwds):\n    \"\"\"Helper for @overload to raise when called.\"\"\"\n    raise NotImplementedError(\n        \"You should not call an overloaded function. \"\n        \"A series of @overload-decorated functions \"\n        \"outside a stub module should always be followed \"\n        \"by an implementation that is not @overload-ed.\")\n\n\ndef overload(func):\n    \"\"\"Decorator for overloaded functions/methods.\n\n    In a stub file, place two or more stub definitions for the same\n    function in a row, each decorated with @overload.  For example:\n\n      @overload\n      def utf8(value: None) -> None: ...\n      @overload\n      def utf8(value: bytes) -> bytes: ...\n      @overload\n      def utf8(value: str) -> bytes: ...\n\n    In a non-stub file (i.e. a regular .py file), do the same but\n    follow it with an implementation.  The implementation should *not*\n    be decorated with @overload.  For example:\n\n      @overload\n      def utf8(value: None) -> None: ...\n      @overload\n      def utf8(value: bytes) -> bytes: ...\n      @overload\n      def utf8(value: str) -> bytes: ...\n      def utf8(value):\n          # implementation goes here\n    \"\"\"\n    return _overload_dummy\n\n\ndef final(f):\n    \"\"\"A decorator to indicate final methods and final classes.\n\n    Use this decorator to indicate to type checkers that the decorated\n    method cannot be overridden, and decorated class cannot be subclassed.\n    For example:\n\n      class Base:\n          @final\n          def done(self) -> None:\n              ...\n      class Sub(Base):\n          def done(self) -> None:  # Error reported by type checker\n                ...\n\n      @final\n      class Leaf:\n          ...\n      class Other(Leaf):  # Error reported by type checker\n          ...\n\n    There is no runtime checking of these properties.\n    \"\"\"\n    return f\n\n\n# Some unconstrained type variables.  These are used by the container types.\n# (These are not for export.)\nT = TypeVar('T')  # Any type.\nKT = TypeVar('KT')  # Key type.\nVT = TypeVar('VT')  # Value type.\nT_co = TypeVar('T_co', covariant=True)  # Any type covariant containers.\nV_co = TypeVar('V_co', covariant=True)  # Any type covariant containers.\nVT_co = TypeVar('VT_co', covariant=True)  # Value type covariant containers.\nT_contra = TypeVar('T_contra', contravariant=True)  # Ditto contravariant.\n# Internal type variable used for Type[].\nCT_co = TypeVar('CT_co', covariant=True, bound=type)\n\n# A useful type variable with constraints.  This represents string types.\n# (This one *is* for export!)\nAnyStr = TypeVar('AnyStr', bytes, str)\n\n\n# Various ABCs mimicking those in collections.abc.\n_alias = _SpecialGenericAlias\n\nHashable = _alias(collections.abc.Hashable, 0)  # Not generic.\nAwaitable = _alias(collections.abc.Awaitable, 1)\nCoroutine = _alias(collections.abc.Coroutine, 3)\nAsyncIterable = _alias(collections.abc.AsyncIterable, 1)\nAsyncIterator = _alias(collections.abc.AsyncIterator, 1)\nIterable = _alias(collections.abc.Iterable, 1)\nIterator = _alias(collections.abc.Iterator, 1)\nReversible = _alias(collections.abc.Reversible, 1)\nSized = _alias(collections.abc.Sized, 0)  # Not generic.\nContainer = _alias(collections.abc.Container, 1)\nCollection = _alias(collections.abc.Collection, 1)\nCallable = _CallableType(collections.abc.Callable, 2)\nCallable.__doc__ = \\\n    \"\"\"Callable type; Callable[[int], str] is a function of (int) -> str.\n\n    The subscription syntax must always be used with exactly two\n    values: the argument list and the return type.  The argument list\n    must be a list of types or ellipsis; the return type must be a single type.\n\n    There is no syntax to indicate optional or keyword arguments,\n    such function types are rarely used as callback types.\n    \"\"\"\nAbstractSet = _alias(collections.abc.Set, 1, name='AbstractSet')\nMutableSet = _alias(collections.abc.MutableSet, 1)\n# NOTE: Mapping is only covariant in the value type.\nMapping = _alias(collections.abc.Mapping, 2)\nMutableMapping = _alias(collections.abc.MutableMapping, 2)\nSequence = _alias(collections.abc.Sequence, 1)\nMutableSequence = _alias(collections.abc.MutableSequence, 1)\nByteString = _alias(collections.abc.ByteString, 0)  # Not generic\n# Tuple accepts variable number of parameters.\nTuple = _TupleType(tuple, -1, inst=False, name='Tuple')\nTuple.__doc__ = \\\n    \"\"\"Tuple type; Tuple[X, Y] is the cross-product type of X and Y.\n\n    Example: Tuple[T1, T2] is a tuple of two elements corresponding\n    to type variables T1 and T2.  Tuple[int, float, str] is a tuple\n    of an int, a float and a string.\n\n    To specify a variable-length tuple of homogeneous type, use Tuple[T, ...].\n    \"\"\"\nList = _alias(list, 1, inst=False, name='List')\nDeque = _alias(collections.deque, 1, name='Deque')\nSet = _alias(set, 1, inst=False, name='Set')\nFrozenSet = _alias(frozenset, 1, inst=False, name='FrozenSet')\nMappingView = _alias(collections.abc.MappingView, 1)\nKeysView = _alias(collections.abc.KeysView, 1)\nItemsView = _alias(collections.abc.ItemsView, 2)\nValuesView = _alias(collections.abc.ValuesView, 1)\nContextManager = _alias(contextlib.AbstractContextManager, 1, name='ContextManager')\nAsyncContextManager = _alias(contextlib.AbstractAsyncContextManager, 1, name='AsyncContextManager')\nDict = _alias(dict, 2, inst=False, name='Dict')\nDefaultDict = _alias(collections.defaultdict, 2, name='DefaultDict')\nOrderedDict = _alias(collections.OrderedDict, 2)\nCounter = _alias(collections.Counter, 1)\nChainMap = _alias(collections.ChainMap, 2)\nGenerator = _alias(collections.abc.Generator, 3)\nAsyncGenerator = _alias(collections.abc.AsyncGenerator, 2)\nType = _alias(type, 1, inst=False, name='Type')\nType.__doc__ = \\\n    \"\"\"A special construct usable to annotate class objects.\n\n    For example, suppose we have the following classes::\n\n      class User: ...  # Abstract base for User classes\n      class BasicUser(User): ...\n      class ProUser(User): ...\n      class TeamUser(User): ...\n\n    And a function that takes a class argument that's a subclass of\n    User and returns an instance of the corresponding class::\n\n      U = TypeVar('U', bound=User)\n      def new_user(user_class: Type[U]) -> U:\n          user = user_class()\n          # (Here we could write the user object to a database)\n          return user\n\n      joe = new_user(BasicUser)\n\n    At this point the type checker knows that joe has type BasicUser.\n    \"\"\"\n\n\n@runtime_checkable\nclass SupportsInt(Protocol):\n    \"\"\"An ABC with one abstract method __int__.\"\"\"\n    __slots__ = ()\n\n    @abstractmethod\n    def __int__(self) -> int:\n        pass\n\n\n@runtime_checkable\nclass SupportsFloat(Protocol):\n    \"\"\"An ABC with one abstract method __float__.\"\"\"\n    __slots__ = ()\n\n    @abstractmethod\n    def __float__(self) -> float:\n        pass\n\n\n@runtime_checkable\nclass SupportsComplex(Protocol):\n    \"\"\"An ABC with one abstract method __complex__.\"\"\"\n    __slots__ = ()\n\n    @abstractmethod\n    def __complex__(self) -> complex:\n        pass\n\n\n@runtime_checkable\nclass SupportsBytes(Protocol):\n    \"\"\"An ABC with one abstract method __bytes__.\"\"\"\n    __slots__ = ()\n\n    @abstractmethod\n    def __bytes__(self) -> bytes:\n        pass\n\n\n@runtime_checkable\nclass SupportsIndex(Protocol):\n    \"\"\"An ABC with one abstract method __index__.\"\"\"\n    __slots__ = ()\n\n    @abstractmethod\n    def __index__(self) -> int:\n        pass\n\n\n@runtime_checkable\nclass SupportsAbs(Protocol[T_co]):\n    \"\"\"An ABC with one abstract method __abs__ that is covariant in its return type.\"\"\"\n    __slots__ = ()\n\n    @abstractmethod\n    def __abs__(self) -> T_co:\n        pass\n\n\n@runtime_checkable\nclass SupportsRound(Protocol[T_co]):\n    \"\"\"An ABC with one abstract method __round__ that is covariant in its return type.\"\"\"\n    __slots__ = ()\n\n    @abstractmethod\n    def __round__(self, ndigits: int = 0) -> T_co:\n        pass\n\n\ndef _make_nmtuple(name, types, module, defaults = ()):\n    fields = [n for n, t in types]\n    types = {n: _type_check(t, f\"field {n} annotation must be a type\")\n             for n, t in types}\n    nm_tpl = collections.namedtuple(name, fields,\n                                    defaults=defaults, module=module)\n    nm_tpl.__annotations__ = nm_tpl.__new__.__annotations__ = types\n    return nm_tpl\n\n\n# attributes prohibited to set in NamedTuple class syntax\n_prohibited = frozenset({'__new__', '__init__', '__slots__', '__getnewargs__',\n                         '_fields', '_field_defaults',\n                         '_make', '_replace', '_asdict', '_source'})\n\n_special = frozenset({'__module__', '__name__', '__annotations__'})\n\n\nclass NamedTupleMeta(type):\n\n    def __new__(cls, typename, bases, ns):\n        assert bases[0] is _NamedTuple\n        types = ns.get('__annotations__', {})\n        default_names = []\n        for field_name in types:\n            if field_name in ns:\n                default_names.append(field_name)\n            elif default_names:\n                raise TypeError(f\"Non-default namedtuple field {field_name} \"\n                                f\"cannot follow default field\"\n                                f\"{'s' if len(default_names) > 1 else ''} \"\n                                f\"{', '.join(default_names)}\")\n        nm_tpl = _make_nmtuple(typename, types.items(),\n                               defaults=[ns[n] for n in default_names],\n                               module=ns['__module__'])\n        # update from user namespace without overriding special namedtuple attributes\n        for key in ns:\n            if key in _prohibited:\n                raise AttributeError(\"Cannot overwrite NamedTuple attribute \" + key)\n            elif key not in _special and key not in nm_tpl._fields:\n                setattr(nm_tpl, key, ns[key])\n        return nm_tpl\n\n\ndef NamedTuple(typename, fields=None, /, **kwargs):\n    \"\"\"Typed version of namedtuple.\n\n    Usage in Python versions >= 3.6::\n\n        class Employee(NamedTuple):\n            name: str\n            id: int\n\n    This is equivalent to::\n\n        Employee = collections.namedtuple('Employee', ['name', 'id'])\n\n    The resulting class has an extra __annotations__ attribute, giving a\n    dict that maps field names to types.  (The field names are also in\n    the _fields attribute, which is part of the namedtuple API.)\n    Alternative equivalent keyword syntax is also accepted::\n\n        Employee = NamedTuple('Employee', name=str, id=int)\n\n    In Python versions <= 3.5 use::\n\n        Employee = NamedTuple('Employee', [('name', str), ('id', int)])\n    \"\"\"\n    if fields is None:\n        fields = kwargs.items()\n    elif kwargs:\n        raise TypeError(\"Either list of fields or keywords\"\n                        \" can be provided to NamedTuple, not both\")\n    try:\n        module = sys._getframe(1).f_globals.get('__name__', '__main__')\n    except (AttributeError, ValueError):\n        module = None\n    return _make_nmtuple(typename, fields, module=module)\n\n_NamedTuple = type.__new__(NamedTupleMeta, 'NamedTuple', (), {})\n\ndef _namedtuple_mro_entries(bases):\n    if len(bases) > 1:\n        raise TypeError(\"Multiple inheritance with NamedTuple is not supported\")\n    assert bases[0] is NamedTuple\n    return (_NamedTuple,)\n\nNamedTuple.__mro_entries__ = _namedtuple_mro_entries\n\n\nclass _TypedDictMeta(type):\n    def __new__(cls, name, bases, ns, total=True):\n        \"\"\"Create new typed dict class object.\n\n        This method is called when TypedDict is subclassed,\n        or when TypedDict is instantiated. This way\n        TypedDict supports all three syntax forms described in its docstring.\n        Subclasses and instances of TypedDict return actual dictionaries.\n        \"\"\"\n        for base in bases:\n            if type(base) is not _TypedDictMeta:\n                raise TypeError('cannot inherit from both a TypedDict type '\n                                'and a non-TypedDict base class')\n        tp_dict = type.__new__(_TypedDictMeta, name, (dict,), ns)\n\n        annotations = {}\n        own_annotations = ns.get('__annotations__', {})\n        own_annotation_keys = set(own_annotations.keys())\n        msg = \"TypedDict('Name', {f0: t0, f1: t1, ...}); each t must be a type\"\n        own_annotations = {\n            n: _type_check(tp, msg, module=tp_dict.__module__)\n            for n, tp in own_annotations.items()\n        }\n        required_keys = set()\n        optional_keys = set()\n\n        for base in bases:\n            annotations.update(base.__dict__.get('__annotations__', {}))\n            required_keys.update(base.__dict__.get('__required_keys__', ()))\n            optional_keys.update(base.__dict__.get('__optional_keys__', ()))\n\n        annotations.update(own_annotations)\n        if total:\n            required_keys.update(own_annotation_keys)\n        else:\n            optional_keys.update(own_annotation_keys)\n\n        tp_dict.__annotations__ = annotations\n        tp_dict.__required_keys__ = frozenset(required_keys)\n        tp_dict.__optional_keys__ = frozenset(optional_keys)\n        if not hasattr(tp_dict, '__total__'):\n            tp_dict.__total__ = total\n        return tp_dict\n\n    __call__ = dict  # static method\n\n    def __subclasscheck__(cls, other):\n        # Typed dicts are only for static structural subtyping.\n        raise TypeError('TypedDict does not support instance and class checks')\n\n    __instancecheck__ = __subclasscheck__\n\n\ndef TypedDict(typename, fields=None, /, *, total=True, **kwargs):\n    \"\"\"A simple typed namespace. At runtime it is equivalent to a plain dict.\n\n    TypedDict creates a dictionary type that expects all of its\n    instances to have a certain set of keys, where each key is\n    associated with a value of a consistent type. This expectation\n    is not checked at runtime but is only enforced by type checkers.\n    Usage::\n\n        class Point2D(TypedDict):\n            x: int\n            y: int\n            label: str\n\n        a: Point2D = {'x': 1, 'y': 2, 'label': 'good'}  # OK\n        b: Point2D = {'z': 3, 'label': 'bad'}           # Fails type check\n\n        assert Point2D(x=1, y=2, label='first') == dict(x=1, y=2, label='first')\n\n    The type info can be accessed via the Point2D.__annotations__ dict, and\n    the Point2D.__required_keys__ and Point2D.__optional_keys__ frozensets.\n    TypedDict supports two additional equivalent forms::\n\n        Point2D = TypedDict('Point2D', x=int, y=int, label=str)\n        Point2D = TypedDict('Point2D', {'x': int, 'y': int, 'label': str})\n\n    By default, all keys must be present in a TypedDict. It is possible\n    to override this by specifying totality.\n    Usage::\n\n        class point2D(TypedDict, total=False):\n            x: int\n            y: int\n\n    This means that a point2D TypedDict can have any of the keys omitted.A type\n    checker is only expected to support a literal False or True as the value of\n    the total argument. True is the default, and makes all items defined in the\n    class body be required.\n\n    The class syntax is only supported in Python 3.6+, while two other\n    syntax forms work for Python 2.7 and 3.2+\n    \"\"\"\n    if fields is None:\n        fields = kwargs\n    elif kwargs:\n        raise TypeError(\"TypedDict takes either a dict or keyword arguments,\"\n                        \" but not both\")\n\n    ns = {'__annotations__': dict(fields)}\n    try:\n        # Setting correct module is necessary to make typed dict classes pickleable.\n        ns['__module__'] = sys._getframe(1).f_globals.get('__name__', '__main__')\n    except (AttributeError, ValueError):\n        pass\n\n    return _TypedDictMeta(typename, (), ns, total=total)\n\n_TypedDict = type.__new__(_TypedDictMeta, 'TypedDict', (), {})\nTypedDict.__mro_entries__ = lambda bases: (_TypedDict,)\n\n\ndef NewType(name, tp):\n    \"\"\"NewType creates simple unique types with almost zero\n    runtime overhead. NewType(name, tp) is considered a subtype of tp\n    by static type checkers. At runtime, NewType(name, tp) returns\n    a dummy function that simply returns its argument. Usage::\n\n        UserId = NewType('UserId', int)\n\n        def name_by_id(user_id: UserId) -> str:\n            ...\n\n        UserId('user')          # Fails type check\n\n        name_by_id(42)          # Fails type check\n        name_by_id(UserId(42))  # OK\n\n        num = UserId(5) + 1     # type: int\n    \"\"\"\n\n    def new_type(x):\n        return x\n\n    new_type.__name__ = name\n    new_type.__supertype__ = tp\n    return new_type\n\n\n# Python-version-specific alias (Python 2: unicode; Python 3: str)\nText = str\n\n\n# Constant that's True when type checking, but False here.\nTYPE_CHECKING = False\n\n\nclass IO(Generic[AnyStr]):\n    \"\"\"Generic base class for TextIO and BinaryIO.\n\n    This is an abstract, generic version of the return of open().\n\n    NOTE: This does not distinguish between the different possible\n    classes (text vs. binary, read vs. write vs. read/write,\n    append-only, unbuffered).  The TextIO and BinaryIO subclasses\n    below capture the distinctions between text vs. binary, which is\n    pervasive in the interface; however we currently do not offer a\n    way to track the other distinctions in the type system.\n    \"\"\"\n\n    __slots__ = ()\n\n    @property\n    @abstractmethod\n    def mode(self) -> str:\n        pass\n\n    @property\n    @abstractmethod\n    def name(self) -> str:\n        pass\n\n    @abstractmethod\n    def close(self) -> None:\n        pass\n\n    @property\n    @abstractmethod\n    def closed(self) -> bool:\n        pass\n\n    @abstractmethod\n    def fileno(self) -> int:\n        pass\n\n    @abstractmethod\n    def flush(self) -> None:\n        pass\n\n    @abstractmethod\n    def isatty(self) -> bool:\n        pass\n\n    @abstractmethod\n    def read(self, n: int = -1) -> AnyStr:\n        pass\n\n    @abstractmethod\n    def readable(self) -> bool:\n        pass\n\n    @abstractmethod\n    def readline(self, limit: int = -1) -> AnyStr:\n        pass\n\n    @abstractmethod\n    def readlines(self, hint: int = -1) -> List[AnyStr]:\n        pass\n\n    @abstractmethod\n    def seek(self, offset: int, whence: int = 0) -> int:\n        pass\n\n    @abstractmethod\n    def seekable(self) -> bool:\n        pass\n\n    @abstractmethod\n    def tell(self) -> int:\n        pass\n\n    @abstractmethod\n    def truncate(self, size: int = None) -> int:\n        pass\n\n    @abstractmethod\n    def writable(self) -> bool:\n        pass\n\n    @abstractmethod\n    def write(self, s: AnyStr) -> int:\n        pass\n\n    @abstractmethod\n    def writelines(self, lines: List[AnyStr]) -> None:\n        pass\n\n    @abstractmethod\n    def __enter__(self) -> 'IO[AnyStr]':\n        pass\n\n    @abstractmethod\n    def __exit__(self, type, value, traceback) -> None:\n        pass\n\n\nclass BinaryIO(IO[bytes]):\n    \"\"\"Typed version of the return of open() in binary mode.\"\"\"\n\n    __slots__ = ()\n\n    @abstractmethod\n    def write(self, s: Union[bytes, bytearray]) -> int:\n        pass\n\n    @abstractmethod\n    def __enter__(self) -> 'BinaryIO':\n        pass\n\n\nclass TextIO(IO[str]):\n    \"\"\"Typed version of the return of open() in text mode.\"\"\"\n\n    __slots__ = ()\n\n    @property\n    @abstractmethod\n    def buffer(self) -> BinaryIO:\n        pass\n\n    @property\n    @abstractmethod\n    def encoding(self) -> str:\n        pass\n\n    @property\n    @abstractmethod\n    def errors(self) -> Optional[str]:\n        pass\n\n    @property\n    @abstractmethod\n    def line_buffering(self) -> bool:\n        pass\n\n    @property\n    @abstractmethod\n    def newlines(self) -> Any:\n        pass\n\n    @abstractmethod\n    def __enter__(self) -> 'TextIO':\n        pass\n\n\nclass io:\n    \"\"\"Wrapper namespace for IO generic classes.\"\"\"\n\n    __all__ = ['IO', 'TextIO', 'BinaryIO']\n    IO = IO\n    TextIO = TextIO\n    BinaryIO = BinaryIO\n\n\nio.__name__ = __name__ + '.io'\nsys.modules[io.__name__] = io\n\nPattern = _alias(stdlib_re.Pattern, 1)\nMatch = _alias(stdlib_re.Match, 1)\n\nclass re:\n    \"\"\"Wrapper namespace for re type aliases.\"\"\"\n\n    __all__ = ['Pattern', 'Match']\n    Pattern = Pattern\n    Match = Match\n\n\nre.__name__ = __name__ + '.re'\nsys.modules[re.__name__] = re\n", 2256], "/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt.py": ["\"\"\" Bayesian Optimization implementation from the thesis by Willemsen \"\"\"\nfrom copy import deepcopy\nfrom random import randint, shuffle\nimport itertools\nimport warnings\nimport time\nfrom typing import Tuple\n\nimport numpy as np\nfrom scipy.stats import norm\n\n# BO imports\ntry:\n    from sklearn.gaussian_process import GaussianProcessRegressor\n    from sklearn.gaussian_process.kernels import ConstantKernel, RBF, Matern\n    from sklearn.exceptions import ConvergenceWarning\n    from skopt.sampler import Lhs\n    bayes_opt_present = True\nexcept ImportError:\n    bayes_opt_present = False\n\nfrom kernel_tuner.strategies import minimize\nfrom kernel_tuner import util\n\nsupported_methods = [\"poi\", \"ei\", \"lcb\", \"lcb-srinivas\", \"multi\", \"multi-advanced\", \"multi-fast\"]\n\n\ndef generate_normalized_param_dicts(tune_params: dict, eps: float) -> Tuple[dict, dict]:\n    \"\"\" Generates normalization and denormalization dictionaries \"\"\"\n    original_to_normalized = dict()\n    normalized_to_original = dict()\n    for param_name in tune_params.keys():\n        original_to_normalized_dict = dict()\n        normalized_to_original_dict = dict()\n        for value_index, value in enumerate(tune_params[param_name]):\n            normalized_value = eps * value_index + 0.5 * eps\n            normalized_to_original_dict[normalized_value] = value\n            original_to_normalized_dict[value] = normalized_value\n        original_to_normalized[param_name] = original_to_normalized_dict\n        normalized_to_original[param_name] = normalized_to_original_dict\n    return original_to_normalized, normalized_to_original\n\n\ndef normalize_parameter_space(param_space: list, tune_params: dict, normalized: dict) -> list:\n    \"\"\" Normalize the parameter space given a normalization dictionary \"\"\"\n    keys = list(tune_params.keys())\n    param_space_normalized = list(tuple(normalized[keys[i]][v] for i, v in enumerate(params)) for params in param_space)\n    return param_space_normalized\n\n\ndef prune_parameter_space(parameter_space, tuning_options, tune_params, normalize_dict):\n    \"\"\" Pruning of the parameter space to remove dimensions that have a constant parameter \"\"\"\n    pruned_tune_params_mask = list()\n    removed_tune_params = list()\n    param_names = list(tune_params.keys())\n    for index, key in enumerate(tune_params.keys()):\n        pruned_tune_params_mask.append(len(tune_params[key]) > 1)\n        if len(tune_params[key]) > 1:\n            removed_tune_params.append(None)\n        else:\n            value = tune_params[key][0]\n            normalized = normalize_dict[param_names[index]][value]\n            removed_tune_params.append(normalized)\n    if 'verbose' in tuning_options and tuning_options.verbose is True and len(tune_params.keys()) != sum(pruned_tune_params_mask):\n        print(f\"Number of parameters (dimensions): {len(tune_params.keys())}, after pruning: {sum(pruned_tune_params_mask)}\")\n    parameter_space = list(tuple(itertools.compress(param_config, pruned_tune_params_mask)) for param_config in parameter_space)\n    return parameter_space, removed_tune_params\n\n\ndef tune(runner, kernel_options, device_options, tuning_options):\n    \"\"\" Find the best performing kernel configuration in the parameter space\n\n    :params runner: A runner from kernel_tuner.runners\n    :type runner: kernel_tuner.runner\n\n    :param kernel_options: A dictionary with all options for the kernel.\n    :type kernel_options: kernel_tuner.interface.Options\n\n    :param device_options: A dictionary with all options for the device\n        on which the kernel should be tuned.\n    :type device_options: kernel_tuner.interface.Options\n\n    :param tuning_options: A dictionary with all options regarding the tuning\n        process. Allows setting hyperparameters via the strategy_options key.\n    :type tuning_options: kernel_tuner.interface.Options\n\n    :returns: A list of dictionaries for executed kernel configurations and their\n        execution times. And a dictionary that contains a information\n        about the hardware/software environment on which the tuning took place.\n    :rtype: list(dict()), dict()\n\n    \"\"\"\n\n    max_fevals = tuning_options.strategy_options.get(\"max_fevals\", 100)\n    prune_parameterspace = tuning_options.strategy_options.get(\"pruneparameterspace\", True)\n    if not bayes_opt_present:\n        raise ImportError(\"Error: optional dependencies for Bayesian Optimization not installed, please install scikit-learn and scikit-optimize\")\n\n    # epsilon for scaling should be the evenly spaced distance between the largest set of parameter options in an interval [0,1]\n    tune_params = tuning_options.tune_params\n    tuning_options[\"scaling\"] = True\n    _, _, eps = minimize.get_bounds_x0_eps(tuning_options)\n\n    # compute cartesian product of all tunable parameters\n    parameter_space = itertools.product(*tune_params.values())\n\n    # check for search space restrictions\n    if tuning_options.restrictions is not None:\n        tuning_options.verbose = False\n    parameter_space = filter(lambda p: util.config_valid(p, tuning_options, runner.dev.max_threads), parameter_space)\n    parameter_space = list(parameter_space)\n    if len(parameter_space) < 1:\n        raise ValueError(\"Empty parameterspace after restrictionscheck. Restrictionscheck is possibly too strict.\")\n    if len(parameter_space) == 1:\n        raise ValueError(f\"Only one configuration after restrictionscheck. Restrictionscheck is possibly too strict. Configuration: {parameter_space[0]}\")\n\n    # normalize search space to [0,1]\n    normalize_dict, denormalize_dict = generate_normalized_param_dicts(tune_params, eps)\n    parameter_space = normalize_parameter_space(parameter_space, tune_params, normalize_dict)\n\n    # prune the parameter space to remove dimensions that have a constant parameter\n    if prune_parameterspace:\n        parameter_space, removed_tune_params = prune_parameter_space(parameter_space, tuning_options, tune_params, normalize_dict)\n    else:\n        parameter_space = list(parameter_space)\n        removed_tune_params = [None] * len(tune_params.keys())\n\n    # initialize and optimize\n    bo = BayesianOptimization(parameter_space, removed_tune_params, kernel_options, tuning_options, normalize_dict, denormalize_dict, runner)\n    results = bo.optimize(max_fevals)\n\n    return results, runner.dev.get_environment()\n\n\nclass BayesianOptimization():\n\n    def __init__(self, searchspace: list, removed_tune_params: list, kernel_options: dict, tuning_options: dict, normalize_dict: dict, denormalize_dict: dict,\n                 runner, opt_direction='min'):\n        time_start = time.perf_counter_ns()\n\n        # supported hyperparameter values\n        self.supported_cov_kernels = [\"constantrbf\", \"rbf\", \"matern32\", \"matern52\"]\n        self.supported_methods = supported_methods\n        self.supported_sampling_methods = [\"random\", \"lhs\"]\n        self.supported_sampling_criterion = [\"correlation\", \"ratio\", \"maximin\", None]\n\n        def get_hyperparam(name: str, default, supported_values=list()):\n            value = tuning_options.strategy_options.get(name, default)\n            if len(supported_values) > 0 and value not in supported_values:\n                raise ValueError(f\"'{name}' is set to {value}, but must be one of {supported_values}\")\n            return value\n\n        # get hyperparameters\n        cov_kernel_name = get_hyperparam(\"covariancekernel\", \"matern32\", self.supported_cov_kernels)\n        cov_kernel_lengthscale = get_hyperparam(\"covariancelengthscale\", 1.5)\n        acquisition_function = get_hyperparam(\"method\", \"multi-advanced\", self.supported_methods)\n        acq = acquisition_function\n        acq_params = get_hyperparam(\"methodparams\", {})\n        multi_af_names = get_hyperparam(\"multi_af_names\", ['ei', 'poi', 'lcb'])\n        self.multi_afs_discount_factor = get_hyperparam(\"multi_af_discount_factor\", 0.65 if acq == 'multi' else 0.95)\n        self.multi_afs_required_improvement_factor = get_hyperparam(\"multi_afs_required_improvement_factor\", 0.15 if acq == 'multi-advanced-precise' else 0.1)\n        self.num_initial_samples = get_hyperparam(\"popsize\", 20)\n        self.sampling_method = get_hyperparam(\"samplingmethod\", \"lhs\", self.supported_sampling_methods)\n        self.sampling_crit = get_hyperparam(\"samplingcriterion\", 'maximin', self.supported_sampling_criterion)\n        self.sampling_iter = get_hyperparam(\"samplingiterations\", 1000)\n\n        # set acquisition function hyperparameter defaults where missing\n        if 'explorationfactor' not in acq_params:\n            acq_params['explorationfactor'] = 'CV'\n        if 'zeta' not in acq_params:\n            acq_params['zeta'] = 1\n        if 'skip_duplicate_after' not in acq_params:\n            acq_params['skip_duplicate_after'] = 5\n\n        # set arguments\n        self.kernel_options = kernel_options\n        self.tuning_options = tuning_options\n        self.tune_params = tuning_options.tune_params\n        self.param_names = list(self.tune_params.keys())\n        self.normalized_dict = normalize_dict\n        self.denormalized_dict = denormalize_dict\n        self.runner = runner\n        self.max_threads = runner.dev.max_threads\n        self.log_timings = False\n\n        # set optimization constants\n        self.invalid_value = 1e20\n        self.opt_direction = opt_direction\n        if opt_direction == 'min':\n            self.worst_value = np.PINF\n            self.argopt = np.argmin\n        elif opt_direction == 'max':\n            self.worst_value = np.NINF\n            self.argopt = np.argmax\n        else:\n            raise ValueError(\"Invalid optimization direction '{}'\".format(opt_direction))\n\n        # set the acquisition function and surrogate model\n        self.optimize = self.__optimize\n        self.af_name = acquisition_function\n        self.af_params = acq_params\n        self.multi_afs = list(self.get_af_by_name(af_name) for af_name in multi_af_names)\n        self.set_acquisition_function(acquisition_function)\n        self.set_surrogate_model(cov_kernel_name, cov_kernel_lengthscale)\n\n        # set remaining values\n        self.results = []\n        self.__searchspace = searchspace\n        self.removed_tune_params = removed_tune_params\n        self.searchspace_size = len(self.searchspace)\n        self.num_dimensions = len(self.dimensions())\n        self.__current_optimum = self.worst_value\n        self.cv_norm_maximum = None\n        self.fevals = 0\n        self.__visited_num = 0\n        self.__visited_valid_num = 0\n        self.__visited_searchspace_indices = [False] * self.searchspace_size\n        self.__observations = [np.NaN] * self.searchspace_size\n        self.__valid_observation_indices = [False] * self.searchspace_size\n        self.__valid_params = list()\n        self.__valid_observations = list()\n        self.unvisited_cache = self.unvisited()\n        time_setup = time.perf_counter_ns()\n        self.error_message_searchspace_fully_observed = \"The search space has been fully observed\"\n\n        # take initial sample\n        if self.num_initial_samples > 0:\n            self.initial_sample()\n            time_initial_sample = time.perf_counter_ns()\n\n        # print the timings\n        if self.log_timings:\n            time_taken_setup = round(time_setup - time_start, 3) / 1000\n            time_taken_initial_sample = round(time_initial_sample - time_setup, 3) / 1000\n            time_taken_total = round(time_initial_sample - time_start, 3) / 1000\n            print(f\"Initialization | total time: {time_taken_total} | Setup: {time_taken_setup} | Initial sample: {time_taken_initial_sample}\", flush=True)\n\n    @property\n    def searchspace(self):\n        return self.__searchspace\n\n    @property\n    def observations(self):\n        return self.__observations\n\n    @property\n    def current_optimum(self):\n        return self.__current_optimum\n\n    @current_optimum.setter\n    def current_optimum(self, value: float):\n        self.__current_optimum = value\n\n    def is_better_than(self, a: float, b: float) -> bool:\n        \"\"\" Determines which one is better depending on optimization direction \"\"\"\n        return a < b if self.opt_direction == 'min' else a > b\n\n    def is_not_visited(self, index: int) -> bool:\n        \"\"\" Returns whether a searchspace index has not been visited \"\"\"\n        return not self.__visited_searchspace_indices[index]\n\n    def is_valid(self, observation: float) -> bool:\n        \"\"\" Returns whether an observation is valid \"\"\"\n        return not (observation == None or observation == self.invalid_value or observation == np.NaN)\n\n    def get_af_by_name(self, name: str):\n        \"\"\" Get the basic acquisition functions by their name \"\"\"\n        basic_af_names = ['ei', 'poi', 'lcb']\n        if name == 'ei':\n            return self.af_expected_improvement\n        elif name == 'poi':\n            return self.af_probability_of_improvement\n        elif name == 'lcb':\n            return self.af_lower_confidence_bound\n        raise ValueError(f\"{name} not in {basic_af_names}\")\n\n    def set_acquisition_function(self, acquisition_function: str):\n        \"\"\" Set the acquisition function \"\"\"\n        if acquisition_function == 'poi':\n            self.__af = self.af_probability_of_improvement\n        elif acquisition_function == 'ei':\n            self.__af = self.af_expected_improvement\n        elif acquisition_function == 'lcb':\n            self.__af = self.af_lower_confidence_bound\n        elif acquisition_function == 'lcb-srinivas':\n            self.__af = self.af_lower_confidence_bound_srinivas\n        elif acquisition_function == 'random':\n            self.__af = self.af_random\n        elif acquisition_function == 'multi':\n            self.optimize = self.__optimize_multi\n        elif acquisition_function == 'multi-advanced':\n            self.optimize = self.__optimize_multi_advanced\n        elif acquisition_function == 'multi-fast':\n            self.optimize = self.__optimize_multi_fast\n        else:\n            raise ValueError(\"Acquisition function must be one of {}, is {}\".format(self.supported_methods, acquisition_function))\n\n    def set_surrogate_model(self, cov_kernel_name: str, cov_kernel_lengthscale: float):\n        \"\"\" Set the surrogate model with a covariance function and lengthscale \"\"\"\n        if cov_kernel_name == \"constantrbf\":\n            kernel = ConstantKernel(1.0, constant_value_bounds=\"fixed\") * RBF(cov_kernel_lengthscale, length_scale_bounds=\"fixed\")\n        elif cov_kernel_name == \"rbf\":\n            kernel = RBF(length_scale=cov_kernel_lengthscale, length_scale_bounds=\"fixed\")\n        elif cov_kernel_name == \"matern32\":\n            kernel = Matern(length_scale=cov_kernel_lengthscale, nu=1.5, length_scale_bounds=\"fixed\")\n        elif cov_kernel_name == \"matern52\":\n            kernel = Matern(length_scale=cov_kernel_lengthscale, nu=2.5, length_scale_bounds=\"fixed\")\n        else:\n            raise ValueError(\"Acquisition function must be one of {}, is {}\".format(self.supported_cov_kernels, cov_kernel_name))\n        self.__model = GaussianProcessRegressor(kernel=kernel, alpha=1e-10, normalize_y=True)    # maybe change alpha to a higher value such as 1e-5?\n\n    def valid_params_observations(self) -> Tuple[list, list]:\n        \"\"\" Returns a list of valid observations and their parameter configurations \"\"\"\n        # if you do this every iteration, better keep it as cache and update in update_after_evaluation\n        params = list()\n        observations = list()\n        for index, valid in enumerate(self.__valid_observation_indices):\n            if valid is True:\n                params.append(self.searchspace[index])\n                observations.append(self.observations[index])\n        return params, observations\n\n    def unvisited(self) -> list:\n        \"\"\" Returns a list of unvisited parameter configurations - attention: cached version exists! \"\"\"\n        params = list(self.searchspace[index] for index, visited in enumerate(self.__visited_searchspace_indices) if visited is False)\n        return params\n\n    def find_param_config_index(self, param_config: tuple) -> int:\n        \"\"\" Find a parameter config index in the search space if it exists \"\"\"\n        return self.searchspace.index(param_config)\n\n    def find_param_config_unvisited_index(self, param_config: tuple) -> int:\n        \"\"\" Find a parameter config index in the unvisited cache if it exists \"\"\"\n        return self.unvisited_cache.index(param_config)\n\n    def normalize_param_config(self, param_config: tuple) -> tuple:\n        \"\"\" Normalizes a parameter configuration \"\"\"\n        normalized = tuple(self.normalized_dict[self.param_names[index]][param_value] for index, param_value in enumerate(param_config))\n        return normalized\n\n    def denormalize_param_config(self, param_config: tuple) -> tuple:\n        \"\"\" Denormalizes a parameter configuration \"\"\"\n        denormalized = tuple(self.denormalized_dict[self.param_names[index]][param_value] for index, param_value in enumerate(param_config))\n        return denormalized\n\n    def unprune_param_config(self, param_config: tuple) -> tuple:\n        \"\"\" In case of pruned dimensions, adds the removed dimensions back in the param config \"\"\"\n        unpruned = list()\n        pruned_count = 0\n        for removed in self.removed_tune_params:\n            if removed is not None:\n                unpruned.append(removed)\n            else:\n                unpruned.append(param_config[pruned_count])\n                pruned_count += 1\n        return tuple(unpruned)\n\n    def update_after_evaluation(self, observation: float, index: int, param_config: tuple):\n        \"\"\" Adjust the visited and valid index records accordingly \"\"\"\n        validity = self.is_valid(observation)\n        self.__visited_num += 1\n        self.__observations[index] = observation\n        self.__visited_searchspace_indices[index] = True\n        del self.unvisited_cache[self.find_param_config_unvisited_index(param_config)]\n        self.__valid_observation_indices[index] = validity\n        if validity is True:\n            self.__visited_valid_num += 1\n            self.__valid_params.append(param_config)\n            self.__valid_observations.append(observation)\n            if self.is_better_than(observation, self.current_optimum):\n                self.current_optimum = observation\n\n    def predict(self, x) -> Tuple[float, float]:\n        \"\"\" Returns a mean and standard deviation predicted by the surrogate model for the parameter configuration \"\"\"\n        return self.__model.predict([x], return_std=True)\n\n    def predict_list(self, lst: list) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\" Returns a list of means and standard deviations predicted by the surrogate model for the parameter configurations, and separate lists of means and standard deviations \"\"\"\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\")\n            mu, std = self.__model.predict(lst, return_std=True)\n            return mu, std\n\n    def fit_observations_to_model(self):\n        \"\"\" Update the model based on the current list of observations \"\"\"\n        self.__model.fit(self.__valid_params, self.__valid_observations)\n\n    def evaluate_objective_function(self, param_config: tuple) -> float:\n        \"\"\" Evaluates the objective function \"\"\"\n        param_config = self.unprune_param_config(param_config)\n        denormalized_param_config = self.denormalize_param_config(param_config)\n        if not util.config_valid(denormalized_param_config, self.tuning_options, self.max_threads):\n            return self.invalid_value\n        val = minimize._cost_func(param_config, self.kernel_options, self.tuning_options, self.runner, self.results)\n        self.fevals += 1\n        return val\n\n    def dimensions(self) -> list:\n        \"\"\" List of parameter values per parameter \"\"\"\n        return self.tune_params.values()\n\n    def draw_random_sample(self) -> Tuple[list, int]:\n        \"\"\" Draw a random sample from the unvisited parameter configurations \"\"\"\n        if len(self.unvisited_cache) < 1:\n            raise ValueError(\"Searchspace exhausted during random sample draw as no valid configurations were found\")\n        index = randint(0, len(self.unvisited_cache) - 1)    # NOSONAR\n        param_config = self.unvisited_cache[index]\n        actual_index = self.find_param_config_index(param_config)\n        return param_config, actual_index\n\n    def draw_latin_hypercube_samples(self, num_samples: int) -> list:\n        \"\"\" Draws an LHS-distributed sample from the search space \"\"\"\n        if self.searchspace_size < num_samples:\n            raise ValueError(\"Can't sample more than the size of the search space\")\n        if self.sampling_crit is None:\n            lhs = Lhs(lhs_type=\"centered\", criterion=None)\n        else:\n            lhs = Lhs(lhs_type=\"classic\", criterion=self.sampling_crit, iterations=self.sampling_iter)\n        param_configs = lhs.generate(self.dimensions(), num_samples)\n        indices = list()\n        normalized_param_configs = list()\n        for i in range(len(param_configs) - 1):\n            try:\n                param_config = self.normalize_param_config(param_configs[i])\n                index = self.find_param_config_index(param_config)\n                indices.append(index)\n                normalized_param_configs.append(param_config)\n            except ValueError:\n                \"\"\" Due to search space restrictions, the search space may not be an exact cartesian product of the tunable parameter values.\n                It is thus possible for LHS to generate a parameter combination that is not in the actual searchspace, which must be skipped. \"\"\"\n                continue\n        return list(zip(normalized_param_configs, indices))\n\n    def initial_sample(self):\n        \"\"\" Draws an initial sample using random sampling \"\"\"\n        if self.num_initial_samples <= 0:\n            raise ValueError(\"At least one initial sample is required\")\n        if self.sampling_method == 'lhs':\n            samples = self.draw_latin_hypercube_samples(self.num_initial_samples)\n        elif self.sampling_method == 'random':\n            samples = list()\n        else:\n            raise ValueError(\"Sampling method must be one of {}, is {}\".format(self.supported_sampling_methods, self.sampling_method))\n        # collect the samples\n        collected_samples = 0\n        for params, index in samples:\n            observation = self.evaluate_objective_function(params)\n            self.update_after_evaluation(observation, index, params)\n            if self.is_valid(observation):\n                collected_samples += 1\n        # collect the remainder of the samples\n        while collected_samples < self.num_initial_samples:\n            params, index = self.draw_random_sample()\n            observation = self.evaluate_objective_function(params)\n            self.update_after_evaluation(observation, index, params)\n            # check for validity to avoid having no actual initial samples\n            if self.is_valid(observation):\n                collected_samples += 1\n        self.fit_observations_to_model()\n        _, std = self.predict_list(self.unvisited_cache)\n        self.initial_sample_mean = np.mean(self.__valid_observations)\n        # Alternatively:\n        # self.initial_sample_std = np.std(self.__valid_observations)\n        # self.initial_sample_mean = np.mean(predictions)\n        self.initial_std = np.mean(std)\n        self.cv_norm_maximum = self.initial_std\n\n    def contextual_variance(self, std: list):\n        \"\"\" Contextual improvement to decide explore / exploit, based on CI proposed by (Jasrasaria, 2018) \"\"\"\n        if not self.af_params['explorationfactor'] == 'CV':\n            return None\n        if self.opt_direction == 'min':\n            if self.current_optimum == self.worst_value:\n                return 0.01\n            if self.current_optimum <= 0:\n                # doesn't work well for minimization beyond 0, should that even be a thing?\n                return abs(np.mean(std) / self.current_optimum)\n            improvement_over_initial_sample = self.initial_sample_mean / self.current_optimum\n            cv = np.mean(std) / improvement_over_initial_sample\n            # normalize if available\n            if self.cv_norm_maximum:\n                cv = cv / self.cv_norm_maximum\n            return cv\n        return np.mean(std) / self.current_optimum\n\n    def __optimize(self, max_fevals):\n        \"\"\" Find the next best candidate configuration(s), evaluate those and update the model accordingly \"\"\"\n        while self.fevals < max_fevals:\n            if self.__visited_num >= self.searchspace_size:\n                raise ValueError(self.error_message_searchspace_fully_observed)\n            predictions = self.predict_list(self.unvisited_cache)\n            hyperparam = self.contextual_variance(predictions[1])\n            list_of_acquisition_values = self.__af(predictions, hyperparam)\n            # afterwards select the best AF value\n            best_af = self.argopt(list_of_acquisition_values)\n            candidate_params = self.unvisited_cache[best_af]\n            candidate_index = self.find_param_config_index(candidate_params)\n            observation = self.evaluate_objective_function(candidate_params)\n            self.update_after_evaluation(observation, candidate_index, candidate_params)\n            self.fit_observations_to_model()\n        return self.results\n\n    def __optimize_multi(self, max_fevals):\n        \"\"\" Optimize with a portfolio of multiple acquisition functions. Predictions are always only taken once. Skips AFs if they suggest X/max_evals duplicates in a row, prefers AF with best discounted average. \"\"\"\n        if self.opt_direction != 'min':\n            raise ValueError(f\"Optimization direction must be minimization ('min'), is {self.opt_direction}\")\n        # calculate how many times an AF can suggest a duplicate candidate before the AF is skipped\n        # skip_duplicates_fraction = self.af_params['skip_duplicates_fraction']\n        # skip_if_duplicate_n_times = int(min(max(round(skip_duplicates_fraction * max_fevals), 3), max_fevals))\n        skip_if_duplicate_n_times = self.af_params['skip_duplicate_after']\n        discount_factor = self.multi_afs_discount_factor\n        # setup the registration of duplicates and runtimes\n        duplicate_count_template = [0 for _ in range(skip_if_duplicate_n_times)]\n        duplicate_candidate_af_count = list(deepcopy(duplicate_count_template) for _ in range(3))\n        skip_af_index = list()\n        af_runtimes = [0, 0, 0]\n        af_observations = [list(), list(), list()]\n        initial_sample_mean = np.mean(self.__valid_observations)\n        while self.fevals < max_fevals:\n            time_start = time.perf_counter_ns()\n            # the first acquisition function is never skipped, so that should be the best for the endgame (EI)\n            aqfs = self.multi_afs\n            predictions = self.predict_list(self.unvisited_cache)\n            hyperparam = self.contextual_variance(predictions[1])\n            if self.__visited_num >= self.searchspace_size:\n                raise ValueError(self.error_message_searchspace_fully_observed)\n            time_predictions = time.perf_counter_ns()\n            actual_candidate_params = list()\n            actual_candidate_indices = list()\n            actual_candidate_af_indices = list()\n            duplicate_candidate_af_indices = list()\n            duplicate_candidate_original_af_indices = list()\n            for af_index, af in enumerate(aqfs):\n                if af_index in skip_af_index:\n                    continue\n                if self.__visited_num >= self.searchspace_size or self.fevals >= max_fevals:\n                    break\n                timer_start = time.perf_counter()\n                list_of_acquisition_values = af(predictions, hyperparam)\n                best_af = self.argopt(list_of_acquisition_values)\n                time_taken = time.perf_counter() - timer_start\n                af_runtimes[af_index] += time_taken\n                is_duplicate = best_af in actual_candidate_indices\n                if not is_duplicate:\n                    candidate_params = self.unvisited_cache[best_af]\n                    actual_candidate_params.append(candidate_params)\n                    actual_candidate_indices.append(best_af)\n                    actual_candidate_af_indices.append(af_index)\n                # register whether the AF suggested a duplicate candidate\n                duplicate_candidate_af_count[af_index].pop(0)\n                duplicate_candidate_af_count[af_index].append(1 if is_duplicate else 0)\n                if is_duplicate:\n                    # find the index of the AF that first registered the duplicate\n                    original_duplicate_af_index = actual_candidate_af_indices[actual_candidate_indices.index(best_af)]\n                    # register that AF as duplicate as well\n                    duplicate_candidate_af_count[original_duplicate_af_index][-1] = 1\n                    duplicate_candidate_af_indices.append(af_index)\n                    duplicate_candidate_original_af_indices.append(original_duplicate_af_index)\n            time_afs = time.perf_counter_ns()\n            # evaluate the non-duplicate candidates\n            for index, af_index in enumerate(actual_candidate_af_indices):\n                candidate_params = actual_candidate_params[index]\n                candidate_index = self.find_param_config_index(candidate_params)\n                observation = self.evaluate_objective_function(candidate_params)\n                self.update_after_evaluation(observation, candidate_index, candidate_params)\n                if observation != self.invalid_value:\n                    # we use the registered observations for maximization of the discounted reward\n                    reg_observation = observation if self.opt_direction == 'min' else -1 * observation\n                    af_observations[actual_candidate_af_indices[index]].append(reg_observation)\n                else:\n                    reg_invalid_observation = initial_sample_mean if self.opt_direction == 'min' else -1 * initial_sample_mean\n                    af_observations[actual_candidate_af_indices[index]].append(reg_invalid_observation)\n            for index, af_index in enumerate(duplicate_candidate_af_indices):\n                original_observation = af_observations[duplicate_candidate_original_af_indices[index]][-1]\n                af_observations[af_index].append(original_observation)\n            self.fit_observations_to_model()\n            time_eval = time.perf_counter_ns()\n            # assert that all observation lists of non-skipped acquisition functions are of the same length\n            non_skipped_af_indices = list(af_index for af_index, _ in enumerate(aqfs) if af_index not in skip_af_index)\n            assert all(len(af_observations[non_skipped_af_indices[0]]) == len(af_observations[af_index]) for af_index in non_skipped_af_indices)\n            # find the AFs elligble for being skipped\n            candidates_for_skip = list()\n            for af_index, count in enumerate(duplicate_candidate_af_count):\n                if sum(count) >= skip_if_duplicate_n_times and af_index not in skip_af_index:\n                    candidates_for_skip.append(af_index)\n            # do not skip the AF with the lowest runtime\n            if len(candidates_for_skip) > 1:\n                candidates_for_skip_discounted = list(\n                    sum(list(obs * discount_factor**(len(observations) - 1 - i) for i, obs in enumerate(observations)))\n                    for af_index, observations in enumerate(af_observations) if af_index in candidates_for_skip)\n                af_not_to_skip = candidates_for_skip[np.argmin(candidates_for_skip_discounted)]\n                for af_index in candidates_for_skip:\n                    if af_index == af_not_to_skip:\n                        # do not skip the AF with the lowest runtime and give it a clean slate\n                        duplicate_candidate_af_count[af_index] = deepcopy(duplicate_count_template)\n                        continue\n                    skip_af_index.append(af_index)\n                    if len(skip_af_index) >= len(aqfs):\n                        raise ValueError(\"There are no acquisition functions left! This should not happen...\")\n            time_af_selection = time.perf_counter_ns()\n\n            # printing timings\n            if self.log_timings:\n                time_taken_predictions = round(time_predictions - time_start, 3) / 1000\n                time_taken_afs = round(time_afs - time_predictions, 3) / 1000\n                time_taken_eval = round(time_eval - time_afs, 3) / 1000\n                time_taken_af_selection = round(time_af_selection - time_eval, 3) / 1000\n                time_taken_total = round(time_af_selection - time_start, 3) / 1000\n                print(\n                    f\"({self.fevals}/{max_fevals}) Total time: {time_taken_total} | Predictions: {time_taken_predictions} | AFs: {time_taken_afs} | Eval: {time_taken_eval} | AF selection: {time_taken_af_selection}\",\n                    flush=True)\n        return self.results\n\n    def __optimize_multi_advanced(self, max_fevals, increase_precision=False):\n        \"\"\" Optimize with a portfolio of multiple acquisition functions. Predictions are only taken once, unless increase_precision is true. Skips AFs if they are consistently worse than the mean of discounted observations, promotes AFs if they are consistently better than this mean. \"\"\"\n        if self.opt_direction != 'min':\n            raise ValueError(f\"Optimization direction must be minimization ('min'), is {self.opt_direction}\")\n        aqfs = self.multi_afs\n        discount_factor = self.multi_afs_discount_factor\n        required_improvement_factor = self.multi_afs_required_improvement_factor\n        required_improvement_worse = 1 + required_improvement_factor\n        required_improvement_better = 1 - required_improvement_factor\n        min_required_count = self.af_params['skip_duplicate_after']\n        skip_af_index = list()\n        single_af = len(aqfs) <= len(skip_af_index) + 1\n        af_observations = [list(), list(), list()]\n        af_performs_worse_count = [0, 0, 0]\n        af_performs_better_count = [0, 0, 0]\n        while self.fevals < max_fevals:\n            if single_af:\n                return self.__optimize(max_fevals)\n            if self.__visited_num >= self.searchspace_size:\n                raise ValueError(self.error_message_searchspace_fully_observed)\n            observations_median = np.median(self.__valid_observations)\n            if increase_precision is False:\n                predictions = self.predict_list(self.unvisited_cache)\n                hyperparam = self.contextual_variance(predictions[1])\n            for af_index, af in enumerate(aqfs):\n                if af_index in skip_af_index:\n                    continue\n                if self.__visited_num >= self.searchspace_size or self.fevals >= max_fevals:\n                    break\n                if increase_precision is True:\n                    predictions, _, std = self.predict_list(self.unvisited_cache)\n                    hyperparam = self.contextual_variance(std)\n                list_of_acquisition_values = af(predictions, hyperparam)\n                best_af = self.argopt(list_of_acquisition_values)\n                np.delete(predictions[0], best_af)    # to avoid going out of bounds\n                np.delete(predictions[1], best_af)\n                candidate_params = self.unvisited_cache[best_af]\n                candidate_index = self.find_param_config_index(candidate_params)\n                observation = self.evaluate_objective_function(candidate_params)\n                self.update_after_evaluation(observation, candidate_index, candidate_params)\n                if increase_precision is True:\n                    self.fit_observations_to_model()\n                # we use the registered observations for maximization of the discounted reward\n                if observation != self.invalid_value:\n                    reg_observation = observation if self.opt_direction == 'min' else -1 * observation\n                    af_observations[af_index].append(reg_observation)\n                else:\n                    # if the observation is invalid, use the median of all valid observations to avoid skewing the discounted observations\n                    reg_invalid_observation = observations_median if self.opt_direction == 'min' else -1 * observations_median\n                    af_observations[af_index].append(reg_invalid_observation)\n            if increase_precision is False:\n                self.fit_observations_to_model()\n\n            # calculate the mean of discounted observations over the remaining acquisition functions\n            discounted_obs = list(\n                sum(list(obs * discount_factor**(len(observations) - 1 - i) for i, obs in enumerate(observations))) for observations in af_observations)\n            disc_obs_mean = np.mean(list(discounted_obs[af_index] for af_index, _ in enumerate(aqfs) if af_index not in skip_af_index))\n\n            # register which AFs perform more than 10% better than average and which more than 10% worse than average\n            for af_index, discounted_observation in enumerate(discounted_obs):\n                if discounted_observation > disc_obs_mean * required_improvement_worse:\n                    af_performs_worse_count[af_index] += 1\n                elif discounted_observation < disc_obs_mean * required_improvement_better:\n                    af_performs_better_count[af_index] += 1\n\n            # find the worst AF, discounted observations is leading for a draw\n            worst_count = max(list(count for af_index, count in enumerate(af_performs_worse_count) if af_index not in skip_af_index))\n            af_index_worst = -1\n            if worst_count >= min_required_count:\n                for af_index, count in enumerate(af_performs_worse_count):\n                    if af_index not in skip_af_index and count == worst_count and (af_index_worst == -1\n                                                                                   or discounted_obs[af_index] > discounted_obs[af_index_worst]):\n                        af_index_worst = af_index\n\n            # skip the worst AF\n            if af_index_worst > -1:\n                skip_af_index.append(af_index_worst)\n                # reset the counts to even the playing field for the remaining AFs\n                af_performs_worse_count = [0, 0, 0]\n                af_performs_better_count = [0, 0, 0]\n                # if there is only one AF left, register as single AF\n                if len(aqfs) <= len(skip_af_index) + 1:\n                    single_af = True\n                    af_indices_left = list(af_index for af_index, _ in enumerate(aqfs) if af_index not in skip_af_index)\n                    assert len(af_indices_left) == 1\n                    self.__af = aqfs[af_indices_left[0]]\n            else:\n                # find the best AF, discounted observations is leading for a draw\n                best_count = max(list(count for af_index, count in enumerate(af_performs_better_count) if af_index not in skip_af_index))\n                af_index_best = -1\n                if best_count >= min_required_count:\n                    for af_index, count in enumerate(af_performs_better_count):\n                        if af_index not in skip_af_index and count == best_count and (af_index_best == -1\n                                                                                      or discounted_obs[af_index] < discounted_obs[af_index_best]):\n                            af_index_best = af_index\n                # make the best AF single\n                if af_index_best > -1:\n                    single_af = True\n                    self.__af = aqfs[af_index_best]\n\n        return self.results\n\n    def __optimize_multi_fast(self, max_fevals):\n        \"\"\" Optimize with a portfolio of multiple acquisition functions. Predictions are only taken once. \"\"\"\n        while self.fevals < max_fevals:\n            aqfs = self.multi_afs\n            # if we take the prediction only once, we want to go from most exploiting to most exploring, because the more exploiting an AF is, the more it relies on non-stale information from the model\n            predictions = self.predict_list(self.unvisited_cache)\n            hyperparam = self.contextual_variance(predictions[1])\n            if self.__visited_num >= self.searchspace_size:\n                raise ValueError(self.error_message_searchspace_fully_observed)\n            for af in aqfs:\n                if self.__visited_num >= self.searchspace_size or self.fevals >= max_fevals:\n                    break\n                list_of_acquisition_values = af(predictions, hyperparam)\n                best_af = self.argopt(list_of_acquisition_values)\n                del predictions[0][best_af]    # to avoid going out of bounds\n                del predictions[1][best_af]\n                candidate_params = self.unvisited_cache[best_af]\n                candidate_index = self.find_param_config_index(candidate_params)\n                observation = self.evaluate_objective_function(candidate_params)\n                self.update_after_evaluation(observation, candidate_index, candidate_params)\n            self.fit_observations_to_model()\n        return self.results\n\n    def af_random(self, predictions=None, hyperparam=None) -> list:\n        \"\"\" Acquisition function returning a randomly shuffled list for comparison \"\"\"\n        list_random = range(len(self.unvisited_cache))\n        shuffle(list_random)\n        return list_random\n\n    def af_probability_of_improvement(self, predictions=None, hyperparam=None) -> list:\n        \"\"\" Acquisition function Probability of Improvement (PI) \"\"\"\n\n        # prefetch required data\n        x_mu, x_std = predictions\n        if hyperparam is None:\n            hyperparam = self.af_params['explorationfactor']\n        fplus = self.current_optimum - hyperparam\n\n        # precompute difference of improvement\n        list_diff_improvement = -((fplus - x_mu) / (x_std + 1E-9))\n\n        # compute probability of improvement with CDF in bulk\n        list_prob_improvement = norm.cdf(list_diff_improvement)\n        return list_prob_improvement\n\n    def af_expected_improvement(self, predictions=None, hyperparam=None) -> list:\n        \"\"\" Acquisition function Expected Improvement (EI) \"\"\"\n\n        # prefetch required data\n        x_mu, x_std = predictions\n        if hyperparam is None:\n            hyperparam = self.af_params['explorationfactor']\n        fplus = self.current_optimum - hyperparam\n\n        # precompute difference of improvement, CDF and PDF in bulk\n        list_diff_improvement = (fplus - x_mu) / (x_std + 1E-9)\n        list_cdf = norm.cdf(list_diff_improvement)\n        list_pdf = norm.pdf(list_diff_improvement)\n\n        # compute expected improvement in bulk\n        list_exp_improvement = -((fplus - x_mu) * list_cdf + x_std * list_pdf)\n        return list_exp_improvement\n\n    def af_lower_confidence_bound(self, predictions=None, hyperparam=None) -> list:\n        \"\"\" Acquisition function Lower Confidence Bound (LCB) \"\"\"\n\n        x_mu, x_std = predictions\n        if hyperparam is None:\n            hyperparam = self.af_params['explorationfactor']\n        beta = hyperparam\n\n        # compute LCB in bulk\n        list_lower_confidence_bound = (x_mu - beta * x_std)\n        return list_lower_confidence_bound\n\n    def af_lower_confidence_bound_srinivas(self, predictions=None, hyperparam=None) -> list:\n        \"\"\" Acquisition function Lower Confidence Bound (UCB-S) after Srinivas, 2010 / Brochu, 2010 \"\"\"\n\n        # prefetch required data\n        x_mu, x_std = predictions\n        if hyperparam is None:\n            hyperparam = self.af_params['explorationfactor']\n\n        # precompute beta parameter\n        zeta = self.af_params['zeta']\n        t = self.fevals\n        d = self.num_dimensions\n        delta = hyperparam\n        beta = np.sqrt(zeta * (2 * np.log((t**(d / 2. + 2)) * (np.pi**2) / (3. * delta))))\n\n        # compute UCB in bulk\n        list_lower_confidence_bound = (x_mu - beta * x_std)\n        return list_lower_confidence_bound\n\n    def visualize_after_opt(self):\n        \"\"\" Visualize the model after the optimization \"\"\"\n        print(self.__model.kernel_.get_params())\n        print(self.__model.log_marginal_likelihood())\n        import matplotlib.pyplot as plt\n        mu, std = self.predict_list(self.searchspace)\n        brute_force_observations = list()\n        for param_config in self.searchspace:\n            obs = minimize._cost_func(param_config, self.kernel_options, self.tuning_options, self.runner, self.results)\n            if obs == self.invalid_value:\n                obs = None\n            brute_force_observations.append(obs)\n        x_axis = range(len(mu))\n        plt.fill_between(x_axis, mu - std, mu + std, alpha=0.2, antialiased=True)\n        plt.plot(x_axis, mu, label=\"predictions\", linestyle=' ', marker='.')\n        plt.plot(x_axis, brute_force_observations, label=\"actual\", linestyle=' ', marker='.')\n        plt.legend()\n        plt.show()\n", 827], "/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/greedy_ils.py": ["\"\"\" A simple greedy iterative local search algorithm for parameter search \"\"\"\n\nfrom kernel_tuner.strategies.minimize import _cost_func\nfrom kernel_tuner import util\nfrom kernel_tuner.strategies.hillclimbers import base_hillclimb\nfrom kernel_tuner.strategies.genetic_algorithm import mutate, random_population\n\ndef tune(runner, kernel_options, device_options, tuning_options):\n    \"\"\" Find the best performing kernel configuration in the parameter space\n\n    :params runner: A runner from kernel_tuner.runners\n    :type runner: kernel_tuner.runner\n\n    :param kernel_options: A dictionary with all options for the kernel.\n    :type kernel_options: kernel_tuner.interface.Options\n\n    :param device_options: A dictionary with all options for the device\n        on which the kernel should be tuned.\n    :type device_options: kernel_tuner.interface.Options\n\n    :param tuning_options: A dictionary with all options regarding the tuning\n        process.\n    :type tuning_options: kernel_tuner.interface.Options\n\n    :returns: A list of dictionaries for executed kernel configurations and their\n        execution times. And a dictionary that contains a information\n        about the hardware/software environment on which the tuning took place.\n    :rtype: list(dict()), dict()\n\n    \"\"\"\n\n    dna_size = len(tuning_options.tune_params.keys())\n    tune_params = tuning_options.tune_params\n\n    options = tuning_options.strategy_options\n\n    neighbor = options.get(\"neighbor\", \"Hamming\")\n    restart = options.get(\"restart\", True)\n    no_improvement = options.get(\"no_improvement\", 50)\n    randomwalk = options.get(\"random_walk\", 0.3)\n    perm_size = int(randomwalk * dna_size)\n    if perm_size == 0:\n        perm_size = 1\n    max_fevals = options.get(\"max_fevals\", 100)\n\n    tuning_options[\"scaling\"] = False\n\n    # limit max_fevals to max size of the parameter space\n    max_threads = runner.dev.max_threads\n    max_fevals = min(util.get_number_of_valid_configs(tuning_options, max_threads), max_fevals)\n\n    fevals = 0\n    all_results = []\n    unique_results = {}\n\n    #while searching\n    candidate = random_population(1, tune_params, tuning_options, max_threads)[0]\n    best_time = _cost_func(candidate, kernel_options, tuning_options, runner, all_results)\n\n    last_improvement = 0\n    while fevals < max_fevals:\n        candidate = base_hillclimb(candidate, neighbor, max_fevals, all_results, unique_results, kernel_options, tuning_options, runner, restart=restart, randomize=True)\n\n        fevals = len(unique_results)\n\n        new_time = _cost_func(candidate, kernel_options, tuning_options, runner, all_results)\n        # How to do maximization?\n        if new_time < best_time:\n            last_improvement = 0\n        else:\n            last_improvement += 1\n\n        # Instead of full restart, permute the starting candidate\n        candidate = random_walk(candidate, perm_size, no_improvement, last_improvement, tune_params, tuning_options, max_threads)\n    return all_results, runner.dev.get_environment()\n\n\ndef random_walk(indiv, permutation_size, no_improve, last_improve, tune_params, tuning_options, max_threads):\n    if last_improve >= no_improve:\n        return random_population(1, tune_params, tuning_options, max_threads)[0]\n    for _ in range(permutation_size):\n        indiv = mutate(indiv, tune_params, 0, tuning_options, max_threads)\n    return indiv\n", 83], "/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/ordered_greedy_mls.py": ["\"\"\" A greedy multi-start local search algorithm for parameter search that traverses variables in order.\"\"\"\n\nfrom kernel_tuner.strategies.greedy_mls import tune as mls_tune\n\ndef tune(runner, kernel_options, device_options, tuning_options):\n    \"\"\" Find the best performing kernel configuration in the parameter space\n\n    :params runner: A runner from kernel_tuner.runners\n    :type runner: kernel_tuner.runner\n\n    :param kernel_options: A dictionary with all options for the kernel.\n    :type kernel_options: kernel_tuner.interface.Options\n\n    :param device_options: A dictionary with all options for the device\n        on which the kernel should be tuned.\n    :type device_options: kernel_tuner.interface.Options\n\n    :param tuning_options: A dictionary with all options regarding the tuning\n        process.\n    :type tuning_options: kernel_tuner.interface.Options\n\n    :returns: A list of dictionaries for executed kernel configurations and their\n        execution times. And a dictionary that contains a information\n        about the hardware/software environment on which the tuning took place.\n    :rtype: list(dict()), dict()\n\n    \"\"\"\n\n    # disable randomization and enable greedy hillclimbing\n    options = tuning_options.strategy_options\n    options[\"restart\"] = True\n    options[\"randomize\"] = False\n    return mls_tune(runner, kernel_options, device_options, tuning_options)\n", 33], "/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/dual_annealing.py": ["\"\"\" The strategy that uses the dual annealing optimization method \"\"\"\nfrom __future__ import print_function\n\nimport scipy.optimize\n\nfrom kernel_tuner.strategies.minimize import _cost_func, get_bounds_x0_eps, setup_method_arguments, setup_method_options\n\nsupported_methods = ['COBYLA','L-BFGS-B','SLSQP','CG','Powell','Nelder-Mead', 'BFGS', 'trust-constr']\n\n\ndef tune(runner, kernel_options, device_options, tuning_options):\n    \"\"\" Find the best performing kernel configuration in the parameter space\n\n    :params runner: A runner from kernel_tuner.runners\n    :type runner: kernel_tuner.runner\n\n    :param kernel_options: A dictionary with all options for the kernel.\n    :type kernel_options: dict\n\n    :param device_options: A dictionary with all options for the device\n        on which the kernel should be tuned.\n    :type device_options: dict\n\n    :param tuning_options: A dictionary with all options regarding the tuning\n        process.\n    :type tuning_options: dict\n\n    :returns: A list of dictionaries for executed kernel configurations and their\n        execution times. And a dictionary that contains a information\n        about the hardware/software environment on which the tuning took place.\n    :rtype: list(dict()), dict()\n\n    \"\"\"\n\n    results = []\n\n    method = tuning_options.strategy_options.get(\"method\", \"Powell\")\n\n    #scale variables in x to make 'eps' relevant for multiple variables\n    tuning_options[\"scaling\"] = True\n\n    bounds, _, _ = get_bounds_x0_eps(tuning_options)\n\n    kwargs = setup_method_arguments(method, bounds)\n    options = setup_method_options(method, tuning_options)\n    kwargs['options'] = options\n\n    args = (kernel_options, tuning_options, runner, results)\n\n    minimizer_kwargs = dict()\n    minimizer_kwargs[\"method\"] = method\n\n    opt_result = scipy.optimize.dual_annealing(_cost_func, bounds,\n            args= args, local_search_options=minimizer_kwargs)\n\n    if tuning_options.verbose:\n        print(opt_result.message)\n\n    return results, runner.dev.get_environment()\n", 59], "/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_old.py": ["\"\"\" Bayesian Optimization implementation from the thesis by Willemsen \"\"\"\nfrom copy import deepcopy\nfrom random import randint, shuffle\nimport itertools\nimport warnings\nimport time\n\nimport numpy as np\n\n# BO imports\ntry:\n    from typing import Tuple\n    from scipy.stats import norm\n    from sklearn.gaussian_process import GaussianProcessRegressor\n    from sklearn.gaussian_process.kernels import ConstantKernel, RBF, Matern\n    from sklearn.exceptions import ConvergenceWarning\n    from skopt.sampler import Lhs\n    bayes_opt_present = True\nexcept ImportError:\n    bayes_opt_present = False\n\nfrom kernel_tuner.strategies import minimize\nfrom kernel_tuner import util\n\nsupported_methods = [\"poi\", \"ei\", \"lcb\", \"lcb-srinivas\", \"multi\", \"multi-advanced\", \"multi-fast\"]\n\n\ndef generate_normalized_param_dicts(tune_params: dict, eps: float) -> Tuple[dict, dict]:\n    \"\"\" Generates normalization and denormalization dictionaries \"\"\"\n    original_to_normalized = dict()\n    normalized_to_original = dict()\n    for param_name in tune_params.keys():\n        original_to_normalized_dict = dict()\n        normalized_to_original_dict = dict()\n        for value_index, value in enumerate(tune_params[param_name]):\n            normalized_value = eps * value_index + 0.5 * eps\n            normalized_to_original_dict[normalized_value] = value\n            original_to_normalized_dict[value] = normalized_value\n        original_to_normalized[param_name] = original_to_normalized_dict\n        normalized_to_original[param_name] = normalized_to_original_dict\n    return original_to_normalized, normalized_to_original\n\n\ndef normalize_parameter_space(param_space: list, tune_params: dict, normalized: dict) -> list:\n    \"\"\" Normalize the parameter space given a normalization dictionary \"\"\"\n    keys = list(tune_params.keys())\n    param_space_normalized = list(tuple(normalized[keys[i]][v] for i, v in enumerate(params)) for params in param_space)\n    return param_space_normalized\n\n\ndef prune_parameter_space(parameter_space, tuning_options, tune_params, normalize_dict):\n    \"\"\" Pruning of the parameter space to remove dimensions that have a constant parameter \"\"\"\n    pruned_tune_params_mask = list()\n    removed_tune_params = list()\n    param_names = list(tune_params.keys())\n    for index, key in enumerate(tune_params.keys()):\n        pruned_tune_params_mask.append(len(tune_params[key]) > 1)\n        if len(tune_params[key]) > 1:\n            removed_tune_params.append(None)\n        else:\n            value = tune_params[key][0]\n            normalized = normalize_dict[param_names[index]][value]\n            removed_tune_params.append(normalized)\n    if 'verbose' in tuning_options and tuning_options.verbose is True and len(tune_params.keys()) != sum(pruned_tune_params_mask):\n        print(f\"Number of parameters (dimensions): {len(tune_params.keys())}, after pruning: {sum(pruned_tune_params_mask)}\")\n    parameter_space = list(tuple(itertools.compress(param_config, pruned_tune_params_mask)) for param_config in parameter_space)\n    return parameter_space, removed_tune_params\n\n\ndef tune(runner, kernel_options, device_options, tuning_options):\n    \"\"\" Find the best performing kernel configuration in the parameter space\n\n    :params runner: A runner from kernel_tuner.runners\n    :type runner: kernel_tuner.runner\n\n    :param kernel_options: A dictionary with all options for the kernel.\n    :type kernel_options: kernel_tuner.interface.Options\n\n    :param device_options: A dictionary with all options for the device\n        on which the kernel should be tuned.\n    :type device_options: kernel_tuner.interface.Options\n\n    :param tuning_options: A dictionary with all options regarding the tuning\n        process. Allows setting hyperparameters via the strategy_options key.\n    :type tuning_options: kernel_tuner.interface.Options\n\n    :returns: A list of dictionaries for executed kernel configurations and their\n        execution times. And a dictionary that contains a information\n        about the hardware/software environment on which the tuning took place.\n    :rtype: list(dict()), dict()\n\n    \"\"\"\n\n    max_fevals = tuning_options.strategy_options.get(\"max_fevals\", 100)\n    prune_parameterspace = tuning_options.strategy_options.get(\"pruneparameterspace\", True)\n    if not bayes_opt_present:\n        raise ImportError(\"Error: optional dependencies for Bayesian Optimization not installed\")\n\n    # epsilon for scaling should be the evenly spaced distance between the largest set of parameter options in an interval [0,1]\n    tune_params = tuning_options.tune_params\n    tuning_options[\"scaling\"] = True\n    _, _, eps = minimize.get_bounds_x0_eps(tuning_options)\n\n    # compute cartesian product of all tunable parameters\n    parameter_space = itertools.product(*tune_params.values())\n\n    # check for search space restrictions\n    if tuning_options.restrictions is not None:\n        tuning_options.verbose = False\n    parameter_space = filter(lambda p: util.config_valid(p, tuning_options, runner.dev.max_threads), parameter_space)\n    parameter_space = list(parameter_space)\n    if len(parameter_space) < 1:\n        raise ValueError(\"Empty parameterspace after restrictionscheck. Restrictionscheck is possibly too strict.\")\n    if len(parameter_space) == 1:\n        raise ValueError(f\"Only one configuration after restrictionscheck. Restrictionscheck is possibly too strict. Configuration: {parameter_space[0]}\")\n\n    # normalize search space to [0,1]\n    normalize_dict, denormalize_dict = generate_normalized_param_dicts(tune_params, eps)\n    parameter_space = normalize_parameter_space(parameter_space, tune_params, normalize_dict)\n\n    # prune the parameter space to remove dimensions that have a constant parameter\n    if prune_parameterspace:\n        parameter_space, removed_tune_params = prune_parameter_space(parameter_space, tuning_options, tune_params, normalize_dict)\n    else:\n        parameter_space = list(parameter_space)\n        removed_tune_params = [None] * len(tune_params.keys())\n\n    # initialize and optimize\n    bo = BayesianOptimization(parameter_space, removed_tune_params, kernel_options, tuning_options, normalize_dict, denormalize_dict, runner)\n    results = bo.optimize(max_fevals)\n\n    return results, runner.dev.get_environment()\n\n\nclass BayesianOptimization():\n\n    def __init__(self, searchspace: list, removed_tune_params: list, kernel_options: dict, tuning_options: dict, normalize_dict: dict, denormalize_dict: dict,\n                 runner, opt_direction='min'):\n        time_start = time.perf_counter_ns()\n\n        # supported hyperparameter values\n        self.supported_cov_kernels = [\"constantrbf\", \"rbf\", \"matern32\", \"matern52\"]\n        self.supported_methods = supported_methods\n        self.supported_sampling_methods = [\"random\", \"lhs\"]\n        self.supported_sampling_criterion = [\"correlation\", \"ratio\", \"maximin\", None]\n\n        def get_hyperparam(name: str, default, supported_values=list()):\n            value = tuning_options.strategy_options.get(name, default)\n            if len(supported_values) > 0 and value not in supported_values:\n                raise ValueError(f\"'{name}' is set to {value}, but must be one of {supported_values}\")\n            return value\n\n        # get hyperparameters\n        cov_kernel_name = get_hyperparam(\"covariancekernel\", \"matern32\", self.supported_cov_kernels)\n        cov_kernel_lengthscale = get_hyperparam(\"covariancelengthscale\", 1.5)\n        acquisition_function = get_hyperparam(\"method\", \"multi-advanced\", self.supported_methods)\n        acq = acquisition_function\n        acq_params = get_hyperparam(\"methodparams\", {})\n        multi_af_names = get_hyperparam(\"multi_af_names\", ['ei', 'poi', 'lcb'])\n        self.multi_afs_discount_factor = get_hyperparam(\"multi_af_discount_factor\", 0.65 if acq == 'multi' else 0.95)\n        self.multi_afs_required_improvement_factor = get_hyperparam(\"multi_afs_required_improvement_factor\", 0.15 if acq == 'multi-advanced-precise' else 0.1)\n        self.num_initial_samples = get_hyperparam(\"popsize\", 20)\n        self.sampling_method = get_hyperparam(\"samplingmethod\", \"lhs\", self.supported_sampling_methods)\n        self.sampling_crit = get_hyperparam(\"samplingcriterion\", 'maximin', self.supported_sampling_criterion)\n        self.sampling_iter = get_hyperparam(\"samplingiterations\", 1000)\n\n        # set acquisition function hyperparameter defaults where missing\n        if 'explorationfactor' not in acq_params:\n            acq_params['explorationfactor'] = 'CV'\n        if 'zeta' not in acq_params:\n            acq_params['zeta'] = 1\n        if 'skip_duplicate_after' not in acq_params:\n            acq_params['skip_duplicate_after'] = 5\n\n        # set arguments\n        self.kernel_options = kernel_options\n        self.tuning_options = tuning_options\n        self.tune_params = tuning_options.tune_params\n        self.param_names = list(self.tune_params.keys())\n        self.normalized_dict = normalize_dict\n        self.denormalized_dict = denormalize_dict\n        self.runner = runner\n        self.max_threads = runner.dev.max_threads\n        self.log_timings = False\n\n        # set optimization constants\n        self.invalid_value = 1e20\n        self.opt_direction = opt_direction\n        if opt_direction == 'min':\n            self.worst_value = np.PINF\n            self.argopt = np.argmin\n        elif opt_direction == 'max':\n            self.worst_value = np.NINF\n            self.argopt = np.argmax\n        else:\n            raise ValueError(\"Invalid optimization direction '{}'\".format(opt_direction))\n\n        # set the acquisition function and surrogate model\n        self.optimize = self.__optimize\n        self.af_name = acquisition_function\n        self.af_params = acq_params\n        self.multi_afs = list(self.get_af_by_name(af_name) for af_name in multi_af_names)\n        self.set_acquisition_function(acquisition_function)\n        self.set_surrogate_model(cov_kernel_name, cov_kernel_lengthscale)\n\n        # set remaining values\n        self.results = []\n        self.__searchspace = searchspace\n        self.removed_tune_params = removed_tune_params\n        self.searchspace_size = len(self.searchspace)\n        self.num_dimensions = len(self.dimensions())\n        self.__current_optimum = self.worst_value\n        self.cv_norm_maximum = None\n        self.fevals = 0\n        self.__visited_num = 0\n        self.__visited_valid_num = 0\n        self.__visited_searchspace_indices = [False] * self.searchspace_size\n        self.__observations = [np.NaN] * self.searchspace_size\n        self.__valid_observation_indices = [False] * self.searchspace_size\n        self.__valid_params = list()\n        self.__valid_observations = list()\n        self.unvisited_cache = self.unvisited()\n        time_setup = time.perf_counter_ns()\n        self.error_message_searchspace_fully_observed = \"The search space has been fully observed\"\n\n        # take initial sample\n        if self.num_initial_samples > 0:\n            self.initial_sample()\n            time_initial_sample = time.perf_counter_ns()\n\n        # print the timings\n        if self.log_timings:\n            time_taken_setup = round(time_setup - time_start, 3) / 1000\n            time_taken_initial_sample = round(time_initial_sample - time_setup, 3) / 1000\n            time_taken_total = round(time_initial_sample - time_start, 3) / 1000\n            print(f\"Initialization | total time: {time_taken_total} | Setup: {time_taken_setup} | Initial sample: {time_taken_initial_sample}\", flush=True)\n\n    @property\n    def searchspace(self):\n        return self.__searchspace\n\n    @property\n    def observations(self):\n        return self.__observations\n\n    @property\n    def current_optimum(self):\n        return self.__current_optimum\n\n    @current_optimum.setter\n    def current_optimum(self, value: float):\n        self.__current_optimum = value\n\n    def is_better_than(self, a: float, b: float) -> bool:\n        \"\"\" Determines which one is better depending on optimization direction \"\"\"\n        return a < b if self.opt_direction == 'min' else a > b\n\n    def is_not_visited(self, index: int) -> bool:\n        \"\"\" Returns whether a searchspace index has not been visited \"\"\"\n        return not self.__visited_searchspace_indices[index]\n\n    def is_valid(self, observation: float) -> bool:\n        \"\"\" Returns whether an observation is valid \"\"\"\n        return not (observation == None or observation == self.invalid_value or observation == np.NaN)\n\n    def get_af_by_name(self, name: str):\n        \"\"\" Get the basic acquisition functions by their name \"\"\"\n        basic_af_names = ['ei', 'poi', 'lcb']\n        if name == 'ei':\n            return self.af_expected_improvement\n        elif name == 'poi':\n            return self.af_probability_of_improvement\n        elif name == 'lcb':\n            return self.af_lower_confidence_bound\n        raise ValueError(f\"{name} not in {basic_af_names}\")\n\n    def set_acquisition_function(self, acquisition_function: str):\n        \"\"\" Set the acquisition function \"\"\"\n        if acquisition_function == 'poi':\n            self.__af = self.af_probability_of_improvement\n        elif acquisition_function == 'ei':\n            self.__af = self.af_expected_improvement\n        elif acquisition_function == 'lcb':\n            self.__af = self.af_lower_confidence_bound\n        elif acquisition_function == 'lcb-srinivas':\n            self.__af = self.af_lower_confidence_bound_srinivas\n        elif acquisition_function == 'random':\n            self.__af = self.af_random\n        elif acquisition_function == 'multi':\n            self.optimize = self.__optimize_multi\n        elif acquisition_function == 'multi-advanced':\n            self.optimize = self.__optimize_multi_advanced\n        elif acquisition_function == 'multi-fast':\n            self.optimize = self.__optimize_multi_fast\n        else:\n            raise ValueError(\"Acquisition function must be one of {}, is {}\".format(self.supported_methods, acquisition_function))\n\n    def set_surrogate_model(self, cov_kernel_name: str, cov_kernel_lengthscale: float):\n        \"\"\" Set the surrogate model with a covariance function and lengthscale \"\"\"\n        if cov_kernel_name == \"constantrbf\":\n            kernel = ConstantKernel(1.0, constant_value_bounds=\"fixed\") * RBF(cov_kernel_lengthscale, length_scale_bounds=\"fixed\")\n        elif cov_kernel_name == \"rbf\":\n            kernel = RBF(length_scale=cov_kernel_lengthscale, length_scale_bounds=\"fixed\")\n        elif cov_kernel_name == \"matern32\":\n            kernel = Matern(length_scale=cov_kernel_lengthscale, nu=1.5, length_scale_bounds=\"fixed\")\n        elif cov_kernel_name == \"matern52\":\n            kernel = Matern(length_scale=cov_kernel_lengthscale, nu=2.5, length_scale_bounds=\"fixed\")\n        else:\n            raise ValueError(\"Acquisition function must be one of {}, is {}\".format(self.supported_cov_kernels, cov_kernel_name))\n        self.__model = GaussianProcessRegressor(kernel=kernel, alpha=1e-10, normalize_y=True)    # maybe change alpha to a higher value such as 1e-5?\n\n    def valid_params_observations(self) -> Tuple[list, list]:\n        \"\"\" Returns a list of valid observations and their parameter configurations \"\"\"\n        # if you do this every iteration, better keep it as cache and update in update_after_evaluation\n        params = list()\n        observations = list()\n        for index, valid in enumerate(self.__valid_observation_indices):\n            if valid is True:\n                params.append(self.searchspace[index])\n                observations.append(self.observations[index])\n        return params, observations\n\n    def unvisited(self) -> list:\n        \"\"\" Returns a list of unvisited parameter configurations - attention: cached version exists! \"\"\"\n        params = list(self.searchspace[index] for index, visited in enumerate(self.__visited_searchspace_indices) if visited is False)\n        return params\n\n    def find_param_config_index(self, param_config: tuple) -> int:\n        \"\"\" Find a parameter config index in the search space if it exists \"\"\"\n        return self.searchspace.index(param_config)\n\n    def find_param_config_unvisited_index(self, param_config: tuple) -> int:\n        \"\"\" Find a parameter config index in the unvisited cache if it exists \"\"\"\n        return self.unvisited_cache.index(param_config)\n\n    def normalize_param_config(self, param_config: tuple) -> tuple:\n        \"\"\" Normalizes a parameter configuration \"\"\"\n        normalized = tuple(self.normalized_dict[self.param_names[index]][param_value] for index, param_value in enumerate(param_config))\n        return normalized\n\n    def denormalize_param_config(self, param_config: tuple) -> tuple:\n        \"\"\" Denormalizes a parameter configuration \"\"\"\n        denormalized = tuple(self.denormalized_dict[self.param_names[index]][param_value] for index, param_value in enumerate(param_config))\n        return denormalized\n\n    def unprune_param_config(self, param_config: tuple) -> tuple:\n        \"\"\" In case of pruned dimensions, adds the removed dimensions back in the param config \"\"\"\n        unpruned = list()\n        pruned_count = 0\n        for removed in self.removed_tune_params:\n            if removed is not None:\n                unpruned.append(removed)\n            else:\n                unpruned.append(param_config[pruned_count])\n                pruned_count += 1\n        return tuple(unpruned)\n\n    def update_after_evaluation(self, observation: float, index: int, param_config: tuple):\n        \"\"\" Adjust the visited and valid index records accordingly \"\"\"\n        validity = self.is_valid(observation)\n        self.__visited_num += 1\n        self.__observations[index] = observation\n        self.__visited_searchspace_indices[index] = True\n        del self.unvisited_cache[self.find_param_config_unvisited_index(param_config)]\n        self.__valid_observation_indices[index] = validity\n        if validity is True:\n            self.__visited_valid_num += 1\n            self.__valid_params.append(param_config)\n            self.__valid_observations.append(observation)\n            if self.is_better_than(observation, self.current_optimum):\n                self.current_optimum = observation\n\n    def predict(self, x) -> Tuple[float, float]:\n        \"\"\" Returns a mean and standard deviation predicted by the surrogate model for the parameter configuration \"\"\"\n        return self.__model.predict([x], return_std=True)\n\n    def predict_list(self, lst: list) -> Tuple[list, list, list]:\n        \"\"\" Returns a list of means and standard deviations predicted by the surrogate model for the parameter configurations, and separate lists of means and standard deviations \"\"\"\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\")\n            mu, std = self.__model.predict(lst, return_std=True)\n            return list(zip(mu, std)), mu, std\n\n    def fit_observations_to_model(self):\n        \"\"\" Update the model based on the current list of observations \"\"\"\n        self.__model.fit(self.__valid_params, self.__valid_observations)\n\n    def evaluate_objective_function(self, param_config: tuple) -> float:\n        \"\"\" Evaluates the objective function \"\"\"\n        param_config = self.unprune_param_config(param_config)\n        denormalized_param_config = self.denormalize_param_config(param_config)\n        if not util.config_valid(denormalized_param_config, self.tuning_options, self.max_threads):\n            return self.invalid_value\n        val = minimize._cost_func(param_config, self.kernel_options, self.tuning_options, self.runner, self.results)\n        self.fevals += 1\n        return val\n\n    def dimensions(self) -> list:\n        \"\"\" List of parameter values per parameter \"\"\"\n        return self.tune_params.values()\n\n    def draw_random_sample(self) -> Tuple[list, int]:\n        \"\"\" Draw a random sample from the unvisited parameter configurations \"\"\"\n        if len(self.unvisited_cache) < 1:\n            raise ValueError(\"Searchspace exhausted during random sample draw as no valid configurations were found\")\n        index = randint(0, len(self.unvisited_cache) - 1)    # NOSONAR\n        param_config = self.unvisited_cache[index]\n        actual_index = self.find_param_config_index(param_config)\n        return param_config, actual_index\n\n    def draw_latin_hypercube_samples(self, num_samples: int) -> list:\n        \"\"\" Draws an LHS-distributed sample from the search space \"\"\"\n        if self.searchspace_size < num_samples:\n            raise ValueError(\"Can't sample more than the size of the search space\")\n        if self.sampling_crit is None:\n            lhs = Lhs(lhs_type=\"centered\", criterion=None)\n        else:\n            lhs = Lhs(lhs_type=\"classic\", criterion=self.sampling_crit, iterations=self.sampling_iter)\n        param_configs = lhs.generate(self.dimensions(), num_samples)\n        indices = list()\n        normalized_param_configs = list()\n        for i in range(len(param_configs) - 1):\n            try:\n                param_config = self.normalize_param_config(param_configs[i])\n                index = self.find_param_config_index(param_config)\n                indices.append(index)\n                normalized_param_configs.append(param_config)\n            except ValueError:\n                \"\"\" Due to search space restrictions, the search space may not be an exact cartesian product of the tunable parameter values.\n                It is thus possible for LHS to generate a parameter combination that is not in the actual searchspace, which must be skipped. \"\"\"\n                continue\n        return list(zip(normalized_param_configs, indices))\n\n    def initial_sample(self):\n        \"\"\" Draws an initial sample using random sampling \"\"\"\n        if self.num_initial_samples <= 0:\n            raise ValueError(\"At least one initial sample is required\")\n        if self.sampling_method == 'lhs':\n            samples = self.draw_latin_hypercube_samples(self.num_initial_samples)\n        elif self.sampling_method == 'random':\n            samples = list()\n        else:\n            raise ValueError(\"Sampling method must be one of {}, is {}\".format(self.supported_sampling_methods, self.sampling_method))\n        # collect the samples\n        collected_samples = 0\n        for params, index in samples:\n            observation = self.evaluate_objective_function(params)\n            self.update_after_evaluation(observation, index, params)\n            if self.is_valid(observation):\n                collected_samples += 1\n        # collect the remainder of the samples\n        while collected_samples < self.num_initial_samples:\n            params, index = self.draw_random_sample()\n            observation = self.evaluate_objective_function(params)\n            self.update_after_evaluation(observation, index, params)\n            # check for validity to avoid having no actual initial samples\n            if self.is_valid(observation):\n                collected_samples += 1\n        self.fit_observations_to_model()\n        _, _, std = self.predict_list(self.unvisited_cache)\n        self.initial_sample_mean = np.mean(self.__valid_observations)\n        # Alternatively:\n        # self.initial_sample_std = np.std(self.__valid_observations)\n        # self.initial_sample_mean = np.mean(predictions)\n        self.initial_std = np.mean(std)\n        self.cv_norm_maximum = self.initial_std\n\n    def contextual_variance(self, std: list):\n        \"\"\" Contextual improvement to decide explore / exploit, based on CI proposed by (Jasrasaria, 2018) \"\"\"\n        if not self.af_params['explorationfactor'] == 'CV':\n            return None\n        if self.opt_direction == 'min':\n            if self.current_optimum == self.worst_value:\n                return 0.01\n            if self.current_optimum <= 0:\n                # doesn't work well for minimization beyond 0, should that even be a thing?\n                return abs(np.mean(std) / self.current_optimum)\n            improvement_over_initial_sample = self.initial_sample_mean / self.current_optimum\n            cv = np.mean(std) / improvement_over_initial_sample\n            # normalize if available\n            if self.cv_norm_maximum:\n                cv = cv / self.cv_norm_maximum\n            return cv\n        return np.mean(std) / self.current_optimum\n\n    def __optimize(self, max_fevals):\n        \"\"\" Find the next best candidate configuration(s), evaluate those and update the model accordingly \"\"\"\n        while self.fevals < max_fevals:\n            if self.__visited_num >= self.searchspace_size:\n                raise ValueError(self.error_message_searchspace_fully_observed)\n            predictions, _, std = self.predict_list(self.unvisited_cache)\n            hyperparam = self.contextual_variance(std)\n            list_of_acquisition_values = self.__af(predictions, hyperparam)\n            # afterwards select the best AF value\n            best_af = self.argopt(list_of_acquisition_values)\n            candidate_params = self.unvisited_cache[best_af]\n            candidate_index = self.find_param_config_index(candidate_params)\n            observation = self.evaluate_objective_function(candidate_params)\n            self.update_after_evaluation(observation, candidate_index, candidate_params)\n            self.fit_observations_to_model()\n        return self.results\n\n    def __optimize_multi(self, max_fevals):\n        \"\"\" Optimize with a portfolio of multiple acquisition functions. Predictions are always only taken once. Skips AFs if they suggest X/max_evals duplicates in a row, prefers AF with best discounted average. \"\"\"\n        if self.opt_direction != 'min':\n            raise ValueError(f\"Optimization direction must be minimization ('min'), is {self.opt_direction}\")\n        # calculate how many times an AF can suggest a duplicate candidate before the AF is skipped\n        # skip_duplicates_fraction = self.af_params['skip_duplicates_fraction']\n        # skip_if_duplicate_n_times = int(min(max(round(skip_duplicates_fraction * max_fevals), 3), max_fevals))\n        skip_if_duplicate_n_times = self.af_params['skip_duplicate_after']\n        discount_factor = self.multi_afs_discount_factor\n        # setup the registration of duplicates and runtimes\n        duplicate_count_template = [0 for _ in range(skip_if_duplicate_n_times)]\n        duplicate_candidate_af_count = list(deepcopy(duplicate_count_template) for _ in range(3))\n        skip_af_index = list()\n        af_runtimes = [0, 0, 0]\n        af_observations = [list(), list(), list()]\n        initial_sample_mean = np.mean(self.__valid_observations)\n        while self.fevals < max_fevals:\n            time_start = time.perf_counter_ns()\n            # the first acquisition function is never skipped, so that should be the best for the endgame (EI)\n            aqfs = self.multi_afs\n            predictions, _, std = self.predict_list(self.unvisited_cache)\n            hyperparam = self.contextual_variance(std)\n            if self.__visited_num >= self.searchspace_size:\n                raise ValueError(self.error_message_searchspace_fully_observed)\n            time_predictions = time.perf_counter_ns()\n            actual_candidate_params = list()\n            actual_candidate_indices = list()\n            actual_candidate_af_indices = list()\n            duplicate_candidate_af_indices = list()\n            duplicate_candidate_original_af_indices = list()\n            for af_index, af in enumerate(aqfs):\n                if af_index in skip_af_index:\n                    continue\n                if self.__visited_num >= self.searchspace_size or self.fevals >= max_fevals:\n                    break\n                timer_start = time.perf_counter()\n                list_of_acquisition_values = af(predictions, hyperparam)\n                best_af = self.argopt(list_of_acquisition_values)\n                time_taken = time.perf_counter() - timer_start\n                af_runtimes[af_index] += time_taken\n                is_duplicate = best_af in actual_candidate_indices\n                if not is_duplicate:\n                    candidate_params = self.unvisited_cache[best_af]\n                    actual_candidate_params.append(candidate_params)\n                    actual_candidate_indices.append(best_af)\n                    actual_candidate_af_indices.append(af_index)\n                # register whether the AF suggested a duplicate candidate\n                duplicate_candidate_af_count[af_index].pop(0)\n                duplicate_candidate_af_count[af_index].append(1 if is_duplicate else 0)\n                if is_duplicate:\n                    # find the index of the AF that first registered the duplicate\n                    original_duplicate_af_index = actual_candidate_af_indices[actual_candidate_indices.index(best_af)]\n                    # register that AF as duplicate as well\n                    duplicate_candidate_af_count[original_duplicate_af_index][-1] = 1\n                    duplicate_candidate_af_indices.append(af_index)\n                    duplicate_candidate_original_af_indices.append(original_duplicate_af_index)\n            time_afs = time.perf_counter_ns()\n            # evaluate the non-duplicate candidates\n            for index, af_index in enumerate(actual_candidate_af_indices):\n                candidate_params = actual_candidate_params[index]\n                candidate_index = self.find_param_config_index(candidate_params)\n                observation = self.evaluate_objective_function(candidate_params)\n                self.update_after_evaluation(observation, candidate_index, candidate_params)\n                if observation != self.invalid_value:\n                    # we use the registered observations for maximization of the discounted reward\n                    reg_observation = observation if self.opt_direction == 'min' else -1 * observation\n                    af_observations[actual_candidate_af_indices[index]].append(reg_observation)\n                else:\n                    reg_invalid_observation = initial_sample_mean if self.opt_direction == 'min' else -1 * initial_sample_mean\n                    af_observations[actual_candidate_af_indices[index]].append(reg_invalid_observation)\n            for index, af_index in enumerate(duplicate_candidate_af_indices):\n                original_observation = af_observations[duplicate_candidate_original_af_indices[index]][-1]\n                af_observations[af_index].append(original_observation)\n            self.fit_observations_to_model()\n            time_eval = time.perf_counter_ns()\n            # assert that all observation lists of non-skipped acquisition functions are of the same length\n            non_skipped_af_indices = list(af_index for af_index, _ in enumerate(aqfs) if af_index not in skip_af_index)\n            assert all(len(af_observations[non_skipped_af_indices[0]]) == len(af_observations[af_index]) for af_index in non_skipped_af_indices)\n            # find the AFs elligble for being skipped\n            candidates_for_skip = list()\n            for af_index, count in enumerate(duplicate_candidate_af_count):\n                if sum(count) >= skip_if_duplicate_n_times and af_index not in skip_af_index:\n                    candidates_for_skip.append(af_index)\n            # do not skip the AF with the lowest runtime\n            if len(candidates_for_skip) > 1:\n                candidates_for_skip_discounted = list(\n                    sum(list(obs * discount_factor**(len(observations) - 1 - i) for i, obs in enumerate(observations)))\n                    for af_index, observations in enumerate(af_observations) if af_index in candidates_for_skip)\n                af_not_to_skip = candidates_for_skip[np.argmin(candidates_for_skip_discounted)]\n                for af_index in candidates_for_skip:\n                    if af_index == af_not_to_skip:\n                        # do not skip the AF with the lowest runtime and give it a clean slate\n                        duplicate_candidate_af_count[af_index] = deepcopy(duplicate_count_template)\n                        continue\n                    skip_af_index.append(af_index)\n                    if len(skip_af_index) >= len(aqfs):\n                        raise ValueError(\"There are no acquisition functions left! This should not happen...\")\n            time_af_selection = time.perf_counter_ns()\n\n            # printing timings\n            if self.log_timings:\n                time_taken_predictions = round(time_predictions - time_start, 3) / 1000\n                time_taken_afs = round(time_afs - time_predictions, 3) / 1000\n                time_taken_eval = round(time_eval - time_afs, 3) / 1000\n                time_taken_af_selection = round(time_af_selection - time_eval, 3) / 1000\n                time_taken_total = round(time_af_selection - time_start, 3) / 1000\n                print(\n                    f\"({self.fevals}/{max_fevals}) Total time: {time_taken_total} | Predictions: {time_taken_predictions} | AFs: {time_taken_afs} | Eval: {time_taken_eval} | AF selection: {time_taken_af_selection}\",\n                    flush=True)\n        return self.results\n\n    def __optimize_multi_advanced(self, max_fevals, increase_precision=False):\n        \"\"\" Optimize with a portfolio of multiple acquisition functions. Predictions are only taken once, unless increase_precision is true. Skips AFs if they are consistently worse than the mean of discounted observations, promotes AFs if they are consistently better than this mean. \"\"\"\n        if self.opt_direction != 'min':\n            raise ValueError(f\"Optimization direction must be minimization ('min'), is {self.opt_direction}\")\n        aqfs = self.multi_afs\n        discount_factor = self.multi_afs_discount_factor\n        required_improvement_factor = self.multi_afs_required_improvement_factor\n        required_improvement_worse = 1 + required_improvement_factor\n        required_improvement_better = 1 - required_improvement_factor\n        min_required_count = self.af_params['skip_duplicate_after']\n        skip_af_index = list()\n        single_af = len(aqfs) <= len(skip_af_index) + 1\n        af_observations = [list(), list(), list()]\n        af_performs_worse_count = [0, 0, 0]\n        af_performs_better_count = [0, 0, 0]\n        while self.fevals < max_fevals:\n            if single_af:\n                return self.__optimize(max_fevals)\n            if self.__visited_num >= self.searchspace_size:\n                raise ValueError(self.error_message_searchspace_fully_observed)\n            observations_median = np.median(self.__valid_observations)\n            if increase_precision is False:\n                predictions, _, std = self.predict_list(self.unvisited_cache)\n                hyperparam = self.contextual_variance(std)\n            for af_index, af in enumerate(aqfs):\n                if af_index in skip_af_index:\n                    continue\n                if self.__visited_num >= self.searchspace_size or self.fevals >= max_fevals:\n                    break\n                if increase_precision is True:\n                    predictions, _, std = self.predict_list(self.unvisited_cache)\n                    hyperparam = self.contextual_variance(std)\n                list_of_acquisition_values = af(predictions, hyperparam)\n                best_af = self.argopt(list_of_acquisition_values)\n                del predictions[best_af]    # to avoid going out of bounds\n                candidate_params = self.unvisited_cache[best_af]\n                candidate_index = self.find_param_config_index(candidate_params)\n                observation = self.evaluate_objective_function(candidate_params)\n                self.update_after_evaluation(observation, candidate_index, candidate_params)\n                if increase_precision is True:\n                    self.fit_observations_to_model()\n                # we use the registered observations for maximization of the discounted reward\n                if observation != self.invalid_value:\n                    reg_observation = observation if self.opt_direction == 'min' else -1 * observation\n                    af_observations[af_index].append(reg_observation)\n                else:\n                    # if the observation is invalid, use the median of all valid observations to avoid skewing the discounted observations\n                    reg_invalid_observation = observations_median if self.opt_direction == 'min' else -1 * observations_median\n                    af_observations[af_index].append(reg_invalid_observation)\n            if increase_precision is False:\n                self.fit_observations_to_model()\n\n            # calculate the mean of discounted observations over the remaining acquisition functions\n            discounted_obs = list(\n                sum(list(obs * discount_factor**(len(observations) - 1 - i) for i, obs in enumerate(observations))) for observations in af_observations)\n            disc_obs_mean = np.mean(list(discounted_obs[af_index] for af_index, _ in enumerate(aqfs) if af_index not in skip_af_index))\n\n            # register which AFs perform more than 10% better than average and which more than 10% worse than average\n            for af_index, discounted_observation in enumerate(discounted_obs):\n                if discounted_observation > disc_obs_mean * required_improvement_worse:\n                    af_performs_worse_count[af_index] += 1\n                elif discounted_observation < disc_obs_mean * required_improvement_better:\n                    af_performs_better_count[af_index] += 1\n\n            # find the worst AF, discounted observations is leading for a draw\n            worst_count = max(list(count for af_index, count in enumerate(af_performs_worse_count) if af_index not in skip_af_index))\n            af_index_worst = -1\n            if worst_count >= min_required_count:\n                for af_index, count in enumerate(af_performs_worse_count):\n                    if af_index not in skip_af_index and count == worst_count and (af_index_worst == -1\n                                                                                   or discounted_obs[af_index] > discounted_obs[af_index_worst]):\n                        af_index_worst = af_index\n\n            # skip the worst AF\n            if af_index_worst > -1:\n                skip_af_index.append(af_index_worst)\n                # reset the counts to even the playing field for the remaining AFs\n                af_performs_worse_count = [0, 0, 0]\n                af_performs_better_count = [0, 0, 0]\n                # if there is only one AF left, register as single AF\n                if len(aqfs) <= len(skip_af_index) + 1:\n                    single_af = True\n                    af_indices_left = list(af_index for af_index, _ in enumerate(aqfs) if af_index not in skip_af_index)\n                    assert len(af_indices_left) == 1\n                    self.__af = aqfs[af_indices_left[0]]\n            else:\n                # find the best AF, discounted observations is leading for a draw\n                best_count = max(list(count for af_index, count in enumerate(af_performs_better_count) if af_index not in skip_af_index))\n                af_index_best = -1\n                if best_count >= min_required_count:\n                    for af_index, count in enumerate(af_performs_better_count):\n                        if af_index not in skip_af_index and count == best_count and (af_index_best == -1\n                                                                                      or discounted_obs[af_index] < discounted_obs[af_index_best]):\n                            af_index_best = af_index\n                # make the best AF single\n                if af_index_best > -1:\n                    single_af = True\n                    self.__af = aqfs[af_index_best]\n\n        return self.results\n\n    def __optimize_multi_fast(self, max_fevals):\n        \"\"\" Optimize with a portfolio of multiple acquisition functions. Predictions are only taken once. \"\"\"\n        while self.fevals < max_fevals:\n            aqfs = self.multi_afs\n            # if we take the prediction only once, we want to go from most exploiting to most exploring, because the more exploiting an AF is, the more it relies on non-stale information from the model\n            predictions, _, std = self.predict_list(self.unvisited_cache)\n            hyperparam = self.contextual_variance(std)\n            if self.__visited_num >= self.searchspace_size:\n                raise ValueError(self.error_message_searchspace_fully_observed)\n            for af in aqfs:\n                if self.__visited_num >= self.searchspace_size or self.fevals >= max_fevals:\n                    break\n                list_of_acquisition_values = af(predictions, hyperparam)\n                best_af = self.argopt(list_of_acquisition_values)\n                del predictions[best_af]    # to avoid going out of bounds\n                candidate_params = self.unvisited_cache[best_af]\n                candidate_index = self.find_param_config_index(candidate_params)\n                observation = self.evaluate_objective_function(candidate_params)\n                self.update_after_evaluation(observation, candidate_index, candidate_params)\n            self.fit_observations_to_model()\n        return self.results\n\n    def af_random(self, predictions=None, hyperparam=None) -> list:\n        \"\"\" Acquisition function returning a randomly shuffled list for comparison \"\"\"\n        list_random = range(len(self.unvisited_cache))\n        shuffle(list_random)\n        return list_random\n\n    def af_probability_of_improvement(self, predictions=None, hyperparam=None) -> list:\n        \"\"\" Acquisition function Probability of Improvement (PI) \"\"\"\n\n        # prefetch required data\n        if predictions is None:\n            predictions, _, _ = self.predict_list(self.unvisited_cache)\n        if hyperparam is None:\n            hyperparam = self.af_params['explorationfactor']\n        fplus = self.current_optimum - hyperparam\n\n        # precompute difference of improvement\n        list_diff_improvement = list(-((fplus - x_mu) / (x_std + 1E-9)) for (x_mu, x_std) in predictions)\n\n        # compute probability of improvement with CDF in bulk\n        list_prob_improvement = norm.cdf(list_diff_improvement)\n\n        return list_prob_improvement\n\n    def af_expected_improvement(self, predictions=None, hyperparam=None) -> list:\n        \"\"\" Acquisition function Expected Improvement (EI) \"\"\"\n\n        # prefetch required data\n        if predictions is None:\n            predictions, _, _ = self.predict_list(self.unvisited_cache)\n        if hyperparam is None:\n            hyperparam = self.af_params['explorationfactor']\n        fplus = self.current_optimum - hyperparam\n\n        # precompute difference of improvement, CDF and PDF in bulk\n        list_diff_improvement = list((fplus - x_mu) / (x_std + 1E-9) for (x_mu, x_std) in predictions)\n        list_cdf = norm.cdf(list_diff_improvement)\n        list_pdf = norm.pdf(list_diff_improvement)\n\n        # specify AF calculation\n        def exp_improvement(index) -> float:\n            x_mu, x_std = predictions[index]\n            ei = (fplus - x_mu) * list_cdf[index] + x_std * list_pdf[index]\n            return -ei\n\n        # calculate AF\n        list_exp_improvement = list(map(exp_improvement, range(len(predictions))))\n        return list_exp_improvement\n\n    def af_lower_confidence_bound(self, predictions=None, hyperparam=None) -> list:\n        \"\"\" Acquisition function Lower Confidence Bound (LCB) \"\"\"\n\n        # prefetch required data\n        if predictions is None:\n            predictions, _, _ = self.predict_list(self.unvisited_cache)\n        if hyperparam is None:\n            hyperparam = self.af_params['explorationfactor']\n        beta = hyperparam\n\n        # compute LCB in bulk\n        list_lower_confidence_bound = list(x_mu - beta * x_std for (x_mu, x_std) in predictions)\n        return list_lower_confidence_bound\n\n    def af_lower_confidence_bound_srinivas(self, predictions=None, hyperparam=None) -> list:\n        \"\"\" Acquisition function Lower Confidence Bound (UCB-S) after Srinivas, 2010 / Brochu, 2010 \"\"\"\n\n        # prefetch required data\n        if predictions is None:\n            predictions, _, _ = self.predict_list(self.unvisited_cache)\n        if hyperparam is None:\n            hyperparam = self.af_params['explorationfactor']\n\n        # precompute beta parameter\n        zeta = self.af_params['zeta']\n        t = self.fevals\n        d = self.num_dimensions\n        delta = hyperparam\n        beta = np.sqrt(zeta * (2 * np.log((t**(d / 2. + 2)) * (np.pi**2) / (3. * delta))))\n\n        # compute UCB in bulk\n        list_lower_confidence_bound = list(x_mu - beta * x_std for (x_mu, x_std) in predictions)\n        return list_lower_confidence_bound\n\n    def visualize_after_opt(self):\n        \"\"\" Visualize the model after the optimization \"\"\"\n        print(self.__model.kernel_.get_params())\n        print(self.__model.log_marginal_likelihood())\n        import matplotlib.pyplot as plt\n        _, mu, std = self.predict_list(self.searchspace)\n        brute_force_observations = list()\n        for param_config in self.searchspace:\n            obs = minimize._cost_func(param_config, self.kernel_options, self.tuning_options, self.runner, self.results)\n            if obs == self.invalid_value:\n                obs = None\n            brute_force_observations.append(obs)\n        x_axis = range(len(mu))\n        plt.fill_between(x_axis, mu - std, mu + std, alpha=0.2, antialiased=True)\n        plt.plot(x_axis, mu, label=\"predictions\", linestyle=' ', marker='.')\n        plt.plot(x_axis, brute_force_observations, label=\"actual\", linestyle=' ', marker='.')\n        plt.legend()\n        plt.show()\n", 837], "/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch.py": ["\"\"\" Bayesian Optimization implementation from the thesis by Willemsen \"\"\"\nfrom copy import deepcopy\nfrom random import randint, shuffle\nimport itertools\nimport warnings\nimport time\nfrom typing import Tuple\n\nimport numpy as np\nfrom scipy.stats import norm\n\n# BO imports\ntry:\n    import torch\n    import gpytorch\n    from sklearn.gaussian_process.kernels import ConstantKernel, RBF, Matern\n    from sklearn.exceptions import ConvergenceWarning\n    from skopt.sampler import Lhs\n    bayes_opt_present = True\nexcept ImportError:\n    bayes_opt_present = False\n\nfrom kernel_tuner.strategies import minimize\nfrom kernel_tuner import util\n\nsupported_methods = [\"poi\", \"ei\", \"lcb\", \"lcb-srinivas\", \"multi\", \"multi-advanced\", \"multi-fast\"]\n\n\ndef generate_normalized_param_dicts(tune_params: dict, eps: float) -> Tuple[dict, dict]:\n    \"\"\" Generates normalization and denormalization dictionaries \"\"\"\n    original_to_normalized = dict()\n    normalized_to_original = dict()\n    for param_name in tune_params.keys():\n        original_to_normalized_dict = dict()\n        normalized_to_original_dict = dict()\n        for value_index, value in enumerate(tune_params[param_name]):\n            normalized_value = eps * value_index + 0.5 * eps\n            normalized_to_original_dict[normalized_value] = value\n            original_to_normalized_dict[value] = normalized_value\n        original_to_normalized[param_name] = original_to_normalized_dict\n        normalized_to_original[param_name] = normalized_to_original_dict\n    return original_to_normalized, normalized_to_original\n\n\ndef normalize_parameter_space(param_space: list, tune_params: dict, normalized: dict) -> list:\n    \"\"\" Normalize the parameter space given a normalization dictionary \"\"\"\n    keys = list(tune_params.keys())\n    param_space_normalized = list(tuple(normalized[keys[i]][v] for i, v in enumerate(params)) for params in param_space)\n    return param_space_normalized\n\n\ndef prune_parameter_space(parameter_space, tuning_options, tune_params, normalize_dict: dict, max_threads: int):\n    \"\"\" Pruning of the parameter space to remove dimensions that have a constant parameter \"\"\"\n    pruned_tune_params_mask = list()\n    removed_tune_params = list()\n    param_names = list(tune_params.keys())\n    for index, key in enumerate(tune_params.keys()):\n        pruned_tune_params_mask.append(len(tune_params[key]) > 1)\n        if len(tune_params[key]) > 1:\n            removed_tune_params.append(None)\n        else:\n            value = tune_params[key][0]\n            normalized = normalize_dict[param_names[index]][value]\n            removed_tune_params.append(normalized)\n    if 'verbose' in tuning_options and tuning_options.verbose is True and len(tune_params.keys()) != sum(pruned_tune_params_mask):\n        print(f\"Number of parameters (dimensions): {len(tune_params.keys())}, after pruning: {sum(pruned_tune_params_mask)}\")\n    # TODO check whether the number of pruned parameters is correct\n    # print(\n    #     f\"Number of parameters (dimensions): {len(tune_params.keys())}, after pruning: {sum(pruned_tune_params_mask)}, by util: {util.get_number_of_valid_configs(tuning_options, max_threads)}\"\n    # )\n    parameter_space = list(tuple(itertools.compress(param_config, pruned_tune_params_mask)) for param_config in parameter_space)\n    return parameter_space, removed_tune_params\n\n\ndef tune(runner, kernel_options, device_options, tuning_options):\n    \"\"\" Find the best performing kernel configuration in the parameter space\n\n    :params runner: A runner from kernel_tuner.runners\n    :type runner: kernel_tuner.runner\n\n    :param kernel_options: A dictionary with all options for the kernel.\n    :type kernel_options: kernel_tuner.interface.Options\n\n    :param device_options: A dictionary with all options for the device\n        on which the kernel should be tuned.\n    :type device_options: kernel_tuner.interface.Options\n\n    :param tuning_options: A dictionary with all options regarding the tuning\n        process. Allows setting hyperparameters via the strategy_options key.\n    :type tuning_options: kernel_tuner.interface.Options\n\n    :returns: A list of dictionaries for executed kernel configurations and their\n        execution times. And a dictionary that contains a information\n        about the hardware/software environment on which the tuning took place.\n    :rtype: list(dict()), dict()\n\n    \"\"\"\n\n    max_fevals = tuning_options.strategy_options.get(\"max_fevals\", 100)\n    prune_parameterspace = tuning_options.strategy_options.get(\"pruneparameterspace\", True)\n    if not bayes_opt_present:\n        raise ImportError(\"Error: optional dependencies for Bayesian Optimization not installed, please install scikit-learn and scikit-optimize\")\n\n    # epsilon for scaling should be the evenly spaced distance between the largest set of parameter options in an interval [0,1]\n    tune_params = tuning_options.tune_params\n    tuning_options[\"scaling\"] = True\n    _, _, eps = minimize.get_bounds_x0_eps(tuning_options)\n\n    # compute cartesian product of all tunable parameters\n    parameter_space = itertools.product(*tune_params.values())\n\n    # check for search space restrictions\n    if tuning_options.restrictions is not None:\n        tuning_options.verbose = False\n    parameter_space = filter(lambda p: util.config_valid(p, tuning_options, runner.dev.max_threads), parameter_space)\n    parameter_space = list(parameter_space)\n    if len(parameter_space) < 1:\n        raise ValueError(\"Empty parameterspace after restrictionscheck. Restrictionscheck is possibly too strict.\")\n    if len(parameter_space) == 1:\n        raise ValueError(f\"Only one configuration after restrictionscheck. Restrictionscheck is possibly too strict. Configuration: {parameter_space[0]}\")\n\n    # normalize search space to [0,1]\n    normalize_dict, denormalize_dict = generate_normalized_param_dicts(tune_params, eps)\n    parameter_space = normalize_parameter_space(parameter_space, tune_params, normalize_dict)\n\n    # prune the parameter space to remove dimensions that have a constant parameter\n    if prune_parameterspace:\n        parameter_space, removed_tune_params = prune_parameter_space(parameter_space, tuning_options, tune_params, normalize_dict, runner.dev.max_threads)\n    else:\n        parameter_space = list(parameter_space)\n        removed_tune_params = [None] * len(tune_params.keys())\n\n    # initialize and optimize\n    bo = BayesianOptimization(parameter_space, removed_tune_params, kernel_options, tuning_options, normalize_dict, denormalize_dict, runner)\n    results = bo.optimize(max_fevals)\n\n    return results, runner.dev.get_environment()\n\n\nclass ExactGPModel(gpytorch.models.ExactGP):\n    \"\"\" Very simple exact Gaussian Process model \"\"\"\n\n    def __init__(self, train_x, train_y, likelihood):\n        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n        self.mean_module = gpytorch.means.ZeroMean()    # TODO maybe try ConstantMean or LinearMean\n        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.MaternKernel(nu=1.5))    # TODO maybe try ScaleKernel(MaternKernel)\n\n    def forward(self, x):\n        mean_x = self.mean_module(x)\n        covar_x = self.covar_module(x)\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n\n\nclass BayesianOptimization():\n\n    def __init__(self, searchspace: list, removed_tune_params: list, kernel_options: dict, tuning_options: dict, normalize_dict: dict, denormalize_dict: dict,\n                 runner, opt_direction='min'):\n        time_start = time.perf_counter_ns()\n\n        # supported hyperparameter values\n        self.supported_cov_kernels = [\"constantrbf\", \"rbf\", \"matern32\", \"matern52\"]\n        self.supported_methods = supported_methods\n        self.supported_sampling_methods = [\"random\", \"lhs\"]\n        self.supported_sampling_criterion = [\"correlation\", \"ratio\", \"maximin\", None]\n\n        def get_hyperparam(name: str, default, supported_values=list()):\n            value = tuning_options.strategy_options.get(name, default)\n            if len(supported_values) > 0 and value not in supported_values:\n                raise ValueError(f\"'{name}' is set to {value}, but must be one of {supported_values}\")\n            return value\n\n        # get hyperparameters\n        cov_kernel_name = get_hyperparam(\"covariancekernel\", \"matern32\", self.supported_cov_kernels)\n        cov_kernel_lengthscale = get_hyperparam(\"covariancelengthscale\", 1.5)\n        acquisition_function = get_hyperparam(\"method\", \"multi-advanced\", self.supported_methods)\n        acq = acquisition_function\n        acq_params = get_hyperparam(\"methodparams\", {})\n        multi_af_names = get_hyperparam(\"multi_af_names\", ['ei', 'poi', 'lcb'])\n        self.multi_afs_discount_factor = get_hyperparam(\"multi_af_discount_factor\", 0.65 if acq == 'multi' else 0.95)\n        self.multi_afs_required_improvement_factor = get_hyperparam(\"multi_afs_required_improvement_factor\", 0.15 if acq == 'multi-advanced-precise' else 0.1)\n        self.training_iter = get_hyperparam(\"training_iter\", 10)\n        self.num_initial_samples = get_hyperparam(\"popsize\", 20)\n        self.sampling_method = get_hyperparam(\"samplingmethod\", \"lhs\", self.supported_sampling_methods)\n        self.sampling_crit = get_hyperparam(\"samplingcriterion\", 'maximin', self.supported_sampling_criterion)\n        self.sampling_iter = get_hyperparam(\"samplingiterations\", 1000)\n\n        # set acquisition function hyperparameter defaults where missing\n        if 'explorationfactor' not in acq_params:\n            acq_params['explorationfactor'] = 'CV'\n        if 'zeta' not in acq_params:\n            acq_params['zeta'] = 1\n        if 'skip_duplicate_after' not in acq_params:\n            acq_params['skip_duplicate_after'] = 5\n\n        # set arguments\n        self.kernel_options = kernel_options\n        self.tuning_options = tuning_options\n        self.tune_params = tuning_options.tune_params\n        self.param_names = list(self.tune_params.keys())\n        self.normalized_dict = normalize_dict\n        self.denormalized_dict = denormalize_dict\n        self.runner = runner\n        self.max_threads = runner.dev.max_threads\n        self.log_timings = False\n\n        # set optimization constants\n        self.invalid_value = 1e20\n        self.opt_direction = opt_direction\n        if opt_direction == 'min':\n            self.worst_value = np.PINF\n            self.argopt = np.argmin\n        elif opt_direction == 'max':\n            self.worst_value = np.NINF\n            self.argopt = np.argmax\n        else:\n            raise ValueError(\"Invalid optimization direction '{}'\".format(opt_direction))\n\n        # set the acquisition function and surrogate model\n        self.optimize = self.__optimize\n        self.af_name = acquisition_function\n        self.af_params = acq_params\n        self.multi_afs = list(self.get_af_by_name(af_name) for af_name in multi_af_names)\n        self.set_acquisition_function(acquisition_function)\n        # self.set_surrogate_model(cov_kernel_name, cov_kernel_lengthscale)\n\n        # set remaining values\n        self.results = []\n        self.__searchspace = searchspace\n        self.removed_tune_params = removed_tune_params\n        self.searchspace_size = len(self.searchspace)\n        self.hyperparams = {\n            'loss': np.nan,\n            'lengthscale': np.nan,\n            'noise': np.nan,\n        }\n        self.num_dimensions = len(self.dimensions())\n        self.__current_optimum = self.worst_value\n        self.cv_norm_maximum = None\n        self.fevals = 0\n        self.__visited_num = 0\n        self.__visited_valid_num = 0\n        self.__visited_searchspace_indices = [False] * self.searchspace_size\n        self.__observations = [np.NaN] * self.searchspace_size\n        self.__valid_observation_indices = [False] * self.searchspace_size\n        self.__valid_params = list()\n        self.__valid_observations = list()\n        self.unvisited_cache = self.unvisited()\n        time_setup = time.perf_counter_ns()\n        self.error_message_searchspace_fully_observed = \"The search space has been fully observed\"\n\n        # take initial sample\n        self.initial_sample()\n        time_initial_sample = time.perf_counter_ns()\n\n        # print the timings\n        if self.log_timings:\n            time_taken_setup = round(time_setup - time_start, 3) / 1000\n            time_taken_initial_sample = round(time_initial_sample - time_setup, 3) / 1000\n            time_taken_total = round(time_initial_sample - time_start, 3) / 1000\n            print(f\"Initialization | total time: {time_taken_total} | Setup: {time_taken_setup} | Initial sample: {time_taken_initial_sample}\", flush=True)\n\n    @property\n    def searchspace(self):\n        return self.__searchspace\n\n    @property\n    def observations(self):\n        return self.__observations\n\n    @property\n    def current_optimum(self):\n        return self.__current_optimum\n\n    @current_optimum.setter\n    def current_optimum(self, value: float):\n        self.__current_optimum = value\n\n    def is_better_than(self, a: float, b: float) -> bool:\n        \"\"\" Determines which one is better depending on optimization direction \"\"\"\n        return a < b if self.opt_direction == 'min' else a > b\n\n    def is_not_visited(self, index: int) -> bool:\n        \"\"\" Returns whether a searchspace index has not been visited \"\"\"\n        return not self.__visited_searchspace_indices[index]\n\n    def is_valid(self, observation: float) -> bool:\n        \"\"\" Returns whether an observation is valid \"\"\"\n        return not (observation == None or observation == self.invalid_value or observation == np.NaN)\n\n    def get_af_by_name(self, name: str):\n        \"\"\" Get the basic acquisition functions by their name \"\"\"\n        basic_af_names = ['ei', 'poi', 'lcb']\n        if name == 'ei':\n            return self.af_expected_improvement\n        elif name == 'poi':\n            return self.af_probability_of_improvement\n        elif name == 'lcb':\n            return self.af_lower_confidence_bound\n        raise ValueError(f\"{name} not in {basic_af_names}\")\n\n    def set_acquisition_function(self, acquisition_function: str):\n        \"\"\" Set the acquisition function \"\"\"\n        if acquisition_function == 'poi':\n            self.__af = self.af_probability_of_improvement\n        elif acquisition_function == 'ei':\n            self.__af = self.af_expected_improvement\n        elif acquisition_function == 'lcb':\n            self.__af = self.af_lower_confidence_bound\n        elif acquisition_function == 'lcb-srinivas':\n            self.__af = self.af_lower_confidence_bound_srinivas\n        elif acquisition_function == 'random':\n            self.__af = self.af_random\n        elif acquisition_function == 'multi':\n            self.optimize = self.__optimize_multi\n        elif acquisition_function == 'multi-advanced':\n            self.optimize = self.__optimize_multi_advanced\n        elif acquisition_function == 'multi-fast':\n            self.optimize = self.__optimize_multi_fast\n        else:\n            raise ValueError(\"Acquisition function must be one of {}, is {}\".format(self.supported_methods, acquisition_function))\n\n    def set_surrogate_model(self, cov_kernel_name: str, cov_kernel_lengthscale: float):\n        \"\"\" Set the surrogate model with a covariance function and lengthscale \"\"\"\n        # TODO remove or adapt this\n        if cov_kernel_name == \"constantrbf\":\n            kernel = ConstantKernel(1.0, constant_value_bounds=\"fixed\") * RBF(cov_kernel_lengthscale, length_scale_bounds=\"fixed\")\n        elif cov_kernel_name == \"rbf\":\n            kernel = RBF(length_scale=cov_kernel_lengthscale, length_scale_bounds=\"fixed\")\n        elif cov_kernel_name == \"matern32\":\n            kernel = Matern(length_scale=cov_kernel_lengthscale, nu=1.5, length_scale_bounds=\"fixed\")\n        elif cov_kernel_name == \"matern52\":\n            kernel = Matern(length_scale=cov_kernel_lengthscale, nu=2.5, length_scale_bounds=\"fixed\")\n        else:\n            raise ValueError(f\"Acquisition function must be one of {self.supported_cov_kernels}, is {cov_kernel_name}\")\n        likelihood = gpytorch.likelihoods.GaussianLikelihood()\n        self.__model = ExactGPModel(train_x, train_y, likelihood)\n        # self.__model = GaussianProcessRegressor(kernel=kernel, alpha=1e-10, normalize_y=True)    # maybe change alpha to a higher value such as 1e-5?\n\n    def valid_params_observations(self) -> Tuple[list, list]:\n        \"\"\" Returns a list of valid observations and their parameter configurations \"\"\"\n        # if you do this every iteration, better keep it as cache and update in update_after_evaluation\n        params = list()\n        observations = list()\n        for index, valid in enumerate(self.__valid_observation_indices):\n            if valid is True:\n                params.append(self.searchspace[index])\n                observations.append(self.observations[index])\n        return params, observations\n\n    def unvisited(self) -> list:\n        \"\"\" Returns a list of unvisited parameter configurations - attention: cached version exists! \"\"\"\n        params = list(self.searchspace[index] for index, visited in enumerate(self.__visited_searchspace_indices) if visited is False)\n        return params\n\n    def find_param_config_index(self, param_config: tuple) -> int:\n        \"\"\" Find a parameter config index in the search space if it exists \"\"\"\n        return self.searchspace.index(param_config)\n\n    def find_param_config_unvisited_index(self, param_config: tuple) -> int:\n        \"\"\" Find a parameter config index in the unvisited cache if it exists \"\"\"\n        return self.unvisited_cache.index(param_config)\n\n    def normalize_param_config(self, param_config: tuple) -> tuple:\n        \"\"\" Normalizes a parameter configuration \"\"\"\n        normalized = tuple(self.normalized_dict[self.param_names[index]][param_value] for index, param_value in enumerate(param_config))\n        return normalized\n\n    def denormalize_param_config(self, param_config: tuple) -> tuple:\n        \"\"\" Denormalizes a parameter configuration \"\"\"\n        denormalized = tuple(self.denormalized_dict[self.param_names[index]][param_value] for index, param_value in enumerate(param_config))\n        return denormalized\n\n    def unprune_param_config(self, param_config: tuple) -> tuple:\n        \"\"\" In case of pruned dimensions, adds the removed dimensions back in the param config \"\"\"\n        unpruned = list()\n        pruned_count = 0\n        for removed in self.removed_tune_params:\n            if removed is not None:\n                unpruned.append(removed)\n            else:\n                unpruned.append(param_config[pruned_count])\n                pruned_count += 1\n        return tuple(unpruned)\n\n    def update_after_evaluation(self, observation: float, index: int, param_config: tuple):\n        \"\"\" Adjust the visited and valid index records accordingly \"\"\"\n        validity = self.is_valid(observation)\n        self.__visited_num += 1\n        self.__observations[index] = observation\n        self.__visited_searchspace_indices[index] = True\n        del self.unvisited_cache[self.find_param_config_unvisited_index(param_config)]\n        self.__valid_observation_indices[index] = validity\n        if validity is True:\n            self.__visited_valid_num += 1\n            self.__valid_params.append(param_config)\n            self.__valid_observations.append(observation)\n            if self.is_better_than(observation, self.current_optimum):\n                self.current_optimum = observation\n\n    def predict(self, x) -> Tuple[float, float]:\n        \"\"\" Returns a mean and standard deviation predicted by the surrogate model for the parameter configuration \"\"\"\n        return self.__model.predict([x], return_std=True)\n\n    def predict_list(self, lst: list) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\" Returns a list of means and standard deviations predicted by the surrogate model for the parameter configurations, and separate lists of means and standard deviations \"\"\"\n        with torch.no_grad(), gpytorch.settings.fast_pred_var():\n            # TODO use torch.cuda for GPU\n            test_x = torch.Tensor(lst)\n            observed_pred = self.__likelihood(self.__model(test_x))\n            mu = observed_pred.mean\n            std = observed_pred.variance\n            return mu.numpy(), std.numpy()\n\n    def evaluate_objective_function(self, param_config: tuple) -> float:\n        \"\"\" Evaluates the objective function \"\"\"\n        param_config = self.unprune_param_config(param_config)\n        denormalized_param_config = self.denormalize_param_config(param_config)\n        if not util.config_valid(denormalized_param_config, self.tuning_options, self.max_threads):\n            return self.invalid_value\n        val = minimize._cost_func(param_config, self.kernel_options, self.tuning_options, self.runner, self.results)\n        self.fevals += 1\n        self.add_model_hyperparams_to_result(denormalized_param_config)\n        return val\n\n    def add_model_hyperparams_to_result(self, param_config: tuple):\n        \"\"\" Add the model parameters (loss and noise) to the results dict at the last result \"\"\"\n        # assert that the results index corresponds to the last index\n        assert self.find_config_index_in_results(param_config) == len(self.results) - 1\n\n        for key, value in self.hyperparams.items():\n            # print(f\"{key}: {value}\")\n            self.results[-1][key] = value\n\n    def find_config_index_in_results(self, param_config: tuple):\n        \"\"\" Find the index of a parameter configuration in the results. Beware that this can be very slow! \"\"\"\n        found_indices = list()\n        for results_index, result_dict in enumerate(self.results):\n            keys = list(result_dict.keys())\n            found = True\n            for index, value in enumerate(param_config):\n                if result_dict[keys[index]] != value:\n                    found = False\n            if found is True:\n                found_indices.append(results_index)\n        assert len(found_indices) == 1\n        return found_indices[0]\n\n    def dimensions(self) -> list:\n        \"\"\" List of parameter values per parameter \"\"\"\n        return self.tune_params.values()\n\n    def draw_random_sample(self) -> Tuple[list, int]:\n        \"\"\" Draw a random sample from the unvisited parameter configurations \"\"\"\n        if len(self.unvisited_cache) < 1:\n            raise ValueError(\"Searchspace exhausted during random sample draw as no valid configurations were found\")\n        index = randint(0, len(self.unvisited_cache) - 1)    # NOSONAR\n        param_config = self.unvisited_cache[index]\n        actual_index = self.find_param_config_index(param_config)\n        return param_config, actual_index\n\n    def draw_latin_hypercube_samples(self, num_samples: int) -> list:\n        \"\"\" Draws an LHS-distributed sample from the search space \"\"\"\n        if self.searchspace_size < num_samples:\n            raise ValueError(\"Can't sample more than the size of the search space\")\n        if self.sampling_crit is None:\n            lhs = Lhs(lhs_type=\"centered\", criterion=None)\n        else:\n            lhs = Lhs(lhs_type=\"classic\", criterion=self.sampling_crit, iterations=self.sampling_iter)\n        param_configs = lhs.generate(self.dimensions(), num_samples)\n        indices = list()\n        normalized_param_configs = list()\n        for i in range(len(param_configs) - 1):\n            try:\n                param_config = self.normalize_param_config(param_configs[i])\n                index = self.find_param_config_index(param_config)\n                indices.append(index)\n                normalized_param_configs.append(param_config)\n            except ValueError:\n                \"\"\" Due to search space restrictions, the search space may not be an exact cartesian product of the tunable parameter values.\n                It is thus possible for LHS to generate a parameter combination that is not in the actual searchspace, which must be skipped. \"\"\"\n                continue\n        return list(zip(normalized_param_configs, indices))\n\n    def train_model_hyperparams(self):\n        \"\"\" Train the model and likelihood hyperparameters \"\"\"\n        # set to training modes\n        self.__model.train()\n        self.__likelihood.train()\n\n        # Use the adam optimizer\n        optimizer = torch.optim.Adam(self.__model.parameters(), lr=0.1)    # Includes GaussianLikelihood parameters\n\n        # \"Loss\" for GPs - the marginal log likelihood\n        mll = gpytorch.mlls.ExactMarginalLogLikelihood(self.__likelihood, self.__model)\n\n        loss = 0\n        lengthscale = 0\n        noise = 0\n        for i in range(self.training_iter):\n            # Zero gradients from previous iteration\n            optimizer.zero_grad()\n            # Output from model\n            output = self.__model(self.__tparams)\n            # Calc loss and backprop gradients\n            loss = -mll(output, self.__tobservations)\n            loss.backward()\n            # print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' %\n            #       (i + 1, self.training_iter, loss.item(), self.__model.covar_module.base_kernel.lengthscale.item(), self.__model.likelihood.noise.item()))\n            optimizer.step()\n\n        # set to prediction mode\n        self.__model.eval()\n        self.__likelihood.eval()\n\n        # set the hyperparameters globally for reference\n        self.hyperparams = {\n            'loss': loss.item(),\n            'lengthscale': self.__model.covar_module.base_kernel.lengthscale.item(),\n            'noise': self.__model.likelihood.noise.item(),\n        }\n        # print(f\"Loss: {self.hyperparams['loss']}, lengthscale: {self.hyperparams['lengthscale']}, noise: {self.hyperparams['noise']}\")\n\n    def initial_sample(self):\n        \"\"\" Draws an initial sample using random sampling \"\"\"\n        if self.num_initial_samples <= 0:\n            raise ValueError(\"At least one initial sample is required\")\n        if self.sampling_method == 'lhs':\n            samples = self.draw_latin_hypercube_samples(self.num_initial_samples)\n        elif self.sampling_method == 'random':\n            samples = list()\n        else:\n            raise ValueError(\"Sampling method must be one of {}, is {}\".format(self.supported_sampling_methods, self.sampling_method))\n        # collect the samples\n        collected_samples = 0\n        for params, index in samples:\n            observation = self.evaluate_objective_function(params)\n            self.update_after_evaluation(observation, index, params)\n            if self.is_valid(observation):\n                collected_samples += 1\n        # collect the remainder of the samples\n        while collected_samples < self.num_initial_samples:\n            params, index = self.draw_random_sample()\n            observation = self.evaluate_objective_function(params)\n            self.update_after_evaluation(observation, index, params)\n            # check for validity to avoid having no actual initial samples\n            if self.is_valid(observation):\n                collected_samples += 1\n\n        # instantiate the model with the initial sample\n        self.__likelihood = gpytorch.likelihoods.GaussianLikelihood()\n        self.__tparams = torch.Tensor(self.__valid_params)\n        self.__tobservations = torch.Tensor(self.__valid_observations)\n        self.__model = ExactGPModel(self.__tparams, self.__tobservations, self.__likelihood)\n        self.train_model_hyperparams()\n\n        # extract the predictions\n        _, std = self.predict_list(self.unvisited_cache)\n        self.initial_sample_mean = np.mean(self.__valid_observations)\n        # Alternatively:\n        # self.initial_sample_std = np.std(self.__valid_observations)\n        # self.initial_sample_mean = np.mean(predictions)\n        self.initial_std = np.mean(std)\n        self.cv_norm_maximum = self.initial_std\n\n    def contextual_variance(self, std: list):\n        \"\"\" Contextual improvement to decide explore / exploit, based on CI proposed by (Jasrasaria, 2018) \"\"\"\n        if not self.af_params['explorationfactor'] == 'CV':\n            return None\n        if self.opt_direction == 'min':\n            if self.current_optimum == self.worst_value:\n                return 0.01\n            if self.current_optimum <= 0:\n                # doesn't work well for minimization beyond 0, should that even be a thing?\n                return abs(np.mean(std) / self.current_optimum)\n            improvement_over_initial_sample = self.initial_sample_mean / self.current_optimum\n            cv = np.mean(std) / improvement_over_initial_sample\n            # normalize if available\n            if self.cv_norm_maximum:\n                cv = cv / self.cv_norm_maximum\n            return cv\n        return np.mean(std) / self.current_optimum\n\n    def __optimize(self, max_fevals):\n        \"\"\" Find the next best candidate configuration(s), evaluate those and update the model accordingly \"\"\"\n        while self.fevals < max_fevals:\n            if self.__visited_num >= self.searchspace_size:\n                raise ValueError(self.error_message_searchspace_fully_observed)\n            predictions = self.predict_list(self.unvisited_cache)\n            hyperparam = self.contextual_variance(predictions[1])\n            list_of_acquisition_values = self.__af(predictions, hyperparam)\n            # afterwards select the best AF value\n            best_af = self.argopt(list_of_acquisition_values)\n            candidate_params = self.unvisited_cache[best_af]\n            candidate_index = self.find_param_config_index(candidate_params)\n            observation = self.evaluate_objective_function(candidate_params)\n            self.update_after_evaluation(observation, candidate_index, candidate_params)\n            self.train_model_hyperparams()\n        return self.results\n\n    def __optimize_multi(self, max_fevals):\n        \"\"\" Optimize with a portfolio of multiple acquisition functions. Predictions are always only taken once. Skips AFs if they suggest X/max_evals duplicates in a row, prefers AF with best discounted average. \"\"\"\n        if self.opt_direction != 'min':\n            raise ValueError(f\"Optimization direction must be minimization ('min'), is {self.opt_direction}\")\n        # calculate how many times an AF can suggest a duplicate candidate before the AF is skipped\n        # skip_duplicates_fraction = self.af_params['skip_duplicates_fraction']\n        # skip_if_duplicate_n_times = int(min(max(round(skip_duplicates_fraction * max_fevals), 3), max_fevals))\n        skip_if_duplicate_n_times = self.af_params['skip_duplicate_after']\n        discount_factor = self.multi_afs_discount_factor\n        # setup the registration of duplicates and runtimes\n        duplicate_count_template = [0 for _ in range(skip_if_duplicate_n_times)]\n        duplicate_candidate_af_count = list(deepcopy(duplicate_count_template) for _ in range(3))\n        skip_af_index = list()\n        af_runtimes = [0, 0, 0]\n        af_observations = [list(), list(), list()]\n        initial_sample_mean = np.mean(self.__valid_observations)\n        while self.fevals < max_fevals:\n            time_start = time.perf_counter_ns()\n            # the first acquisition function is never skipped, so that should be the best for the endgame (EI)\n            aqfs = self.multi_afs\n            predictions = self.predict_list(self.unvisited_cache)\n            hyperparam = self.contextual_variance(predictions[1])\n            if self.__visited_num >= self.searchspace_size:\n                raise ValueError(self.error_message_searchspace_fully_observed)\n            time_predictions = time.perf_counter_ns()\n            actual_candidate_params = list()\n            actual_candidate_indices = list()\n            actual_candidate_af_indices = list()\n            duplicate_candidate_af_indices = list()\n            duplicate_candidate_original_af_indices = list()\n            for af_index, af in enumerate(aqfs):\n                if af_index in skip_af_index:\n                    continue\n                if self.__visited_num >= self.searchspace_size or self.fevals >= max_fevals:\n                    break\n                timer_start = time.perf_counter()\n                list_of_acquisition_values = af(predictions, hyperparam)\n                best_af = self.argopt(list_of_acquisition_values)\n                time_taken = time.perf_counter() - timer_start\n                af_runtimes[af_index] += time_taken\n                is_duplicate = best_af in actual_candidate_indices\n                if not is_duplicate:\n                    candidate_params = self.unvisited_cache[best_af]\n                    actual_candidate_params.append(candidate_params)\n                    actual_candidate_indices.append(best_af)\n                    actual_candidate_af_indices.append(af_index)\n                # register whether the AF suggested a duplicate candidate\n                duplicate_candidate_af_count[af_index].pop(0)\n                duplicate_candidate_af_count[af_index].append(1 if is_duplicate else 0)\n                if is_duplicate:\n                    # find the index of the AF that first registered the duplicate\n                    original_duplicate_af_index = actual_candidate_af_indices[actual_candidate_indices.index(best_af)]\n                    # register that AF as duplicate as well\n                    duplicate_candidate_af_count[original_duplicate_af_index][-1] = 1\n                    duplicate_candidate_af_indices.append(af_index)\n                    duplicate_candidate_original_af_indices.append(original_duplicate_af_index)\n            time_afs = time.perf_counter_ns()\n            # evaluate the non-duplicate candidates\n            for index, af_index in enumerate(actual_candidate_af_indices):\n                candidate_params = actual_candidate_params[index]\n                candidate_index = self.find_param_config_index(candidate_params)\n                observation = self.evaluate_objective_function(candidate_params)\n                self.update_after_evaluation(observation, candidate_index, candidate_params)\n                if observation != self.invalid_value:\n                    # we use the registered observations for maximization of the discounted reward\n                    reg_observation = observation if self.opt_direction == 'min' else -1 * observation\n                    af_observations[actual_candidate_af_indices[index]].append(reg_observation)\n                else:\n                    reg_invalid_observation = initial_sample_mean if self.opt_direction == 'min' else -1 * initial_sample_mean\n                    af_observations[actual_candidate_af_indices[index]].append(reg_invalid_observation)\n            for index, af_index in enumerate(duplicate_candidate_af_indices):\n                original_observation = af_observations[duplicate_candidate_original_af_indices[index]][-1]\n                af_observations[af_index].append(original_observation)\n            self.train_model_hyperparams()\n            time_eval = time.perf_counter_ns()\n            # assert that all observation lists of non-skipped acquisition functions are of the same length\n            non_skipped_af_indices = list(af_index for af_index, _ in enumerate(aqfs) if af_index not in skip_af_index)\n            assert all(len(af_observations[non_skipped_af_indices[0]]) == len(af_observations[af_index]) for af_index in non_skipped_af_indices)\n            # find the AFs elligble for being skipped\n            candidates_for_skip = list()\n            for af_index, count in enumerate(duplicate_candidate_af_count):\n                if sum(count) >= skip_if_duplicate_n_times and af_index not in skip_af_index:\n                    candidates_for_skip.append(af_index)\n            # do not skip the AF with the lowest runtime\n            if len(candidates_for_skip) > 1:\n                candidates_for_skip_discounted = list(\n                    sum(list(obs * discount_factor**(len(observations) - 1 - i) for i, obs in enumerate(observations)))\n                    for af_index, observations in enumerate(af_observations) if af_index in candidates_for_skip)\n                af_not_to_skip = candidates_for_skip[np.argmin(candidates_for_skip_discounted)]\n                for af_index in candidates_for_skip:\n                    if af_index == af_not_to_skip:\n                        # do not skip the AF with the lowest runtime and give it a clean slate\n                        duplicate_candidate_af_count[af_index] = deepcopy(duplicate_count_template)\n                        continue\n                    skip_af_index.append(af_index)\n                    if len(skip_af_index) >= len(aqfs):\n                        raise ValueError(\"There are no acquisition functions left! This should not happen...\")\n            time_af_selection = time.perf_counter_ns()\n\n            # printing timings\n            if self.log_timings:\n                time_taken_predictions = round(time_predictions - time_start, 3) / 1000\n                time_taken_afs = round(time_afs - time_predictions, 3) / 1000\n                time_taken_eval = round(time_eval - time_afs, 3) / 1000\n                time_taken_af_selection = round(time_af_selection - time_eval, 3) / 1000\n                time_taken_total = round(time_af_selection - time_start, 3) / 1000\n                print(\n                    f\"({self.fevals}/{max_fevals}) Total time: {time_taken_total} | Predictions: {time_taken_predictions} | AFs: {time_taken_afs} | Eval: {time_taken_eval} | AF selection: {time_taken_af_selection}\",\n                    flush=True)\n        return self.results\n\n    def __optimize_multi_advanced(self, max_fevals, increase_precision=False):\n        \"\"\" Optimize with a portfolio of multiple acquisition functions. Predictions are only taken once, unless increase_precision is true. Skips AFs if they are consistently worse than the mean of discounted observations, promotes AFs if they are consistently better than this mean. \"\"\"\n        if self.opt_direction != 'min':\n            raise ValueError(f\"Optimization direction must be minimization ('min'), is {self.opt_direction}\")\n        aqfs = self.multi_afs\n        discount_factor = self.multi_afs_discount_factor\n        required_improvement_factor = self.multi_afs_required_improvement_factor\n        required_improvement_worse = 1 + required_improvement_factor\n        required_improvement_better = 1 - required_improvement_factor\n        min_required_count = self.af_params['skip_duplicate_after']\n        skip_af_index = list()\n        single_af = len(aqfs) <= len(skip_af_index) + 1\n        af_observations = [list(), list(), list()]\n        af_performs_worse_count = [0, 0, 0]\n        af_performs_better_count = [0, 0, 0]\n        while self.fevals < max_fevals:\n            if single_af:\n                return self.__optimize(max_fevals)\n            if self.__visited_num >= self.searchspace_size:\n                raise ValueError(self.error_message_searchspace_fully_observed)\n            observations_median = np.median(self.__valid_observations)\n            if increase_precision is False:\n                predictions = self.predict_list(self.unvisited_cache)\n                hyperparam = self.contextual_variance(predictions[1])\n            for af_index, af in enumerate(aqfs):\n                if af_index in skip_af_index:\n                    continue\n                if self.__visited_num >= self.searchspace_size or self.fevals >= max_fevals:\n                    break\n                if increase_precision is True:\n                    predictions = self.predict_list(self.unvisited_cache)\n                    hyperparam = self.contextual_variance(predictions[1])\n                list_of_acquisition_values = af(predictions, hyperparam)\n                best_af = self.argopt(list_of_acquisition_values)\n                # to avoid going out of bounds on the next iteration, remove the best_af\n                predictions = (np.delete(predictions[0], best_af), np.delete(predictions[1], best_af))\n                candidate_params = self.unvisited_cache[best_af]\n                candidate_index = self.find_param_config_index(candidate_params)\n                observation = self.evaluate_objective_function(candidate_params)\n                self.update_after_evaluation(observation, candidate_index, candidate_params)\n                if increase_precision is True:\n                    self.train_model_hyperparams()\n                # we use the registered observations for maximization of the discounted reward\n                if observation != self.invalid_value:\n                    reg_observation = observation if self.opt_direction == 'min' else -1 * observation\n                    af_observations[af_index].append(reg_observation)\n                else:\n                    # if the observation is invalid, use the median of all valid observations to avoid skewing the discounted observations\n                    reg_invalid_observation = observations_median if self.opt_direction == 'min' else -1 * observations_median\n                    af_observations[af_index].append(reg_invalid_observation)\n            if increase_precision is False:\n                self.train_model_hyperparams()\n\n            # calculate the mean of discounted observations over the remaining acquisition functions\n            discounted_obs = list(\n                sum(list(obs * discount_factor**(len(observations) - 1 - i) for i, obs in enumerate(observations))) for observations in af_observations)\n            disc_obs_mean = np.mean(list(discounted_obs[af_index] for af_index, _ in enumerate(aqfs) if af_index not in skip_af_index))\n\n            # register which AFs perform more than 10% better than average and which more than 10% worse than average\n            for af_index, discounted_observation in enumerate(discounted_obs):\n                if discounted_observation > disc_obs_mean * required_improvement_worse:\n                    af_performs_worse_count[af_index] += 1\n                elif discounted_observation < disc_obs_mean * required_improvement_better:\n                    af_performs_better_count[af_index] += 1\n\n            # find the worst AF, discounted observations is leading for a draw\n            worst_count = max(list(count for af_index, count in enumerate(af_performs_worse_count) if af_index not in skip_af_index))\n            af_index_worst = -1\n            if worst_count >= min_required_count:\n                for af_index, count in enumerate(af_performs_worse_count):\n                    if af_index not in skip_af_index and count == worst_count and (af_index_worst == -1\n                                                                                   or discounted_obs[af_index] > discounted_obs[af_index_worst]):\n                        af_index_worst = af_index\n\n            # skip the worst AF\n            if af_index_worst > -1:\n                skip_af_index.append(af_index_worst)\n                # reset the counts to even the playing field for the remaining AFs\n                af_performs_worse_count = [0, 0, 0]\n                af_performs_better_count = [0, 0, 0]\n                # if there is only one AF left, register as single AF\n                if len(aqfs) <= len(skip_af_index) + 1:\n                    single_af = True\n                    af_indices_left = list(af_index for af_index, _ in enumerate(aqfs) if af_index not in skip_af_index)\n                    assert len(af_indices_left) == 1\n                    self.__af = aqfs[af_indices_left[0]]\n            else:\n                # find the best AF, discounted observations is leading for a draw\n                best_count = max(list(count for af_index, count in enumerate(af_performs_better_count) if af_index not in skip_af_index))\n                af_index_best = -1\n                if best_count >= min_required_count:\n                    for af_index, count in enumerate(af_performs_better_count):\n                        if af_index not in skip_af_index and count == best_count and (af_index_best == -1\n                                                                                      or discounted_obs[af_index] < discounted_obs[af_index_best]):\n                            af_index_best = af_index\n                # make the best AF single\n                if af_index_best > -1:\n                    single_af = True\n                    self.__af = aqfs[af_index_best]\n\n        return self.results\n\n    def __optimize_multi_fast(self, max_fevals):\n        \"\"\" Optimize with a portfolio of multiple acquisition functions. Predictions are only taken once. \"\"\"\n        while self.fevals < max_fevals:\n            aqfs = self.multi_afs\n            # if we take the prediction only once, we want to go from most exploiting to most exploring, because the more exploiting an AF is, the more it relies on non-stale information from the model\n            predictions = self.predict_list(self.unvisited_cache)\n            hyperparam = self.contextual_variance(predictions[1])\n            if self.__visited_num >= self.searchspace_size:\n                raise ValueError(self.error_message_searchspace_fully_observed)\n            for af in aqfs:\n                if self.__visited_num >= self.searchspace_size or self.fevals >= max_fevals:\n                    break\n                list_of_acquisition_values = af(predictions, hyperparam)\n                best_af = self.argopt(list_of_acquisition_values)\n                del predictions[0][best_af]    # to avoid going out of bounds\n                del predictions[1][best_af]\n                candidate_params = self.unvisited_cache[best_af]\n                candidate_index = self.find_param_config_index(candidate_params)\n                observation = self.evaluate_objective_function(candidate_params)\n                self.update_after_evaluation(observation, candidate_index, candidate_params)\n            self.train_model_hyperparams()\n        return self.results\n\n    def af_random(self, predictions=None, hyperparam=None) -> list:\n        \"\"\" Acquisition function returning a randomly shuffled list for comparison \"\"\"\n        list_random = range(len(self.unvisited_cache))\n        shuffle(list_random)\n        return list_random\n\n    def af_probability_of_improvement(self, predictions=None, hyperparam=None) -> list:\n        \"\"\" Acquisition function Probability of Improvement (PI) \"\"\"\n\n        # prefetch required data\n        x_mu, x_std = predictions\n        if hyperparam is None:\n            hyperparam = self.af_params['explorationfactor']\n        fplus = self.current_optimum - hyperparam\n\n        # precompute difference of improvement\n        list_diff_improvement = -((fplus - x_mu) / (x_std + 1E-9))\n\n        # compute probability of improvement with CDF in bulk\n        list_prob_improvement = norm.cdf(list_diff_improvement)\n        return list_prob_improvement\n\n    def af_expected_improvement(self, predictions=None, hyperparam=None) -> list:\n        \"\"\" Acquisition function Expected Improvement (EI) \"\"\"\n\n        # prefetch required data\n        x_mu, x_std = predictions\n        if hyperparam is None:\n            hyperparam = self.af_params['explorationfactor']\n        fplus = self.current_optimum - hyperparam\n\n        # precompute difference of improvement, CDF and PDF in bulk\n        list_diff_improvement = (fplus - x_mu) / (x_std + 1E-9)\n        list_cdf = norm.cdf(list_diff_improvement)\n        list_pdf = norm.pdf(list_diff_improvement)\n\n        # compute expected improvement in bulk\n        list_exp_improvement = -((fplus - x_mu) * list_cdf + x_std * list_pdf)\n        return list_exp_improvement\n\n    def af_lower_confidence_bound(self, predictions=None, hyperparam=None) -> list:\n        \"\"\" Acquisition function Lower Confidence Bound (LCB) \"\"\"\n\n        x_mu, x_std = predictions\n        if hyperparam is None:\n            hyperparam = self.af_params['explorationfactor']\n        beta = hyperparam\n\n        # compute LCB in bulk\n        list_lower_confidence_bound = (x_mu - beta * x_std)\n        return list_lower_confidence_bound\n\n    def af_lower_confidence_bound_srinivas(self, predictions=None, hyperparam=None) -> list:\n        \"\"\" Acquisition function Lower Confidence Bound (UCB-S) after Srinivas, 2010 / Brochu, 2010 \"\"\"\n\n        # prefetch required data\n        x_mu, x_std = predictions\n        if hyperparam is None:\n            hyperparam = self.af_params['explorationfactor']\n\n        # precompute beta parameter\n        zeta = self.af_params['zeta']\n        t = self.fevals\n        d = self.num_dimensions\n        delta = hyperparam\n        beta = np.sqrt(zeta * (2 * np.log((t**(d / 2. + 2)) * (np.pi**2) / (3. * delta))))\n\n        # compute UCB in bulk\n        list_lower_confidence_bound = (x_mu - beta * x_std)\n        return list_lower_confidence_bound\n\n    def visualize_after_opt(self):\n        \"\"\" Visualize the model after the optimization \"\"\"\n        print(self.__model.kernel_.get_params())\n        print(self.__model.log_marginal_likelihood())\n        import matplotlib.pyplot as plt\n        mu, std = self.predict_list(self.searchspace)\n        brute_force_observations = list()\n        for param_config in self.searchspace:\n            obs = minimize._cost_func(param_config, self.kernel_options, self.tuning_options, self.runner, self.results)\n            if obs == self.invalid_value:\n                obs = None\n            brute_force_observations.append(obs)\n        x_axis = range(len(mu))\n        plt.fill_between(x_axis, mu - std, mu + std, alpha=0.2, antialiased=True)\n        plt.plot(x_axis, mu, label=\"predictions\", linestyle=' ', marker='.')\n        plt.plot(x_axis, brute_force_observations, label=\"actual\", linestyle=' ', marker='.')\n        plt.legend()\n        plt.show()\n", 924], "/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py": ["\"\"\" Lean implementation of Bayesian Optimization with GPyTorch \"\"\"\n# python\nfrom copy import deepcopy\nfrom typing import Any, Tuple\nfrom random import randint, shuffle, choice\nfrom math import ceil\nimport warnings\nimport ast    # for casting strings to dict\n\n# external\nimport numpy as np\nfrom numpy.random import default_rng\nimport torch\nimport gpytorch\nimport arviz as az\n\n# internal\nfrom kernel_tuner.util import get_valid_configs, config_valid\nfrom kernel_tuner.strategies import minimize\n\nsupported_precisions = ['float', 'double']\nsupported_initial_sample_methods = ['lhs', 'index', 'random']\nsupported_methods = ['ei', 'poi', 'random']\nsupported_cov_kernels = ['matern', 'matern_scalekernel']\nsupported_likelihoods = ['Gaussian', 'GaussianPrior', 'FixedNoise']\nsupported_optimizers = ['LBFGS', 'Adam']\n\n\ndef tune(runner, kernel_options, device_options, tuning_options):\n    \"\"\" Find the best performing kernel configuration in the parameter space\n\n    :params runner: A runner from kernel_tuner.runners\n    :type runner: kernel_tuner.runner\n\n    :param kernel_options: A dictionary with all options for the kernel.\n    :type kernel_options: kernel_tuner.interface.Options\n\n    :param device_options: A dictionary with all options for the device\n        on which the kernel should be tuned.\n    :type device_options: kernel_tuner.interface.Options\n\n    :param tuning_options: A dictionary with all options regarding the tuning\n        process.\n    :type tuning_options: kernel_tuner.interface.Options\n\n    :returns: A list of dictionaries for executed kernel configurations and their\n        execution times. And a dictionary that contains a information\n        about the hardware/software environment on which the tuning took place.\n    :rtype: list(dict()), dict()\n\n    \"\"\"\n\n    # set CUDA availability\n    use_cuda = False\n    cuda_available = torch.cuda.is_available() and use_cuda\n    device = torch.device(\"cuda:0\" if cuda_available else \"cpu\")\n    if cuda_available:\n        print(f\"CUDA is available, device: {torch.cuda.get_device_name(device)}\")\n\n    # retrieve options with defaults\n    options = tuning_options.strategy_options\n    optimization_direction = options.get(\"optimization_direction\", 'min')\n    num_initial_samples = int(options.get(\"popsize\", 20))\n    max_fevals = int(options.get(\"max_fevals\", 100))\n    max_threads = runner.dev.max_threads\n    # if max_fevals < num_initial_samples:\n    # raise ValueError(f\"Maximum number of function evaluations ({max_fevals}) can not be lower than the number of initial samples ({num_initial_samples}) \")\n\n    # enabling scaling will unscale and snap inputs on evaluation, more efficient to scale all at once and keep unscaled values\n    tuning_options[\"snap\"] = False\n    tuning_options[\"scaling\"] = False\n\n    # prune the search space using restrictions\n    parameter_space = get_valid_configs(tuning_options, max_threads)\n\n    # limit max_fevals to max size of the parameter space\n    max_fevals = min(len(parameter_space), max_fevals)\n\n    # execute Bayesian Optimization\n    BO = BayesianOptimization(parameter_space, kernel_options, tuning_options, runner, num_initial_samples, optimization_direction, device)\n    # BO.visualize()\n    # BO.to_xarray()\n    all_results = BO.optimize(max_fevals)\n    # BO.visualize()\n\n    return all_results, runner.dev.get_environment()\n\n\nclass ExactGPModel(gpytorch.models.ExactGP):\n\n    def __init__(self, train_x, train_y, likelihood, cov_kernel_name: str, cov_kernel_lengthscale: float):\n        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n        self.mean_module = gpytorch.means.ZeroMean()\n        if cov_kernel_name == 'matern':\n            self.covar_module = gpytorch.kernels.MaternKernel(nu=cov_kernel_lengthscale)\n        elif cov_kernel_name == 'matern_scalekernel':\n            self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.MaternKernel(nu=cov_kernel_lengthscale))\n\n    def forward(self, x):\n        mean_x = self.mean_module(x)\n        covar_x = self.covar_module(x)\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n\n\nclass BayesianOptimization:\n\n    def __init__(self, parameter_space: list, kernel_options, tuning_options, runner, num_initial_samples: int, optimization_direction: str,\n                 device: torch.device) -> None:\n        self.animate = False    # TODO remove\n\n        # set defaults\n        self.num_initial_samples = num_initial_samples\n        self.fevals = 0\n        self.all_results = []\n        self.unique_results = {}\n        self.current_optimal_config = None\n\n        # set Kernel Tuner data\n        self.kernel_options = kernel_options\n        self.tuning_options = tuning_options\n        self.runner = runner\n        self.max_threads = runner.dev.max_threads\n\n        # get precision options\n        self.dtype = torch.float if self.get_hyperparam(\"precision\", \"float\", supported_precisions) == \"float\" else torch.double\n        self.min_std = self.get_hyperparam(\"minimum_std\", 1e-9, type=float)\n\n        # get tuning options\n        self.initial_sample_method = self.get_hyperparam(\"initialsamplemethod\", \"lhs\", supported_initial_sample_methods)\n        self.initial_sample_random_offset_factor = self.get_hyperparam(\"initialsamplerandomoffsetfactor\", 0.1, type=float)\n        self.initial_training_iter = self.get_hyperparam(\"initialtrainingiter\", 50, type=int)\n        self.training_iter = self.get_hyperparam(\"trainingiter\", 3, type=int)\n        self.cov_kernel_name = self.get_hyperparam(\"covariancekernel\", \"matern_scalekernel\", supported_cov_kernels)\n        self.cov_kernel_lengthscale = self.get_hyperparam(\"covariancelengthscale\", 1.5, type=float)\n        self.likelihood_name = self.get_hyperparam(\"likelihood\", \"Gaussian\", supported_likelihoods)\n        self.optimizer_name = self.get_hyperparam(\"optimizer\", \"LBFGS\", supported_optimizers)\n        self.optimizer_learningrate = self.get_hyperparam(\"optimizer_learningrate\", 0.1, type=float)\n        acquisition_function_name = self.get_hyperparam(\"method\", \"ei\", supported_methods)\n        af_params = self.get_hyperparam(\"methodparams\", {}, type=dict, cast=ast.literal_eval)\n\n        # set acquisition function options\n        self.set_acquisition_function(acquisition_function_name)\n        if 'explorationfactor' not in af_params:\n            af_params['explorationfactor'] = 'CV'\n        self.af_params = af_params\n\n        # set Tensors\n        self.device = device\n        self.out_device = torch.device(\"cpu\")\n        self.size = len(parameter_space)\n        self.index_counter = torch.arange(self.size)\n        # the unvisited_configs and valid_configs are to be used as boolean masks on the other tensors, more efficient than adding to / removing from tensors\n        self.unvisited_configs = torch.ones(self.size, dtype=torch.bool).to(device)\n        self.valid_configs = torch.zeros(self.size, dtype=torch.bool).to(device)\n        self.inital_sample_configs = torch.zeros(self.size, dtype=torch.bool).to(device)\n        self.results = torch.zeros(self.size, dtype=self.dtype).to(device) * np.nan    # x (param configs) and y (results) must be the same type\n        self.results_std = torch.ones(self.size, dtype=self.dtype).to(device)    # only a valid assumption if normalized\n\n        # transform non-numerical parameters to numerical, keep true_param_configs for evaluation function\n        self.param_configs, self.tune_params = self.transform_nonnumerical_params(parameter_space)\n        self.true_param_configs = parameter_space\n\n        # set scaling\n        self.scaled_input = True\n        self.scaled_output = True\n        if not self.scaled_input:\n            self.param_configs_scaled = self.param_configs\n        else:\n            self.apply_scaling_to_inputs()\n\n        # set optimization settings\n        self.invalid_value = 1e20\n        self.optimization_direction = optimization_direction\n        if self.optimization_direction == 'min':\n            self.is_better_than = lambda a, b: a < b\n            self.inf_value = np.PINF\n            self.opt = torch.min\n            self.argopt = torch.argmin\n        elif self.optimization_direction == 'max':\n            self.is_better_than = lambda a, b: a > b\n            self.inf_value = np.NINF\n            self.opt = torch.max\n            self.argopt = torch.argmax\n        else:\n            raise ValueError(f\"Invalid optimization direction {self.optimization_direction}\")\n\n        # set the model\n        self.current_optimum = self.inf_value\n        self.hyperparams = {\n            'loss': np.nan,\n            'lengthscale': np.nan,\n            'noise': np.nan,\n        }\n        self.hyperparams_means = {\n            'loss': list(),\n            'lengthscale': list(),\n            'noise': list(),\n        }\n        self.initialize_model()\n\n    @property\n    def train_x(self):\n        \"\"\" Get the valid parameter configurations \"\"\"\n        return self.param_configs_scaled[self.valid_configs].to(self.device)\n\n    @property\n    def train_y(self):\n        \"\"\" Get the valid results \"\"\"\n        outputs = self.results[self.valid_configs]\n        if self.scaled_output:\n            # z-score, remove mean and make unit variance to scale it to N(0,1)\n            # alternatively, first min-max the outputs between -1 and +1 and apply a Fisher transformation (np.arctanh)\n            outputs = (outputs - outputs.mean()) / outputs.std()\n        return outputs\n\n    @property\n    def train_y_err(self):\n        \"\"\" Get the error on the valid results \"\"\"\n        std = self.results_std[self.valid_configs]\n        if self.scaled_output and std.std() > 0.0:\n            std = (std - std.mean()) / std.std()\n        return std\n\n    @property\n    def test_x(self):\n        \"\"\" Get the not yet visited parameter configurations \"\"\"\n        return self.param_configs_scaled[self.unvisited_configs].to(self.device)\n\n    @property\n    def test_x_unscaled(self):\n        \"\"\" Get the unscaled, not yet visited parameter configurations \"\"\"\n        return self.param_configs[self.unvisited_configs]\n\n    @property\n    def invalid_x(self):\n        \"\"\" Get the invalid parameter configurations by checking which visited configs are not valid (equivalent to checking which unvisited configs are valid) \"\"\"\n        invalid_mask = (self.unvisited_configs == self.valid_configs)\n        return self.param_configs[invalid_mask]\n\n    def true_param_config_index(self, target_index: int) -> int:\n        \"\"\" The index required to get the true config param index when dealing with test_x \"\"\"\n        # get the index of the #index-th True (for example the 9th+1 True could be index 13 because there are 4 Falses in between)\n        masked_counter = self.index_counter[self.unvisited_configs]\n        return masked_counter[target_index]\n\n    def true_param_config_indices(self, target_indices: torch.Tensor) -> torch.Tensor:\n        \"\"\" Same as true_param_config_index, but for an array of targets instead. \"\"\"\n        masked_counter = self.index_counter[self.unvisited_configs]\n        return masked_counter.index_select(0, target_indices)\n\n    def initialize_model(self, take_initial_sample=True, train_hyperparams=True):\n        \"\"\" Initialize the surrogate model \"\"\"\n        if not self.runner.simulation_mode:\n            self.import_cached_evaluations()\n        self.initial_sample_std = self.min_std\n        if take_initial_sample:\n            self.initial_sample()\n\n        # create the model\n        if self.likelihood_name == 'Gaussian':\n            self.likelihood = gpytorch.likelihoods.GaussianLikelihood()\n        elif self.likelihood_name == 'FixedNoise':\n            self.likelihood = gpytorch.likelihoods.FixedNoiseGaussianLikelihood(noise=self.train_y_err.clamp(min=self.min_std), learn_additional_noise=False)\n        self.likelihood = self.likelihood.to(self.device)\n        self.model = ExactGPModel(self.train_x, self.train_y, self.likelihood, self.cov_kernel_name, self.cov_kernel_lengthscale)\n\n        # Find optimal model hyperparameters\n        self.model.train()\n        self.likelihood.train()\n        model_parameters = filter(lambda p: p.requires_grad, self.model.parameters())\n\n        # LBFGS is probably better as Adam is first-order\n        if self.optimizer_name == 'LBFGS':\n            self.optimizer = torch.optim.LBFGS(model_parameters, lr=self.optimizer_learningrate)\n        elif self.optimizer_name == 'Adam':\n            self.optimizer = torch.optim.Adam(model_parameters, lr=self.optimizer_learningrate)\n\n        self.mll = gpytorch.mlls.ExactMarginalLogLikelihood(self.likelihood, self.model).to(self.device)\n        if train_hyperparams:\n            self.train_hyperparams(self.initial_training_iter)\n        else:\n            self.train_hyperparams(0)\n\n    def import_cached_evaluations(self):\n        \"\"\" Import the previously evaluated configurations into this run \"\"\"\n        # make strings of all the parameter configurations in the search space\n        param_config_strings = list()\n        for param_config in self.true_param_configs:\n            param_config_strings.append(\",\".join([str(v) for v in param_config]))\n\n        # load the results from the cache into the run\n        cache = self.tuning_options.cache\n        if len(cache.keys()) > 0:\n            print(\"Previous cachefile found while not in simulation mode, importing previous evaluations.\")\n        for param_config_string, result in cache.items():\n            # get the index of the string in the search space\n            param_config_index = param_config_strings.index(param_config_string)\n            time = self.evaluate_config(param_config_index)\n            print(len(self.all_results))\n            assert time == result['time']\n\n    def initial_sample(self):\n        \"\"\" Take an initial sample of the parameter space \"\"\"\n        list_param_config_indices = list(self.index_counter[~self.unvisited_configs])\n\n        # generate a random offset from a normal distribution to add to the sample indices\n        rng = default_rng()\n        if self.initial_sample_random_offset_factor > 0.5:\n            raise ValueError(\"Random offset factor should not be greater than 0.5 to avoid overlapping index offsets\")\n        random_offset_size = (self.size / self.num_initial_samples) * self.initial_sample_random_offset_factor\n        random_offsets = np.round(rng.standard_normal(self.num_initial_samples) * random_offset_size)\n\n        # first apply the initial sampling method\n        if self.initial_sample_method == 'lhs':\n            indices = self.get_lhs_samples(random_offsets)\n            for param_config_index in indices.tolist():\n                if param_config_index in list_param_config_indices:\n                    continue\n                list_param_config_indices.append(param_config_index)\n                self.evaluate_config(param_config_index)\n        elif self.initial_sample_method == 'random':\n            while self.fevals < self.num_initial_samples:\n                param_config_index = randint(0, self.size - 1)\n                if param_config_index in list_param_config_indices:\n                    continue\n                list_param_config_indices.append(param_config_index)\n                self.evaluate_config(param_config_index)\n\n        # then take index-spaced samples until all samples are valid\n        while self.fevals < self.num_initial_samples:\n            least_evaluated_region_index = self.get_middle_index_of_least_evaluated_region()\n            param_config_index = min(max(int(least_evaluated_region_index + random_offsets[self.fevals].item()), 0), self.size - 1)\n            list_param_config_indices.append(param_config_index)\n            self.evaluate_config(param_config_index)\n\n        # set the current optimum, initial sample mean and initial sample std\n        self.current_optimum = self.opt(self.train_y).item()\n        self.initial_sample_mean = self.train_y.mean().item()\n        # self.initial_sample_std = self.train_y.std().item()\n        self.initial_sample_std = self.min_std    # temporary until the predictive posterior has been taken\n\n        # save a boolean mask of the initial samples\n        self.inital_sample_configs = self.valid_configs.detach().clone()\n\n    def get_lhs_samples(self, random_offsets: np.ndarray) -> torch.Tensor:\n        \"\"\" Get a centered Latin Hypercube Sample with a random offset \"\"\"\n        n_samples = self.num_initial_samples\n\n        # first get the seperate parameter values to make possibly fictional distributed parameter configurations\n        temp_param_configs = [[] for _ in range(n_samples)]\n        for param_values in self.tune_params.values():\n            l = len(param_values)\n\n            # determine the interval and offset\n            interval = l / n_samples\n            offset = 0\n            if l > n_samples:\n                # take the difference between the last index and the end of the list, and the first index and the start of the list\n                offset = ((l - 1 - interval * n_samples) - interval) / 2\n\n            # assemble the parameter configurations\n            for i in range(n_samples):\n                index = ceil(offset + interval * (i + 1)) - 1\n                temp_param_configs[i].append(param_values[index])\n\n        # create a tensor of the possibly fictional parameter configurations\n        param_configs = torch.tensor(list(tuple(param_config) for param_config in temp_param_configs), dtype=self.dtype).to(self.device)\n        param_configs = param_configs.unique(dim=0)    # remove duplicates\n        n_samples_unique = len(param_configs)\n\n        # get the indices of the parameter configurations\n        num_params = len(self.param_configs[0])\n        minimum_required_num_matching_params = round(num_params *\n                                                     0.75)    # set the number of parameter matches allowed to be dropped before the search is stopped\n        param_configs_indices = torch.full((n_samples_unique, ), -1, dtype=torch.int)\n        for selected_index, selected_param_config in enumerate(param_configs):\n            # for each parameter configuration, count the number of matching parameters\n            required_num_matching_params = num_params\n            matching_params = torch.count_nonzero(self.param_configs == selected_param_config, -1)\n            match_mask = (matching_params == required_num_matching_params)\n            # if there is not at least one matching parameter configuration, lower the required number of matching parameters\n            found_num_matching_param_configs = match_mask.count_nonzero()\n            while found_num_matching_param_configs < 1 and required_num_matching_params > minimum_required_num_matching_params:\n                required_num_matching_params -= 1\n                match_mask = (matching_params == required_num_matching_params)\n                found_num_matching_param_configs = match_mask.count_nonzero()\n\n            # if more than one possible parameter configuration has been found, pick a random one\n            if found_num_matching_param_configs > 1:\n                index = choice(self.index_counter[match_mask])\n            elif found_num_matching_param_configs == 1:\n                index = self.index_counter[match_mask].item()\n            else:\n                # if no matching parameter configurations were found\n                continue\n\n            # set the selected index\n            param_configs_indices[selected_index] = min(max(int(index + random_offsets[selected_index].item()), 0), self.size - 1)\n\n        # filter -1 indices and duplicates that occurred because of the random offset\n        param_configs_indices = param_configs_indices[param_configs_indices >= 0]\n        param_configs_indices = param_configs_indices.unique().type(torch.int)\n        if len(param_configs_indices) < n_samples / 2:\n            warnings.warn(\n                str(f\"{n_samples - len(param_configs_indices)} out of the {n_samples} LHS samples were duplicates or -1.\" +\n                    f\"This might be because you have few initial samples ({n_samples}) relative to the number of parameters ({num_params}).\" +\n                    \"Perhaps try something other than LHS.\"))\n        return param_configs_indices\n\n    def get_middle_index_of_least_evaluated_region(self) -> int:\n        \"\"\" Get the middle index of the region of parameter configurations that is the least visited \"\"\"\n        # This uses the largest distance between visited parameter configurations. That means it does not properly take the parameters into account, only the index of the parameter configurations, whereas LHS does.\n        distance_tensor = torch.arange(self.size)\n\n        # first get the indices that were visited (must be in ascending order)\n        indices_visited = self.index_counter[~self.unvisited_configs]\n\n        # then reset the range after the visited index\n        for index_visited in indices_visited:\n            distance_tensor[index_visited:] = torch.arange(self.size - index_visited)\n\n        biggest_distance_index = distance_tensor.argmax()\n        biggest_distance = distance_tensor[biggest_distance_index].item()\n        middle_index = biggest_distance_index - round(biggest_distance / 2)\n        # print(f\"Max distance {biggest_distance}, index: {middle_index}, between: {biggest_distance_index-biggest_distance}-{biggest_distance_index}\")\n        return middle_index\n\n    def train_hyperparams(self, training_iter: int):\n        \"\"\" Optimize the surrogate model hyperparameters iteratively \"\"\"\n        self.model.train()\n        self.likelihood.train()\n        model_parameters = filter(lambda p: p.requires_grad, self.model.parameters())\n        self.optimizer = torch.optim.LBFGS(model_parameters, lr=self.optimizer_learningrate)\n\n        def closure():\n            self.optimizer.zero_grad()\n            output = self.model(self.train_x)    # get model output\n            try:\n                loss = -self.mll(output, self.train_y)    # calculate loss and backprop gradients\n                # print(loss)\n                # large sudden increase in loss signals numerical instability\n                with warnings.catch_warnings():\n                    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n                    if loss.item() > np.nanmean(self.hyperparams_means['loss']) * 10:\n                        warnings.warn(\"Avoiding loss surge, aborting training\", AvoidedLossSurgeWarning)\n                        return np.nan\n                loss.backward()\n                return loss\n            except gpytorch.utils.errors.NotPSDError:\n                warnings.warn(\"Matrix not positive definite during training\", NotPSDTrainingWarning)\n                return np.nan\n\n        loss = None\n        for _ in range(training_iter):\n            try:\n                _loss = self.optimizer.step(closure)\n                if _loss is np.nan:\n                    break\n                if _loss is not None:\n                    loss = _loss\n            except gpytorch.utils.errors.NanError as e:\n                warnings.warn(\"PSD_safe_Cholesky failed due to too many NaN\", NaNTrainingWarning)\n                break\n\n        # set the hyperparams to the new values\n        try:\n            lengthscale = float(self.model.covar_module.lengthscale.item())\n        except AttributeError:\n            lengthscale = float(self.model.covar_module.base_kernel.lengthscale.item())\n        loss = float(loss.item()) if loss is not None else np.nan\n        noise = float(self.model.likelihood.noise.mean().detach())\n        self.hyperparams = {\n            'loss': loss,\n            'lengthscale': lengthscale,\n            'noise': noise,\n        }\n        self.hyperparams_means['loss'].append(loss)\n        self.hyperparams_means['lengthscale'].append(lengthscale)\n        self.hyperparams_means['noise'].append(noise)\n\n        # get into evaluation (predictive posterior) mode\n        self.model.eval()\n        self.likelihood.eval()\n\n    def optimize(self, max_fevals: int) -> Tuple[tuple, float]:    #NOSONAR\n        \"\"\" Optimize the objective \"\"\"\n        predictions_tuple = None\n        short_param_config_index = None\n        last_invalid = False\n        report_multiple_minima = ceil(round(self.size / 10))    # if more than 10% of the space is minima, print a warning\n        use_contextual_variance = self.af_params['explorationfactor'] == 'CV'\n        while self.fevals < max_fevals:\n            if last_invalid:\n                # TODO no need to get the predictions again as the predictions are unchanged, just set the invalid param config mean to the worst non-NAN value and the std to 0\n                # predictions_tuple[0][short_param_config_index] = torch.nanmean(predictions_tuple[0])\n                # predictions_tuple[1][short_param_config_index] = 0\n                predictions_tuple = self.remove_from_predict_list(predictions_tuple, short_param_config_index)\n            else:\n                predictions_tuple = self.predict_list()\n                if self.initial_sample_std <= self.min_std:\n                    self.initial_sample_std = min(max(predictions_tuple[1].mean().item(), self.min_std), 10.0)\n            # if all of the predicted std are the same, take from the least evaluated region\n            if torch.all(predictions_tuple[1] == predictions_tuple[1][0]):\n                least_evaluated_region_index = self.get_middle_index_of_least_evaluated_region()\n                param_config_index = least_evaluated_region_index\n                short_param_config_index = -1\n                warnings.warn(\n                    f\"After {self.fevals}/{max_fevals} fevals, all STD were the same, picking one based on the least evaluated region and resetting the surrogate model\",\n                    ResetModelWarning)\n                self.initialize_model(take_initial_sample=False, train_hyperparams=False)\n            else:\n                # otherwise, optimize the acquisition function to find the next candidate\n                hyperparam = self.contextual_variance(predictions_tuple[0], predictions_tuple[1]) if use_contextual_variance else None\n                acquisition_values = self.acquisition_function(predictions_tuple, hyperparam)\n                short_param_config_index = self.argopt(acquisition_values)\n                param_config_index = self.true_param_config_index(short_param_config_index)\n\n                # if there are multiple minima in the acquisition function values, we want to take one from the least evaluated region\n                min_acquisition_function_value = acquisition_values[short_param_config_index]\n                indices_where_min = (acquisition_values <= min_acquisition_function_value).nonzero(as_tuple=True)[0]\n                if len(indices_where_min) > 1:\n                    # first get the true index for the minima\n                    true_indices_where_min = self.true_param_config_indices(indices_where_min)\n                    # then get the index of the least evaluated region\n                    least_evaluated_region_index = self.get_middle_index_of_least_evaluated_region()\n                    # now find the minima closest to the least evaluated region\n                    param_config_index = self.find_nearest(least_evaluated_region_index, true_indices_where_min)\n                    short_param_config_index = -1    # invalidate the short_param_config_index because we bypassed it\n                    if len(indices_where_min) > report_multiple_minima:\n                        warnings.warn(\n                            f\"After {self.fevals}/{max_fevals} fevals, there were multiple minima in the acquisition values ({len(indices_where_min)}), picking one based on the least evaluated region\",\n                            MultipleMinimaWarning)\n\n            # evaluate and register the result\n            result = self.evaluate_config(param_config_index)\n            if result == self.invalid_value and short_param_config_index > -1:\n                # can't use last_invalid if short_param_config_index is not set\n                last_invalid = True\n            else:\n                last_invalid = False\n                self.model.set_train_data(self.train_x, self.train_y, strict=False)\n                # do not train if there are multiple minima, because it introduces numerical instability or insolvability\n                if self.training_iter > 0:\n                    self.train_hyperparams(training_iter=self.training_iter)\n                # set the current optimum\n                self.current_optimum = self.opt(self.train_y).item()\n            # print(f\"Valid: {len(self.train_x)}, unvisited: {len(self.test_x)}, invalid: {len(self.invalid_x)}, last invalid: {last_invalid}\")\n            if self.animate:\n                self.visualize()\n\n        return self.all_results\n\n    def objective_function(self, param_config: tuple) -> float:\n        return minimize._cost_func(param_config, self.kernel_options, self.tuning_options, self.runner, self.all_results, check_restrictions=False)\n\n    def evaluate_config(self, param_config_index: int) -> float:\n        \"\"\" Evaluates a parameter configuration, returns the time \"\"\"\n        param_config = self.true_param_configs[param_config_index]\n        time = self.objective_function(param_config)\n        self.register_result(time, param_config_index)\n        self.update_unique_results()\n        self.fevals = len(self.unique_results)\n        return time\n\n    def register_result(self, result: float, param_config_index: int):\n        \"\"\" Registers the result to the Tensors and adds the hyperparameters to the results dict \"\"\"\n        # set the unvisited Tensors\n        if self.unvisited_configs[param_config_index] == False:\n            raise ValueError(f\"The param config index {param_config_index} was already set to False!\")\n        self.unvisited_configs[param_config_index] = False\n\n        # set the results Tensors\n        last_result = self.all_results[-1]\n        if result != self.invalid_value:\n            self.valid_configs[param_config_index] = True\n            self.results[param_config_index] = result\n            assert last_result['time'] == result\n            self.results_std[param_config_index] = max(np.std(last_result['times']), self.min_std)\n\n        # add the current model parameters to the last entry of the results dict\n        if len(self.all_results) < 1:\n            return\n        for key, value in self.hyperparams.items():\n            last_result[\"hyperparam_\" + key] = value\n        self.all_results[-1] = last_result\n        # TODO check if it is possible to write these results to the cache if not in simulation mode, maybe with observer?\n\n    def update_unique_results(self):\n        \"\"\" Updates the unique results dictionary \"\"\"\n        record = self.all_results[-1]\n        # make a unique string by taking every value in a result, if it already exists, it is overwritten\n        self.unique_results.update({\",\".join([str(v) for k, v in record.items() if k in self.tuning_options.tune_params]): record[\"time\"]})\n\n    def predict_list(self) -> Tuple[torch.Tensor, torch.Tensor]:\n        \"\"\" Returns the means and standard deviations predicted by the surrogate model for the unvisited parameter configurations \"\"\"\n        with torch.no_grad(), gpytorch.settings.fast_pred_samples(), gpytorch.settings.fast_pred_var():\n            try:\n                observed_pred = self.likelihood(self.model(self.test_x))\n                mu = observed_pred.mean\n                std = observed_pred.variance.clamp(min=self.min_std)    # TODO .sqrt() or not? looks like without is better\n                return mu, std\n            except gpytorch.utils.errors.NanError:\n                warnings.warn(\"NaN error during predictions\", NaNPredictionWarning)\n                return torch.ones_like(self.test_x), torch.zeros_like(self.test_x)\n            except gpytorch.utils.errors.NotPSDError:\n                warnings.warn(\"NotPSD error during predictions\", NotPSDPredictionWarning)\n                return torch.ones_like(self.test_x), torch.zeros_like(self.test_x)\n\n    def get_diff_improvement(self, y_mu, y_std, fplus) -> torch.Tensor:\n        \"\"\" compute probability of improvement by assuming normality on the difference in improvement \"\"\"\n        diff_improvement = (y_mu - fplus) / y_std    # y_std can be very small, causing diff_improvement to be very large\n        diff_improvement = (diff_improvement - diff_improvement.mean()) / max(diff_improvement.std(), self.min_std)    # force to N(0,1) with z-score\n        if self.optimization_direction == 'max':\n            diff_improvement = -diff_improvement\n        return diff_improvement\n\n    def contextual_variance(self, mean: torch.Tensor, std: torch.Tensor):\n        \"\"\" Contextual improvement to decide explore / exploit, based on CI proposed by (Jasrasaria, 2018) \"\"\"\n        if not self.af_params['explorationfactor'] == 'CV':\n            raise ValueError(f\"Contextual Variance was called, but is not set as the exploration factor ({self.af_params['explorationfactor']})\")\n        if self.optimization_direction == 'max':\n            raise NotImplementedError(\"Contextual Variance has not yet been implemented for maximisation\")\n        if self.current_optimum == self.inf_value:\n            return 0.01\n        if self.scaled_output:\n            improvement_over_initial_sample = (abs(self.current_optimum) - self.initial_sample_mean) / self.initial_sample_std\n            improvement_over_current_sample = (abs(self.current_optimum) - self.train_y.mean().item()) / std.mean().item()\n            improvement_diff = improvement_over_current_sample - improvement_over_initial_sample\n            # the closer the improvement over the current sample is to the improvement over the initial sample, the greater the exploration\n            x = 1 - min(max(1 - improvement_diff, 0.2), 0.0)\n            # x = 1 - min(max(improvement_diff, 1) * 0.2, 0.0)\n            # the smaller the difference between the initial sample error and current sample error, the greater the exploration\n            # x = 1 - min(max(self.initial_sample_std - std.mean().item(), 1.0), 0.8)\n            # print(self.initial_sample_std, std.mean().item())\n            # print(x)\n            cv = np.log10(x) + 0.1    # at x=0.0, y=0.1; at x=0.2, y=0.003; at x=0.2057, y=0.0.\n            # print(cv)\n            return cv\n        else:\n            raise NotImplementedError(\"Contextual Variance has not yet been implemented for non-scaled outputs\")\n\n    def af_random(self, predictions=None, hyperparam=None) -> list:\n        \"\"\" Acquisition function returning a randomly shuffled list for comparison \"\"\"\n        list_random = list(range(len(self.unvisited_param_configs)))\n        shuffle(list_random)\n        return list_random\n\n    def af_probability_of_improvement_tensor(self, predictions: Tuple[torch.Tensor, torch.Tensor], hyperparam=None) -> torch.Tensor:\n        \"\"\" Acquisition function Probability of Improvement (PoI) tensor-based \"\"\"\n\n        # prefetch required data\n        y_mu, y_std = predictions\n        if hyperparam is None:\n            hyperparam = self.af_params['explorationfactor']\n        fplus = self.current_optimum - hyperparam\n\n        diff_improvement = self.get_diff_improvement(y_mu, y_std, fplus)\n        normal = torch.distributions.Normal(torch.zeros_like(diff_improvement), torch.ones_like(diff_improvement))\n        cdf = normal.cdf(diff_improvement)\n\n        # # sanity check\n        # if torch.all(cdf == cdf[0]):\n        #     raise FloatingPointError(\"You need to scale the diff_improvement-values!\")\n        return cdf\n\n    def af_expected_improvement_tensor(self, predictions: Tuple[torch.Tensor, torch.Tensor], hyperparam=None) -> torch.Tensor:\n        \"\"\" Acquisition function Expected Improvement (EI) tensor-based \"\"\"\n\n        # prefetch required data\n        y_mu, y_std = predictions\n        if hyperparam is None:\n            hyperparam = self.af_params['explorationfactor']\n        fplus = self.current_optimum - hyperparam\n\n        diff_improvement = self.get_diff_improvement(y_mu, y_std, fplus)\n        normal = torch.distributions.Normal(torch.zeros_like(diff_improvement), torch.ones_like(diff_improvement))\n        cdf = normal.cdf(diff_improvement)\n        pdf = torch.exp(normal.log_prob(diff_improvement))\n\n        # # sanity check\n        # if torch.all(cdf == cdf[0]) and torch.all(pdf == pdf[0]):\n        #     raise FloatingPointError(\"You need to scale the diff_improvement-values!\")\n\n        # compute expected improvement in bulk\n        exp_improvement = (pdf + diff_improvement + y_std * cdf)\n        # alternative exp_improvement = y_std * (pdf + diff_improvement * cdf)\n        # alternative exp_improvement = -((fplus - y_mu) * cdf + y_std * pdf)\n        return exp_improvement\n\n    \"\"\"                  \"\"\"\n    \"\"\" Helper functions \"\"\"\n    \"\"\"                  \"\"\"\n\n    def apply_scaling_to_inputs(self):\n        \"\"\" Scale the inputs using min-max normalization (0-1) and remove constant parameters \"\"\"\n        param_configs_scaled = torch.zeros_like(self.param_configs)\n\n        # first get the scaling factors of each parameter\n        v_min_list = list()\n        v_diff_list = list()\n        unchanging_params_list = list()\n        for param_values in self.tune_params.values():\n            v_min = min(param_values)\n            v_max = max(param_values)\n            v_min_list.append(v_min)\n            v_diff_list.append(v_max - v_min)\n            unchanging_params_list.append(v_min == v_max)\n\n        # then set each parameter value to the scaled value\n        for param_index in range(len(self.param_configs[0])):\n            v_min = v_min_list[param_index]\n            v_diff = v_diff_list[param_index]\n            param_configs_scaled[:, param_index] = torch.sub(self.param_configs[:, param_index], v_min).div(v_diff)\n\n        # finally remove parameters that are constant by applying a mask\n        unchanging_params_tensor = ~torch.tensor(unchanging_params_list, dtype=torch.bool)\n        # if torch.all(unchanging_params_tensor == False):\n        # raise ValueError(f\"All of the parameter configurations ({self.size}) are the same: {self.param_configs[0]}, nothing to optimize\")\n        nonstatic_param_count = torch.count_nonzero(unchanging_params_tensor)\n        self.param_configs_scaled = torch.zeros([len(param_configs_scaled), nonstatic_param_count], dtype=self.dtype)\n        for param_config_index, param_config in enumerate(param_configs_scaled):\n            self.param_configs_scaled[param_config_index] = param_config[unchanging_params_tensor]\n        self.nonstatic_params = unchanging_params_tensor\n\n    def find_nearest(self, value, array: torch.Tensor):\n        \"\"\" Find the value nearest to the given value in the array \"\"\"\n        index = (torch.abs(array - value)).argmin()\n        return array[index]\n\n    def get_hyperparam(self, name: str, default, supported_values=list(), type=None, cast=None):\n        \"\"\" Retrieve the value of a hyperparameter based on the name \"\"\"\n        value = self.tuning_options.strategy_options.get(name, default)\n        # check with predifined value list\n        if len(supported_values) > 0 and value not in supported_values:\n            raise ValueError(f\"'{name}' is set to {value}, but must be one of {supported_values}\")\n        # cast to type if provided\n        if type and not isinstance(value, type):\n            if cast:\n                value = cast(value)\n            else:\n                value = type(value)\n        # exceptions with more complex types\n        if value == 'methodparams' and 'explorationfactor' in value and value['explorationfactor'] != 'CV':\n            value = float(value)\n        return value\n\n    def remove_from_predict_list(self, p: Tuple[torch.Tensor, torch.Tensor], i: int) -> Tuple[torch.Tensor, torch.Tensor]:\n        \"\"\" Remove an index from a tuple of predictions \"\"\"\n        return torch.cat([p[0][:i], p[0][i + 1:]]), torch.cat([p[1][:i], p[1][i + 1:]])\n\n    def set_acquisition_function(self, acquisition_function: str):\n        \"\"\" Set the acquisition function based on the name \"\"\"\n        if acquisition_function not in supported_methods:\n            raise ValueError(\"Acquisition function must be one of {}, is {}\".format(self.supported_methods, acquisition_function))\n\n        if acquisition_function == 'poi':\n            self.acquisition_function = self.af_probability_of_improvement_tensor\n        elif acquisition_function == 'ei':\n            self.acquisition_function = self.af_expected_improvement_tensor\n        elif acquisition_function == 'random':\n            self.acquisition_function = self.af_random\n\n    def transform_nonnumerical_params(self, parameter_space: list) -> Tuple[torch.Tensor, dict]:\n        \"\"\" transform non-numerical or mixed-type parameters to numerical Tensor, also return new tune_params \"\"\"\n        parameter_space = deepcopy(parameter_space)\n        number_of_params = len(parameter_space[0])\n\n        # find out which parameters have nonnumerical or mixed types, and create a range of integers instead\n        nonnumericals_exist = False\n        nonnumerical_type = torch.zeros(number_of_params, dtype=torch.bool)\n        nonnumerical_values = [[] for _ in range(number_of_params)]\n        tune_params = deepcopy(self.tuning_options.tune_params)\n        for param_index, (param_key, param_values) in enumerate(self.tuning_options.tune_params.items()):\n            if not all(isinstance(v, (int, float, complex)) for v in param_values):\n                nonnumericals_exist = True\n                nonnumerical_type[param_index] = True\n                nonnumerical_values[param_index] = param_values\n                tune_params[param_key] = range(len(param_values))\n\n        # overwrite the nonnumerical parameters with numerical parameters\n        if nonnumericals_exist:\n            self.tuning_options[\"snap\"] = False    # snapping is only possible with numerical values\n            for param_config_index, param_config in enumerate(parameter_space):\n                parameter_space[param_config_index] = list(param_config)\n                for param_index, param_value in enumerate(param_config):\n                    if nonnumerical_type[param_index]:\n                        # just use the index of the non-numerical value instead of the value\n                        new_value = nonnumerical_values[param_index].index(param_value)\n                        parameter_space[param_config_index][param_index] = new_value\n\n        return torch.tensor(parameter_space, dtype=self.dtype).to(self.device), tune_params\n\n    def to_xarray(self):\n        # print(self.tuning_options['tune_params'])\n        # print(az.convert_to_inference_data(self.tuning_options['tune_params']).posterior)\n        with torch.no_grad(), gpytorch.settings.fast_pred_samples(), gpytorch.settings.fast_pred_var():\n            posterior = self.model(self.param_configs_scaled)\n            predictive_posterior = self.likelihood(posterior)\n            # print(posterior.variance)\n            # print(az.convert_to_inference_data(posterior.to_data_independent_dist()))\n            # print(len(posterior.covariance_matrix))\n            # print(len(posterior.covariance_matrix[0]))\n            # exit(0)\n\n            # data = az.load_arviz_data('centered_eight')\n            # az.plot_posterior(data, show=True)\n\n            param_configs = list(tuple(pc) for pc in self.param_configs.tolist())\n            # posterior_dict = dict(zip(param_configs, posterior.get_base_samples()))\n            posterior_dict = {\n                'mu': posterior.mean,\n                'var': posterior.variance\n            }\n            predictive_posterior_dict = {\n                'mu': predictive_posterior.mean,\n                'var': predictive_posterior.variance\n            }\n            print(posterior_dict)\n            # predictive_posterior_dict = dict(zip(str(self.param_configs_scaled.numpy()), predictive_posterior.get_base_samples()))\n            # log_prob_dict = dict(zip(self.param_configs_scaled, predictive_posterior.log_prob()))\n            tune_param_keys = np.array(list(self.tune_params.keys()))[self.nonstatic_params]\n            tune_param_values = np.array(list(self.tune_params.values()), dtype=object)[self.nonstatic_params]\n            coordinates = dict(zip(tune_param_keys, tune_param_values))\n            dimensions = dict(zip(tune_param_keys, ([k] for k in tune_param_keys)))\n            print(coordinates)\n            print(dimensions)\n            data = az.from_dict(posterior_dict, posterior_predictive=predictive_posterior_dict)\n            print(az.summary(data))\n            print(data.posterior)\n            print(data.posterior_predictive)\n            az.plot_trace(data, show=True)\n            exit(0)\n            print(data.posterior_predictive)\n\n            # print(az.convert_to_inference_data(posterior.get_base_samples()))\n        # TODO create InferenceData\n        # print(predictive_posterior.sample())\n        # print(az.from_dict())\n        # print(az.convert_to_inference_data(predictive_posterior))\n        exit(0)\n\n    def visualize(self):\n        \"\"\" Visualize the surrogate model and observations in a plot \"\"\"\n        from matplotlib import pyplot as plt\n        with torch.no_grad(), gpytorch.settings.fast_pred_var():\n            # Initialize plot\n            f = plt.figure(constrained_layout=True, figsize=(10, 8))\n            subfigures = f.subfigures(2, 1)\n            ax = subfigures[0].subplots(1, 1)\n            axes2 = subfigures[1].subplots(1, 3)\n            ax.set_ylabel('Value')\n            ax.set_xlabel('Parameter')\n\n            param_configs = self.true_param_configs\n\n            # get true function\n            objective_results = np.array([])\n            for param_config in param_configs:\n                result = self.objective_function(tuple(param_config))\n                if result == self.invalid_value:\n                    result = np.nan\n                objective_results = np.append(objective_results, result)\n            if self.scaled_output:\n                objective_results = (objective_results - objective_results.mean()) / objective_results.std()\n\n            if len(param_configs[0]) == 1:\n                ax.plot(np.linspace(param_configs[0], param_configs[-1], self.size), objective_results, 'r')\n            else:\n                ax.plot(range(self.size), objective_results, 'r')\n\n            # take the parameter values for 1D, otherwise the indices\n            if len(param_configs[0]) == 1:\n                x_axis_param_configs = param_configs\n                test_x_x_axis = self.test_x_unscaled.squeeze().to(self.out_device).numpy()\n            else:\n                x_axis_param_configs = torch.arange(self.size)\n                test_x_x_axis = x_axis_param_configs[self.unvisited_configs].to(self.out_device)\n\n            # Get upper and lower confidence bounds\n            observed_pred = self.likelihood(self.model(self.test_x))\n            lower, upper = observed_pred.confidence_region()\n            lower, upper = lower.to(self.out_device), upper.to(self.out_device)\n\n            # Plot initial sample as green stars\n            initial_sample_x_axis = x_axis_param_configs[self.inital_sample_configs].to(self.out_device)\n            initial_sample_y_axis = self.results[self.inital_sample_configs].to(self.out_device)\n            ax.plot(initial_sample_x_axis.numpy(), initial_sample_y_axis.numpy(), 'g*')\n\n            # Plot training data as black stars\n            mask_training_data_no_initial_sample = ~self.inital_sample_configs == self.valid_configs\n            training_x_axis = x_axis_param_configs[mask_training_data_no_initial_sample].to(self.out_device)\n            training_y_axis = self.results[mask_training_data_no_initial_sample].to(self.out_device)\n            ax.plot(training_x_axis.numpy(), training_y_axis.numpy(), 'k*')\n\n            # Plot predictive means as blue line\n            test_x_y_axis = observed_pred.mean.to(self.out_device)\n            ax.plot(test_x_x_axis, test_x_y_axis.numpy(), 'b')\n\n            # Shade between the lower and upper confidence bounds\n            ax.fill_between(test_x_x_axis, lower.numpy(), upper.numpy(), alpha=0.5)\n\n            # set the limits and legend\n            # ax.set_ylim(min(objective_results), max(filter(lambda x: x != self.invalid_value, objective_results)))\n            ax.legend(['Objective Function', 'Initial Sample', 'Observed Data', 'Mean', 'Confidence'])\n\n            # draw the hyperparameter plots\n            # loss\n            axes2[0].plot(self.hyperparams_means['loss'])\n            axes2[0].set_ylabel('Loss')\n            axes2[0].set_xlabel('Number of evaluations')\n            # lengthscale\n            axes2[1].plot(self.hyperparams_means['lengthscale'])\n            axes2[1].set_ylabel('Lengthscale')\n            axes2[1].set_xlabel('Number of evaluations')\n            # noise\n            axes2[2].plot(self.hyperparams_means['noise'])\n            axes2[2].set_ylabel('Noise')\n            axes2[2].set_xlabel('Number of evaluations')\n\n            if self.animate:\n                # f.canvas.draw()\n                plt.savefig('animation_last_graph')\n                # plt.pause(0.1)\n\n            # plt.show()\n\n\nclass CustomWarning(Warning):\n\n    def __init__(self, message: str, category: str) -> None:\n        # super().__init__()\n        self.message = message\n        self.category = category\n\n    def __str__(self):\n        return repr(self.message)\n\n    def category(self):\n        return self.category.__name__\n\n\nclass AvoidedLossSurgeWarning(CustomWarning):\n\n    def __init__(self, message: str) -> None:\n        super().__init__(message, \"AvoidedLossSurgeWarning\")\n\n\nclass NotPSDTrainingWarning(CustomWarning):\n\n    def __init__(self, message: str) -> None:\n        super().__init__(message, \"NotPSDTrainingWarning\")\n\n\nclass NaNTrainingWarning(CustomWarning):\n\n    def __init__(self, message: str) -> None:\n        super().__init__(message, \"NaNTrainingWarning\")\n\n\nclass NaNPredictionWarning(CustomWarning):\n\n    def __init__(self, message: str) -> None:\n        super().__init__(message, \"NaNPredictionWarning\")\n\n\nclass NotPSDPredictionWarning(CustomWarning):\n\n    def __init__(self, message: str) -> None:\n        super().__init__(message, \"NotPSDPredictionWarning\")\n\n\nclass ResetModelWarning(CustomWarning):\n\n    def __init__(self, message: str) -> None:\n        super().__init__(message, \"ResetModelWarning\")\n\n\nclass MultipleMinimaWarning(CustomWarning):\n\n    def __init__(self, message: str) -> None:\n        super().__init__(message, \"MultipleMinimaWarning\")\n", 981], "/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_alt_BOTorch.py": ["\"\"\" BOTorch package from https://github.com/pytorch/botorch \"\"\"\nfrom __future__ import print_function\n\nfrom collections import OrderedDict\nimport numpy as np\n\ntry:\n    import torch\n    from botorch.models import SingleTaskGP\n    from botorch.fit import fit_gpytorch_model\n    from botorch.utils import standardize\n    from gpytorch.mlls import ExactMarginalLogLikelihood\n    from botorch.acquisition import UpperConfidenceBound\n    from botorch.optim import optimize_acqf\nexcept Exception:\n    BayesianOptimization = None\n    bayes_opt_present = False\n\nfrom kernel_tuner.strategies import minimize\n\nsupported_methods = [\"poi\", \"ei\", \"ucb\"]\n\n\ndef tune(runner, kernel_options, device_options, tuning_options):\n    \"\"\" Find the best performing kernel configuration in the parameter space\n\n    :params runner: A runner from kernel_tuner.runners\n    :type runner: kernel_tuner.runner\n\n    :param kernel_options: A dictionary with all options for the kernel.\n    :type kernel_options: kernel_tuner.interface.Options\n\n    :param device_options: A dictionary with all options for the device\n        on which the kernel should be tuned.\n    :type device_options: kernel_tuner.interface.Options\n\n    :param tuning_options: A dictionary with all options regarding the tuning\n        process.\n    :type tuning_options: kernel_tuner.interface.Options\n\n    :returns: A list of dictionaries for executed kernel configurations and their\n        execution times. And a dictionary that contains a information\n        about the hardware/software environment on which the tuning took place.\n    :rtype: list(dict()), dict()\n\n    \"\"\"\n\n    if not bayes_opt_present:\n        raise ImportError(\"Error: optional dependency Bayesian Optimization not installed\")\n    init_points = tuning_options.strategy_options.get(\"popsize\", 20)\n    n_iter = tuning_options.strategy_options.get(\"max_fevals\", 100)\n\n    # defaults as used by Bayesian Optimization Python package\n    acq = tuning_options.strategy_options.get(\"method\", \"ucb\")\n    kappa = tuning_options.strategy_options.get(\"kappa\", 2.576)\n    xi = tuning_options.strategy_options.get(\"xi\", 0.0)\n\n    tuning_options[\"scaling\"] = True\n\n    results = []\n\n    # function to pass to the optimizer\n    def func(**kwargs):\n        args = [kwargs[key] for key in tuning_options.tune_params.keys()]\n        return -1.0 * minimize._cost_func(args, kernel_options, tuning_options, runner, results)\n\n    bounds, _, _ = minimize.get_bounds_x0_eps(tuning_options)\n    pbounds = OrderedDict(zip(tuning_options.tune_params.keys(), bounds))\n\n    verbose = 0\n    if tuning_options.verbose:\n        verbose = 2\n\n    # print(np.isnan(init_points).any())\n\n    optimizer = BayesianOptimization(f=func, pbounds=pbounds, verbose=verbose)\n\n    optimizer.maximize(init_points=init_points, n_iter=n_iter, acq=acq, kappa=kappa, xi=xi)\n\n    if tuning_options.verbose:\n        print(optimizer.max)\n\n    return results, runner.dev.get_environment()\n", 83], "/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py": ["\"\"\"Kernel Tuner interface module\n\nThis module contains the main functions that Kernel Tuner\noffers to its users.\n\nAuthor\n------\nBen van Werkhoven <b.vanwerkhoven@esciencenter.nl>\n\nCopyright and License\n---------------------\n* Copyright 2016 Netherlands eScience Center\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\"\"\"\nfrom __future__ import print_function\n\nimport json\nimport os.path\nfrom collections import OrderedDict\nimport importlib\nfrom datetime import datetime\nimport logging\nimport sys\nimport numpy\n\nimport kernel_tuner.util as util\nimport kernel_tuner.core as core\n\nfrom kernel_tuner.runners.sequential import SequentialRunner\nfrom kernel_tuner.runners.simulation import SimulationRunner\n\ntry:\n    import torch\nexcept ImportError:\n    torch = util.TorchPlaceHolder()\n\nfrom kernel_tuner.strategies import brute_force, random_sample, diff_evo, minimize, basinhopping, genetic_algorithm, mls, pso, simulated_annealing, firefly_algorithm, bayes_opt, greedy_mls, greedy_ils, ordered_greedy_mls, dual_annealing, bayes_opt_old, bayes_opt_GPyTorch, bayes_opt_GPyTorch_lean, bayes_opt_alt_BOTorch\n\nstrategy_map = {\n    \"brute_force\": brute_force,\n    \"random_sample\": random_sample,\n    \"minimize\": minimize,\n    \"basinhopping\": basinhopping,\n    \"diff_evo\": diff_evo,\n    \"genetic_algorithm\": genetic_algorithm,\n    \"greedy_mls\": greedy_mls,\n    \"ordered_greedy_mls\": ordered_greedy_mls,\n    \"greedy_ils\": greedy_ils,\n    \"dual_annealing\": dual_annealing,\n    \"mls\": mls,\n    \"pso\": pso,\n    \"simulated_annealing\": simulated_annealing,\n    \"firefly_algorithm\": firefly_algorithm,\n    \"bayes_opt\": bayes_opt,\n    \"bayes_opt_old\": bayes_opt_old,\n    \"bayes_opt_GPyTorch\": bayes_opt_GPyTorch,\n    \"bayes_opt_GPyTorch_lean\": bayes_opt_GPyTorch_lean,\n    \"bayes_opt_BOTorch\": bayes_opt_alt_BOTorch,\n}\n\n\nclass Options(OrderedDict):\n    \"\"\"read-only class for passing options around\"\"\"\n\n    def __getattr__(self, name):\n        if not name.startswith('_'):\n            return self[name]\n        return super(Options, self).__getattr__(name)\n\n    def __deepcopy__(self, _):\n        return self\n\n\n_kernel_options = Options([(\"kernel_name\", (\"\"\"The name of the kernel in the code.\"\"\", \"string\")),\n                           (\"kernel_source\", (\"\"\"The CUDA, OpenCL, or C kernel code.\n            It is allowed for the code to be passed as a string, a filename, a function\n            that returns a string of code, or a list when the code needs auxilliary files.\n\n            To support combined host and device code tuning, a list of\n            filenames can be passed. The first file in the list should be the\n            file that contains the host code. The host code is assumed to\n            include or read in any of the files in the list beyond the first.\n            The tunable parameters can be used within all files.\n\n            Another alternative is to pass a code generating function.\n            The purpose of this is to support the use of code generating\n            functions that generate the kernel code based on the specific\n            parameters. This function should take one positional argument,\n            which will be used to pass a dict containing the parameters.\n            The function should return a string with the source code for\n            the kernel.\"\"\", \"string or list and/or callable\")),\n                           (\"lang\", (\"\"\"Specifies the language used for GPU kernels. The kernel_tuner\n        automatically detects the language, but if it fails, you may specify\n        the language using this argument, currently supported: \"CUDA\", \"Cupy\",\n        \"OpenCL\", or \"C\".\"\"\", \"string\")),\n                           (\"problem_size\", (\"\"\"The size of the domain from which the grid dimensions\n            of the kernel are computed.\n\n            This can be specified using an int, string, function, or\n            1,2,3-dimensional tuple.\n\n            In general, do not divide the problem_size yourself by the thread block sizes.\n            Kernel Tuner does this for you based on tunable parameters,\n            called \"block_size_x\", \"block_size_y\", and \"block_size_z\".\n            If more or different parameters divide the grid dimensions use\n            grid_div_x/y/z options to specify this.\n\n            In most use-cases the problem_size is specified using a single integer\n            or a tuple of integers,\n            but Kernel Tuner supports more advanced use cases where the problem_size\n            itself depends on the tunable parameters in some way.\n\n            You are allowed to use a function or string to specify the problem_size.\n            A function should accept a dictionary with the tunable parameters\n            for this kernel configuration and directly return a tuple\n            that specifies the problem size in all dimensions.\n\n            When passing a string, you are allowed to write Python\n            arithmetic and use the names of tunable parameters as variables\n            in these expressions. Kernel Tuner will replace instances of the tunable\n            parameters with their current value when computing the grid dimensions.\n            This option exists for convenience, but do note that using a lambda\n            function is probably safer. The string notation should only return\n            the problem size for one dimension, but can be used inside\n            a tuple, possibly in combination with integers or more strings in\n            different dimensions.\n\n            See the reduction CUDA example for an example use of this feature.\"\"\", \"callable, string, int, or tuple(int or string, ..)\")),\n                           (\"arguments\", (\"\"\"A list of kernel arguments, use numpy arrays for\n            arrays, use numpy.int32 or numpy.float32 for scalars.\"\"\", \"list\")),\n                           (\"grid_div_x\", (\"\"\"A list of names of the parameters whose values divide\n            the grid dimensions in the x-direction.\n            The product of all grid divisor expressions is computed before dividing\n            the problem_size in that dimension. Also note that the divison is treated\n            as a float divison and resulting grid dimensions will be rounded up to\n            the nearest integer number.\n\n            Arithmetic expressions can be\n            used if necessary inside the string containing a parameter name. For\n            example, in some cases you may want to divide the problem size in the\n            x-dimension with the number of warps rather than the number of threads\n            in a block, in such cases one could for example use [\"block_size_x/32\"].\n            Another option is to pass a function to grid_div_x that accepts a\n            dictionary with the tunable parameters and returns the grid divisor\n            in this dimension, for example: grid_div_x=lambda p:p[\"block_size_x\"]/32.\n\n            If not supplied, [\"block_size_x\"] will be used by default, if you do not\n            want any grid x-dimension divisors pass an empty list.\"\"\", \"callable or list\")),\n                           (\"grid_div_y\", (\"\"\"A list of names of the parameters whose values divide\n            the grid dimensions in the y-direction, [\"block_size_y\"] by default.\n            If you do not want to divide the problem_size, you should pass an empty list.\n            See grid_div_x for more details.\"\"\", \"list\")),\n                           (\"grid_div_z\", (\"\"\"A list of names of the parameters whose values divide\n            the grid dimensions in the z-direction, [\"block_size_z\"] by default.\n            If you do not want to divide the problem_size, you should pass an empty list.\n            See grid_div_x for more details.\"\"\", \"list\")),\n                           (\"smem_args\", (\"\"\"CUDA-specific feature for specifying shared memory options\n            to the kernel. At the moment only 'size' is supported, but setting the\n            shared memory configuration on Kepler GPUs for example could be added\n            in the future. Size should denote the number of bytes for to use when\n            dynamically allocating shared memory.\"\"\", \"dict(string: numpy object)\")),\n                           (\"cmem_args\", (\"\"\"CUDA-specific feature for specifying constant memory\n            arguments to the kernel. In OpenCL these are handled as normal\n            kernel arguments, but in CUDA you can copy to a symbol. The way you\n            specify constant memory arguments is by passing a dictionary with\n            strings containing the constant memory symbol name together with numpy\n            objects in the same way as normal kernel arguments.\"\"\", \"dict(string: numpy object)\")),\n                           (\"texmem_args\", (\"\"\"CUDA-specific feature for specifying texture memory\n            arguments to the kernel. You specify texture memory arguments by passing a\n            dictionary with strings containing the texture reference name together with\n            the texture contents. These contents can be either simply a numpy object,\n            or a dictionary containing the numpy object under the key 'array' plus the\n            configuration options 'filter_mode' ('point' or 'linear), 'address_mode'\n            (a list of 'border', 'clamp', 'mirror', 'wrap' per axis),\n            'normalized_coordinates' (True/False).\"\"\", \"dict(string: numpy object or dict)\")),\n                           (\"block_size_names\", (\"\"\"A list of strings that replace the defaults for the names\n            that denote the thread block dimensions. If not passed, the behavior\n            defaults to ``[\"block_size_x\", \"block_size_y\", \"block_size_z\"]``\"\"\", \"list(string)\"))])\n\n_tuning_options = Options([(\"tune_params\", (\"\"\"A dictionary containing the parameter names as keys,\n            and lists of possible parameter settings as values.\n            Kernel Tuner will try to compile and benchmark all possible\n            combinations of all possible values for all tuning parameters.\n            This typically results in a rather large search space of all\n            possible kernel configurations.\n\n            For each kernel configuration, each tuning parameter is\n            replaced at compile-time with its current value.\n            Currently, Kernel Tuner uses the convention that the following\n            list of tuning parameters are used as thread block dimensions:\n\n                * \"block_size_x\"   thread block (work group) x-dimension\n                * \"block_size_y\"   thread block (work group) y-dimension\n                * \"block_size_z\"   thread block (work group) z-dimension\n\n            Options for changing these defaults may be added later. If you\n            don't want the thread block dimensions to be compiled in, you\n            may use the built-in variables blockDim.xyz in CUDA or the\n            built-in function get_local_size() in OpenCL instead.\"\"\", \"dict( string : [...]\")),\n                           (\"restrictions\", (\"\"\"An option to limit the search space with restrictions.\n        The restrictions can be specified using a function or a list of strings.\n        The function should take one argument, namely a dictionary with the\n        tunable parameters of the kernel configuration, if the function returns\n        True the configuration is considered to be part of the search space, or\n        False otherwise.\n        The other way to specify restrictions is using a list of strings\n        containing boolean expression that must be satisfied by the kernel\n        configuration. These expressions must all be true for the configuration\n        to be part of the search space. For example:\n        restrictions=[\"block_size_x==block_size_y*tile_size_y\"] limits the\n        search to configurations where the block_size_x equals the product\n        of block_size_y and tile_size_y.\n        The default is None.\"\"\", \"callable or list(strings)\")),\n                           (\"answer\", (\"\"\"A list of arguments, similar to what you pass to arguments,\n        that contains the expected output of the kernel after it has executed\n        and contains None for each argument that is input-only. The expected\n        output of the kernel will then be used to verify the correctness of\n        each kernel in the parameter space before it will be benchmarked.\"\"\", \"list\")),\n                           (\"atol\", (\"\"\"The maximum allowed absolute difference between two elements\n        in the output and the reference answer, as passed to numpy.allclose().\n        Ignored if you have not passed a reference answer. Default value is\n        1e-6, that is 0.000001.\"\"\", \"float\")),\n                           (\"verify\", (\"\"\"Python function used for output verification. By default,\n        numpy.allclose is used for output verification, if this does not suit\n        your application, you can pass a different function here.\n\n        The function is expected to have two positional arguments. The first\n        is the reference result, the second is the output computed by the\n        kernel being verified. The types of these arguments depends on the\n        type of the output arguments you are verifying. The function may also\n        have an optional argument named atol, to which the value will be\n        passed that was specified using the atol option to tune_kernel.\n        The function should return True when the output passes the test, and\n        False when the output fails the test.\"\"\", \"func(ref, ans, atol=None)\")),\n                           (\"strategy\", (\"\"\"Specify the strategy to use for searching through the\n        parameter space, choose from:\n\n            * \"brute_force\" (default) iterates through the entire search space.\n            * \"random_sample\" takes a random sample of the search space.\n            * \"minimize\" uses a local minimization algorithm.\n            * \"basinhopping\" combines global stepping with a local minimization at each step.\n            * \"diff_evo\" differential evolution.\n            * \"genetic_algorithm\" a genetic algorithm optimization strategy.\n            * \"mls\" multi-start local search\n            * \"pso\" particle swarm optimization\n            * \"firefly_algorithm\" firefly algorithm strategy.\n            * \"simulated_annealing\" simulated annealing strategy.\n            * \"bayes_opt\" Bayesian Optimization strategy.\n\n        Strategy-specific parameters and options are explained under strategy_options.\n\n        \"\"\", \"\")),\n                           (\"strategy_options\", (\"\"\"A dict with options specific to the selected tuning strategy.\n\n\n            * **\"random_sample\"**\n\n              * \"fraction\", float, fraction of the search space to cover in [0,1], default 0.1.\n\n            * **\"minimize\"**\n\n              * \"method\", string, any of \"Nelder-Mead\", \"Powell\", \"CG\", \"BFGS\", \"L-BFGS-B\", \"TNC\", \"COBYLA\", or \"SLSQP\", default \"L-BFGS-B\".\n\n            * **\"basinhopping\"**\n\n              * \"method\", string, any of \"Nelder-Mead\", \"Powell\", \"CG\", \"BFGS\", \"L-BFGS-B\", \"TNC\", \"COBYLA\", or \"SLSQP\", default \"L-BFGS-B\".\n\n              * \"T\", float, Temperature parameter for the accept or reject criterion, default 1.0.\n\n            * **\"diff_evo\"**\n\n              * \"method\", string, any of \"best1bin\", \"best1exp\", \"rand1exp\", \"randtobest1exp\", \"best2exp\", \"rand2exp\", \"randtobest1bin\", \"best2bin\", \"rand2bin\", \"rand1bin\", default \"best1bin\".\n\n            * **\"genetic_algorithm\"**\n\n              * \"popsize\", integer, population size, default 20.\n\n              * \"maxiter\", integer, number of generations, default 50.\n\n              * \"method\", string, crossover method any of \"single_point\", \"two_point\", \"uniform\", \"disruptive_uniform\", default \"uniform\".\n\n              * \"mutation_chance\", integer, specifies the 1 in mutation_chance of a mutation, default 10.\n\n              * \"max_fevals\", integer, specifies the maximum allowed number of unique function evaluations, default 100.\n\n            * **\"mls\"**\n\n              * \"max_fevals\", integer, specifies the maximum allowed number of unique function evaluations, default 100.\n\n            * **\"pso\"**\n\n              * \"popsize\", integer, population size, default 20.\n\n              * \"maxiter\", integer, number of generations, default 100.\n\n              * \"w\", float, inertia constant, default 0.5.\n\n              * \"c1\", float, cognitive constant, default 2.0.\n\n              * \"c2\", float, social constant, default 1.0.\n\n            * **\"firefly_algorithm\"**\n\n              * \"popsize\", integer, population size, default 20.\n\n              * \"maxiter\", integer, number of generations, default 100.\n\n              * \"B0\", float, B0 parameter, default 1.0.\n\n              * \"gamma\", float, gamma parameter, default 1.0.\n\n              * \"alpha\", float, alpha parameter, default 0.2.\n\n            * **\"simulated_annealing\"**\n\n              * \"T\", float, starting temperature parameter, default 1.0.\n\n              * \"T_min\", float, end temperature parameter, default 0.001.\n\n              * \"alpha\", float, alpha parameter, default 0.9.\n\n              * \"maxiter\", integer, number of iterations of possibly accepting neighboring points, default 20.\n\n            * **\"bayes_opt\"**\n\n              * \"method\": any of \"poi\", \"ei\", \"lcb\", \"lcb-srinivas\", \"multi\", \"multi-advanced\", \"multi-fast\", default \"multi-advanced\".\n\n              * \"covariancekernel\", any of \"constantrbf\", \"rbf\", \"matern32\", \"matern52\", default \"matern32\".\n\n              * \"covariancelengthscale\", float, default 1.5.\n\n              * \"samplingmethod\" any of \"random\", \"lhs\", default \"lhs\".\n\n\n\n    \"\"\", \"dict\")),\n                           (\"iterations\", (\"\"\"The number of times a kernel should be executed and\n        its execution time measured when benchmarking a kernel, 7 by default.\"\"\", \"int\")),\n                           (\"verbose\", (\"\"\"Sets whether or not to report about configurations that\n        were skipped during the search. This could be due to several reasons:\n\n            * kernel configuration fails one or more restrictions\n            * too many threads per thread block\n            * too much shared memory used by the kernel\n            * too many resources requested for launch\n\n        verbose is False by default.\"\"\", \"bool\")),\n                           (\"cache\", (\"\"\"filename for caching/logging benchmarked instances\n        filename uses suffix \".json\"\n        if the file exists it is read and tuning continues from this file\n        \"\"\", \"string\")), (\"metrics\", (\"specifies user-defined metrics\", \"OrderedDict\")),\n                           (\"simulation_mode\", (\"Simulate an auto-tuning search from an existing cachefile\", \"bool\")),\n                           (\"observers\", (\"\"\"A list of BenchmarkObservers\"\"\", \"list\"))])\n\n_device_options = Options([(\"device\", (\"\"\"CUDA/OpenCL device to use, in case you have multiple\n        CUDA-capable GPUs or OpenCL devices you may use this to select one,\n        0 by default. Ignored if you are tuning host code by passing\n        lang=\"C\".\"\"\", \"int\")),\n                           (\"platform\", (\"\"\"OpenCL platform to use, in case you have multiple\n        OpenCL platforms you may use this to select one,\n        0 by default. Ignored if not using OpenCL. \"\"\", \"int\")),\n                           (\"quiet\", (\"\"\"Control whether or not to print to the console which\n        device is being used, False by default\"\"\", \"boolean\")),\n                           (\"compiler\", (\"\"\"A string containing your preferred compiler,\n        only effective with lang=\"C\". \"\"\", \"string\")), (\"compiler_options\", (\"\"\"A list of strings that specify compiler\n        options.\"\"\", \"list(string)\"))])\n\n\ndef _get_docstring(opts):\n    docstr = \"\"\n    for k, v in opts.items():\n        docstr += \"    :param \" + k + \": \" + v[0] + \"\\n\"\n        docstr += \"    :type \" + k + \": \" + v[1] + \"\\n\\n\"\n    return docstr\n\n\n_tune_kernel_docstring = \"\"\" Tune a CUDA kernel given a set of tunable parameters\n\n%s\n\n    :returns: A list of dictionaries of all executed kernel configurations and their\n        execution times. And a dictionary with information about the environment\n        in which the tuning took place. This records device name, properties,\n        version info, and so on.\n    :rtype: list(dict()), dict()\n\n\"\"\" % _get_docstring(_kernel_options) + _get_docstring(_tuning_options) + _get_docstring(_device_options)\n\n#\"\"\"\n\n\ndef tune_kernel(kernel_name, kernel_source, problem_size, arguments, tune_params, grid_div_x=None, grid_div_y=None, grid_div_z=None, restrictions=None,\n                answer=None, atol=1e-6, verify=None, verbose=False, lang=None, device=0, platform=0, smem_args=None, cmem_args=None, texmem_args=None,\n                compiler=None, compiler_options=None, log=None, iterations=7, block_size_names=None, quiet=False, strategy=None, strategy_options=None,\n                cache=None, metrics=None, simulation_mode=False, parallel_mode=False, observers=None):\n\n    if log:\n        logging.basicConfig(filename=kernel_name + datetime.now().strftime('%Y%m%d-%H:%M:%S') + '.log', level=log)\n\n    kernelsource = core.KernelSource(kernel_name, kernel_source, lang)\n\n    _check_user_input(kernel_name, kernelsource, arguments, block_size_names)\n\n    # check for forbidden names in tune parameters\n    util.check_tune_params_list(tune_params)\n\n    # check whether block_size_names are used as expected\n    util.check_block_size_params_names_list(block_size_names, tune_params)\n\n    # if the restrictions are not callable, make them (increases restrictions check performance significantly)\n    if restrictions is not None and not callable(restrictions):\n        restrictions = util.parse_restrictions(restrictions)\n\n    if iterations < 1:\n        raise ValueError(\"Iterations should be at least one!\")\n\n    #sort all the options into separate dicts\n    opts = locals()\n    kernel_options = Options([(k, opts[k]) for k in _kernel_options.keys()])\n    tuning_options = Options([(k, opts[k]) for k in _tuning_options.keys()])\n    device_options = Options([(k, opts[k]) for k in _device_options.keys()])\n    tuning_options[\"snap\"] = True\n\n    logging.debug('tune_kernel called')\n    logging.debug('kernel_options: %s', util.get_config_string(kernel_options))\n    logging.debug('tuning_options: %s', util.get_config_string(tuning_options))\n    logging.debug('device_options: %s', util.get_config_string(device_options))\n\n    if strategy:\n        if strategy in strategy_map:\n            strategy = strategy_map[strategy]\n        else:\n            raise ValueError(\"Strategy %s not recognized\" % strategy)\n\n        #make strategy_options into an Options object\n        if tuning_options.strategy_options:\n            if not isinstance(strategy_options, Options):\n                tuning_options.strategy_options = Options(strategy_options)\n\n            #select strategy based on user options\n            if \"fraction\" in tuning_options.strategy_options and not tuning_options.strategy == 'random_sample':\n                raise ValueError('It is not possible to use fraction in combination with strategies other than \"random_sample\". ' \\\n                                 'Please set strategy=\"random_sample\", when using \"fraction\" in strategy_options')\n\n            #check if method is supported by the selected strategy\n            if \"method\" in tuning_options.strategy_options:\n                method = tuning_options.strategy_options.method\n                if not method in strategy.supported_methods:\n                    raise ValueError('Method %s is not supported for strategy %s' % (method, tuning_options.strategy))\n\n        #if no strategy_options dict has been passed, create empty dictionary\n        else:\n            tuning_options.strategy_options = Options({})\n\n    #if no strategy selected\n    else:\n        strategy = brute_force\n\n    # select the runner for this job based on input\n    selected_runner = SimulationRunner if simulation_mode is True else SequentialRunner\n    with selected_runner(kernelsource, kernel_options, device_options, iterations, observers, parallel_mode) as runner:\n\n        #the user-specified function may or may not have an optional atol argument;\n        #we normalize it so that it always accepts atol.\n        tuning_options.verify = util.normalize_verify_function(tuning_options.verify)\n\n        #process cache\n        if cache:\n            if cache[-5:] != \".json\":\n                cache += \".json\"\n\n            util.process_cache(cache, kernel_options, tuning_options, runner)\n        else:\n            tuning_options.cache = {}\n            tuning_options.cachefile = None\n\n        #call the strategy to execute the tuning process\n        results, env = strategy.tune(runner, kernel_options, device_options, tuning_options)\n\n        #finished iterating over search space\n        if not device_options.quiet:\n            if results:    #checks if results is not empty\n                best_config = min(results, key=lambda x: x['time'])\n                units = getattr(runner, \"units\", None)\n                print(\"best performing configuration:\")\n                util.print_config_output(tune_params, best_config, device_options.quiet, metrics, units)\n            else:\n                print(\"no results to report\")\n\n        if cache and not simulation_mode:\n            util.close_cache(cache)\n\n    return results, env\n\n\ntune_kernel.__doc__ = _tune_kernel_docstring\n\n_run_kernel_docstring = \"\"\"Compile and run a single kernel\n\n    Compiles and runs a single kernel once, given a specific instance of the kernels tuning parameters.\n    However, instead of measuring execution time run_kernel returns the output of the kernel.\n    The output is returned as a list of numpy arrays that contains the state of all the kernel arguments\n    after execution on the GPU.\n\n    To summarize what this function will do for you in one call:\n     * Compile the kernel according to the set of parameters passed\n     * Allocate GPU memory to hold all kernel arguments\n     * Move the all data to the GPU\n     * Execute the kernel on the GPU\n     * Copy all data from the GPU back to the host and return it as a list of Numpy arrays\n\n    This function was added to Kernel Tuner mostly to allow easy testing for kernel correctness.\n    On purpose, the interface is a lot like `tune_kernel()`.\n\n%s\n\n    :param params: A dictionary containing the tuning parameter names as keys\n            and a single value per tuning parameter as values.\n    :type params: dict( string: int )\n\n    :returns: A list of numpy arrays, similar to the arguments passed to this\n        function, containing the output after kernel execution.\n    :rtype: list\n\"\"\" % _get_docstring(_kernel_options) + _get_docstring(_device_options)\n\n\ndef run_kernel(kernel_name, kernel_source, problem_size, arguments, params, grid_div_x=None, grid_div_y=None, grid_div_z=None, lang=None, device=0, platform=0,\n               smem_args=None, cmem_args=None, texmem_args=None, compiler=None, compiler_options=None, block_size_names=None, quiet=False, log=None):\n\n    if log:\n        logging.basicConfig(filename=kernel_name + datetime.now().strftime('%Y%m%d-%H:%M:%S') + '.log', level=log)\n\n    kernelsource = core.KernelSource(kernel_name, kernel_source, lang)\n\n    _check_user_input(kernel_name, kernelsource, arguments, block_size_names)\n\n    #sort options into separate dicts\n    opts = locals()\n    kernel_options = Options([(k, opts[k]) for k in _kernel_options.keys()])\n    device_options = Options([(k, opts[k]) for k in _device_options.keys()])\n\n    #detect language and create the right device function interface\n    with core.DeviceInterface(kernelsource, iterations=1, **device_options) as dev:\n\n        #move data to the GPU\n        gpu_args = dev.ready_argument_list(arguments)\n\n        instance = None\n        try:\n            #create kernel instance\n            instance = dev.create_kernel_instance(kernelsource, kernel_options, params, False)\n            if instance is None:\n                raise Exception(\"cannot create kernel instance, too many threads per block\")\n\n            # see if the kernel arguments have correct type\n            util.check_argument_list(instance.name, instance.kernel_string, arguments)\n\n            #compile the kernel\n            func = dev.compile_kernel(instance, False)\n            if func is None:\n                raise Exception(\"cannot compile kernel, too much shared memory used\")\n\n            #add shared memory arguments to compiled module\n            if smem_args is not None:\n                dev.copy_shared_memory_args(util.get_smem_args(smem_args, params))\n            #add constant memory arguments to compiled module\n            if cmem_args is not None:\n                dev.copy_constant_memory_args(cmem_args)\n            #add texture memory arguments to compiled module\n            if texmem_args is not None:\n                dev.copy_texture_memory_args(texmem_args)\n        finally:\n            #delete temp files\n            if instance is not None:\n                instance.delete_temp_files()\n\n        #run the kernel\n        if not dev.run_kernel(func, gpu_args, instance):\n            raise Exception(\"runtime error occured, too many resources requested\")\n\n        #copy data in GPU memory back to the host\n        results = []\n        for i, arg in enumerate(arguments):\n            if numpy.isscalar(arg):\n                results.append(arg)\n            elif isinstance(arg, torch.Tensor):\n                results.append(arg.cpu())\n            else:\n                results.append(numpy.zeros_like(arg))\n                dev.memcpy_dtoh(results[-1], gpu_args[i])\n\n    return results\n\n\nrun_kernel.__doc__ = _run_kernel_docstring\n\n\ndef _check_user_input(kernel_name, kernelsource, arguments, block_size_names):\n    # see if the kernel arguments have correct type\n    kernelsource.check_argument_lists(kernel_name, arguments)\n\n    # check for types and length of block_size_names\n    util.check_block_size_names(block_size_names)\n", 614], "/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/__init__.py": ["\nfrom kernel_tuner.integration import store_results, create_device_targets\n\nfrom kernel_tuner.interface import tune_kernel, run_kernel\n\n", 5], "/Users/fjwillemsen/Library/CloudStorage/OneDrive-NetherlandseScienceCenter/Projects/Bayesian Optimization in Kernel Tuner/Code/cached_data_used/bootstrap_hyperparamtuning.py": ["#!/usr/bin/env python\nfrom collections import OrderedDict\nfrom time import perf_counter\n\nfrom kernel_tuner import tune_kernel\nfrom kernel_tuner import observers\nfrom kernel_tuner.observers import BenchmarkObserver\nimport numpy as np\n\nprog_name = \"bootstrap_hyperparamtuning\"\n\n\ndef tune(strategy=\"bayes_opt_GPyTorch_lean\", iterations=35, strategy_options=None):\n    simulation_mode = False\n    parallel_mode = True\n    verbose = False\n    quiet = False\n\n    # input dimensions and data\n    x = 100\n    y = 100\n    problem_size = (x, y)\n    args = []\n    metrics = OrderedDict()\n    strategy_options = {}\n    strategy_options['max_fevals'] = 5000\n    strategy_options['popsize'] = 100\n\n    def make_dict(key: str, value):\n        return {\n            key: value\n        }\n\n    # fixed tune params\n    tune_params = OrderedDict()\n    tune_params[\"max_fevals\"] = [220]\n    tune_params[\"method\"] = ['ei']\n    strategy_options['max_fevals'] = 1\n\n    # # test precision\n    # tune_params = OrderedDict()\n    # tune_params[\"max_fevals\"] = [220]\n    # tune_params[\"dummy_param\"] = [1, 2, 3, 4, 5]\n    # # tune_params[\"precision\"] = ['float', 'double']\n    # # tune_params[\"minimum_std\"] = [1e-3, 1e-5, 1e-6, 1e-7, 1e-9]\n    # strategy_options['max_fevals'] = np.prod(tuple(len(params) for params in tune_params.values()))\n\n    # # setup tunable parameters\n    # tune_params = OrderedDict()\n    # tune_params[\"max_fevals\"] = [220]\n    # tune_params[\"initialsamplemethod\"] = ['lhs', 'index']\n    # tune_params[\"initialsamplerandomoffsetfactor\"] = [0.01, 0.05, 0.1, 0.2, 0.3]\n    # tune_params[\"method\"] = ['ei', 'poi']\n    # tune_params[\"methodparams\"] = [make_dict('explorationfactor', v) for v in [0.005, 0.01, 0.05, 0.1]]\n    # tune_params[\"covariancekernel\"] = ['matern', 'matern_scalekernel']\n    # tune_params[\"covariancelengthscale\"] = [0.5, 1.5, 2.5]\n    # # tune_params[\"likelihood\"] = ['Gaussian', 'FixedNoise']    # TODO this causes a NanError for cholesky_cpu\n    # tune_params[\"optimizer\"] = ['LBFGS', 'Adam']\n    # tune_params[\"optimizer_learningrate\"] = [0.01, 0.05, 0.1]\n    # tune_params[\"initial_training_iter\"] = [5, 10, 25, 50]\n    # tune_params[\"training_iter\"] = [0, 1, 3]\n\n    search_space_size = tuple(len(params) for params in tune_params.values())\n    print(f\"Search space size: {np.prod(search_space_size)}\")\n\n    class DurationObserver(BenchmarkObserver):\n\n        def before_start(self):\n            super().before_start()\n            self.start_time = perf_counter()\n\n        def after_finish(self):\n            super().after_finish()\n            self.end_time = perf_counter()\n\n        def get_results(self):\n            super().get_results()\n            return {\n                'strategy_time': self.end_time - self.start_time\n            }\n\n    #start tuning\n    results, env = tune_kernel(prog_name + \"_kernel\", prog_name + \"_kernel.py\", problem_size, args, tune_params, lang='Python', iterations=iterations,\n                               metrics=metrics, verbose=verbose, quiet=quiet, strategy=strategy, strategy_options=strategy_options,\n                               simulation_mode=simulation_mode, parallel_mode=parallel_mode, cache=\"cache_files/\" + prog_name, observers=[])\n\n    # print(len(results))\n\n    return results, env\n\n\nif __name__ == \"__main__\":\n    tune()\n", 93], "/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/fromnumeric.py": ["\"\"\"Module containing non-deprecated functions borrowed from Numeric.\n\n\"\"\"\nimport functools\nimport types\nimport warnings\n\nimport numpy as np\nfrom . import multiarray as mu\nfrom . import overrides\nfrom . import umath as um\nfrom . import numerictypes as nt\nfrom .multiarray import asarray, array, asanyarray, concatenate\nfrom . import _methods\n\n_dt_ = nt.sctype2char\n\n# functions that are methods\n__all__ = [\n    'alen', 'all', 'alltrue', 'amax', 'amin', 'any', 'argmax',\n    'argmin', 'argpartition', 'argsort', 'around', 'choose', 'clip',\n    'compress', 'cumprod', 'cumproduct', 'cumsum', 'diagonal', 'mean',\n    'ndim', 'nonzero', 'partition', 'prod', 'product', 'ptp', 'put',\n    'ravel', 'repeat', 'reshape', 'resize', 'round_',\n    'searchsorted', 'shape', 'size', 'sometrue', 'sort', 'squeeze',\n    'std', 'sum', 'swapaxes', 'take', 'trace', 'transpose', 'var',\n]\n\n_gentype = types.GeneratorType\n# save away Python sum\n_sum_ = sum\n\narray_function_dispatch = functools.partial(\n    overrides.array_function_dispatch, module='numpy')\n\n\n# functions that are now methods\ndef _wrapit(obj, method, *args, **kwds):\n    try:\n        wrap = obj.__array_wrap__\n    except AttributeError:\n        wrap = None\n    result = getattr(asarray(obj), method)(*args, **kwds)\n    if wrap:\n        if not isinstance(result, mu.ndarray):\n            result = asarray(result)\n        result = wrap(result)\n    return result\n\n\ndef _wrapfunc(obj, method, *args, **kwds):\n    bound = getattr(obj, method, None)\n    if bound is None:\n        return _wrapit(obj, method, *args, **kwds)\n\n    try:\n        return bound(*args, **kwds)\n    except TypeError:\n        # A TypeError occurs if the object does have such a method in its\n        # class, but its signature is not identical to that of NumPy's. This\n        # situation has occurred in the case of a downstream library like\n        # 'pandas'.\n        #\n        # Call _wrapit from within the except clause to ensure a potential\n        # exception has a traceback chain.\n        return _wrapit(obj, method, *args, **kwds)\n\n\ndef _wrapreduction(obj, ufunc, method, axis, dtype, out, **kwargs):\n    passkwargs = {k: v for k, v in kwargs.items()\n                  if v is not np._NoValue}\n\n    if type(obj) is not mu.ndarray:\n        try:\n            reduction = getattr(obj, method)\n        except AttributeError:\n            pass\n        else:\n            # This branch is needed for reductions like any which don't\n            # support a dtype.\n            if dtype is not None:\n                return reduction(axis=axis, dtype=dtype, out=out, **passkwargs)\n            else:\n                return reduction(axis=axis, out=out, **passkwargs)\n\n    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n\n\ndef _take_dispatcher(a, indices, axis=None, out=None, mode=None):\n    return (a, out)\n\n\n@array_function_dispatch(_take_dispatcher)\ndef take(a, indices, axis=None, out=None, mode='raise'):\n    \"\"\"\n    Take elements from an array along an axis.\n\n    When axis is not None, this function does the same thing as \"fancy\"\n    indexing (indexing arrays using arrays); however, it can be easier to use\n    if you need elements along a given axis. A call such as\n    ``np.take(arr, indices, axis=3)`` is equivalent to\n    ``arr[:,:,:,indices,...]``.\n\n    Explained without fancy indexing, this is equivalent to the following use\n    of `ndindex`, which sets each of ``ii``, ``jj``, and ``kk`` to a tuple of\n    indices::\n\n        Ni, Nk = a.shape[:axis], a.shape[axis+1:]\n        Nj = indices.shape\n        for ii in ndindex(Ni):\n            for jj in ndindex(Nj):\n                for kk in ndindex(Nk):\n                    out[ii + jj + kk] = a[ii + (indices[jj],) + kk]\n\n    Parameters\n    ----------\n    a : array_like (Ni..., M, Nk...)\n        The source array.\n    indices : array_like (Nj...)\n        The indices of the values to extract.\n\n        .. versionadded:: 1.8.0\n\n        Also allow scalars for indices.\n    axis : int, optional\n        The axis over which to select values. By default, the flattened\n        input array is used.\n    out : ndarray, optional (Ni..., Nj..., Nk...)\n        If provided, the result will be placed in this array. It should\n        be of the appropriate shape and dtype. Note that `out` is always\n        buffered if `mode='raise'`; use other modes for better performance.\n    mode : {'raise', 'wrap', 'clip'}, optional\n        Specifies how out-of-bounds indices will behave.\n\n        * 'raise' -- raise an error (default)\n        * 'wrap' -- wrap around\n        * 'clip' -- clip to the range\n\n        'clip' mode means that all indices that are too large are replaced\n        by the index that addresses the last element along that axis. Note\n        that this disables indexing with negative numbers.\n\n    Returns\n    -------\n    out : ndarray (Ni..., Nj..., Nk...)\n        The returned array has the same type as `a`.\n\n    See Also\n    --------\n    compress : Take elements using a boolean mask\n    ndarray.take : equivalent method\n    take_along_axis : Take elements by matching the array and the index arrays\n\n    Notes\n    -----\n\n    By eliminating the inner loop in the description above, and using `s_` to\n    build simple slice objects, `take` can be expressed  in terms of applying\n    fancy indexing to each 1-d slice::\n\n        Ni, Nk = a.shape[:axis], a.shape[axis+1:]\n        for ii in ndindex(Ni):\n            for kk in ndindex(Nj):\n                out[ii + s_[...,] + kk] = a[ii + s_[:,] + kk][indices]\n\n    For this reason, it is equivalent to (but faster than) the following use\n    of `apply_along_axis`::\n\n        out = np.apply_along_axis(lambda a_1d: a_1d[indices], axis, a)\n\n    Examples\n    --------\n    >>> a = [4, 3, 5, 7, 6, 8]\n    >>> indices = [0, 1, 4]\n    >>> np.take(a, indices)\n    array([4, 3, 6])\n\n    In this example if `a` is an ndarray, \"fancy\" indexing can be used.\n\n    >>> a = np.array(a)\n    >>> a[indices]\n    array([4, 3, 6])\n\n    If `indices` is not one dimensional, the output also has these dimensions.\n\n    >>> np.take(a, [[0, 1], [2, 3]])\n    array([[4, 3],\n           [5, 7]])\n    \"\"\"\n    return _wrapfunc(a, 'take', indices, axis=axis, out=out, mode=mode)\n\n\ndef _reshape_dispatcher(a, newshape, order=None):\n    return (a,)\n\n\n# not deprecated --- copy if necessary, view otherwise\n@array_function_dispatch(_reshape_dispatcher)\ndef reshape(a, newshape, order='C'):\n    \"\"\"\n    Gives a new shape to an array without changing its data.\n\n    Parameters\n    ----------\n    a : array_like\n        Array to be reshaped.\n    newshape : int or tuple of ints\n        The new shape should be compatible with the original shape. If\n        an integer, then the result will be a 1-D array of that length.\n        One shape dimension can be -1. In this case, the value is\n        inferred from the length of the array and remaining dimensions.\n    order : {'C', 'F', 'A'}, optional\n        Read the elements of `a` using this index order, and place the\n        elements into the reshaped array using this index order.  'C'\n        means to read / write the elements using C-like index order,\n        with the last axis index changing fastest, back to the first\n        axis index changing slowest. 'F' means to read / write the\n        elements using Fortran-like index order, with the first index\n        changing fastest, and the last index changing slowest. Note that\n        the 'C' and 'F' options take no account of the memory layout of\n        the underlying array, and only refer to the order of indexing.\n        'A' means to read / write the elements in Fortran-like index\n        order if `a` is Fortran *contiguous* in memory, C-like order\n        otherwise.\n\n    Returns\n    -------\n    reshaped_array : ndarray\n        This will be a new view object if possible; otherwise, it will\n        be a copy.  Note there is no guarantee of the *memory layout* (C- or\n        Fortran- contiguous) of the returned array.\n\n    See Also\n    --------\n    ndarray.reshape : Equivalent method.\n\n    Notes\n    -----\n    It is not always possible to change the shape of an array without\n    copying the data. If you want an error to be raised when the data is copied,\n    you should assign the new shape to the shape attribute of the array::\n\n     >>> a = np.zeros((10, 2))\n\n     # A transpose makes the array non-contiguous\n     >>> b = a.T\n\n     # Taking a view makes it possible to modify the shape without modifying\n     # the initial object.\n     >>> c = b.view()\n     >>> c.shape = (20)\n     Traceback (most recent call last):\n        ...\n     AttributeError: Incompatible shape for in-place modification. Use\n     `.reshape()` to make a copy with the desired shape.\n\n    The `order` keyword gives the index ordering both for *fetching* the values\n    from `a`, and then *placing* the values into the output array.\n    For example, let's say you have an array:\n\n    >>> a = np.arange(6).reshape((3, 2))\n    >>> a\n    array([[0, 1],\n           [2, 3],\n           [4, 5]])\n\n    You can think of reshaping as first raveling the array (using the given\n    index order), then inserting the elements from the raveled array into the\n    new array using the same kind of index ordering as was used for the\n    raveling.\n\n    >>> np.reshape(a, (2, 3)) # C-like index ordering\n    array([[0, 1, 2],\n           [3, 4, 5]])\n    >>> np.reshape(np.ravel(a), (2, 3)) # equivalent to C ravel then C reshape\n    array([[0, 1, 2],\n           [3, 4, 5]])\n    >>> np.reshape(a, (2, 3), order='F') # Fortran-like index ordering\n    array([[0, 4, 3],\n           [2, 1, 5]])\n    >>> np.reshape(np.ravel(a, order='F'), (2, 3), order='F')\n    array([[0, 4, 3],\n           [2, 1, 5]])\n\n    Examples\n    --------\n    >>> a = np.array([[1,2,3], [4,5,6]])\n    >>> np.reshape(a, 6)\n    array([1, 2, 3, 4, 5, 6])\n    >>> np.reshape(a, 6, order='F')\n    array([1, 4, 2, 5, 3, 6])\n\n    >>> np.reshape(a, (3,-1))       # the unspecified value is inferred to be 2\n    array([[1, 2],\n           [3, 4],\n           [5, 6]])\n    \"\"\"\n    return _wrapfunc(a, 'reshape', newshape, order=order)\n\n\ndef _choose_dispatcher(a, choices, out=None, mode=None):\n    yield a\n    yield from choices\n    yield out\n\n\n@array_function_dispatch(_choose_dispatcher)\ndef choose(a, choices, out=None, mode='raise'):\n    \"\"\"\n    Construct an array from an index array and a list of arrays to choose from.\n\n    First of all, if confused or uncertain, definitely look at the Examples -\n    in its full generality, this function is less simple than it might\n    seem from the following code description (below ndi =\n    `numpy.lib.index_tricks`):\n\n    ``np.choose(a,c) == np.array([c[a[I]][I] for I in ndi.ndindex(a.shape)])``.\n\n    But this omits some subtleties.  Here is a fully general summary:\n\n    Given an \"index\" array (`a`) of integers and a sequence of ``n`` arrays\n    (`choices`), `a` and each choice array are first broadcast, as necessary,\n    to arrays of a common shape; calling these *Ba* and *Bchoices[i], i =\n    0,...,n-1* we have that, necessarily, ``Ba.shape == Bchoices[i].shape``\n    for each ``i``.  Then, a new array with shape ``Ba.shape`` is created as\n    follows:\n\n    * if ``mode='raise'`` (the default), then, first of all, each element of\n      ``a`` (and thus ``Ba``) must be in the range ``[0, n-1]``; now, suppose\n      that ``i`` (in that range) is the value at the ``(j0, j1, ..., jm)``\n      position in ``Ba`` - then the value at the same position in the new array\n      is the value in ``Bchoices[i]`` at that same position;\n\n    * if ``mode='wrap'``, values in `a` (and thus `Ba`) may be any (signed)\n      integer; modular arithmetic is used to map integers outside the range\n      `[0, n-1]` back into that range; and then the new array is constructed\n      as above;\n\n    * if ``mode='clip'``, values in `a` (and thus ``Ba``) may be any (signed)\n      integer; negative integers are mapped to 0; values greater than ``n-1``\n      are mapped to ``n-1``; and then the new array is constructed as above.\n\n    Parameters\n    ----------\n    a : int array\n        This array must contain integers in ``[0, n-1]``, where ``n`` is the\n        number of choices, unless ``mode=wrap`` or ``mode=clip``, in which\n        cases any integers are permissible.\n    choices : sequence of arrays\n        Choice arrays. `a` and all of the choices must be broadcastable to the\n        same shape.  If `choices` is itself an array (not recommended), then\n        its outermost dimension (i.e., the one corresponding to\n        ``choices.shape[0]``) is taken as defining the \"sequence\".\n    out : array, optional\n        If provided, the result will be inserted into this array. It should\n        be of the appropriate shape and dtype. Note that `out` is always\n        buffered if ``mode='raise'``; use other modes for better performance.\n    mode : {'raise' (default), 'wrap', 'clip'}, optional\n        Specifies how indices outside ``[0, n-1]`` will be treated:\n\n          * 'raise' : an exception is raised\n          * 'wrap' : value becomes value mod ``n``\n          * 'clip' : values < 0 are mapped to 0, values > n-1 are mapped to n-1\n\n    Returns\n    -------\n    merged_array : array\n        The merged result.\n\n    Raises\n    ------\n    ValueError: shape mismatch\n        If `a` and each choice array are not all broadcastable to the same\n        shape.\n\n    See Also\n    --------\n    ndarray.choose : equivalent method\n    numpy.take_along_axis : Preferable if `choices` is an array\n\n    Notes\n    -----\n    To reduce the chance of misinterpretation, even though the following\n    \"abuse\" is nominally supported, `choices` should neither be, nor be\n    thought of as, a single array, i.e., the outermost sequence-like container\n    should be either a list or a tuple.\n\n    Examples\n    --------\n\n    >>> choices = [[0, 1, 2, 3], [10, 11, 12, 13],\n    ...   [20, 21, 22, 23], [30, 31, 32, 33]]\n    >>> np.choose([2, 3, 1, 0], choices\n    ... # the first element of the result will be the first element of the\n    ... # third (2+1) \"array\" in choices, namely, 20; the second element\n    ... # will be the second element of the fourth (3+1) choice array, i.e.,\n    ... # 31, etc.\n    ... )\n    array([20, 31, 12,  3])\n    >>> np.choose([2, 4, 1, 0], choices, mode='clip') # 4 goes to 3 (4-1)\n    array([20, 31, 12,  3])\n    >>> # because there are 4 choice arrays\n    >>> np.choose([2, 4, 1, 0], choices, mode='wrap') # 4 goes to (4 mod 4)\n    array([20,  1, 12,  3])\n    >>> # i.e., 0\n\n    A couple examples illustrating how choose broadcasts:\n\n    >>> a = [[1, 0, 1], [0, 1, 0], [1, 0, 1]]\n    >>> choices = [-10, 10]\n    >>> np.choose(a, choices)\n    array([[ 10, -10,  10],\n           [-10,  10, -10],\n           [ 10, -10,  10]])\n\n    >>> # With thanks to Anne Archibald\n    >>> a = np.array([0, 1]).reshape((2,1,1))\n    >>> c1 = np.array([1, 2, 3]).reshape((1,3,1))\n    >>> c2 = np.array([-1, -2, -3, -4, -5]).reshape((1,1,5))\n    >>> np.choose(a, (c1, c2)) # result is 2x3x5, res[0,:,:]=c1, res[1,:,:]=c2\n    array([[[ 1,  1,  1,  1,  1],\n            [ 2,  2,  2,  2,  2],\n            [ 3,  3,  3,  3,  3]],\n           [[-1, -2, -3, -4, -5],\n            [-1, -2, -3, -4, -5],\n            [-1, -2, -3, -4, -5]]])\n\n    \"\"\"\n    return _wrapfunc(a, 'choose', choices, out=out, mode=mode)\n\n\ndef _repeat_dispatcher(a, repeats, axis=None):\n    return (a,)\n\n\n@array_function_dispatch(_repeat_dispatcher)\ndef repeat(a, repeats, axis=None):\n    \"\"\"\n    Repeat elements of an array.\n\n    Parameters\n    ----------\n    a : array_like\n        Input array.\n    repeats : int or array of ints\n        The number of repetitions for each element.  `repeats` is broadcasted\n        to fit the shape of the given axis.\n    axis : int, optional\n        The axis along which to repeat values.  By default, use the\n        flattened input array, and return a flat output array.\n\n    Returns\n    -------\n    repeated_array : ndarray\n        Output array which has the same shape as `a`, except along\n        the given axis.\n\n    See Also\n    --------\n    tile : Tile an array.\n    unique : Find the unique elements of an array.\n\n    Examples\n    --------\n    >>> np.repeat(3, 4)\n    array([3, 3, 3, 3])\n    >>> x = np.array([[1,2],[3,4]])\n    >>> np.repeat(x, 2)\n    array([1, 1, 2, 2, 3, 3, 4, 4])\n    >>> np.repeat(x, 3, axis=1)\n    array([[1, 1, 1, 2, 2, 2],\n           [3, 3, 3, 4, 4, 4]])\n    >>> np.repeat(x, [1, 2], axis=0)\n    array([[1, 2],\n           [3, 4],\n           [3, 4]])\n\n    \"\"\"\n    return _wrapfunc(a, 'repeat', repeats, axis=axis)\n\n\ndef _put_dispatcher(a, ind, v, mode=None):\n    return (a, ind, v)\n\n\n@array_function_dispatch(_put_dispatcher)\ndef put(a, ind, v, mode='raise'):\n    \"\"\"\n    Replaces specified elements of an array with given values.\n\n    The indexing works on the flattened target array. `put` is roughly\n    equivalent to:\n\n    ::\n\n        a.flat[ind] = v\n\n    Parameters\n    ----------\n    a : ndarray\n        Target array.\n    ind : array_like\n        Target indices, interpreted as integers.\n    v : array_like\n        Values to place in `a` at target indices. If `v` is shorter than\n        `ind` it will be repeated as necessary.\n    mode : {'raise', 'wrap', 'clip'}, optional\n        Specifies how out-of-bounds indices will behave.\n\n        * 'raise' -- raise an error (default)\n        * 'wrap' -- wrap around\n        * 'clip' -- clip to the range\n\n        'clip' mode means that all indices that are too large are replaced\n        by the index that addresses the last element along that axis. Note\n        that this disables indexing with negative numbers. In 'raise' mode,\n        if an exception occurs the target array may still be modified.\n\n    See Also\n    --------\n    putmask, place\n    put_along_axis : Put elements by matching the array and the index arrays\n\n    Examples\n    --------\n    >>> a = np.arange(5)\n    >>> np.put(a, [0, 2], [-44, -55])\n    >>> a\n    array([-44,   1, -55,   3,   4])\n\n    >>> a = np.arange(5)\n    >>> np.put(a, 22, -5, mode='clip')\n    >>> a\n    array([ 0,  1,  2,  3, -5])\n\n    \"\"\"\n    try:\n        put = a.put\n    except AttributeError as e:\n        raise TypeError(\"argument 1 must be numpy.ndarray, \"\n                        \"not {name}\".format(name=type(a).__name__)) from e\n\n    return put(ind, v, mode=mode)\n\n\ndef _swapaxes_dispatcher(a, axis1, axis2):\n    return (a,)\n\n\n@array_function_dispatch(_swapaxes_dispatcher)\ndef swapaxes(a, axis1, axis2):\n    \"\"\"\n    Interchange two axes of an array.\n\n    Parameters\n    ----------\n    a : array_like\n        Input array.\n    axis1 : int\n        First axis.\n    axis2 : int\n        Second axis.\n\n    Returns\n    -------\n    a_swapped : ndarray\n        For NumPy >= 1.10.0, if `a` is an ndarray, then a view of `a` is\n        returned; otherwise a new array is created. For earlier NumPy\n        versions a view of `a` is returned only if the order of the\n        axes is changed, otherwise the input array is returned.\n\n    Examples\n    --------\n    >>> x = np.array([[1,2,3]])\n    >>> np.swapaxes(x,0,1)\n    array([[1],\n           [2],\n           [3]])\n\n    >>> x = np.array([[[0,1],[2,3]],[[4,5],[6,7]]])\n    >>> x\n    array([[[0, 1],\n            [2, 3]],\n           [[4, 5],\n            [6, 7]]])\n\n    >>> np.swapaxes(x,0,2)\n    array([[[0, 4],\n            [2, 6]],\n           [[1, 5],\n            [3, 7]]])\n\n    \"\"\"\n    return _wrapfunc(a, 'swapaxes', axis1, axis2)\n\n\ndef _transpose_dispatcher(a, axes=None):\n    return (a,)\n\n\n@array_function_dispatch(_transpose_dispatcher)\ndef transpose(a, axes=None):\n    \"\"\"\n    Reverse or permute the axes of an array; returns the modified array.\n\n    For an array a with two axes, transpose(a) gives the matrix transpose.\n\n    Refer to `numpy.ndarray.transpose` for full documentation.\n\n    Parameters\n    ----------\n    a : array_like\n        Input array.\n    axes : tuple or list of ints, optional\n        If specified, it must be a tuple or list which contains a permutation of\n        [0,1,..,N-1] where N is the number of axes of a.  The i'th axis of the\n        returned array will correspond to the axis numbered ``axes[i]`` of the\n        input.  If not specified, defaults to ``range(a.ndim)[::-1]``, which\n        reverses the order of the axes.\n\n    Returns\n    -------\n    p : ndarray\n        `a` with its axes permuted.  A view is returned whenever\n        possible.\n\n    See Also\n    --------\n    ndarray.transpose : Equivalent method\n    moveaxis\n    argsort\n\n    Notes\n    -----\n    Use `transpose(a, argsort(axes))` to invert the transposition of tensors\n    when using the `axes` keyword argument.\n\n    Transposing a 1-D array returns an unchanged view of the original array.\n\n    Examples\n    --------\n    >>> x = np.arange(4).reshape((2,2))\n    >>> x\n    array([[0, 1],\n           [2, 3]])\n\n    >>> np.transpose(x)\n    array([[0, 2],\n           [1, 3]])\n\n    >>> x = np.ones((1, 2, 3))\n    >>> np.transpose(x, (1, 0, 2)).shape\n    (2, 1, 3)\n\n    >>> x = np.ones((2, 3, 4, 5))\n    >>> np.transpose(x).shape\n    (5, 4, 3, 2)\n\n    \"\"\"\n    return _wrapfunc(a, 'transpose', axes)\n\n\ndef _partition_dispatcher(a, kth, axis=None, kind=None, order=None):\n    return (a,)\n\n\n@array_function_dispatch(_partition_dispatcher)\ndef partition(a, kth, axis=-1, kind='introselect', order=None):\n    \"\"\"\n    Return a partitioned copy of an array.\n\n    Creates a copy of the array with its elements rearranged in such a\n    way that the value of the element in k-th position is in the\n    position it would be in a sorted array. All elements smaller than\n    the k-th element are moved before this element and all equal or\n    greater are moved behind it. The ordering of the elements in the two\n    partitions is undefined.\n\n    .. versionadded:: 1.8.0\n\n    Parameters\n    ----------\n    a : array_like\n        Array to be sorted.\n    kth : int or sequence of ints\n        Element index to partition by. The k-th value of the element\n        will be in its final sorted position and all smaller elements\n        will be moved before it and all equal or greater elements behind\n        it. The order of all elements in the partitions is undefined. If\n        provided with a sequence of k-th it will partition all elements\n        indexed by k-th  of them into their sorted position at once.\n    axis : int or None, optional\n        Axis along which to sort. If None, the array is flattened before\n        sorting. The default is -1, which sorts along the last axis.\n    kind : {'introselect'}, optional\n        Selection algorithm. Default is 'introselect'.\n    order : str or list of str, optional\n        When `a` is an array with fields defined, this argument\n        specifies which fields to compare first, second, etc.  A single\n        field can be specified as a string.  Not all fields need be\n        specified, but unspecified fields will still be used, in the\n        order in which they come up in the dtype, to break ties.\n\n    Returns\n    -------\n    partitioned_array : ndarray\n        Array of the same type and shape as `a`.\n\n    See Also\n    --------\n    ndarray.partition : Method to sort an array in-place.\n    argpartition : Indirect partition.\n    sort : Full sorting\n\n    Notes\n    -----\n    The various selection algorithms are characterized by their average\n    speed, worst case performance, work space size, and whether they are\n    stable. A stable sort keeps items with the same key in the same\n    relative order. The available algorithms have the following\n    properties:\n\n    ================= ======= ============= ============ =======\n       kind            speed   worst case    work space  stable\n    ================= ======= ============= ============ =======\n    'introselect'        1        O(n)           0         no\n    ================= ======= ============= ============ =======\n\n    All the partition algorithms make temporary copies of the data when\n    partitioning along any but the last axis.  Consequently,\n    partitioning along the last axis is faster and uses less space than\n    partitioning along any other axis.\n\n    The sort order for complex numbers is lexicographic. If both the\n    real and imaginary parts are non-nan then the order is determined by\n    the real parts except when they are equal, in which case the order\n    is determined by the imaginary parts.\n\n    Examples\n    --------\n    >>> a = np.array([3, 4, 2, 1])\n    >>> np.partition(a, 3)\n    array([2, 1, 3, 4])\n\n    >>> np.partition(a, (1, 3))\n    array([1, 2, 3, 4])\n\n    \"\"\"\n    if axis is None:\n        # flatten returns (1, N) for np.matrix, so always use the last axis\n        a = asanyarray(a).flatten()\n        axis = -1\n    else:\n        a = asanyarray(a).copy(order=\"K\")\n    a.partition(kth, axis=axis, kind=kind, order=order)\n    return a\n\n\ndef _argpartition_dispatcher(a, kth, axis=None, kind=None, order=None):\n    return (a,)\n\n\n@array_function_dispatch(_argpartition_dispatcher)\ndef argpartition(a, kth, axis=-1, kind='introselect', order=None):\n    \"\"\"\n    Perform an indirect partition along the given axis using the\n    algorithm specified by the `kind` keyword. It returns an array of\n    indices of the same shape as `a` that index data along the given\n    axis in partitioned order.\n\n    .. versionadded:: 1.8.0\n\n    Parameters\n    ----------\n    a : array_like\n        Array to sort.\n    kth : int or sequence of ints\n        Element index to partition by. The k-th element will be in its\n        final sorted position and all smaller elements will be moved\n        before it and all larger elements behind it. The order all\n        elements in the partitions is undefined. If provided with a\n        sequence of k-th it will partition all of them into their sorted\n        position at once.\n    axis : int or None, optional\n        Axis along which to sort. The default is -1 (the last axis). If\n        None, the flattened array is used.\n    kind : {'introselect'}, optional\n        Selection algorithm. Default is 'introselect'\n    order : str or list of str, optional\n        When `a` is an array with fields defined, this argument\n        specifies which fields to compare first, second, etc. A single\n        field can be specified as a string, and not all fields need be\n        specified, but unspecified fields will still be used, in the\n        order in which they come up in the dtype, to break ties.\n\n    Returns\n    -------\n    index_array : ndarray, int\n        Array of indices that partition `a` along the specified axis.\n        If `a` is one-dimensional, ``a[index_array]`` yields a partitioned `a`.\n        More generally, ``np.take_along_axis(a, index_array, axis=a)`` always\n        yields the partitioned `a`, irrespective of dimensionality.\n\n    See Also\n    --------\n    partition : Describes partition algorithms used.\n    ndarray.partition : Inplace partition.\n    argsort : Full indirect sort.\n    take_along_axis : Apply ``index_array`` from argpartition\n                      to an array as if by calling partition.\n\n    Notes\n    -----\n    See `partition` for notes on the different selection algorithms.\n\n    Examples\n    --------\n    One dimensional array:\n\n    >>> x = np.array([3, 4, 2, 1])\n    >>> x[np.argpartition(x, 3)]\n    array([2, 1, 3, 4])\n    >>> x[np.argpartition(x, (1, 3))]\n    array([1, 2, 3, 4])\n\n    >>> x = [3, 4, 2, 1]\n    >>> np.array(x)[np.argpartition(x, 3)]\n    array([2, 1, 3, 4])\n\n    Multi-dimensional array:\n\n    >>> x = np.array([[3, 4, 2], [1, 3, 1]])\n    >>> index_array = np.argpartition(x, kth=1, axis=-1)\n    >>> np.take_along_axis(x, index_array, axis=-1)  # same as np.partition(x, kth=1)\n    array([[2, 3, 4],\n           [1, 1, 3]])\n\n    \"\"\"\n    return _wrapfunc(a, 'argpartition', kth, axis=axis, kind=kind, order=order)\n\n\ndef _sort_dispatcher(a, axis=None, kind=None, order=None):\n    return (a,)\n\n\n@array_function_dispatch(_sort_dispatcher)\ndef sort(a, axis=-1, kind=None, order=None):\n    \"\"\"\n    Return a sorted copy of an array.\n\n    Parameters\n    ----------\n    a : array_like\n        Array to be sorted.\n    axis : int or None, optional\n        Axis along which to sort. If None, the array is flattened before\n        sorting. The default is -1, which sorts along the last axis.\n    kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, optional\n        Sorting algorithm. The default is 'quicksort'. Note that both 'stable'\n        and 'mergesort' use timsort or radix sort under the covers and, in general,\n        the actual implementation will vary with data type. The 'mergesort' option\n        is retained for backwards compatibility.\n\n        .. versionchanged:: 1.15.0.\n           The 'stable' option was added.\n\n    order : str or list of str, optional\n        When `a` is an array with fields defined, this argument specifies\n        which fields to compare first, second, etc.  A single field can\n        be specified as a string, and not all fields need be specified,\n        but unspecified fields will still be used, in the order in which\n        they come up in the dtype, to break ties.\n\n    Returns\n    -------\n    sorted_array : ndarray\n        Array of the same type and shape as `a`.\n\n    See Also\n    --------\n    ndarray.sort : Method to sort an array in-place.\n    argsort : Indirect sort.\n    lexsort : Indirect stable sort on multiple keys.\n    searchsorted : Find elements in a sorted array.\n    partition : Partial sort.\n\n    Notes\n    -----\n    The various sorting algorithms are characterized by their average speed,\n    worst case performance, work space size, and whether they are stable. A\n    stable sort keeps items with the same key in the same relative\n    order. The four algorithms implemented in NumPy have the following\n    properties:\n\n    =========== ======= ============= ============ ========\n       kind      speed   worst case    work space   stable\n    =========== ======= ============= ============ ========\n    'quicksort'    1     O(n^2)            0          no\n    'heapsort'     3     O(n*log(n))       0          no\n    'mergesort'    2     O(n*log(n))      ~n/2        yes\n    'timsort'      2     O(n*log(n))      ~n/2        yes\n    =========== ======= ============= ============ ========\n\n    .. note:: The datatype determines which of 'mergesort' or 'timsort'\n       is actually used, even if 'mergesort' is specified. User selection\n       at a finer scale is not currently available.\n\n    All the sort algorithms make temporary copies of the data when\n    sorting along any but the last axis.  Consequently, sorting along\n    the last axis is faster and uses less space than sorting along\n    any other axis.\n\n    The sort order for complex numbers is lexicographic. If both the real\n    and imaginary parts are non-nan then the order is determined by the\n    real parts except when they are equal, in which case the order is\n    determined by the imaginary parts.\n\n    Previous to numpy 1.4.0 sorting real and complex arrays containing nan\n    values led to undefined behaviour. In numpy versions >= 1.4.0 nan\n    values are sorted to the end. The extended sort order is:\n\n      * Real: [R, nan]\n      * Complex: [R + Rj, R + nanj, nan + Rj, nan + nanj]\n\n    where R is a non-nan real value. Complex values with the same nan\n    placements are sorted according to the non-nan part if it exists.\n    Non-nan values are sorted as before.\n\n    .. versionadded:: 1.12.0\n\n    quicksort has been changed to `introsort <https://en.wikipedia.org/wiki/Introsort>`_.\n    When sorting does not make enough progress it switches to\n    `heapsort <https://en.wikipedia.org/wiki/Heapsort>`_.\n    This implementation makes quicksort O(n*log(n)) in the worst case.\n\n    'stable' automatically chooses the best stable sorting algorithm\n    for the data type being sorted.\n    It, along with 'mergesort' is currently mapped to\n    `timsort <https://en.wikipedia.org/wiki/Timsort>`_\n    or `radix sort <https://en.wikipedia.org/wiki/Radix_sort>`_\n    depending on the data type.\n    API forward compatibility currently limits the\n    ability to select the implementation and it is hardwired for the different\n    data types.\n\n    .. versionadded:: 1.17.0\n\n    Timsort is added for better performance on already or nearly\n    sorted data. On random data timsort is almost identical to\n    mergesort. It is now used for stable sort while quicksort is still the\n    default sort if none is chosen. For timsort details, refer to\n    `CPython listsort.txt <https://github.com/python/cpython/blob/3.7/Objects/listsort.txt>`_.\n    'mergesort' and 'stable' are mapped to radix sort for integer data types. Radix sort is an\n    O(n) sort instead of O(n log n).\n\n    .. versionchanged:: 1.18.0\n\n    NaT now sorts to the end of arrays for consistency with NaN.\n\n    Examples\n    --------\n    >>> a = np.array([[1,4],[3,1]])\n    >>> np.sort(a)                # sort along the last axis\n    array([[1, 4],\n           [1, 3]])\n    >>> np.sort(a, axis=None)     # sort the flattened array\n    array([1, 1, 3, 4])\n    >>> np.sort(a, axis=0)        # sort along the first axis\n    array([[1, 1],\n           [3, 4]])\n\n    Use the `order` keyword to specify a field to use when sorting a\n    structured array:\n\n    >>> dtype = [('name', 'S10'), ('height', float), ('age', int)]\n    >>> values = [('Arthur', 1.8, 41), ('Lancelot', 1.9, 38),\n    ...           ('Galahad', 1.7, 38)]\n    >>> a = np.array(values, dtype=dtype)       # create a structured array\n    >>> np.sort(a, order='height')                        # doctest: +SKIP\n    array([('Galahad', 1.7, 38), ('Arthur', 1.8, 41),\n           ('Lancelot', 1.8999999999999999, 38)],\n          dtype=[('name', '|S10'), ('height', '<f8'), ('age', '<i4')])\n\n    Sort by age, then height if ages are equal:\n\n    >>> np.sort(a, order=['age', 'height'])               # doctest: +SKIP\n    array([('Galahad', 1.7, 38), ('Lancelot', 1.8999999999999999, 38),\n           ('Arthur', 1.8, 41)],\n          dtype=[('name', '|S10'), ('height', '<f8'), ('age', '<i4')])\n\n    \"\"\"\n    if axis is None:\n        # flatten returns (1, N) for np.matrix, so always use the last axis\n        a = asanyarray(a).flatten()\n        axis = -1\n    else:\n        a = asanyarray(a).copy(order=\"K\")\n    a.sort(axis=axis, kind=kind, order=order)\n    return a\n\n\ndef _argsort_dispatcher(a, axis=None, kind=None, order=None):\n    return (a,)\n\n\n@array_function_dispatch(_argsort_dispatcher)\ndef argsort(a, axis=-1, kind=None, order=None):\n    \"\"\"\n    Returns the indices that would sort an array.\n\n    Perform an indirect sort along the given axis using the algorithm specified\n    by the `kind` keyword. It returns an array of indices of the same shape as\n    `a` that index data along the given axis in sorted order.\n\n    Parameters\n    ----------\n    a : array_like\n        Array to sort.\n    axis : int or None, optional\n        Axis along which to sort.  The default is -1 (the last axis). If None,\n        the flattened array is used.\n    kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, optional\n        Sorting algorithm. The default is 'quicksort'. Note that both 'stable'\n        and 'mergesort' use timsort under the covers and, in general, the\n        actual implementation will vary with data type. The 'mergesort' option\n        is retained for backwards compatibility.\n\n        .. versionchanged:: 1.15.0.\n           The 'stable' option was added.\n    order : str or list of str, optional\n        When `a` is an array with fields defined, this argument specifies\n        which fields to compare first, second, etc.  A single field can\n        be specified as a string, and not all fields need be specified,\n        but unspecified fields will still be used, in the order in which\n        they come up in the dtype, to break ties.\n\n    Returns\n    -------\n    index_array : ndarray, int\n        Array of indices that sort `a` along the specified `axis`.\n        If `a` is one-dimensional, ``a[index_array]`` yields a sorted `a`.\n        More generally, ``np.take_along_axis(a, index_array, axis=axis)``\n        always yields the sorted `a`, irrespective of dimensionality.\n\n    See Also\n    --------\n    sort : Describes sorting algorithms used.\n    lexsort : Indirect stable sort with multiple keys.\n    ndarray.sort : Inplace sort.\n    argpartition : Indirect partial sort.\n    take_along_axis : Apply ``index_array`` from argsort\n                      to an array as if by calling sort.\n\n    Notes\n    -----\n    See `sort` for notes on the different sorting algorithms.\n\n    As of NumPy 1.4.0 `argsort` works with real/complex arrays containing\n    nan values. The enhanced sort order is documented in `sort`.\n\n    Examples\n    --------\n    One dimensional array:\n\n    >>> x = np.array([3, 1, 2])\n    >>> np.argsort(x)\n    array([1, 2, 0])\n\n    Two-dimensional array:\n\n    >>> x = np.array([[0, 3], [2, 2]])\n    >>> x\n    array([[0, 3],\n           [2, 2]])\n\n    >>> ind = np.argsort(x, axis=0)  # sorts along first axis (down)\n    >>> ind\n    array([[0, 1],\n           [1, 0]])\n    >>> np.take_along_axis(x, ind, axis=0)  # same as np.sort(x, axis=0)\n    array([[0, 2],\n           [2, 3]])\n\n    >>> ind = np.argsort(x, axis=1)  # sorts along last axis (across)\n    >>> ind\n    array([[0, 1],\n           [0, 1]])\n    >>> np.take_along_axis(x, ind, axis=1)  # same as np.sort(x, axis=1)\n    array([[0, 3],\n           [2, 2]])\n\n    Indices of the sorted elements of a N-dimensional array:\n\n    >>> ind = np.unravel_index(np.argsort(x, axis=None), x.shape)\n    >>> ind\n    (array([0, 1, 1, 0]), array([0, 0, 1, 1]))\n    >>> x[ind]  # same as np.sort(x, axis=None)\n    array([0, 2, 2, 3])\n\n    Sorting with keys:\n\n    >>> x = np.array([(1, 0), (0, 1)], dtype=[('x', '<i4'), ('y', '<i4')])\n    >>> x\n    array([(1, 0), (0, 1)],\n          dtype=[('x', '<i4'), ('y', '<i4')])\n\n    >>> np.argsort(x, order=('x','y'))\n    array([1, 0])\n\n    >>> np.argsort(x, order=('y','x'))\n    array([0, 1])\n\n    \"\"\"\n    return _wrapfunc(a, 'argsort', axis=axis, kind=kind, order=order)\n\n\ndef _argmax_dispatcher(a, axis=None, out=None):\n    return (a, out)\n\n\n@array_function_dispatch(_argmax_dispatcher)\ndef argmax(a, axis=None, out=None):\n    \"\"\"\n    Returns the indices of the maximum values along an axis.\n\n    Parameters\n    ----------\n    a : array_like\n        Input array.\n    axis : int, optional\n        By default, the index is into the flattened array, otherwise\n        along the specified axis.\n    out : array, optional\n        If provided, the result will be inserted into this array. It should\n        be of the appropriate shape and dtype.\n\n    Returns\n    -------\n    index_array : ndarray of ints\n        Array of indices into the array. It has the same shape as `a.shape`\n        with the dimension along `axis` removed.\n\n    See Also\n    --------\n    ndarray.argmax, argmin\n    amax : The maximum value along a given axis.\n    unravel_index : Convert a flat index into an index tuple.\n    take_along_axis : Apply ``np.expand_dims(index_array, axis)``\n                      from argmax to an array as if by calling max.\n\n    Notes\n    -----\n    In case of multiple occurrences of the maximum values, the indices\n    corresponding to the first occurrence are returned.\n\n    Examples\n    --------\n    >>> a = np.arange(6).reshape(2,3) + 10\n    >>> a\n    array([[10, 11, 12],\n           [13, 14, 15]])\n    >>> np.argmax(a)\n    5\n    >>> np.argmax(a, axis=0)\n    array([1, 1, 1])\n    >>> np.argmax(a, axis=1)\n    array([2, 2])\n\n    Indexes of the maximal elements of a N-dimensional array:\n\n    >>> ind = np.unravel_index(np.argmax(a, axis=None), a.shape)\n    >>> ind\n    (1, 2)\n    >>> a[ind]\n    15\n\n    >>> b = np.arange(6)\n    >>> b[1] = 5\n    >>> b\n    array([0, 5, 2, 3, 4, 5])\n    >>> np.argmax(b)  # Only the first occurrence is returned.\n    1\n\n    >>> x = np.array([[4,2,3], [1,0,3]])\n    >>> index_array = np.argmax(x, axis=-1)\n    >>> # Same as np.max(x, axis=-1, keepdims=True)\n    >>> np.take_along_axis(x, np.expand_dims(index_array, axis=-1), axis=-1)\n    array([[4],\n           [3]])\n    >>> # Same as np.max(x, axis=-1)\n    >>> np.take_along_axis(x, np.expand_dims(index_array, axis=-1), axis=-1).squeeze(axis=-1)\n    array([4, 3])\n\n    \"\"\"\n    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n\n\ndef _argmin_dispatcher(a, axis=None, out=None):\n    return (a, out)\n\n\n@array_function_dispatch(_argmin_dispatcher)\ndef argmin(a, axis=None, out=None):\n    \"\"\"\n    Returns the indices of the minimum values along an axis.\n\n    Parameters\n    ----------\n    a : array_like\n        Input array.\n    axis : int, optional\n        By default, the index is into the flattened array, otherwise\n        along the specified axis.\n    out : array, optional\n        If provided, the result will be inserted into this array. It should\n        be of the appropriate shape and dtype.\n\n    Returns\n    -------\n    index_array : ndarray of ints\n        Array of indices into the array. It has the same shape as `a.shape`\n        with the dimension along `axis` removed.\n\n    See Also\n    --------\n    ndarray.argmin, argmax\n    amin : The minimum value along a given axis.\n    unravel_index : Convert a flat index into an index tuple.\n    take_along_axis : Apply ``np.expand_dims(index_array, axis)``\n                      from argmin to an array as if by calling min.\n\n    Notes\n    -----\n    In case of multiple occurrences of the minimum values, the indices\n    corresponding to the first occurrence are returned.\n\n    Examples\n    --------\n    >>> a = np.arange(6).reshape(2,3) + 10\n    >>> a\n    array([[10, 11, 12],\n           [13, 14, 15]])\n    >>> np.argmin(a)\n    0\n    >>> np.argmin(a, axis=0)\n    array([0, 0, 0])\n    >>> np.argmin(a, axis=1)\n    array([0, 0])\n\n    Indices of the minimum elements of a N-dimensional array:\n\n    >>> ind = np.unravel_index(np.argmin(a, axis=None), a.shape)\n    >>> ind\n    (0, 0)\n    >>> a[ind]\n    10\n\n    >>> b = np.arange(6) + 10\n    >>> b[4] = 10\n    >>> b\n    array([10, 11, 12, 13, 10, 15])\n    >>> np.argmin(b)  # Only the first occurrence is returned.\n    0\n\n    >>> x = np.array([[4,2,3], [1,0,3]])\n    >>> index_array = np.argmin(x, axis=-1)\n    >>> # Same as np.min(x, axis=-1, keepdims=True)\n    >>> np.take_along_axis(x, np.expand_dims(index_array, axis=-1), axis=-1)\n    array([[2],\n           [0]])\n    >>> # Same as np.max(x, axis=-1)\n    >>> np.take_along_axis(x, np.expand_dims(index_array, axis=-1), axis=-1).squeeze(axis=-1)\n    array([2, 0])\n\n    \"\"\"\n    return _wrapfunc(a, 'argmin', axis=axis, out=out)\n\n\ndef _searchsorted_dispatcher(a, v, side=None, sorter=None):\n    return (a, v, sorter)\n\n\n@array_function_dispatch(_searchsorted_dispatcher)\ndef searchsorted(a, v, side='left', sorter=None):\n    \"\"\"\n    Find indices where elements should be inserted to maintain order.\n\n    Find the indices into a sorted array `a` such that, if the\n    corresponding elements in `v` were inserted before the indices, the\n    order of `a` would be preserved.\n\n    Assuming that `a` is sorted:\n\n    ======  ============================\n    `side`  returned index `i` satisfies\n    ======  ============================\n    left    ``a[i-1] < v <= a[i]``\n    right   ``a[i-1] <= v < a[i]``\n    ======  ============================\n\n    Parameters\n    ----------\n    a : 1-D array_like\n        Input array. If `sorter` is None, then it must be sorted in\n        ascending order, otherwise `sorter` must be an array of indices\n        that sort it.\n    v : array_like\n        Values to insert into `a`.\n    side : {'left', 'right'}, optional\n        If 'left', the index of the first suitable location found is given.\n        If 'right', return the last such index.  If there is no suitable\n        index, return either 0 or N (where N is the length of `a`).\n    sorter : 1-D array_like, optional\n        Optional array of integer indices that sort array a into ascending\n        order. They are typically the result of argsort.\n\n        .. versionadded:: 1.7.0\n\n    Returns\n    -------\n    indices : array of ints\n        Array of insertion points with the same shape as `v`.\n\n    See Also\n    --------\n    sort : Return a sorted copy of an array.\n    histogram : Produce histogram from 1-D data.\n\n    Notes\n    -----\n    Binary search is used to find the required insertion points.\n\n    As of NumPy 1.4.0 `searchsorted` works with real/complex arrays containing\n    `nan` values. The enhanced sort order is documented in `sort`.\n\n    This function uses the same algorithm as the builtin python `bisect.bisect_left`\n    (``side='left'``) and `bisect.bisect_right` (``side='right'``) functions,\n    which is also vectorized in the `v` argument.\n\n    Examples\n    --------\n    >>> np.searchsorted([1,2,3,4,5], 3)\n    2\n    >>> np.searchsorted([1,2,3,4,5], 3, side='right')\n    3\n    >>> np.searchsorted([1,2,3,4,5], [-10, 10, 2, 3])\n    array([0, 5, 1, 2])\n\n    \"\"\"\n    return _wrapfunc(a, 'searchsorted', v, side=side, sorter=sorter)\n\n\ndef _resize_dispatcher(a, new_shape):\n    return (a,)\n\n\n@array_function_dispatch(_resize_dispatcher)\ndef resize(a, new_shape):\n    \"\"\"\n    Return a new array with the specified shape.\n\n    If the new array is larger than the original array, then the new\n    array is filled with repeated copies of `a`.  Note that this behavior\n    is different from a.resize(new_shape) which fills with zeros instead\n    of repeated copies of `a`.\n\n    Parameters\n    ----------\n    a : array_like\n        Array to be resized.\n\n    new_shape : int or tuple of int\n        Shape of resized array.\n\n    Returns\n    -------\n    reshaped_array : ndarray\n        The new array is formed from the data in the old array, repeated\n        if necessary to fill out the required number of elements.  The\n        data are repeated iterating over the array in C-order.\n\n    See Also\n    --------\n    np.reshape : Reshape an array without changing the total size.\n    np.pad : Enlarge and pad an array.\n    np.repeat : Repeat elements of an array.\n    ndarray.resize : resize an array in-place.\n\n    Notes\n    -----\n    When the total size of the array does not change `~numpy.reshape` should\n    be used.  In most other cases either indexing (to reduce the size)\n    or padding (to increase the size) may be a more appropriate solution.\n\n    Warning: This functionality does **not** consider axes separately,\n    i.e. it does not apply interpolation/extrapolation.\n    It fills the return array with the required number of elements, iterating\n    over `a` in C-order, disregarding axes (and cycling back from the start if\n    the new shape is larger).  This functionality is therefore not suitable to\n    resize images, or data where each axis represents a separate and distinct\n    entity.\n\n    Examples\n    --------\n    >>> a=np.array([[0,1],[2,3]])\n    >>> np.resize(a,(2,3))\n    array([[0, 1, 2],\n           [3, 0, 1]])\n    >>> np.resize(a,(1,4))\n    array([[0, 1, 2, 3]])\n    >>> np.resize(a,(2,4))\n    array([[0, 1, 2, 3],\n           [0, 1, 2, 3]])\n\n    \"\"\"\n    if isinstance(new_shape, (int, nt.integer)):\n        new_shape = (new_shape,)\n\n    a = ravel(a)\n\n    new_size = 1\n    for dim_length in new_shape:\n        new_size *= dim_length\n        if dim_length < 0:\n            raise ValueError('all elements of `new_shape` must be non-negative')\n\n    if a.size == 0 or new_size == 0:\n        # First case must zero fill. The second would have repeats == 0.\n        return np.zeros_like(a, shape=new_shape)\n\n    repeats = -(-new_size // a.size)  # ceil division\n    a = concatenate((a,) * repeats)[:new_size]\n\n    return reshape(a, new_shape)\n\n\ndef _squeeze_dispatcher(a, axis=None):\n    return (a,)\n\n\n@array_function_dispatch(_squeeze_dispatcher)\ndef squeeze(a, axis=None):\n    \"\"\"\n    Remove axes of length one from `a`.\n\n    Parameters\n    ----------\n    a : array_like\n        Input data.\n    axis : None or int or tuple of ints, optional\n        .. versionadded:: 1.7.0\n\n        Selects a subset of the entries of length one in the\n        shape. If an axis is selected with shape entry greater than\n        one, an error is raised.\n\n    Returns\n    -------\n    squeezed : ndarray\n        The input array, but with all or a subset of the\n        dimensions of length 1 removed. This is always `a` itself\n        or a view into `a`. Note that if all axes are squeezed,\n        the result is a 0d array and not a scalar.\n\n    Raises\n    ------\n    ValueError\n        If `axis` is not None, and an axis being squeezed is not of length 1\n\n    See Also\n    --------\n    expand_dims : The inverse operation, adding entries of length one\n    reshape : Insert, remove, and combine dimensions, and resize existing ones\n\n    Examples\n    --------\n    >>> x = np.array([[[0], [1], [2]]])\n    >>> x.shape\n    (1, 3, 1)\n    >>> np.squeeze(x).shape\n    (3,)\n    >>> np.squeeze(x, axis=0).shape\n    (3, 1)\n    >>> np.squeeze(x, axis=1).shape\n    Traceback (most recent call last):\n    ...\n    ValueError: cannot select an axis to squeeze out which has size not equal to one\n    >>> np.squeeze(x, axis=2).shape\n    (1, 3)\n    >>> x = np.array([[1234]])\n    >>> x.shape\n    (1, 1)\n    >>> np.squeeze(x)\n    array(1234)  # 0d array\n    >>> np.squeeze(x).shape\n    ()\n    >>> np.squeeze(x)[()]\n    1234\n\n    \"\"\"\n    try:\n        squeeze = a.squeeze\n    except AttributeError:\n        return _wrapit(a, 'squeeze', axis=axis)\n    if axis is None:\n        return squeeze()\n    else:\n        return squeeze(axis=axis)\n\n\ndef _diagonal_dispatcher(a, offset=None, axis1=None, axis2=None):\n    return (a,)\n\n\n@array_function_dispatch(_diagonal_dispatcher)\ndef diagonal(a, offset=0, axis1=0, axis2=1):\n    \"\"\"\n    Return specified diagonals.\n\n    If `a` is 2-D, returns the diagonal of `a` with the given offset,\n    i.e., the collection of elements of the form ``a[i, i+offset]``.  If\n    `a` has more than two dimensions, then the axes specified by `axis1`\n    and `axis2` are used to determine the 2-D sub-array whose diagonal is\n    returned.  The shape of the resulting array can be determined by\n    removing `axis1` and `axis2` and appending an index to the right equal\n    to the size of the resulting diagonals.\n\n    In versions of NumPy prior to 1.7, this function always returned a new,\n    independent array containing a copy of the values in the diagonal.\n\n    In NumPy 1.7 and 1.8, it continues to return a copy of the diagonal,\n    but depending on this fact is deprecated. Writing to the resulting\n    array continues to work as it used to, but a FutureWarning is issued.\n\n    Starting in NumPy 1.9 it returns a read-only view on the original array.\n    Attempting to write to the resulting array will produce an error.\n\n    In some future release, it will return a read/write view and writing to\n    the returned array will alter your original array.  The returned array\n    will have the same type as the input array.\n\n    If you don't write to the array returned by this function, then you can\n    just ignore all of the above.\n\n    If you depend on the current behavior, then we suggest copying the\n    returned array explicitly, i.e., use ``np.diagonal(a).copy()`` instead\n    of just ``np.diagonal(a)``. This will work with both past and future\n    versions of NumPy.\n\n    Parameters\n    ----------\n    a : array_like\n        Array from which the diagonals are taken.\n    offset : int, optional\n        Offset of the diagonal from the main diagonal.  Can be positive or\n        negative.  Defaults to main diagonal (0).\n    axis1 : int, optional\n        Axis to be used as the first axis of the 2-D sub-arrays from which\n        the diagonals should be taken.  Defaults to first axis (0).\n    axis2 : int, optional\n        Axis to be used as the second axis of the 2-D sub-arrays from\n        which the diagonals should be taken. Defaults to second axis (1).\n\n    Returns\n    -------\n    array_of_diagonals : ndarray\n        If `a` is 2-D, then a 1-D array containing the diagonal and of the\n        same type as `a` is returned unless `a` is a `matrix`, in which case\n        a 1-D array rather than a (2-D) `matrix` is returned in order to\n        maintain backward compatibility.\n\n        If ``a.ndim > 2``, then the dimensions specified by `axis1` and `axis2`\n        are removed, and a new axis inserted at the end corresponding to the\n        diagonal.\n\n    Raises\n    ------\n    ValueError\n        If the dimension of `a` is less than 2.\n\n    See Also\n    --------\n    diag : MATLAB work-a-like for 1-D and 2-D arrays.\n    diagflat : Create diagonal arrays.\n    trace : Sum along diagonals.\n\n    Examples\n    --------\n    >>> a = np.arange(4).reshape(2,2)\n    >>> a\n    array([[0, 1],\n           [2, 3]])\n    >>> a.diagonal()\n    array([0, 3])\n    >>> a.diagonal(1)\n    array([1])\n\n    A 3-D example:\n\n    >>> a = np.arange(8).reshape(2,2,2); a\n    array([[[0, 1],\n            [2, 3]],\n           [[4, 5],\n            [6, 7]]])\n    >>> a.diagonal(0,  # Main diagonals of two arrays created by skipping\n    ...            0,  # across the outer(left)-most axis last and\n    ...            1)  # the \"middle\" (row) axis first.\n    array([[0, 6],\n           [1, 7]])\n\n    The sub-arrays whose main diagonals we just obtained; note that each\n    corresponds to fixing the right-most (column) axis, and that the\n    diagonals are \"packed\" in rows.\n\n    >>> a[:,:,0]  # main diagonal is [0 6]\n    array([[0, 2],\n           [4, 6]])\n    >>> a[:,:,1]  # main diagonal is [1 7]\n    array([[1, 3],\n           [5, 7]])\n\n    The anti-diagonal can be obtained by reversing the order of elements\n    using either `numpy.flipud` or `numpy.fliplr`.\n\n    >>> a = np.arange(9).reshape(3, 3)\n    >>> a\n    array([[0, 1, 2],\n           [3, 4, 5],\n           [6, 7, 8]])\n    >>> np.fliplr(a).diagonal()  # Horizontal flip\n    array([2, 4, 6])\n    >>> np.flipud(a).diagonal()  # Vertical flip\n    array([6, 4, 2])\n\n    Note that the order in which the diagonal is retrieved varies depending\n    on the flip function.\n    \"\"\"\n    if isinstance(a, np.matrix):\n        # Make diagonal of matrix 1-D to preserve backward compatibility.\n        return asarray(a).diagonal(offset=offset, axis1=axis1, axis2=axis2)\n    else:\n        return asanyarray(a).diagonal(offset=offset, axis1=axis1, axis2=axis2)\n\n\ndef _trace_dispatcher(\n        a, offset=None, axis1=None, axis2=None, dtype=None, out=None):\n    return (a, out)\n\n\n@array_function_dispatch(_trace_dispatcher)\ndef trace(a, offset=0, axis1=0, axis2=1, dtype=None, out=None):\n    \"\"\"\n    Return the sum along diagonals of the array.\n\n    If `a` is 2-D, the sum along its diagonal with the given offset\n    is returned, i.e., the sum of elements ``a[i,i+offset]`` for all i.\n\n    If `a` has more than two dimensions, then the axes specified by axis1 and\n    axis2 are used to determine the 2-D sub-arrays whose traces are returned.\n    The shape of the resulting array is the same as that of `a` with `axis1`\n    and `axis2` removed.\n\n    Parameters\n    ----------\n    a : array_like\n        Input array, from which the diagonals are taken.\n    offset : int, optional\n        Offset of the diagonal from the main diagonal. Can be both positive\n        and negative. Defaults to 0.\n    axis1, axis2 : int, optional\n        Axes to be used as the first and second axis of the 2-D sub-arrays\n        from which the diagonals should be taken. Defaults are the first two\n        axes of `a`.\n    dtype : dtype, optional\n        Determines the data-type of the returned array and of the accumulator\n        where the elements are summed. If dtype has the value None and `a` is\n        of integer type of precision less than the default integer\n        precision, then the default integer precision is used. Otherwise,\n        the precision is the same as that of `a`.\n    out : ndarray, optional\n        Array into which the output is placed. Its type is preserved and\n        it must be of the right shape to hold the output.\n\n    Returns\n    -------\n    sum_along_diagonals : ndarray\n        If `a` is 2-D, the sum along the diagonal is returned.  If `a` has\n        larger dimensions, then an array of sums along diagonals is returned.\n\n    See Also\n    --------\n    diag, diagonal, diagflat\n\n    Examples\n    --------\n    >>> np.trace(np.eye(3))\n    3.0\n    >>> a = np.arange(8).reshape((2,2,2))\n    >>> np.trace(a)\n    array([6, 8])\n\n    >>> a = np.arange(24).reshape((2,2,2,3))\n    >>> np.trace(a).shape\n    (2, 3)\n\n    \"\"\"\n    if isinstance(a, np.matrix):\n        # Get trace of matrix via an array to preserve backward compatibility.\n        return asarray(a).trace(offset=offset, axis1=axis1, axis2=axis2, dtype=dtype, out=out)\n    else:\n        return asanyarray(a).trace(offset=offset, axis1=axis1, axis2=axis2, dtype=dtype, out=out)\n\n\ndef _ravel_dispatcher(a, order=None):\n    return (a,)\n\n\n@array_function_dispatch(_ravel_dispatcher)\ndef ravel(a, order='C'):\n    \"\"\"Return a contiguous flattened array.\n\n    A 1-D array, containing the elements of the input, is returned.  A copy is\n    made only if needed.\n\n    As of NumPy 1.10, the returned array will have the same type as the input\n    array. (for example, a masked array will be returned for a masked array\n    input)\n\n    Parameters\n    ----------\n    a : array_like\n        Input array.  The elements in `a` are read in the order specified by\n        `order`, and packed as a 1-D array.\n    order : {'C','F', 'A', 'K'}, optional\n\n        The elements of `a` are read using this index order. 'C' means\n        to index the elements in row-major, C-style order,\n        with the last axis index changing fastest, back to the first\n        axis index changing slowest.  'F' means to index the elements\n        in column-major, Fortran-style order, with the\n        first index changing fastest, and the last index changing\n        slowest. Note that the 'C' and 'F' options take no account of\n        the memory layout of the underlying array, and only refer to\n        the order of axis indexing.  'A' means to read the elements in\n        Fortran-like index order if `a` is Fortran *contiguous* in\n        memory, C-like order otherwise.  'K' means to read the\n        elements in the order they occur in memory, except for\n        reversing the data when strides are negative.  By default, 'C'\n        index order is used.\n\n    Returns\n    -------\n    y : array_like\n        y is an array of the same subtype as `a`, with shape ``(a.size,)``.\n        Note that matrices are special cased for backward compatibility, if `a`\n        is a matrix, then y is a 1-D ndarray.\n\n    See Also\n    --------\n    ndarray.flat : 1-D iterator over an array.\n    ndarray.flatten : 1-D array copy of the elements of an array\n                      in row-major order.\n    ndarray.reshape : Change the shape of an array without changing its data.\n\n    Notes\n    -----\n    In row-major, C-style order, in two dimensions, the row index\n    varies the slowest, and the column index the quickest.  This can\n    be generalized to multiple dimensions, where row-major order\n    implies that the index along the first axis varies slowest, and\n    the index along the last quickest.  The opposite holds for\n    column-major, Fortran-style index ordering.\n\n    When a view is desired in as many cases as possible, ``arr.reshape(-1)``\n    may be preferable.\n\n    Examples\n    --------\n    It is equivalent to ``reshape(-1, order=order)``.\n\n    >>> x = np.array([[1, 2, 3], [4, 5, 6]])\n    >>> np.ravel(x)\n    array([1, 2, 3, 4, 5, 6])\n\n    >>> x.reshape(-1)\n    array([1, 2, 3, 4, 5, 6])\n\n    >>> np.ravel(x, order='F')\n    array([1, 4, 2, 5, 3, 6])\n\n    When ``order`` is 'A', it will preserve the array's 'C' or 'F' ordering:\n\n    >>> np.ravel(x.T)\n    array([1, 4, 2, 5, 3, 6])\n    >>> np.ravel(x.T, order='A')\n    array([1, 2, 3, 4, 5, 6])\n\n    When ``order`` is 'K', it will preserve orderings that are neither 'C'\n    nor 'F', but won't reverse axes:\n\n    >>> a = np.arange(3)[::-1]; a\n    array([2, 1, 0])\n    >>> a.ravel(order='C')\n    array([2, 1, 0])\n    >>> a.ravel(order='K')\n    array([2, 1, 0])\n\n    >>> a = np.arange(12).reshape(2,3,2).swapaxes(1,2); a\n    array([[[ 0,  2,  4],\n            [ 1,  3,  5]],\n           [[ 6,  8, 10],\n            [ 7,  9, 11]]])\n    >>> a.ravel(order='C')\n    array([ 0,  2,  4,  1,  3,  5,  6,  8, 10,  7,  9, 11])\n    >>> a.ravel(order='K')\n    array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n\n    \"\"\"\n    if isinstance(a, np.matrix):\n        return asarray(a).ravel(order=order)\n    else:\n        return asanyarray(a).ravel(order=order)\n\n\ndef _nonzero_dispatcher(a):\n    return (a,)\n\n\n@array_function_dispatch(_nonzero_dispatcher)\ndef nonzero(a):\n    \"\"\"\n    Return the indices of the elements that are non-zero.\n\n    Returns a tuple of arrays, one for each dimension of `a`,\n    containing the indices of the non-zero elements in that\n    dimension. The values in `a` are always tested and returned in\n    row-major, C-style order.\n\n    To group the indices by element, rather than dimension, use `argwhere`,\n    which returns a row for each non-zero element.\n\n    .. note::\n\n       When called on a zero-d array or scalar, ``nonzero(a)`` is treated\n       as ``nonzero(atleast_1d(a))``.\n\n       .. deprecated:: 1.17.0\n\n          Use `atleast_1d` explicitly if this behavior is deliberate.\n\n    Parameters\n    ----------\n    a : array_like\n        Input array.\n\n    Returns\n    -------\n    tuple_of_arrays : tuple\n        Indices of elements that are non-zero.\n\n    See Also\n    --------\n    flatnonzero :\n        Return indices that are non-zero in the flattened version of the input\n        array.\n    ndarray.nonzero :\n        Equivalent ndarray method.\n    count_nonzero :\n        Counts the number of non-zero elements in the input array.\n\n    Notes\n    -----\n    While the nonzero values can be obtained with ``a[nonzero(a)]``, it is\n    recommended to use ``x[x.astype(bool)]`` or ``x[x != 0]`` instead, which\n    will correctly handle 0-d arrays.\n\n    Examples\n    --------\n    >>> x = np.array([[3, 0, 0], [0, 4, 0], [5, 6, 0]])\n    >>> x\n    array([[3, 0, 0],\n           [0, 4, 0],\n           [5, 6, 0]])\n    >>> np.nonzero(x)\n    (array([0, 1, 2, 2]), array([0, 1, 0, 1]))\n\n    >>> x[np.nonzero(x)]\n    array([3, 4, 5, 6])\n    >>> np.transpose(np.nonzero(x))\n    array([[0, 0],\n           [1, 1],\n           [2, 0],\n           [2, 1]])\n\n    A common use for ``nonzero`` is to find the indices of an array, where\n    a condition is True.  Given an array `a`, the condition `a` > 3 is a\n    boolean array and since False is interpreted as 0, np.nonzero(a > 3)\n    yields the indices of the `a` where the condition is true.\n\n    >>> a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n    >>> a > 3\n    array([[False, False, False],\n           [ True,  True,  True],\n           [ True,  True,  True]])\n    >>> np.nonzero(a > 3)\n    (array([1, 1, 1, 2, 2, 2]), array([0, 1, 2, 0, 1, 2]))\n\n    Using this result to index `a` is equivalent to using the mask directly:\n\n    >>> a[np.nonzero(a > 3)]\n    array([4, 5, 6, 7, 8, 9])\n    >>> a[a > 3]  # prefer this spelling\n    array([4, 5, 6, 7, 8, 9])\n\n    ``nonzero`` can also be called as a method of the array.\n\n    >>> (a > 3).nonzero()\n    (array([1, 1, 1, 2, 2, 2]), array([0, 1, 2, 0, 1, 2]))\n\n    \"\"\"\n    return _wrapfunc(a, 'nonzero')\n\n\ndef _shape_dispatcher(a):\n    return (a,)\n\n\n@array_function_dispatch(_shape_dispatcher)\ndef shape(a):\n    \"\"\"\n    Return the shape of an array.\n\n    Parameters\n    ----------\n    a : array_like\n        Input array.\n\n    Returns\n    -------\n    shape : tuple of ints\n        The elements of the shape tuple give the lengths of the\n        corresponding array dimensions.\n\n    See Also\n    --------\n    len\n    ndarray.shape : Equivalent array method.\n\n    Examples\n    --------\n    >>> np.shape(np.eye(3))\n    (3, 3)\n    >>> np.shape([[1, 2]])\n    (1, 2)\n    >>> np.shape([0])\n    (1,)\n    >>> np.shape(0)\n    ()\n\n    >>> a = np.array([(1, 2), (3, 4)], dtype=[('x', 'i4'), ('y', 'i4')])\n    >>> np.shape(a)\n    (2,)\n    >>> a.shape\n    (2,)\n\n    \"\"\"\n    try:\n        result = a.shape\n    except AttributeError:\n        result = asarray(a).shape\n    return result\n\n\ndef _compress_dispatcher(condition, a, axis=None, out=None):\n    return (condition, a, out)\n\n\n@array_function_dispatch(_compress_dispatcher)\ndef compress(condition, a, axis=None, out=None):\n    \"\"\"\n    Return selected slices of an array along given axis.\n\n    When working along a given axis, a slice along that axis is returned in\n    `output` for each index where `condition` evaluates to True. When\n    working on a 1-D array, `compress` is equivalent to `extract`.\n\n    Parameters\n    ----------\n    condition : 1-D array of bools\n        Array that selects which entries to return. If len(condition)\n        is less than the size of `a` along the given axis, then output is\n        truncated to the length of the condition array.\n    a : array_like\n        Array from which to extract a part.\n    axis : int, optional\n        Axis along which to take slices. If None (default), work on the\n        flattened array.\n    out : ndarray, optional\n        Output array.  Its type is preserved and it must be of the right\n        shape to hold the output.\n\n    Returns\n    -------\n    compressed_array : ndarray\n        A copy of `a` without the slices along axis for which `condition`\n        is false.\n\n    See Also\n    --------\n    take, choose, diag, diagonal, select\n    ndarray.compress : Equivalent method in ndarray\n    extract : Equivalent method when working on 1-D arrays\n    :ref:`ufuncs-output-type`\n\n    Examples\n    --------\n    >>> a = np.array([[1, 2], [3, 4], [5, 6]])\n    >>> a\n    array([[1, 2],\n           [3, 4],\n           [5, 6]])\n    >>> np.compress([0, 1], a, axis=0)\n    array([[3, 4]])\n    >>> np.compress([False, True, True], a, axis=0)\n    array([[3, 4],\n           [5, 6]])\n    >>> np.compress([False, True], a, axis=1)\n    array([[2],\n           [4],\n           [6]])\n\n    Working on the flattened array does not return slices along an axis but\n    selects elements.\n\n    >>> np.compress([False, True], a)\n    array([2])\n\n    \"\"\"\n    return _wrapfunc(a, 'compress', condition, axis=axis, out=out)\n\n\ndef _clip_dispatcher(a, a_min, a_max, out=None, **kwargs):\n    return (a, a_min, a_max)\n\n\n@array_function_dispatch(_clip_dispatcher)\ndef clip(a, a_min, a_max, out=None, **kwargs):\n    \"\"\"\n    Clip (limit) the values in an array.\n\n    Given an interval, values outside the interval are clipped to\n    the interval edges.  For example, if an interval of ``[0, 1]``\n    is specified, values smaller than 0 become 0, and values larger\n    than 1 become 1.\n\n    Equivalent to but faster than ``np.minimum(a_max, np.maximum(a, a_min))``.\n\n    No check is performed to ensure ``a_min < a_max``.\n\n    Parameters\n    ----------\n    a : array_like\n        Array containing elements to clip.\n    a_min, a_max : array_like or None\n        Minimum and maximum value. If ``None``, clipping is not performed on\n        the corresponding edge. Only one of `a_min` and `a_max` may be\n        ``None``. Both are broadcast against `a`.\n    out : ndarray, optional\n        The results will be placed in this array. It may be the input\n        array for in-place clipping.  `out` must be of the right shape\n        to hold the output.  Its type is preserved.\n    **kwargs\n        For other keyword-only arguments, see the\n        :ref:`ufunc docs <ufuncs.kwargs>`.\n\n        .. versionadded:: 1.17.0\n\n    Returns\n    -------\n    clipped_array : ndarray\n        An array with the elements of `a`, but where values\n        < `a_min` are replaced with `a_min`, and those > `a_max`\n        with `a_max`.\n\n    See Also\n    --------\n    :ref:`ufuncs-output-type`\n\n    Notes\n    -----\n    When `a_min` is greater than `a_max`, `clip` returns an \n    array in which all values are equal to `a_max`, \n    as shown in the second example.  \n\n    Examples\n    --------\n    >>> a = np.arange(10)\n    >>> a\n    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n    >>> np.clip(a, 1, 8)\n    array([1, 1, 2, 3, 4, 5, 6, 7, 8, 8])\n    >>> np.clip(a, 8, 1)\n    array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n    >>> np.clip(a, 3, 6, out=a)\n    array([3, 3, 3, 3, 4, 5, 6, 6, 6, 6])\n    >>> a\n    array([3, 3, 3, 3, 4, 5, 6, 6, 6, 6])\n    >>> a = np.arange(10)\n    >>> a\n    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n    >>> np.clip(a, [3, 4, 1, 1, 1, 4, 4, 4, 4, 4], 8)\n    array([3, 4, 2, 3, 4, 5, 6, 7, 8, 8])\n\n    \"\"\"\n    return _wrapfunc(a, 'clip', a_min, a_max, out=out, **kwargs)\n\n\ndef _sum_dispatcher(a, axis=None, dtype=None, out=None, keepdims=None,\n                    initial=None, where=None):\n    return (a, out)\n\n\n@array_function_dispatch(_sum_dispatcher)\ndef sum(a, axis=None, dtype=None, out=None, keepdims=np._NoValue,\n        initial=np._NoValue, where=np._NoValue):\n    \"\"\"\n    Sum of array elements over a given axis.\n\n    Parameters\n    ----------\n    a : array_like\n        Elements to sum.\n    axis : None or int or tuple of ints, optional\n        Axis or axes along which a sum is performed.  The default,\n        axis=None, will sum all of the elements of the input array.  If\n        axis is negative it counts from the last to the first axis.\n\n        .. versionadded:: 1.7.0\n\n        If axis is a tuple of ints, a sum is performed on all of the axes\n        specified in the tuple instead of a single axis or all the axes as\n        before.\n    dtype : dtype, optional\n        The type of the returned array and of the accumulator in which the\n        elements are summed.  The dtype of `a` is used by default unless `a`\n        has an integer dtype of less precision than the default platform\n        integer.  In that case, if `a` is signed then the platform integer\n        is used while if `a` is unsigned then an unsigned integer of the\n        same precision as the platform integer is used.\n    out : ndarray, optional\n        Alternative output array in which to place the result. It must have\n        the same shape as the expected output, but the type of the output\n        values will be cast if necessary.\n    keepdims : bool, optional\n        If this is set to True, the axes which are reduced are left\n        in the result as dimensions with size one. With this option,\n        the result will broadcast correctly against the input array.\n\n        If the default value is passed, then `keepdims` will not be\n        passed through to the `sum` method of sub-classes of\n        `ndarray`, however any non-default value will be.  If the\n        sub-class' method does not implement `keepdims` any\n        exceptions will be raised.\n    initial : scalar, optional\n        Starting value for the sum. See `~numpy.ufunc.reduce` for details.\n\n        .. versionadded:: 1.15.0\n\n    where : array_like of bool, optional\n        Elements to include in the sum. See `~numpy.ufunc.reduce` for details.\n\n        .. versionadded:: 1.17.0\n\n    Returns\n    -------\n    sum_along_axis : ndarray\n        An array with the same shape as `a`, with the specified\n        axis removed.   If `a` is a 0-d array, or if `axis` is None, a scalar\n        is returned.  If an output array is specified, a reference to\n        `out` is returned.\n\n    See Also\n    --------\n    ndarray.sum : Equivalent method.\n\n    add.reduce : Equivalent functionality of `add`.\n\n    cumsum : Cumulative sum of array elements.\n\n    trapz : Integration of array values using the composite trapezoidal rule.\n\n    mean, average\n\n    Notes\n    -----\n    Arithmetic is modular when using integer types, and no error is\n    raised on overflow.\n\n    The sum of an empty array is the neutral element 0:\n\n    >>> np.sum([])\n    0.0\n\n    For floating point numbers the numerical precision of sum (and\n    ``np.add.reduce``) is in general limited by directly adding each number\n    individually to the result causing rounding errors in every step.\n    However, often numpy will use a  numerically better approach (partial\n    pairwise summation) leading to improved precision in many use-cases.\n    This improved precision is always provided when no ``axis`` is given.\n    When ``axis`` is given, it will depend on which axis is summed.\n    Technically, to provide the best speed possible, the improved precision\n    is only used when the summation is along the fast axis in memory.\n    Note that the exact precision may vary depending on other parameters.\n    In contrast to NumPy, Python's ``math.fsum`` function uses a slower but\n    more precise approach to summation.\n    Especially when summing a large number of lower precision floating point\n    numbers, such as ``float32``, numerical errors can become significant.\n    In such cases it can be advisable to use `dtype=\"float64\"` to use a higher\n    precision for the output.\n\n    Examples\n    --------\n    >>> np.sum([0.5, 1.5])\n    2.0\n    >>> np.sum([0.5, 0.7, 0.2, 1.5], dtype=np.int32)\n    1\n    >>> np.sum([[0, 1], [0, 5]])\n    6\n    >>> np.sum([[0, 1], [0, 5]], axis=0)\n    array([0, 6])\n    >>> np.sum([[0, 1], [0, 5]], axis=1)\n    array([1, 5])\n    >>> np.sum([[0, 1], [np.nan, 5]], where=[False, True], axis=1)\n    array([1., 5.])\n\n    If the accumulator is too small, overflow occurs:\n\n    >>> np.ones(128, dtype=np.int8).sum(dtype=np.int8)\n    -128\n\n    You can also start the sum with a value other than zero:\n\n    >>> np.sum([10], initial=5)\n    15\n    \"\"\"\n    if isinstance(a, _gentype):\n        # 2018-02-25, 1.15.0\n        warnings.warn(\n            \"Calling np.sum(generator) is deprecated, and in the future will give a different result. \"\n            \"Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\",\n            DeprecationWarning, stacklevel=3)\n\n        res = _sum_(a)\n        if out is not None:\n            out[...] = res\n            return out\n        return res\n\n    return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n                          initial=initial, where=where)\n\n\ndef _any_dispatcher(a, axis=None, out=None, keepdims=None, *,\n                    where=np._NoValue):\n    return (a, where, out)\n\n\n@array_function_dispatch(_any_dispatcher)\ndef any(a, axis=None, out=None, keepdims=np._NoValue, *, where=np._NoValue):\n    \"\"\"\n    Test whether any array element along a given axis evaluates to True.\n\n    Returns single boolean unless `axis` is not ``None``\n\n    Parameters\n    ----------\n    a : array_like\n        Input array or object that can be converted to an array.\n    axis : None or int or tuple of ints, optional\n        Axis or axes along which a logical OR reduction is performed.\n        The default (``axis=None``) is to perform a logical OR over all\n        the dimensions of the input array. `axis` may be negative, in\n        which case it counts from the last to the first axis.\n\n        .. versionadded:: 1.7.0\n\n        If this is a tuple of ints, a reduction is performed on multiple\n        axes, instead of a single axis or all the axes as before.\n    out : ndarray, optional\n        Alternate output array in which to place the result.  It must have\n        the same shape as the expected output and its type is preserved\n        (e.g., if it is of type float, then it will remain so, returning\n        1.0 for True and 0.0 for False, regardless of the type of `a`).\n        See :ref:`ufuncs-output-type` for more details.\n\n    keepdims : bool, optional\n        If this is set to True, the axes which are reduced are left\n        in the result as dimensions with size one. With this option,\n        the result will broadcast correctly against the input array.\n\n        If the default value is passed, then `keepdims` will not be\n        passed through to the `any` method of sub-classes of\n        `ndarray`, however any non-default value will be.  If the\n        sub-class' method does not implement `keepdims` any\n        exceptions will be raised.\n\n    where : array_like of bool, optional\n        Elements to include in checking for any `True` values.\n        See `~numpy.ufunc.reduce` for details.\n\n        .. versionadded:: 1.20.0\n\n    Returns\n    -------\n    any : bool or ndarray\n        A new boolean or `ndarray` is returned unless `out` is specified,\n        in which case a reference to `out` is returned.\n\n    See Also\n    --------\n    ndarray.any : equivalent method\n\n    all : Test whether all elements along a given axis evaluate to True.\n\n    Notes\n    -----\n    Not a Number (NaN), positive infinity and negative infinity evaluate\n    to `True` because these are not equal to zero.\n\n    Examples\n    --------\n    >>> np.any([[True, False], [True, True]])\n    True\n\n    >>> np.any([[True, False], [False, False]], axis=0)\n    array([ True, False])\n\n    >>> np.any([-1, 0, 5])\n    True\n\n    >>> np.any(np.nan)\n    True\n\n    >>> np.any([[True, False], [False, False]], where=[[False], [True]])\n    False\n\n    >>> o=np.array(False)\n    >>> z=np.any([-1, 4, 5], out=o)\n    >>> z, o\n    (array(True), array(True))\n    >>> # Check now that z is a reference to o\n    >>> z is o\n    True\n    >>> id(z), id(o) # identity of z and o              # doctest: +SKIP\n    (191614240, 191614240)\n\n    \"\"\"\n    return _wrapreduction(a, np.logical_or, 'any', axis, None, out,\n                          keepdims=keepdims, where=where)\n\n\ndef _all_dispatcher(a, axis=None, out=None, keepdims=None, *,\n                    where=None):\n    return (a, where, out)\n\n\n@array_function_dispatch(_all_dispatcher)\ndef all(a, axis=None, out=None, keepdims=np._NoValue, *, where=np._NoValue):\n    \"\"\"\n    Test whether all array elements along a given axis evaluate to True.\n\n    Parameters\n    ----------\n    a : array_like\n        Input array or object that can be converted to an array.\n    axis : None or int or tuple of ints, optional\n        Axis or axes along which a logical AND reduction is performed.\n        The default (``axis=None``) is to perform a logical AND over all\n        the dimensions of the input array. `axis` may be negative, in\n        which case it counts from the last to the first axis.\n\n        .. versionadded:: 1.7.0\n\n        If this is a tuple of ints, a reduction is performed on multiple\n        axes, instead of a single axis or all the axes as before.\n    out : ndarray, optional\n        Alternate output array in which to place the result.\n        It must have the same shape as the expected output and its\n        type is preserved (e.g., if ``dtype(out)`` is float, the result\n        will consist of 0.0's and 1.0's). See :ref:`ufuncs-output-type` for more\n        details.\n\n    keepdims : bool, optional\n        If this is set to True, the axes which are reduced are left\n        in the result as dimensions with size one. With this option,\n        the result will broadcast correctly against the input array.\n\n        If the default value is passed, then `keepdims` will not be\n        passed through to the `all` method of sub-classes of\n        `ndarray`, however any non-default value will be.  If the\n        sub-class' method does not implement `keepdims` any\n        exceptions will be raised.\n\n    where : array_like of bool, optional\n        Elements to include in checking for all `True` values.\n        See `~numpy.ufunc.reduce` for details.\n\n        .. versionadded:: 1.20.0\n\n    Returns\n    -------\n    all : ndarray, bool\n        A new boolean or array is returned unless `out` is specified,\n        in which case a reference to `out` is returned.\n\n    See Also\n    --------\n    ndarray.all : equivalent method\n\n    any : Test whether any element along a given axis evaluates to True.\n\n    Notes\n    -----\n    Not a Number (NaN), positive infinity and negative infinity\n    evaluate to `True` because these are not equal to zero.\n\n    Examples\n    --------\n    >>> np.all([[True,False],[True,True]])\n    False\n\n    >>> np.all([[True,False],[True,True]], axis=0)\n    array([ True, False])\n\n    >>> np.all([-1, 4, 5])\n    True\n\n    >>> np.all([1.0, np.nan])\n    True\n\n    >>> np.all([[True, True], [False, True]], where=[[True], [False]])\n    True\n\n    >>> o=np.array(False)\n    >>> z=np.all([-1, 4, 5], out=o)\n    >>> id(z), id(o), z\n    (28293632, 28293632, array(True)) # may vary\n\n    \"\"\"\n    return _wrapreduction(a, np.logical_and, 'all', axis, None, out,\n                          keepdims=keepdims, where=where)\n\n\ndef _cumsum_dispatcher(a, axis=None, dtype=None, out=None):\n    return (a, out)\n\n\n@array_function_dispatch(_cumsum_dispatcher)\ndef cumsum(a, axis=None, dtype=None, out=None):\n    \"\"\"\n    Return the cumulative sum of the elements along a given axis.\n\n    Parameters\n    ----------\n    a : array_like\n        Input array.\n    axis : int, optional\n        Axis along which the cumulative sum is computed. The default\n        (None) is to compute the cumsum over the flattened array.\n    dtype : dtype, optional\n        Type of the returned array and of the accumulator in which the\n        elements are summed.  If `dtype` is not specified, it defaults\n        to the dtype of `a`, unless `a` has an integer dtype with a\n        precision less than that of the default platform integer.  In\n        that case, the default platform integer is used.\n    out : ndarray, optional\n        Alternative output array in which to place the result. It must\n        have the same shape and buffer length as the expected output\n        but the type will be cast if necessary. See :ref:`ufuncs-output-type` for\n        more details.\n\n    Returns\n    -------\n    cumsum_along_axis : ndarray.\n        A new array holding the result is returned unless `out` is\n        specified, in which case a reference to `out` is returned. The\n        result has the same size as `a`, and the same shape as `a` if\n        `axis` is not None or `a` is a 1-d array.\n\n    See Also\n    --------\n    sum : Sum array elements.\n    trapz : Integration of array values using the composite trapezoidal rule.\n    diff : Calculate the n-th discrete difference along given axis.\n\n    Notes\n    -----\n    Arithmetic is modular when using integer types, and no error is\n    raised on overflow.\n\n    ``cumsum(a)[-1]`` may not be equal to ``sum(a)`` for floating-point\n    values since ``sum`` may use a pairwise summation routine, reducing\n    the roundoff-error. See `sum` for more information.\n\n    Examples\n    --------\n    >>> a = np.array([[1,2,3], [4,5,6]])\n    >>> a\n    array([[1, 2, 3],\n           [4, 5, 6]])\n    >>> np.cumsum(a)\n    array([ 1,  3,  6, 10, 15, 21])\n    >>> np.cumsum(a, dtype=float)     # specifies type of output value(s)\n    array([  1.,   3.,   6.,  10.,  15.,  21.])\n\n    >>> np.cumsum(a,axis=0)      # sum over rows for each of the 3 columns\n    array([[1, 2, 3],\n           [5, 7, 9]])\n    >>> np.cumsum(a,axis=1)      # sum over columns for each of the 2 rows\n    array([[ 1,  3,  6],\n           [ 4,  9, 15]])\n\n    ``cumsum(b)[-1]`` may not be equal to ``sum(b)``\n\n    >>> b = np.array([1, 2e-9, 3e-9] * 1000000)\n    >>> b.cumsum()[-1]\n    1000000.0050045159\n    >>> b.sum()                    \n    1000000.0050000029\n\n    \"\"\"\n    return _wrapfunc(a, 'cumsum', axis=axis, dtype=dtype, out=out)\n\n\ndef _ptp_dispatcher(a, axis=None, out=None, keepdims=None):\n    return (a, out)\n\n\n@array_function_dispatch(_ptp_dispatcher)\ndef ptp(a, axis=None, out=None, keepdims=np._NoValue):\n    \"\"\"\n    Range of values (maximum - minimum) along an axis.\n\n    The name of the function comes from the acronym for 'peak to peak'.\n\n    .. warning::\n        `ptp` preserves the data type of the array. This means the\n        return value for an input of signed integers with n bits\n        (e.g. `np.int8`, `np.int16`, etc) is also a signed integer\n        with n bits.  In that case, peak-to-peak values greater than\n        ``2**(n-1)-1`` will be returned as negative values. An example\n        with a work-around is shown below.\n\n    Parameters\n    ----------\n    a : array_like\n        Input values.\n    axis : None or int or tuple of ints, optional\n        Axis along which to find the peaks.  By default, flatten the\n        array.  `axis` may be negative, in\n        which case it counts from the last to the first axis.\n\n        .. versionadded:: 1.15.0\n\n        If this is a tuple of ints, a reduction is performed on multiple\n        axes, instead of a single axis or all the axes as before.\n    out : array_like\n        Alternative output array in which to place the result. It must\n        have the same shape and buffer length as the expected output,\n        but the type of the output values will be cast if necessary.\n\n    keepdims : bool, optional\n        If this is set to True, the axes which are reduced are left\n        in the result as dimensions with size one. With this option,\n        the result will broadcast correctly against the input array.\n\n        If the default value is passed, then `keepdims` will not be\n        passed through to the `ptp` method of sub-classes of\n        `ndarray`, however any non-default value will be.  If the\n        sub-class' method does not implement `keepdims` any\n        exceptions will be raised.\n\n    Returns\n    -------\n    ptp : ndarray\n        A new array holding the result, unless `out` was\n        specified, in which case a reference to `out` is returned.\n\n    Examples\n    --------\n    >>> x = np.array([[4, 9, 2, 10],\n    ...               [6, 9, 7, 12]])\n\n    >>> np.ptp(x, axis=1)\n    array([8, 6])\n\n    >>> np.ptp(x, axis=0)\n    array([2, 0, 5, 2])\n\n    >>> np.ptp(x)\n    10\n\n    This example shows that a negative value can be returned when\n    the input is an array of signed integers.\n\n    >>> y = np.array([[1, 127],\n    ...               [0, 127],\n    ...               [-1, 127],\n    ...               [-2, 127]], dtype=np.int8)\n    >>> np.ptp(y, axis=1)\n    array([ 126,  127, -128, -127], dtype=int8)\n\n    A work-around is to use the `view()` method to view the result as\n    unsigned integers with the same bit width:\n\n    >>> np.ptp(y, axis=1).view(np.uint8)\n    array([126, 127, 128, 129], dtype=uint8)\n\n    \"\"\"\n    kwargs = {}\n    if keepdims is not np._NoValue:\n        kwargs['keepdims'] = keepdims\n    if type(a) is not mu.ndarray:\n        try:\n            ptp = a.ptp\n        except AttributeError:\n            pass\n        else:\n            return ptp(axis=axis, out=out, **kwargs)\n    return _methods._ptp(a, axis=axis, out=out, **kwargs)\n\n\ndef _amax_dispatcher(a, axis=None, out=None, keepdims=None, initial=None,\n                     where=None):\n    return (a, out)\n\n\n@array_function_dispatch(_amax_dispatcher)\ndef amax(a, axis=None, out=None, keepdims=np._NoValue, initial=np._NoValue,\n         where=np._NoValue):\n    \"\"\"\n    Return the maximum of an array or maximum along an axis.\n\n    Parameters\n    ----------\n    a : array_like\n        Input data.\n    axis : None or int or tuple of ints, optional\n        Axis or axes along which to operate.  By default, flattened input is\n        used.\n\n        .. versionadded:: 1.7.0\n\n        If this is a tuple of ints, the maximum is selected over multiple axes,\n        instead of a single axis or all the axes as before.\n    out : ndarray, optional\n        Alternative output array in which to place the result.  Must\n        be of the same shape and buffer length as the expected output.\n        See :ref:`ufuncs-output-type` for more details.\n\n    keepdims : bool, optional\n        If this is set to True, the axes which are reduced are left\n        in the result as dimensions with size one. With this option,\n        the result will broadcast correctly against the input array.\n\n        If the default value is passed, then `keepdims` will not be\n        passed through to the `amax` method of sub-classes of\n        `ndarray`, however any non-default value will be.  If the\n        sub-class' method does not implement `keepdims` any\n        exceptions will be raised.\n\n    initial : scalar, optional\n        The minimum value of an output element. Must be present to allow\n        computation on empty slice. See `~numpy.ufunc.reduce` for details.\n\n        .. versionadded:: 1.15.0\n\n    where : array_like of bool, optional\n        Elements to compare for the maximum. See `~numpy.ufunc.reduce`\n        for details.\n\n        .. versionadded:: 1.17.0\n\n    Returns\n    -------\n    amax : ndarray or scalar\n        Maximum of `a`. If `axis` is None, the result is a scalar value.\n        If `axis` is given, the result is an array of dimension\n        ``a.ndim - 1``.\n\n    See Also\n    --------\n    amin :\n        The minimum value of an array along a given axis, propagating any NaNs.\n    nanmax :\n        The maximum value of an array along a given axis, ignoring any NaNs.\n    maximum :\n        Element-wise maximum of two arrays, propagating any NaNs.\n    fmax :\n        Element-wise maximum of two arrays, ignoring any NaNs.\n    argmax :\n        Return the indices of the maximum values.\n\n    nanmin, minimum, fmin\n\n    Notes\n    -----\n    NaN values are propagated, that is if at least one item is NaN, the\n    corresponding max value will be NaN as well. To ignore NaN values\n    (MATLAB behavior), please use nanmax.\n\n    Don't use `amax` for element-wise comparison of 2 arrays; when\n    ``a.shape[0]`` is 2, ``maximum(a[0], a[1])`` is faster than\n    ``amax(a, axis=0)``.\n\n    Examples\n    --------\n    >>> a = np.arange(4).reshape((2,2))\n    >>> a\n    array([[0, 1],\n           [2, 3]])\n    >>> np.amax(a)           # Maximum of the flattened array\n    3\n    >>> np.amax(a, axis=0)   # Maxima along the first axis\n    array([2, 3])\n    >>> np.amax(a, axis=1)   # Maxima along the second axis\n    array([1, 3])\n    >>> np.amax(a, where=[False, True], initial=-1, axis=0)\n    array([-1,  3])\n    >>> b = np.arange(5, dtype=float)\n    >>> b[2] = np.NaN\n    >>> np.amax(b)\n    nan\n    >>> np.amax(b, where=~np.isnan(b), initial=-1)\n    4.0\n    >>> np.nanmax(b)\n    4.0\n\n    You can use an initial value to compute the maximum of an empty slice, or\n    to initialize it to a different value:\n\n    >>> np.max([[-50], [10]], axis=-1, initial=0)\n    array([ 0, 10])\n\n    Notice that the initial value is used as one of the elements for which the\n    maximum is determined, unlike for the default argument Python's max\n    function, which is only used for empty iterables.\n\n    >>> np.max([5], initial=6)\n    6\n    >>> max([5], default=6)\n    5\n    \"\"\"\n    return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n                          keepdims=keepdims, initial=initial, where=where)\n\n\ndef _amin_dispatcher(a, axis=None, out=None, keepdims=None, initial=None,\n                     where=None):\n    return (a, out)\n\n\n@array_function_dispatch(_amin_dispatcher)\ndef amin(a, axis=None, out=None, keepdims=np._NoValue, initial=np._NoValue,\n         where=np._NoValue):\n    \"\"\"\n    Return the minimum of an array or minimum along an axis.\n\n    Parameters\n    ----------\n    a : array_like\n        Input data.\n    axis : None or int or tuple of ints, optional\n        Axis or axes along which to operate.  By default, flattened input is\n        used.\n\n        .. versionadded:: 1.7.0\n\n        If this is a tuple of ints, the minimum is selected over multiple axes,\n        instead of a single axis or all the axes as before.\n    out : ndarray, optional\n        Alternative output array in which to place the result.  Must\n        be of the same shape and buffer length as the expected output.\n        See :ref:`ufuncs-output-type` for more details.\n\n    keepdims : bool, optional\n        If this is set to True, the axes which are reduced are left\n        in the result as dimensions with size one. With this option,\n        the result will broadcast correctly against the input array.\n\n        If the default value is passed, then `keepdims` will not be\n        passed through to the `amin` method of sub-classes of\n        `ndarray`, however any non-default value will be.  If the\n        sub-class' method does not implement `keepdims` any\n        exceptions will be raised.\n\n    initial : scalar, optional\n        The maximum value of an output element. Must be present to allow\n        computation on empty slice. See `~numpy.ufunc.reduce` for details.\n\n        .. versionadded:: 1.15.0\n\n    where : array_like of bool, optional\n        Elements to compare for the minimum. See `~numpy.ufunc.reduce`\n        for details.\n\n        .. versionadded:: 1.17.0\n\n    Returns\n    -------\n    amin : ndarray or scalar\n        Minimum of `a`. If `axis` is None, the result is a scalar value.\n        If `axis` is given, the result is an array of dimension\n        ``a.ndim - 1``.\n\n    See Also\n    --------\n    amax :\n        The maximum value of an array along a given axis, propagating any NaNs.\n    nanmin :\n        The minimum value of an array along a given axis, ignoring any NaNs.\n    minimum :\n        Element-wise minimum of two arrays, propagating any NaNs.\n    fmin :\n        Element-wise minimum of two arrays, ignoring any NaNs.\n    argmin :\n        Return the indices of the minimum values.\n\n    nanmax, maximum, fmax\n\n    Notes\n    -----\n    NaN values are propagated, that is if at least one item is NaN, the\n    corresponding min value will be NaN as well. To ignore NaN values\n    (MATLAB behavior), please use nanmin.\n\n    Don't use `amin` for element-wise comparison of 2 arrays; when\n    ``a.shape[0]`` is 2, ``minimum(a[0], a[1])`` is faster than\n    ``amin(a, axis=0)``.\n\n    Examples\n    --------\n    >>> a = np.arange(4).reshape((2,2))\n    >>> a\n    array([[0, 1],\n           [2, 3]])\n    >>> np.amin(a)           # Minimum of the flattened array\n    0\n    >>> np.amin(a, axis=0)   # Minima along the first axis\n    array([0, 1])\n    >>> np.amin(a, axis=1)   # Minima along the second axis\n    array([0, 2])\n    >>> np.amin(a, where=[False, True], initial=10, axis=0)\n    array([10,  1])\n\n    >>> b = np.arange(5, dtype=float)\n    >>> b[2] = np.NaN\n    >>> np.amin(b)\n    nan\n    >>> np.amin(b, where=~np.isnan(b), initial=10)\n    0.0\n    >>> np.nanmin(b)\n    0.0\n\n    >>> np.min([[-50], [10]], axis=-1, initial=0)\n    array([-50,   0])\n\n    Notice that the initial value is used as one of the elements for which the\n    minimum is determined, unlike for the default argument Python's max\n    function, which is only used for empty iterables.\n\n    Notice that this isn't the same as Python's ``default`` argument.\n\n    >>> np.min([6], initial=5)\n    5\n    >>> min([6], default=5)\n    6\n    \"\"\"\n    return _wrapreduction(a, np.minimum, 'min', axis, None, out,\n                          keepdims=keepdims, initial=initial, where=where)\n\n\ndef _alen_dispathcer(a):\n    return (a,)\n\n\n@array_function_dispatch(_alen_dispathcer)\ndef alen(a):\n    \"\"\"\n    Return the length of the first dimension of the input array.\n\n    .. deprecated:: 1.18\n       `numpy.alen` is deprecated, use `len` instead.\n\n    Parameters\n    ----------\n    a : array_like\n       Input array.\n\n    Returns\n    -------\n    alen : int\n       Length of the first dimension of `a`.\n\n    See Also\n    --------\n    shape, size\n\n    Examples\n    --------\n    >>> a = np.zeros((7,4,5))\n    >>> a.shape[0]\n    7\n    >>> np.alen(a)\n    7\n\n    \"\"\"\n    # NumPy 1.18.0, 2019-08-02\n    warnings.warn(\n        \"`np.alen` is deprecated, use `len` instead\",\n        DeprecationWarning, stacklevel=2)\n    try:\n        return len(a)\n    except TypeError:\n        return len(array(a, ndmin=1))\n\n\ndef _prod_dispatcher(a, axis=None, dtype=None, out=None, keepdims=None,\n                     initial=None, where=None):\n    return (a, out)\n\n\n@array_function_dispatch(_prod_dispatcher)\ndef prod(a, axis=None, dtype=None, out=None, keepdims=np._NoValue,\n         initial=np._NoValue, where=np._NoValue):\n    \"\"\"\n    Return the product of array elements over a given axis.\n\n    Parameters\n    ----------\n    a : array_like\n        Input data.\n    axis : None or int or tuple of ints, optional\n        Axis or axes along which a product is performed.  The default,\n        axis=None, will calculate the product of all the elements in the\n        input array. If axis is negative it counts from the last to the\n        first axis.\n\n        .. versionadded:: 1.7.0\n\n        If axis is a tuple of ints, a product is performed on all of the\n        axes specified in the tuple instead of a single axis or all the\n        axes as before.\n    dtype : dtype, optional\n        The type of the returned array, as well as of the accumulator in\n        which the elements are multiplied.  The dtype of `a` is used by\n        default unless `a` has an integer dtype of less precision than the\n        default platform integer.  In that case, if `a` is signed then the\n        platform integer is used while if `a` is unsigned then an unsigned\n        integer of the same precision as the platform integer is used.\n    out : ndarray, optional\n        Alternative output array in which to place the result. It must have\n        the same shape as the expected output, but the type of the output\n        values will be cast if necessary.\n    keepdims : bool, optional\n        If this is set to True, the axes which are reduced are left in the\n        result as dimensions with size one. With this option, the result\n        will broadcast correctly against the input array.\n\n        If the default value is passed, then `keepdims` will not be\n        passed through to the `prod` method of sub-classes of\n        `ndarray`, however any non-default value will be.  If the\n        sub-class' method does not implement `keepdims` any\n        exceptions will be raised.\n    initial : scalar, optional\n        The starting value for this product. See `~numpy.ufunc.reduce` for details.\n\n        .. versionadded:: 1.15.0\n\n    where : array_like of bool, optional\n        Elements to include in the product. See `~numpy.ufunc.reduce` for details.\n\n        .. versionadded:: 1.17.0\n\n    Returns\n    -------\n    product_along_axis : ndarray, see `dtype` parameter above.\n        An array shaped as `a` but with the specified axis removed.\n        Returns a reference to `out` if specified.\n\n    See Also\n    --------\n    ndarray.prod : equivalent method\n    :ref:`ufuncs-output-type`\n\n    Notes\n    -----\n    Arithmetic is modular when using integer types, and no error is\n    raised on overflow.  That means that, on a 32-bit platform:\n\n    >>> x = np.array([536870910, 536870910, 536870910, 536870910])\n    >>> np.prod(x)\n    16 # may vary\n\n    The product of an empty array is the neutral element 1:\n\n    >>> np.prod([])\n    1.0\n\n    Examples\n    --------\n    By default, calculate the product of all elements:\n\n    >>> np.prod([1.,2.])\n    2.0\n\n    Even when the input array is two-dimensional:\n\n    >>> np.prod([[1.,2.],[3.,4.]])\n    24.0\n\n    But we can also specify the axis over which to multiply:\n\n    >>> np.prod([[1.,2.],[3.,4.]], axis=1)\n    array([  2.,  12.])\n\n    Or select specific elements to include:\n\n    >>> np.prod([1., np.nan, 3.], where=[True, False, True])\n    3.0\n\n    If the type of `x` is unsigned, then the output type is\n    the unsigned platform integer:\n\n    >>> x = np.array([1, 2, 3], dtype=np.uint8)\n    >>> np.prod(x).dtype == np.uint\n    True\n\n    If `x` is of a signed integer type, then the output type\n    is the default platform integer:\n\n    >>> x = np.array([1, 2, 3], dtype=np.int8)\n    >>> np.prod(x).dtype == int\n    True\n\n    You can also start the product with a value other than one:\n\n    >>> np.prod([1, 2], initial=5)\n    10\n    \"\"\"\n    return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n                          keepdims=keepdims, initial=initial, where=where)\n\n\ndef _cumprod_dispatcher(a, axis=None, dtype=None, out=None):\n    return (a, out)\n\n\n@array_function_dispatch(_cumprod_dispatcher)\ndef cumprod(a, axis=None, dtype=None, out=None):\n    \"\"\"\n    Return the cumulative product of elements along a given axis.\n\n    Parameters\n    ----------\n    a : array_like\n        Input array.\n    axis : int, optional\n        Axis along which the cumulative product is computed.  By default\n        the input is flattened.\n    dtype : dtype, optional\n        Type of the returned array, as well as of the accumulator in which\n        the elements are multiplied.  If *dtype* is not specified, it\n        defaults to the dtype of `a`, unless `a` has an integer dtype with\n        a precision less than that of the default platform integer.  In\n        that case, the default platform integer is used instead.\n    out : ndarray, optional\n        Alternative output array in which to place the result. It must\n        have the same shape and buffer length as the expected output\n        but the type of the resulting values will be cast if necessary.\n\n    Returns\n    -------\n    cumprod : ndarray\n        A new array holding the result is returned unless `out` is\n        specified, in which case a reference to out is returned.\n\n    See Also\n    --------\n    :ref:`ufuncs-output-type`\n\n    Notes\n    -----\n    Arithmetic is modular when using integer types, and no error is\n    raised on overflow.\n\n    Examples\n    --------\n    >>> a = np.array([1,2,3])\n    >>> np.cumprod(a) # intermediate results 1, 1*2\n    ...               # total product 1*2*3 = 6\n    array([1, 2, 6])\n    >>> a = np.array([[1, 2, 3], [4, 5, 6]])\n    >>> np.cumprod(a, dtype=float) # specify type of output\n    array([   1.,    2.,    6.,   24.,  120.,  720.])\n\n    The cumulative product for each column (i.e., over the rows) of `a`:\n\n    >>> np.cumprod(a, axis=0)\n    array([[ 1,  2,  3],\n           [ 4, 10, 18]])\n\n    The cumulative product for each row (i.e. over the columns) of `a`:\n\n    >>> np.cumprod(a,axis=1)\n    array([[  1,   2,   6],\n           [  4,  20, 120]])\n\n    \"\"\"\n    return _wrapfunc(a, 'cumprod', axis=axis, dtype=dtype, out=out)\n\n\ndef _ndim_dispatcher(a):\n    return (a,)\n\n\n@array_function_dispatch(_ndim_dispatcher)\ndef ndim(a):\n    \"\"\"\n    Return the number of dimensions of an array.\n\n    Parameters\n    ----------\n    a : array_like\n        Input array.  If it is not already an ndarray, a conversion is\n        attempted.\n\n    Returns\n    -------\n    number_of_dimensions : int\n        The number of dimensions in `a`.  Scalars are zero-dimensional.\n\n    See Also\n    --------\n    ndarray.ndim : equivalent method\n    shape : dimensions of array\n    ndarray.shape : dimensions of array\n\n    Examples\n    --------\n    >>> np.ndim([[1,2,3],[4,5,6]])\n    2\n    >>> np.ndim(np.array([[1,2,3],[4,5,6]]))\n    2\n    >>> np.ndim(1)\n    0\n\n    \"\"\"\n    try:\n        return a.ndim\n    except AttributeError:\n        return asarray(a).ndim\n\n\ndef _size_dispatcher(a, axis=None):\n    return (a,)\n\n\n@array_function_dispatch(_size_dispatcher)\ndef size(a, axis=None):\n    \"\"\"\n    Return the number of elements along a given axis.\n\n    Parameters\n    ----------\n    a : array_like\n        Input data.\n    axis : int, optional\n        Axis along which the elements are counted.  By default, give\n        the total number of elements.\n\n    Returns\n    -------\n    element_count : int\n        Number of elements along the specified axis.\n\n    See Also\n    --------\n    shape : dimensions of array\n    ndarray.shape : dimensions of array\n    ndarray.size : number of elements in array\n\n    Examples\n    --------\n    >>> a = np.array([[1,2,3],[4,5,6]])\n    >>> np.size(a)\n    6\n    >>> np.size(a,1)\n    3\n    >>> np.size(a,0)\n    2\n\n    \"\"\"\n    if axis is None:\n        try:\n            return a.size\n        except AttributeError:\n            return asarray(a).size\n    else:\n        try:\n            return a.shape[axis]\n        except AttributeError:\n            return asarray(a).shape[axis]\n\n\ndef _around_dispatcher(a, decimals=None, out=None):\n    return (a, out)\n\n\n@array_function_dispatch(_around_dispatcher)\ndef around(a, decimals=0, out=None):\n    \"\"\"\n    Evenly round to the given number of decimals.\n\n    Parameters\n    ----------\n    a : array_like\n        Input data.\n    decimals : int, optional\n        Number of decimal places to round to (default: 0).  If\n        decimals is negative, it specifies the number of positions to\n        the left of the decimal point.\n    out : ndarray, optional\n        Alternative output array in which to place the result. It must have\n        the same shape as the expected output, but the type of the output\n        values will be cast if necessary. See :ref:`ufuncs-output-type` for more\n        details.\n\n    Returns\n    -------\n    rounded_array : ndarray\n        An array of the same type as `a`, containing the rounded values.\n        Unless `out` was specified, a new array is created.  A reference to\n        the result is returned.\n\n        The real and imaginary parts of complex numbers are rounded\n        separately.  The result of rounding a float is a float.\n\n    See Also\n    --------\n    ndarray.round : equivalent method\n\n    ceil, fix, floor, rint, trunc\n\n\n    Notes\n    -----\n    For values exactly halfway between rounded decimal values, NumPy\n    rounds to the nearest even value. Thus 1.5 and 2.5 round to 2.0,\n    -0.5 and 0.5 round to 0.0, etc.\n\n    ``np.around`` uses a fast but sometimes inexact algorithm to round\n    floating-point datatypes. For positive `decimals` it is equivalent to\n    ``np.true_divide(np.rint(a * 10**decimals), 10**decimals)``, which has\n    error due to the inexact representation of decimal fractions in the IEEE\n    floating point standard [1]_ and errors introduced when scaling by powers\n    of ten. For instance, note the extra \"1\" in the following:\n\n        >>> np.round(56294995342131.5, 3)\n        56294995342131.51\n\n    If your goal is to print such values with a fixed number of decimals, it is\n    preferable to use numpy's float printing routines to limit the number of\n    printed decimals:\n\n        >>> np.format_float_positional(56294995342131.5, precision=3)\n        '56294995342131.5'\n\n    The float printing routines use an accurate but much more computationally\n    demanding algorithm to compute the number of digits after the decimal\n    point.\n\n    Alternatively, Python's builtin `round` function uses a more accurate\n    but slower algorithm for 64-bit floating point values:\n\n        >>> round(56294995342131.5, 3)\n        56294995342131.5\n        >>> np.round(16.055, 2), round(16.055, 2)  # equals 16.0549999999999997\n        (16.06, 16.05)\n\n\n    References\n    ----------\n    .. [1] \"Lecture Notes on the Status of IEEE 754\", William Kahan,\n           https://people.eecs.berkeley.edu/~wkahan/ieee754status/IEEE754.PDF\n    .. [2] \"How Futile are Mindless Assessments of\n           Roundoff in Floating-Point Computation?\", William Kahan,\n           https://people.eecs.berkeley.edu/~wkahan/Mindless.pdf\n\n    Examples\n    --------\n    >>> np.around([0.37, 1.64])\n    array([0.,  2.])\n    >>> np.around([0.37, 1.64], decimals=1)\n    array([0.4,  1.6])\n    >>> np.around([.5, 1.5, 2.5, 3.5, 4.5]) # rounds to nearest even value\n    array([0.,  2.,  2.,  4.,  4.])\n    >>> np.around([1,2,3,11], decimals=1) # ndarray of ints is returned\n    array([ 1,  2,  3, 11])\n    >>> np.around([1,2,3,11], decimals=-1)\n    array([ 0,  0,  0, 10])\n\n    \"\"\"\n    return _wrapfunc(a, 'round', decimals=decimals, out=out)\n\n\ndef _mean_dispatcher(a, axis=None, dtype=None, out=None, keepdims=None, *,\n                     where=None):\n    return (a, where, out)\n\n\n@array_function_dispatch(_mean_dispatcher)\ndef mean(a, axis=None, dtype=None, out=None, keepdims=np._NoValue, *,\n         where=np._NoValue):\n    \"\"\"\n    Compute the arithmetic mean along the specified axis.\n\n    Returns the average of the array elements.  The average is taken over\n    the flattened array by default, otherwise over the specified axis.\n    `float64` intermediate and return values are used for integer inputs.\n\n    Parameters\n    ----------\n    a : array_like\n        Array containing numbers whose mean is desired. If `a` is not an\n        array, a conversion is attempted.\n    axis : None or int or tuple of ints, optional\n        Axis or axes along which the means are computed. The default is to\n        compute the mean of the flattened array.\n\n        .. versionadded:: 1.7.0\n\n        If this is a tuple of ints, a mean is performed over multiple axes,\n        instead of a single axis or all the axes as before.\n    dtype : data-type, optional\n        Type to use in computing the mean.  For integer inputs, the default\n        is `float64`; for floating point inputs, it is the same as the\n        input dtype.\n    out : ndarray, optional\n        Alternate output array in which to place the result.  The default\n        is ``None``; if provided, it must have the same shape as the\n        expected output, but the type will be cast if necessary.\n        See :ref:`ufuncs-output-type` for more details.\n\n    keepdims : bool, optional\n        If this is set to True, the axes which are reduced are left\n        in the result as dimensions with size one. With this option,\n        the result will broadcast correctly against the input array.\n\n        If the default value is passed, then `keepdims` will not be\n        passed through to the `mean` method of sub-classes of\n        `ndarray`, however any non-default value will be.  If the\n        sub-class' method does not implement `keepdims` any\n        exceptions will be raised.\n\n    where : array_like of bool, optional\n        Elements to include in the mean. See `~numpy.ufunc.reduce` for details.\n\n        .. versionadded:: 1.20.0\n\n    Returns\n    -------\n    m : ndarray, see dtype parameter above\n        If `out=None`, returns a new array containing the mean values,\n        otherwise a reference to the output array is returned.\n\n    See Also\n    --------\n    average : Weighted average\n    std, var, nanmean, nanstd, nanvar\n\n    Notes\n    -----\n    The arithmetic mean is the sum of the elements along the axis divided\n    by the number of elements.\n\n    Note that for floating-point input, the mean is computed using the\n    same precision the input has.  Depending on the input data, this can\n    cause the results to be inaccurate, especially for `float32` (see\n    example below).  Specifying a higher-precision accumulator using the\n    `dtype` keyword can alleviate this issue.\n\n    By default, `float16` results are computed using `float32` intermediates\n    for extra precision.\n\n    Examples\n    --------\n    >>> a = np.array([[1, 2], [3, 4]])\n    >>> np.mean(a)\n    2.5\n    >>> np.mean(a, axis=0)\n    array([2., 3.])\n    >>> np.mean(a, axis=1)\n    array([1.5, 3.5])\n\n    In single precision, `mean` can be inaccurate:\n\n    >>> a = np.zeros((2, 512*512), dtype=np.float32)\n    >>> a[0, :] = 1.0\n    >>> a[1, :] = 0.1\n    >>> np.mean(a)\n    0.54999924\n\n    Computing the mean in float64 is more accurate:\n\n    >>> np.mean(a, dtype=np.float64)\n    0.55000000074505806 # may vary\n\n    Specifying a where argument:\n    >>> a = np.array([[5, 9, 13], [14, 10, 12], [11, 15, 19]])\n    >>> np.mean(a)\n    12.0\n    >>> np.mean(a, where=[[True], [False], [False]])\n    9.0\n\n    \"\"\"\n    kwargs = {}\n    if keepdims is not np._NoValue:\n        kwargs['keepdims'] = keepdims\n    if where is not np._NoValue:\n        kwargs['where'] = where\n    if type(a) is not mu.ndarray:\n        try:\n            mean = a.mean\n        except AttributeError:\n            pass\n        else:\n            return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n\n    return _methods._mean(a, axis=axis, dtype=dtype,\n                          out=out, **kwargs)\n\n\ndef _std_dispatcher(a, axis=None, dtype=None, out=None, ddof=None,\n                    keepdims=None, *, where=None):\n    return (a, where, out)\n\n\n@array_function_dispatch(_std_dispatcher)\ndef std(a, axis=None, dtype=None, out=None, ddof=0, keepdims=np._NoValue, *,\n        where=np._NoValue):\n    \"\"\"\n    Compute the standard deviation along the specified axis.\n\n    Returns the standard deviation, a measure of the spread of a distribution,\n    of the array elements. The standard deviation is computed for the\n    flattened array by default, otherwise over the specified axis.\n\n    Parameters\n    ----------\n    a : array_like\n        Calculate the standard deviation of these values.\n    axis : None or int or tuple of ints, optional\n        Axis or axes along which the standard deviation is computed. The\n        default is to compute the standard deviation of the flattened array.\n\n        .. versionadded:: 1.7.0\n\n        If this is a tuple of ints, a standard deviation is performed over\n        multiple axes, instead of a single axis or all the axes as before.\n    dtype : dtype, optional\n        Type to use in computing the standard deviation. For arrays of\n        integer type the default is float64, for arrays of float types it is\n        the same as the array type.\n    out : ndarray, optional\n        Alternative output array in which to place the result. It must have\n        the same shape as the expected output but the type (of the calculated\n        values) will be cast if necessary.\n    ddof : int, optional\n        Means Delta Degrees of Freedom.  The divisor used in calculations\n        is ``N - ddof``, where ``N`` represents the number of elements.\n        By default `ddof` is zero.\n    keepdims : bool, optional\n        If this is set to True, the axes which are reduced are left\n        in the result as dimensions with size one. With this option,\n        the result will broadcast correctly against the input array.\n\n        If the default value is passed, then `keepdims` will not be\n        passed through to the `std` method of sub-classes of\n        `ndarray`, however any non-default value will be.  If the\n        sub-class' method does not implement `keepdims` any\n        exceptions will be raised.\n\n    where : array_like of bool, optional\n        Elements to include in the standard deviation.\n        See `~numpy.ufunc.reduce` for details.\n\n        .. versionadded:: 1.20.0\n\n    Returns\n    -------\n    standard_deviation : ndarray, see dtype parameter above.\n        If `out` is None, return a new array containing the standard deviation,\n        otherwise return a reference to the output array.\n\n    See Also\n    --------\n    var, mean, nanmean, nanstd, nanvar\n    :ref:`ufuncs-output-type`\n\n    Notes\n    -----\n    The standard deviation is the square root of the average of the squared\n    deviations from the mean, i.e., ``std = sqrt(mean(x))``, where\n    ``x = abs(a - a.mean())**2``.\n\n    The average squared deviation is typically calculated as ``x.sum() / N``,\n    where ``N = len(x)``. If, however, `ddof` is specified, the divisor\n    ``N - ddof`` is used instead. In standard statistical practice, ``ddof=1``\n    provides an unbiased estimator of the variance of the infinite population.\n    ``ddof=0`` provides a maximum likelihood estimate of the variance for\n    normally distributed variables. The standard deviation computed in this\n    function is the square root of the estimated variance, so even with\n    ``ddof=1``, it will not be an unbiased estimate of the standard deviation\n    per se.\n\n    Note that, for complex numbers, `std` takes the absolute\n    value before squaring, so that the result is always real and nonnegative.\n\n    For floating-point input, the *std* is computed using the same\n    precision the input has. Depending on the input data, this can cause\n    the results to be inaccurate, especially for float32 (see example below).\n    Specifying a higher-accuracy accumulator using the `dtype` keyword can\n    alleviate this issue.\n\n    Examples\n    --------\n    >>> a = np.array([[1, 2], [3, 4]])\n    >>> np.std(a)\n    1.1180339887498949 # may vary\n    >>> np.std(a, axis=0)\n    array([1.,  1.])\n    >>> np.std(a, axis=1)\n    array([0.5,  0.5])\n\n    In single precision, std() can be inaccurate:\n\n    >>> a = np.zeros((2, 512*512), dtype=np.float32)\n    >>> a[0, :] = 1.0\n    >>> a[1, :] = 0.1\n    >>> np.std(a)\n    0.45000005\n\n    Computing the standard deviation in float64 is more accurate:\n\n    >>> np.std(a, dtype=np.float64)\n    0.44999999925494177 # may vary\n\n    Specifying a where argument:\n\n    >>> a = np.array([[14, 8, 11, 10], [7, 9, 10, 11], [10, 15, 5, 10]])\n    >>> np.std(a)\n    2.614064523559687 # may vary\n    >>> np.std(a, where=[[True], [True], [False]])\n    2.0\n\n    \"\"\"\n    kwargs = {}\n    if keepdims is not np._NoValue:\n        kwargs['keepdims'] = keepdims\n    if where is not np._NoValue:\n        kwargs['where'] = where\n    if type(a) is not mu.ndarray:\n        try:\n            std = a.std\n        except AttributeError:\n            pass\n        else:\n            return std(axis=axis, dtype=dtype, out=out, ddof=ddof, **kwargs)\n\n    return _methods._std(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n                         **kwargs)\n\n\ndef _var_dispatcher(a, axis=None, dtype=None, out=None, ddof=None,\n                    keepdims=None, *, where=None):\n    return (a, where, out)\n\n\n@array_function_dispatch(_var_dispatcher)\ndef var(a, axis=None, dtype=None, out=None, ddof=0, keepdims=np._NoValue, *,\n        where=np._NoValue):\n    \"\"\"\n    Compute the variance along the specified axis.\n\n    Returns the variance of the array elements, a measure of the spread of a\n    distribution.  The variance is computed for the flattened array by\n    default, otherwise over the specified axis.\n\n    Parameters\n    ----------\n    a : array_like\n        Array containing numbers whose variance is desired.  If `a` is not an\n        array, a conversion is attempted.\n    axis : None or int or tuple of ints, optional\n        Axis or axes along which the variance is computed.  The default is to\n        compute the variance of the flattened array.\n\n        .. versionadded:: 1.7.0\n\n        If this is a tuple of ints, a variance is performed over multiple axes,\n        instead of a single axis or all the axes as before.\n    dtype : data-type, optional\n        Type to use in computing the variance.  For arrays of integer type\n        the default is `float64`; for arrays of float types it is the same as\n        the array type.\n    out : ndarray, optional\n        Alternate output array in which to place the result.  It must have\n        the same shape as the expected output, but the type is cast if\n        necessary.\n    ddof : int, optional\n        \"Delta Degrees of Freedom\": the divisor used in the calculation is\n        ``N - ddof``, where ``N`` represents the number of elements. By\n        default `ddof` is zero.\n    keepdims : bool, optional\n        If this is set to True, the axes which are reduced are left\n        in the result as dimensions with size one. With this option,\n        the result will broadcast correctly against the input array.\n\n        If the default value is passed, then `keepdims` will not be\n        passed through to the `var` method of sub-classes of\n        `ndarray`, however any non-default value will be.  If the\n        sub-class' method does not implement `keepdims` any\n        exceptions will be raised.\n\n    where : array_like of bool, optional\n        Elements to include in the variance. See `~numpy.ufunc.reduce` for\n        details.\n\n        .. versionadded:: 1.20.0\n\n    Returns\n    -------\n    variance : ndarray, see dtype parameter above\n        If ``out=None``, returns a new array containing the variance;\n        otherwise, a reference to the output array is returned.\n\n    See Also\n    --------\n    std, mean, nanmean, nanstd, nanvar\n    :ref:`ufuncs-output-type`\n\n    Notes\n    -----\n    The variance is the average of the squared deviations from the mean,\n    i.e.,  ``var = mean(x)``, where ``x = abs(a - a.mean())**2``.\n\n    The mean is typically calculated as ``x.sum() / N``, where ``N = len(x)``.\n    If, however, `ddof` is specified, the divisor ``N - ddof`` is used\n    instead.  In standard statistical practice, ``ddof=1`` provides an\n    unbiased estimator of the variance of a hypothetical infinite population.\n    ``ddof=0`` provides a maximum likelihood estimate of the variance for\n    normally distributed variables.\n\n    Note that for complex numbers, the absolute value is taken before\n    squaring, so that the result is always real and nonnegative.\n\n    For floating-point input, the variance is computed using the same\n    precision the input has.  Depending on the input data, this can cause\n    the results to be inaccurate, especially for `float32` (see example\n    below).  Specifying a higher-accuracy accumulator using the ``dtype``\n    keyword can alleviate this issue.\n\n    Examples\n    --------\n    >>> a = np.array([[1, 2], [3, 4]])\n    >>> np.var(a)\n    1.25\n    >>> np.var(a, axis=0)\n    array([1.,  1.])\n    >>> np.var(a, axis=1)\n    array([0.25,  0.25])\n\n    In single precision, var() can be inaccurate:\n\n    >>> a = np.zeros((2, 512*512), dtype=np.float32)\n    >>> a[0, :] = 1.0\n    >>> a[1, :] = 0.1\n    >>> np.var(a)\n    0.20250003\n\n    Computing the variance in float64 is more accurate:\n\n    >>> np.var(a, dtype=np.float64)\n    0.20249999932944759 # may vary\n    >>> ((1-0.55)**2 + (0.1-0.55)**2)/2\n    0.2025\n\n    Specifying a where argument:\n\n    >>> a = np.array([[14, 8, 11, 10], [7, 9, 10, 11], [10, 15, 5, 10]])\n    >>> np.var(a)\n    6.833333333333333 # may vary\n    >>> np.var(a, where=[[True], [True], [False]])\n    4.0\n\n    \"\"\"\n    kwargs = {}\n    if keepdims is not np._NoValue:\n        kwargs['keepdims'] = keepdims\n    if where is not np._NoValue:\n        kwargs['where'] = where\n\n    if type(a) is not mu.ndarray:\n        try:\n            var = a.var\n\n        except AttributeError:\n            pass\n        else:\n            return var(axis=axis, dtype=dtype, out=out, ddof=ddof, **kwargs)\n\n    return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n                         **kwargs)\n\n\n# Aliases of other functions. These have their own definitions only so that\n# they can have unique docstrings.\n\n@array_function_dispatch(_around_dispatcher)\ndef round_(a, decimals=0, out=None):\n    \"\"\"\n    Round an array to the given number of decimals.\n\n    See Also\n    --------\n    around : equivalent function; see for details.\n    \"\"\"\n    return around(a, decimals=decimals, out=out)\n\n\n@array_function_dispatch(_prod_dispatcher, verify=False)\ndef product(*args, **kwargs):\n    \"\"\"\n    Return the product of array elements over a given axis.\n\n    See Also\n    --------\n    prod : equivalent function; see for details.\n    \"\"\"\n    return prod(*args, **kwargs)\n\n\n@array_function_dispatch(_cumprod_dispatcher, verify=False)\ndef cumproduct(*args, **kwargs):\n    \"\"\"\n    Return the cumulative product over the given axis.\n\n    See Also\n    --------\n    cumprod : equivalent function; see for details.\n    \"\"\"\n    return cumprod(*args, **kwargs)\n\n\n@array_function_dispatch(_any_dispatcher, verify=False)\ndef sometrue(*args, **kwargs):\n    \"\"\"\n    Check whether some values are true.\n\n    Refer to `any` for full documentation.\n\n    See Also\n    --------\n    any : equivalent function; see for details.\n    \"\"\"\n    return any(*args, **kwargs)\n\n\n@array_function_dispatch(_all_dispatcher, verify=False)\ndef alltrue(*args, **kwargs):\n    \"\"\"\n    Check if all elements of input array are true.\n\n    See Also\n    --------\n    numpy.all : Equivalent function; see for details.\n    \"\"\"\n    return all(*args, **kwargs)\n", 3789], "/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/abc.py": ["# Copyright 2007 Google, Inc. All Rights Reserved.\n# Licensed to PSF under a Contributor Agreement.\n\n\"\"\"Abstract Base Classes (ABCs) according to PEP 3119.\"\"\"\n\n\ndef abstractmethod(funcobj):\n    \"\"\"A decorator indicating abstract methods.\n\n    Requires that the metaclass is ABCMeta or derived from it.  A\n    class that has a metaclass derived from ABCMeta cannot be\n    instantiated unless all of its abstract methods are overridden.\n    The abstract methods can be called using any of the normal\n    'super' call mechanisms.  abstractmethod() may be used to declare\n    abstract methods for properties and descriptors.\n\n    Usage:\n\n        class C(metaclass=ABCMeta):\n            @abstractmethod\n            def my_abstract_method(self, ...):\n                ...\n    \"\"\"\n    funcobj.__isabstractmethod__ = True\n    return funcobj\n\n\nclass abstractclassmethod(classmethod):\n    \"\"\"A decorator indicating abstract classmethods.\n\n    Deprecated, use 'classmethod' with 'abstractmethod' instead:\n\n        class C(ABC):\n            @classmethod\n            @abstractmethod\n            def my_abstract_classmethod(cls, ...):\n                ...\n\n    \"\"\"\n\n    __isabstractmethod__ = True\n\n    def __init__(self, callable):\n        callable.__isabstractmethod__ = True\n        super().__init__(callable)\n\n\nclass abstractstaticmethod(staticmethod):\n    \"\"\"A decorator indicating abstract staticmethods.\n\n    Deprecated, use 'staticmethod' with 'abstractmethod' instead:\n\n        class C(ABC):\n            @staticmethod\n            @abstractmethod\n            def my_abstract_staticmethod(...):\n                ...\n\n    \"\"\"\n\n    __isabstractmethod__ = True\n\n    def __init__(self, callable):\n        callable.__isabstractmethod__ = True\n        super().__init__(callable)\n\n\nclass abstractproperty(property):\n    \"\"\"A decorator indicating abstract properties.\n\n    Deprecated, use 'property' with 'abstractmethod' instead:\n\n        class C(ABC):\n            @property\n            @abstractmethod\n            def my_abstract_property(self):\n                ...\n\n    \"\"\"\n\n    __isabstractmethod__ = True\n\n\ntry:\n    from _abc import (get_cache_token, _abc_init, _abc_register,\n                      _abc_instancecheck, _abc_subclasscheck, _get_dump,\n                      _reset_registry, _reset_caches)\nexcept ImportError:\n    from _py_abc import ABCMeta, get_cache_token\n    ABCMeta.__module__ = 'abc'\nelse:\n    class ABCMeta(type):\n        \"\"\"Metaclass for defining Abstract Base Classes (ABCs).\n\n        Use this metaclass to create an ABC.  An ABC can be subclassed\n        directly, and then acts as a mix-in class.  You can also register\n        unrelated concrete classes (even built-in classes) and unrelated\n        ABCs as 'virtual subclasses' -- these and their descendants will\n        be considered subclasses of the registering ABC by the built-in\n        issubclass() function, but the registering ABC won't show up in\n        their MRO (Method Resolution Order) nor will method\n        implementations defined by the registering ABC be callable (not\n        even via super()).\n        \"\"\"\n        def __new__(mcls, name, bases, namespace, **kwargs):\n            cls = super().__new__(mcls, name, bases, namespace, **kwargs)\n            _abc_init(cls)\n            return cls\n\n        def register(cls, subclass):\n            \"\"\"Register a virtual subclass of an ABC.\n\n            Returns the subclass, to allow usage as a class decorator.\n            \"\"\"\n            return _abc_register(cls, subclass)\n\n        def __instancecheck__(cls, instance):\n            \"\"\"Override for isinstance(instance, cls).\"\"\"\n            return _abc_instancecheck(cls, instance)\n\n        def __subclasscheck__(cls, subclass):\n            \"\"\"Override for issubclass(subclass, cls).\"\"\"\n            return _abc_subclasscheck(cls, subclass)\n\n        def _dump_registry(cls, file=None):\n            \"\"\"Debug helper to print the ABC registry.\"\"\"\n            print(f\"Class: {cls.__module__}.{cls.__qualname__}\", file=file)\n            print(f\"Inv. counter: {get_cache_token()}\", file=file)\n            (_abc_registry, _abc_cache, _abc_negative_cache,\n             _abc_negative_cache_version) = _get_dump(cls)\n            print(f\"_abc_registry: {_abc_registry!r}\", file=file)\n            print(f\"_abc_cache: {_abc_cache!r}\", file=file)\n            print(f\"_abc_negative_cache: {_abc_negative_cache!r}\", file=file)\n            print(f\"_abc_negative_cache_version: {_abc_negative_cache_version!r}\",\n                  file=file)\n\n        def _abc_registry_clear(cls):\n            \"\"\"Clear the registry (for debugging or testing).\"\"\"\n            _reset_registry(cls)\n\n        def _abc_caches_clear(cls):\n            \"\"\"Clear the caches (for debugging or testing).\"\"\"\n            _reset_caches(cls)\n\n\nclass ABC(metaclass=ABCMeta):\n    \"\"\"Helper class that provides a standard way to create an ABC using\n    inheritance.\n    \"\"\"\n    __slots__ = ()\n", 150], "/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py": ["# Copyright 2001-2019 by Vinay Sajip. All Rights Reserved.\n#\n# Permission to use, copy, modify, and distribute this software and its\n# documentation for any purpose and without fee is hereby granted,\n# provided that the above copyright notice appear in all copies and that\n# both that copyright notice and this permission notice appear in\n# supporting documentation, and that the name of Vinay Sajip\n# not be used in advertising or publicity pertaining to distribution\n# of the software without specific, written prior permission.\n# VINAY SAJIP DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE, INCLUDING\n# ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL\n# VINAY SAJIP BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR\n# ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER\n# IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT\n# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n\n\"\"\"\nLogging package for Python. Based on PEP 282 and comments thereto in\ncomp.lang.python.\n\nCopyright (C) 2001-2019 Vinay Sajip. All Rights Reserved.\n\nTo use, simply 'import logging' and log away!\n\"\"\"\n\nimport sys, os, time, io, re, traceback, warnings, weakref, collections.abc\n\nfrom string import Template\nfrom string import Formatter as StrFormatter\n\n\n__all__ = ['BASIC_FORMAT', 'BufferingFormatter', 'CRITICAL', 'DEBUG', 'ERROR',\n           'FATAL', 'FileHandler', 'Filter', 'Formatter', 'Handler', 'INFO',\n           'LogRecord', 'Logger', 'LoggerAdapter', 'NOTSET', 'NullHandler',\n           'StreamHandler', 'WARN', 'WARNING', 'addLevelName', 'basicConfig',\n           'captureWarnings', 'critical', 'debug', 'disable', 'error',\n           'exception', 'fatal', 'getLevelName', 'getLogger', 'getLoggerClass',\n           'info', 'log', 'makeLogRecord', 'setLoggerClass', 'shutdown',\n           'warn', 'warning', 'getLogRecordFactory', 'setLogRecordFactory',\n           'lastResort', 'raiseExceptions']\n\nimport threading\n\n__author__  = \"Vinay Sajip <vinay_sajip@red-dove.com>\"\n__status__  = \"production\"\n# The following module attributes are no longer updated.\n__version__ = \"0.5.1.2\"\n__date__    = \"07 February 2010\"\n\n#---------------------------------------------------------------------------\n#   Miscellaneous module data\n#---------------------------------------------------------------------------\n\n#\n#_startTime is used as the base when calculating the relative time of events\n#\n_startTime = time.time()\n\n#\n#raiseExceptions is used to see if exceptions during handling should be\n#propagated\n#\nraiseExceptions = True\n\n#\n# If you don't want threading information in the log, set this to zero\n#\nlogThreads = True\n\n#\n# If you don't want multiprocessing information in the log, set this to zero\n#\nlogMultiprocessing = True\n\n#\n# If you don't want process information in the log, set this to zero\n#\nlogProcesses = True\n\n#---------------------------------------------------------------------------\n#   Level related stuff\n#---------------------------------------------------------------------------\n#\n# Default levels and level names, these can be replaced with any positive set\n# of values having corresponding names. There is a pseudo-level, NOTSET, which\n# is only really there as a lower limit for user-defined levels. Handlers and\n# loggers are initialized with NOTSET so that they will log all messages, even\n# at user-defined levels.\n#\n\nCRITICAL = 50\nFATAL = CRITICAL\nERROR = 40\nWARNING = 30\nWARN = WARNING\nINFO = 20\nDEBUG = 10\nNOTSET = 0\n\n_levelToName = {\n    CRITICAL: 'CRITICAL',\n    ERROR: 'ERROR',\n    WARNING: 'WARNING',\n    INFO: 'INFO',\n    DEBUG: 'DEBUG',\n    NOTSET: 'NOTSET',\n}\n_nameToLevel = {\n    'CRITICAL': CRITICAL,\n    'FATAL': FATAL,\n    'ERROR': ERROR,\n    'WARN': WARNING,\n    'WARNING': WARNING,\n    'INFO': INFO,\n    'DEBUG': DEBUG,\n    'NOTSET': NOTSET,\n}\n\ndef getLevelName(level):\n    \"\"\"\n    Return the textual or numeric representation of logging level 'level'.\n\n    If the level is one of the predefined levels (CRITICAL, ERROR, WARNING,\n    INFO, DEBUG) then you get the corresponding string. If you have\n    associated levels with names using addLevelName then the name you have\n    associated with 'level' is returned.\n\n    If a numeric value corresponding to one of the defined levels is passed\n    in, the corresponding string representation is returned.\n\n    If a string representation of the level is passed in, the corresponding\n    numeric value is returned.\n\n    If no matching numeric or string value is passed in, the string\n    'Level %s' % level is returned.\n    \"\"\"\n    # See Issues #22386, #27937 and #29220 for why it's this way\n    result = _levelToName.get(level)\n    if result is not None:\n        return result\n    result = _nameToLevel.get(level)\n    if result is not None:\n        return result\n    return \"Level %s\" % level\n\ndef addLevelName(level, levelName):\n    \"\"\"\n    Associate 'levelName' with 'level'.\n\n    This is used when converting levels to text during message formatting.\n    \"\"\"\n    _acquireLock()\n    try:    #unlikely to cause an exception, but you never know...\n        _levelToName[level] = levelName\n        _nameToLevel[levelName] = level\n    finally:\n        _releaseLock()\n\nif hasattr(sys, '_getframe'):\n    currentframe = lambda: sys._getframe(3)\nelse: #pragma: no cover\n    def currentframe():\n        \"\"\"Return the frame object for the caller's stack frame.\"\"\"\n        try:\n            raise Exception\n        except Exception:\n            return sys.exc_info()[2].tb_frame.f_back\n\n#\n# _srcfile is used when walking the stack to check when we've got the first\n# caller stack frame, by skipping frames whose filename is that of this\n# module's source. It therefore should contain the filename of this module's\n# source file.\n#\n# Ordinarily we would use __file__ for this, but frozen modules don't always\n# have __file__ set, for some reason (see Issue #21736). Thus, we get the\n# filename from a handy code object from a function defined in this module.\n# (There's no particular reason for picking addLevelName.)\n#\n\n_srcfile = os.path.normcase(addLevelName.__code__.co_filename)\n\n# _srcfile is only used in conjunction with sys._getframe().\n# To provide compatibility with older versions of Python, set _srcfile\n# to None if _getframe() is not available; this value will prevent\n# findCaller() from being called. You can also do this if you want to avoid\n# the overhead of fetching caller information, even when _getframe() is\n# available.\n#if not hasattr(sys, '_getframe'):\n#    _srcfile = None\n\n\ndef _checkLevel(level):\n    if isinstance(level, int):\n        rv = level\n    elif str(level) == level:\n        if level not in _nameToLevel:\n            raise ValueError(\"Unknown level: %r\" % level)\n        rv = _nameToLevel[level]\n    else:\n        raise TypeError(\"Level not an integer or a valid string: %r\" % level)\n    return rv\n\n#---------------------------------------------------------------------------\n#   Thread-related stuff\n#---------------------------------------------------------------------------\n\n#\n#_lock is used to serialize access to shared data structures in this module.\n#This needs to be an RLock because fileConfig() creates and configures\n#Handlers, and so might arbitrary user threads. Since Handler code updates the\n#shared dictionary _handlers, it needs to acquire the lock. But if configuring,\n#the lock would already have been acquired - so we need an RLock.\n#The same argument applies to Loggers and Manager.loggerDict.\n#\n_lock = threading.RLock()\n\ndef _acquireLock():\n    \"\"\"\n    Acquire the module-level lock for serializing access to shared data.\n\n    This should be released with _releaseLock().\n    \"\"\"\n    if _lock:\n        _lock.acquire()\n\ndef _releaseLock():\n    \"\"\"\n    Release the module-level lock acquired by calling _acquireLock().\n    \"\"\"\n    if _lock:\n        _lock.release()\n\n\n# Prevent a held logging lock from blocking a child from logging.\n\nif not hasattr(os, 'register_at_fork'):  # Windows and friends.\n    def _register_at_fork_reinit_lock(instance):\n        pass  # no-op when os.register_at_fork does not exist.\nelse:\n    # A collection of instances with a _at_fork_reinit method (logging.Handler)\n    # to be called in the child after forking.  The weakref avoids us keeping\n    # discarded Handler instances alive.\n    _at_fork_reinit_lock_weakset = weakref.WeakSet()\n\n    def _register_at_fork_reinit_lock(instance):\n        _acquireLock()\n        try:\n            _at_fork_reinit_lock_weakset.add(instance)\n        finally:\n            _releaseLock()\n\n    def _after_at_fork_child_reinit_locks():\n        for handler in _at_fork_reinit_lock_weakset:\n            handler._at_fork_reinit()\n\n        # _acquireLock() was called in the parent before forking.\n        # The lock is reinitialized to unlocked state.\n        _lock._at_fork_reinit()\n\n    os.register_at_fork(before=_acquireLock,\n                        after_in_child=_after_at_fork_child_reinit_locks,\n                        after_in_parent=_releaseLock)\n\n\n#---------------------------------------------------------------------------\n#   The logging record\n#---------------------------------------------------------------------------\n\nclass LogRecord(object):\n    \"\"\"\n    A LogRecord instance represents an event being logged.\n\n    LogRecord instances are created every time something is logged. They\n    contain all the information pertinent to the event being logged. The\n    main information passed in is in msg and args, which are combined\n    using str(msg) % args to create the message field of the record. The\n    record also includes information such as when the record was created,\n    the source line where the logging call was made, and any exception\n    information to be logged.\n    \"\"\"\n    def __init__(self, name, level, pathname, lineno,\n                 msg, args, exc_info, func=None, sinfo=None, **kwargs):\n        \"\"\"\n        Initialize a logging record with interesting information.\n        \"\"\"\n        ct = time.time()\n        self.name = name\n        self.msg = msg\n        #\n        # The following statement allows passing of a dictionary as a sole\n        # argument, so that you can do something like\n        #  logging.debug(\"a %(a)d b %(b)s\", {'a':1, 'b':2})\n        # Suggested by Stefan Behnel.\n        # Note that without the test for args[0], we get a problem because\n        # during formatting, we test to see if the arg is present using\n        # 'if self.args:'. If the event being logged is e.g. 'Value is %d'\n        # and if the passed arg fails 'if self.args:' then no formatting\n        # is done. For example, logger.warning('Value is %d', 0) would log\n        # 'Value is %d' instead of 'Value is 0'.\n        # For the use case of passing a dictionary, this should not be a\n        # problem.\n        # Issue #21172: a request was made to relax the isinstance check\n        # to hasattr(args[0], '__getitem__'). However, the docs on string\n        # formatting still seem to suggest a mapping object is required.\n        # Thus, while not removing the isinstance check, it does now look\n        # for collections.abc.Mapping rather than, as before, dict.\n        if (args and len(args) == 1 and isinstance(args[0], collections.abc.Mapping)\n            and args[0]):\n            args = args[0]\n        self.args = args\n        self.levelname = getLevelName(level)\n        self.levelno = level\n        self.pathname = pathname\n        try:\n            self.filename = os.path.basename(pathname)\n            self.module = os.path.splitext(self.filename)[0]\n        except (TypeError, ValueError, AttributeError):\n            self.filename = pathname\n            self.module = \"Unknown module\"\n        self.exc_info = exc_info\n        self.exc_text = None      # used to cache the traceback text\n        self.stack_info = sinfo\n        self.lineno = lineno\n        self.funcName = func\n        self.created = ct\n        self.msecs = (ct - int(ct)) * 1000\n        self.relativeCreated = (self.created - _startTime) * 1000\n        if logThreads:\n            self.thread = threading.get_ident()\n            self.threadName = threading.current_thread().name\n        else: # pragma: no cover\n            self.thread = None\n            self.threadName = None\n        if not logMultiprocessing: # pragma: no cover\n            self.processName = None\n        else:\n            self.processName = 'MainProcess'\n            mp = sys.modules.get('multiprocessing')\n            if mp is not None:\n                # Errors may occur if multiprocessing has not finished loading\n                # yet - e.g. if a custom import hook causes third-party code\n                # to run when multiprocessing calls import. See issue 8200\n                # for an example\n                try:\n                    self.processName = mp.current_process().name\n                except Exception: #pragma: no cover\n                    pass\n        if logProcesses and hasattr(os, 'getpid'):\n            self.process = os.getpid()\n        else:\n            self.process = None\n\n    def __repr__(self):\n        return '<LogRecord: %s, %s, %s, %s, \"%s\">'%(self.name, self.levelno,\n            self.pathname, self.lineno, self.msg)\n\n    def getMessage(self):\n        \"\"\"\n        Return the message for this LogRecord.\n\n        Return the message for this LogRecord after merging any user-supplied\n        arguments with the message.\n        \"\"\"\n        msg = str(self.msg)\n        if self.args:\n            msg = msg % self.args\n        return msg\n\n#\n#   Determine which class to use when instantiating log records.\n#\n_logRecordFactory = LogRecord\n\ndef setLogRecordFactory(factory):\n    \"\"\"\n    Set the factory to be used when instantiating a log record.\n\n    :param factory: A callable which will be called to instantiate\n    a log record.\n    \"\"\"\n    global _logRecordFactory\n    _logRecordFactory = factory\n\ndef getLogRecordFactory():\n    \"\"\"\n    Return the factory to be used when instantiating a log record.\n    \"\"\"\n\n    return _logRecordFactory\n\ndef makeLogRecord(dict):\n    \"\"\"\n    Make a LogRecord whose attributes are defined by the specified dictionary,\n    This function is useful for converting a logging event received over\n    a socket connection (which is sent as a dictionary) into a LogRecord\n    instance.\n    \"\"\"\n    rv = _logRecordFactory(None, None, \"\", 0, \"\", (), None, None)\n    rv.__dict__.update(dict)\n    return rv\n\n\n#---------------------------------------------------------------------------\n#   Formatter classes and functions\n#---------------------------------------------------------------------------\n_str_formatter = StrFormatter()\ndel StrFormatter\n\n\nclass PercentStyle(object):\n\n    default_format = '%(message)s'\n    asctime_format = '%(asctime)s'\n    asctime_search = '%(asctime)'\n    validation_pattern = re.compile(r'%\\(\\w+\\)[#0+ -]*(\\*|\\d+)?(\\.(\\*|\\d+))?[diouxefgcrsa%]', re.I)\n\n    def __init__(self, fmt):\n        self._fmt = fmt or self.default_format\n\n    def usesTime(self):\n        return self._fmt.find(self.asctime_search) >= 0\n\n    def validate(self):\n        \"\"\"Validate the input format, ensure it matches the correct style\"\"\"\n        if not self.validation_pattern.search(self._fmt):\n            raise ValueError(\"Invalid format '%s' for '%s' style\" % (self._fmt, self.default_format[0]))\n\n    def _format(self, record):\n        return self._fmt % record.__dict__\n\n    def format(self, record):\n        try:\n            return self._format(record)\n        except KeyError as e:\n            raise ValueError('Formatting field not found in record: %s' % e)\n\n\nclass StrFormatStyle(PercentStyle):\n    default_format = '{message}'\n    asctime_format = '{asctime}'\n    asctime_search = '{asctime'\n\n    fmt_spec = re.compile(r'^(.?[<>=^])?[+ -]?#?0?(\\d+|{\\w+})?[,_]?(\\.(\\d+|{\\w+}))?[bcdefgnosx%]?$', re.I)\n    field_spec = re.compile(r'^(\\d+|\\w+)(\\.\\w+|\\[[^]]+\\])*$')\n\n    def _format(self, record):\n        return self._fmt.format(**record.__dict__)\n\n    def validate(self):\n        \"\"\"Validate the input format, ensure it is the correct string formatting style\"\"\"\n        fields = set()\n        try:\n            for _, fieldname, spec, conversion in _str_formatter.parse(self._fmt):\n                if fieldname:\n                    if not self.field_spec.match(fieldname):\n                        raise ValueError('invalid field name/expression: %r' % fieldname)\n                    fields.add(fieldname)\n                if conversion and conversion not in 'rsa':\n                    raise ValueError('invalid conversion: %r' % conversion)\n                if spec and not self.fmt_spec.match(spec):\n                    raise ValueError('bad specifier: %r' % spec)\n        except ValueError as e:\n            raise ValueError('invalid format: %s' % e)\n        if not fields:\n            raise ValueError('invalid format: no fields')\n\n\nclass StringTemplateStyle(PercentStyle):\n    default_format = '${message}'\n    asctime_format = '${asctime}'\n    asctime_search = '${asctime}'\n\n    def __init__(self, fmt):\n        self._fmt = fmt or self.default_format\n        self._tpl = Template(self._fmt)\n\n    def usesTime(self):\n        fmt = self._fmt\n        return fmt.find('$asctime') >= 0 or fmt.find(self.asctime_format) >= 0\n\n    def validate(self):\n        pattern = Template.pattern\n        fields = set()\n        for m in pattern.finditer(self._fmt):\n            d = m.groupdict()\n            if d['named']:\n                fields.add(d['named'])\n            elif d['braced']:\n                fields.add(d['braced'])\n            elif m.group(0) == '$':\n                raise ValueError('invalid format: bare \\'$\\' not allowed')\n        if not fields:\n            raise ValueError('invalid format: no fields')\n\n    def _format(self, record):\n        return self._tpl.substitute(**record.__dict__)\n\n\nBASIC_FORMAT = \"%(levelname)s:%(name)s:%(message)s\"\n\n_STYLES = {\n    '%': (PercentStyle, BASIC_FORMAT),\n    '{': (StrFormatStyle, '{levelname}:{name}:{message}'),\n    '$': (StringTemplateStyle, '${levelname}:${name}:${message}'),\n}\n\nclass Formatter(object):\n    \"\"\"\n    Formatter instances are used to convert a LogRecord to text.\n\n    Formatters need to know how a LogRecord is constructed. They are\n    responsible for converting a LogRecord to (usually) a string which can\n    be interpreted by either a human or an external system. The base Formatter\n    allows a formatting string to be specified. If none is supplied, the\n    style-dependent default value, \"%(message)s\", \"{message}\", or\n    \"${message}\", is used.\n\n    The Formatter can be initialized with a format string which makes use of\n    knowledge of the LogRecord attributes - e.g. the default value mentioned\n    above makes use of the fact that the user's message and arguments are pre-\n    formatted into a LogRecord's message attribute. Currently, the useful\n    attributes in a LogRecord are described by:\n\n    %(name)s            Name of the logger (logging channel)\n    %(levelno)s         Numeric logging level for the message (DEBUG, INFO,\n                        WARNING, ERROR, CRITICAL)\n    %(levelname)s       Text logging level for the message (\"DEBUG\", \"INFO\",\n                        \"WARNING\", \"ERROR\", \"CRITICAL\")\n    %(pathname)s        Full pathname of the source file where the logging\n                        call was issued (if available)\n    %(filename)s        Filename portion of pathname\n    %(module)s          Module (name portion of filename)\n    %(lineno)d          Source line number where the logging call was issued\n                        (if available)\n    %(funcName)s        Function name\n    %(created)f         Time when the LogRecord was created (time.time()\n                        return value)\n    %(asctime)s         Textual time when the LogRecord was created\n    %(msecs)d           Millisecond portion of the creation time\n    %(relativeCreated)d Time in milliseconds when the LogRecord was created,\n                        relative to the time the logging module was loaded\n                        (typically at application startup time)\n    %(thread)d          Thread ID (if available)\n    %(threadName)s      Thread name (if available)\n    %(process)d         Process ID (if available)\n    %(message)s         The result of record.getMessage(), computed just as\n                        the record is emitted\n    \"\"\"\n\n    converter = time.localtime\n\n    def __init__(self, fmt=None, datefmt=None, style='%', validate=True):\n        \"\"\"\n        Initialize the formatter with specified format strings.\n\n        Initialize the formatter either with the specified format string, or a\n        default as described above. Allow for specialized date formatting with\n        the optional datefmt argument. If datefmt is omitted, you get an\n        ISO8601-like (or RFC 3339-like) format.\n\n        Use a style parameter of '%', '{' or '$' to specify that you want to\n        use one of %-formatting, :meth:`str.format` (``{}``) formatting or\n        :class:`string.Template` formatting in your format string.\n\n        .. versionchanged:: 3.2\n           Added the ``style`` parameter.\n        \"\"\"\n        if style not in _STYLES:\n            raise ValueError('Style must be one of: %s' % ','.join(\n                             _STYLES.keys()))\n        self._style = _STYLES[style][0](fmt)\n        if validate:\n            self._style.validate()\n\n        self._fmt = self._style._fmt\n        self.datefmt = datefmt\n\n    default_time_format = '%Y-%m-%d %H:%M:%S'\n    default_msec_format = '%s,%03d'\n\n    def formatTime(self, record, datefmt=None):\n        \"\"\"\n        Return the creation time of the specified LogRecord as formatted text.\n\n        This method should be called from format() by a formatter which\n        wants to make use of a formatted time. This method can be overridden\n        in formatters to provide for any specific requirement, but the\n        basic behaviour is as follows: if datefmt (a string) is specified,\n        it is used with time.strftime() to format the creation time of the\n        record. Otherwise, an ISO8601-like (or RFC 3339-like) format is used.\n        The resulting string is returned. This function uses a user-configurable\n        function to convert the creation time to a tuple. By default,\n        time.localtime() is used; to change this for a particular formatter\n        instance, set the 'converter' attribute to a function with the same\n        signature as time.localtime() or time.gmtime(). To change it for all\n        formatters, for example if you want all logging times to be shown in GMT,\n        set the 'converter' attribute in the Formatter class.\n        \"\"\"\n        ct = self.converter(record.created)\n        if datefmt:\n            s = time.strftime(datefmt, ct)\n        else:\n            s = time.strftime(self.default_time_format, ct)\n            if self.default_msec_format:\n                s = self.default_msec_format % (s, record.msecs)\n        return s\n\n    def formatException(self, ei):\n        \"\"\"\n        Format and return the specified exception information as a string.\n\n        This default implementation just uses\n        traceback.print_exception()\n        \"\"\"\n        sio = io.StringIO()\n        tb = ei[2]\n        # See issues #9427, #1553375. Commented out for now.\n        #if getattr(self, 'fullstack', False):\n        #    traceback.print_stack(tb.tb_frame.f_back, file=sio)\n        traceback.print_exception(ei[0], ei[1], tb, None, sio)\n        s = sio.getvalue()\n        sio.close()\n        if s[-1:] == \"\\n\":\n            s = s[:-1]\n        return s\n\n    def usesTime(self):\n        \"\"\"\n        Check if the format uses the creation time of the record.\n        \"\"\"\n        return self._style.usesTime()\n\n    def formatMessage(self, record):\n        return self._style.format(record)\n\n    def formatStack(self, stack_info):\n        \"\"\"\n        This method is provided as an extension point for specialized\n        formatting of stack information.\n\n        The input data is a string as returned from a call to\n        :func:`traceback.print_stack`, but with the last trailing newline\n        removed.\n\n        The base implementation just returns the value passed in.\n        \"\"\"\n        return stack_info\n\n    def format(self, record):\n        \"\"\"\n        Format the specified record as text.\n\n        The record's attribute dictionary is used as the operand to a\n        string formatting operation which yields the returned string.\n        Before formatting the dictionary, a couple of preparatory steps\n        are carried out. The message attribute of the record is computed\n        using LogRecord.getMessage(). If the formatting string uses the\n        time (as determined by a call to usesTime(), formatTime() is\n        called to format the event time. If there is exception information,\n        it is formatted using formatException() and appended to the message.\n        \"\"\"\n        record.message = record.getMessage()\n        if self.usesTime():\n            record.asctime = self.formatTime(record, self.datefmt)\n        s = self.formatMessage(record)\n        if record.exc_info:\n            # Cache the traceback text to avoid converting it multiple times\n            # (it's constant anyway)\n            if not record.exc_text:\n                record.exc_text = self.formatException(record.exc_info)\n        if record.exc_text:\n            if s[-1:] != \"\\n\":\n                s = s + \"\\n\"\n            s = s + record.exc_text\n        if record.stack_info:\n            if s[-1:] != \"\\n\":\n                s = s + \"\\n\"\n            s = s + self.formatStack(record.stack_info)\n        return s\n\n#\n#   The default formatter to use when no other is specified\n#\n_defaultFormatter = Formatter()\n\nclass BufferingFormatter(object):\n    \"\"\"\n    A formatter suitable for formatting a number of records.\n    \"\"\"\n    def __init__(self, linefmt=None):\n        \"\"\"\n        Optionally specify a formatter which will be used to format each\n        individual record.\n        \"\"\"\n        if linefmt:\n            self.linefmt = linefmt\n        else:\n            self.linefmt = _defaultFormatter\n\n    def formatHeader(self, records):\n        \"\"\"\n        Return the header string for the specified records.\n        \"\"\"\n        return \"\"\n\n    def formatFooter(self, records):\n        \"\"\"\n        Return the footer string for the specified records.\n        \"\"\"\n        return \"\"\n\n    def format(self, records):\n        \"\"\"\n        Format the specified records and return the result as a string.\n        \"\"\"\n        rv = \"\"\n        if len(records) > 0:\n            rv = rv + self.formatHeader(records)\n            for record in records:\n                rv = rv + self.linefmt.format(record)\n            rv = rv + self.formatFooter(records)\n        return rv\n\n#---------------------------------------------------------------------------\n#   Filter classes and functions\n#---------------------------------------------------------------------------\n\nclass Filter(object):\n    \"\"\"\n    Filter instances are used to perform arbitrary filtering of LogRecords.\n\n    Loggers and Handlers can optionally use Filter instances to filter\n    records as desired. The base filter class only allows events which are\n    below a certain point in the logger hierarchy. For example, a filter\n    initialized with \"A.B\" will allow events logged by loggers \"A.B\",\n    \"A.B.C\", \"A.B.C.D\", \"A.B.D\" etc. but not \"A.BB\", \"B.A.B\" etc. If\n    initialized with the empty string, all events are passed.\n    \"\"\"\n    def __init__(self, name=''):\n        \"\"\"\n        Initialize a filter.\n\n        Initialize with the name of the logger which, together with its\n        children, will have its events allowed through the filter. If no\n        name is specified, allow every event.\n        \"\"\"\n        self.name = name\n        self.nlen = len(name)\n\n    def filter(self, record):\n        \"\"\"\n        Determine if the specified record is to be logged.\n\n        Returns True if the record should be logged, or False otherwise.\n        If deemed appropriate, the record may be modified in-place.\n        \"\"\"\n        if self.nlen == 0:\n            return True\n        elif self.name == record.name:\n            return True\n        elif record.name.find(self.name, 0, self.nlen) != 0:\n            return False\n        return (record.name[self.nlen] == \".\")\n\nclass Filterer(object):\n    \"\"\"\n    A base class for loggers and handlers which allows them to share\n    common code.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initialize the list of filters to be an empty list.\n        \"\"\"\n        self.filters = []\n\n    def addFilter(self, filter):\n        \"\"\"\n        Add the specified filter to this handler.\n        \"\"\"\n        if not (filter in self.filters):\n            self.filters.append(filter)\n\n    def removeFilter(self, filter):\n        \"\"\"\n        Remove the specified filter from this handler.\n        \"\"\"\n        if filter in self.filters:\n            self.filters.remove(filter)\n\n    def filter(self, record):\n        \"\"\"\n        Determine if a record is loggable by consulting all the filters.\n\n        The default is to allow the record to be logged; any filter can veto\n        this and the record is then dropped. Returns a zero value if a record\n        is to be dropped, else non-zero.\n\n        .. versionchanged:: 3.2\n\n           Allow filters to be just callables.\n        \"\"\"\n        rv = True\n        for f in self.filters:\n            if hasattr(f, 'filter'):\n                result = f.filter(record)\n            else:\n                result = f(record) # assume callable - will raise if not\n            if not result:\n                rv = False\n                break\n        return rv\n\n#---------------------------------------------------------------------------\n#   Handler classes and functions\n#---------------------------------------------------------------------------\n\n_handlers = weakref.WeakValueDictionary()  #map of handler names to handlers\n_handlerList = [] # added to allow handlers to be removed in reverse of order initialized\n\ndef _removeHandlerRef(wr):\n    \"\"\"\n    Remove a handler reference from the internal cleanup list.\n    \"\"\"\n    # This function can be called during module teardown, when globals are\n    # set to None. It can also be called from another thread. So we need to\n    # pre-emptively grab the necessary globals and check if they're None,\n    # to prevent race conditions and failures during interpreter shutdown.\n    acquire, release, handlers = _acquireLock, _releaseLock, _handlerList\n    if acquire and release and handlers:\n        acquire()\n        try:\n            if wr in handlers:\n                handlers.remove(wr)\n        finally:\n            release()\n\ndef _addHandlerRef(handler):\n    \"\"\"\n    Add a handler to the internal cleanup list using a weak reference.\n    \"\"\"\n    _acquireLock()\n    try:\n        _handlerList.append(weakref.ref(handler, _removeHandlerRef))\n    finally:\n        _releaseLock()\n\nclass Handler(Filterer):\n    \"\"\"\n    Handler instances dispatch logging events to specific destinations.\n\n    The base handler class. Acts as a placeholder which defines the Handler\n    interface. Handlers can optionally use Formatter instances to format\n    records as desired. By default, no formatter is specified; in this case,\n    the 'raw' message as determined by record.message is logged.\n    \"\"\"\n    def __init__(self, level=NOTSET):\n        \"\"\"\n        Initializes the instance - basically setting the formatter to None\n        and the filter list to empty.\n        \"\"\"\n        Filterer.__init__(self)\n        self._name = None\n        self.level = _checkLevel(level)\n        self.formatter = None\n        # Add the handler to the global _handlerList (for cleanup on shutdown)\n        _addHandlerRef(self)\n        self.createLock()\n\n    def get_name(self):\n        return self._name\n\n    def set_name(self, name):\n        _acquireLock()\n        try:\n            if self._name in _handlers:\n                del _handlers[self._name]\n            self._name = name\n            if name:\n                _handlers[name] = self\n        finally:\n            _releaseLock()\n\n    name = property(get_name, set_name)\n\n    def createLock(self):\n        \"\"\"\n        Acquire a thread lock for serializing access to the underlying I/O.\n        \"\"\"\n        self.lock = threading.RLock()\n        _register_at_fork_reinit_lock(self)\n\n    def _at_fork_reinit(self):\n        self.lock._at_fork_reinit()\n\n    def acquire(self):\n        \"\"\"\n        Acquire the I/O thread lock.\n        \"\"\"\n        if self.lock:\n            self.lock.acquire()\n\n    def release(self):\n        \"\"\"\n        Release the I/O thread lock.\n        \"\"\"\n        if self.lock:\n            self.lock.release()\n\n    def setLevel(self, level):\n        \"\"\"\n        Set the logging level of this handler.  level must be an int or a str.\n        \"\"\"\n        self.level = _checkLevel(level)\n\n    def format(self, record):\n        \"\"\"\n        Format the specified record.\n\n        If a formatter is set, use it. Otherwise, use the default formatter\n        for the module.\n        \"\"\"\n        if self.formatter:\n            fmt = self.formatter\n        else:\n            fmt = _defaultFormatter\n        return fmt.format(record)\n\n    def emit(self, record):\n        \"\"\"\n        Do whatever it takes to actually log the specified logging record.\n\n        This version is intended to be implemented by subclasses and so\n        raises a NotImplementedError.\n        \"\"\"\n        raise NotImplementedError('emit must be implemented '\n                                  'by Handler subclasses')\n\n    def handle(self, record):\n        \"\"\"\n        Conditionally emit the specified logging record.\n\n        Emission depends on filters which may have been added to the handler.\n        Wrap the actual emission of the record with acquisition/release of\n        the I/O thread lock. Returns whether the filter passed the record for\n        emission.\n        \"\"\"\n        rv = self.filter(record)\n        if rv:\n            self.acquire()\n            try:\n                self.emit(record)\n            finally:\n                self.release()\n        return rv\n\n    def setFormatter(self, fmt):\n        \"\"\"\n        Set the formatter for this handler.\n        \"\"\"\n        self.formatter = fmt\n\n    def flush(self):\n        \"\"\"\n        Ensure all logging output has been flushed.\n\n        This version does nothing and is intended to be implemented by\n        subclasses.\n        \"\"\"\n        pass\n\n    def close(self):\n        \"\"\"\n        Tidy up any resources used by the handler.\n\n        This version removes the handler from an internal map of handlers,\n        _handlers, which is used for handler lookup by name. Subclasses\n        should ensure that this gets called from overridden close()\n        methods.\n        \"\"\"\n        #get the module data lock, as we're updating a shared structure.\n        _acquireLock()\n        try:    #unlikely to raise an exception, but you never know...\n            if self._name and self._name in _handlers:\n                del _handlers[self._name]\n        finally:\n            _releaseLock()\n\n    def handleError(self, record):\n        \"\"\"\n        Handle errors which occur during an emit() call.\n\n        This method should be called from handlers when an exception is\n        encountered during an emit() call. If raiseExceptions is false,\n        exceptions get silently ignored. This is what is mostly wanted\n        for a logging system - most users will not care about errors in\n        the logging system, they are more interested in application errors.\n        You could, however, replace this with a custom handler if you wish.\n        The record which was being processed is passed in to this method.\n        \"\"\"\n        if raiseExceptions and sys.stderr:  # see issue 13807\n            t, v, tb = sys.exc_info()\n            try:\n                sys.stderr.write('--- Logging error ---\\n')\n                traceback.print_exception(t, v, tb, None, sys.stderr)\n                sys.stderr.write('Call stack:\\n')\n                # Walk the stack frame up until we're out of logging,\n                # so as to print the calling context.\n                frame = tb.tb_frame\n                while (frame and os.path.dirname(frame.f_code.co_filename) ==\n                       __path__[0]):\n                    frame = frame.f_back\n                if frame:\n                    traceback.print_stack(frame, file=sys.stderr)\n                else:\n                    # couldn't find the right stack frame, for some reason\n                    sys.stderr.write('Logged from file %s, line %s\\n' % (\n                                     record.filename, record.lineno))\n                # Issue 18671: output logging message and arguments\n                try:\n                    sys.stderr.write('Message: %r\\n'\n                                     'Arguments: %s\\n' % (record.msg,\n                                                          record.args))\n                except RecursionError:  # See issue 36272\n                    raise\n                except Exception:\n                    sys.stderr.write('Unable to print the message and arguments'\n                                     ' - possible formatting error.\\nUse the'\n                                     ' traceback above to help find the error.\\n'\n                                    )\n            except OSError: #pragma: no cover\n                pass    # see issue 5971\n            finally:\n                del t, v, tb\n\n    def __repr__(self):\n        level = getLevelName(self.level)\n        return '<%s (%s)>' % (self.__class__.__name__, level)\n\nclass StreamHandler(Handler):\n    \"\"\"\n    A handler class which writes logging records, appropriately formatted,\n    to a stream. Note that this class does not close the stream, as\n    sys.stdout or sys.stderr may be used.\n    \"\"\"\n\n    terminator = '\\n'\n\n    def __init__(self, stream=None):\n        \"\"\"\n        Initialize the handler.\n\n        If stream is not specified, sys.stderr is used.\n        \"\"\"\n        Handler.__init__(self)\n        if stream is None:\n            stream = sys.stderr\n        self.stream = stream\n\n    def flush(self):\n        \"\"\"\n        Flushes the stream.\n        \"\"\"\n        self.acquire()\n        try:\n            if self.stream and hasattr(self.stream, \"flush\"):\n                self.stream.flush()\n        finally:\n            self.release()\n\n    def emit(self, record):\n        \"\"\"\n        Emit a record.\n\n        If a formatter is specified, it is used to format the record.\n        The record is then written to the stream with a trailing newline.  If\n        exception information is present, it is formatted using\n        traceback.print_exception and appended to the stream.  If the stream\n        has an 'encoding' attribute, it is used to determine how to do the\n        output to the stream.\n        \"\"\"\n        try:\n            msg = self.format(record)\n            stream = self.stream\n            # issue 35046: merged two stream.writes into one.\n            stream.write(msg + self.terminator)\n            self.flush()\n        except RecursionError:  # See issue 36272\n            raise\n        except Exception:\n            self.handleError(record)\n\n    def setStream(self, stream):\n        \"\"\"\n        Sets the StreamHandler's stream to the specified value,\n        if it is different.\n\n        Returns the old stream, if the stream was changed, or None\n        if it wasn't.\n        \"\"\"\n        if stream is self.stream:\n            result = None\n        else:\n            result = self.stream\n            self.acquire()\n            try:\n                self.flush()\n                self.stream = stream\n            finally:\n                self.release()\n        return result\n\n    def __repr__(self):\n        level = getLevelName(self.level)\n        name = getattr(self.stream, 'name', '')\n        #  bpo-36015: name can be an int\n        name = str(name)\n        if name:\n            name += ' '\n        return '<%s %s(%s)>' % (self.__class__.__name__, name, level)\n\n\nclass FileHandler(StreamHandler):\n    \"\"\"\n    A handler class which writes formatted logging records to disk files.\n    \"\"\"\n    def __init__(self, filename, mode='a', encoding=None, delay=False, errors=None):\n        \"\"\"\n        Open the specified file and use it as the stream for logging.\n        \"\"\"\n        # Issue #27493: add support for Path objects to be passed in\n        filename = os.fspath(filename)\n        #keep the absolute path, otherwise derived classes which use this\n        #may come a cropper when the current directory changes\n        self.baseFilename = os.path.abspath(filename)\n        self.mode = mode\n        self.encoding = encoding\n        self.errors = errors\n        self.delay = delay\n        if delay:\n            #We don't open the stream, but we still need to call the\n            #Handler constructor to set level, formatter, lock etc.\n            Handler.__init__(self)\n            self.stream = None\n        else:\n            StreamHandler.__init__(self, self._open())\n\n    def close(self):\n        \"\"\"\n        Closes the stream.\n        \"\"\"\n        self.acquire()\n        try:\n            try:\n                if self.stream:\n                    try:\n                        self.flush()\n                    finally:\n                        stream = self.stream\n                        self.stream = None\n                        if hasattr(stream, \"close\"):\n                            stream.close()\n            finally:\n                # Issue #19523: call unconditionally to\n                # prevent a handler leak when delay is set\n                StreamHandler.close(self)\n        finally:\n            self.release()\n\n    def _open(self):\n        \"\"\"\n        Open the current base file with the (original) mode and encoding.\n        Return the resulting stream.\n        \"\"\"\n        return open(self.baseFilename, self.mode, encoding=self.encoding,\n                    errors=self.errors)\n\n    def emit(self, record):\n        \"\"\"\n        Emit a record.\n\n        If the stream was not opened because 'delay' was specified in the\n        constructor, open it before calling the superclass's emit.\n        \"\"\"\n        if self.stream is None:\n            self.stream = self._open()\n        StreamHandler.emit(self, record)\n\n    def __repr__(self):\n        level = getLevelName(self.level)\n        return '<%s %s (%s)>' % (self.__class__.__name__, self.baseFilename, level)\n\n\nclass _StderrHandler(StreamHandler):\n    \"\"\"\n    This class is like a StreamHandler using sys.stderr, but always uses\n    whatever sys.stderr is currently set to rather than the value of\n    sys.stderr at handler construction time.\n    \"\"\"\n    def __init__(self, level=NOTSET):\n        \"\"\"\n        Initialize the handler.\n        \"\"\"\n        Handler.__init__(self, level)\n\n    @property\n    def stream(self):\n        return sys.stderr\n\n\n_defaultLastResort = _StderrHandler(WARNING)\nlastResort = _defaultLastResort\n\n#---------------------------------------------------------------------------\n#   Manager classes and functions\n#---------------------------------------------------------------------------\n\nclass PlaceHolder(object):\n    \"\"\"\n    PlaceHolder instances are used in the Manager logger hierarchy to take\n    the place of nodes for which no loggers have been defined. This class is\n    intended for internal use only and not as part of the public API.\n    \"\"\"\n    def __init__(self, alogger):\n        \"\"\"\n        Initialize with the specified logger being a child of this placeholder.\n        \"\"\"\n        self.loggerMap = { alogger : None }\n\n    def append(self, alogger):\n        \"\"\"\n        Add the specified logger as a child of this placeholder.\n        \"\"\"\n        if alogger not in self.loggerMap:\n            self.loggerMap[alogger] = None\n\n#\n#   Determine which class to use when instantiating loggers.\n#\n\ndef setLoggerClass(klass):\n    \"\"\"\n    Set the class to be used when instantiating a logger. The class should\n    define __init__() such that only a name argument is required, and the\n    __init__() should call Logger.__init__()\n    \"\"\"\n    if klass != Logger:\n        if not issubclass(klass, Logger):\n            raise TypeError(\"logger not derived from logging.Logger: \"\n                            + klass.__name__)\n    global _loggerClass\n    _loggerClass = klass\n\ndef getLoggerClass():\n    \"\"\"\n    Return the class to be used when instantiating a logger.\n    \"\"\"\n    return _loggerClass\n\nclass Manager(object):\n    \"\"\"\n    There is [under normal circumstances] just one Manager instance, which\n    holds the hierarchy of loggers.\n    \"\"\"\n    def __init__(self, rootnode):\n        \"\"\"\n        Initialize the manager with the root node of the logger hierarchy.\n        \"\"\"\n        self.root = rootnode\n        self.disable = 0\n        self.emittedNoHandlerWarning = False\n        self.loggerDict = {}\n        self.loggerClass = None\n        self.logRecordFactory = None\n\n    @property\n    def disable(self):\n        return self._disable\n\n    @disable.setter\n    def disable(self, value):\n        self._disable = _checkLevel(value)\n\n    def getLogger(self, name):\n        \"\"\"\n        Get a logger with the specified name (channel name), creating it\n        if it doesn't yet exist. This name is a dot-separated hierarchical\n        name, such as \"a\", \"a.b\", \"a.b.c\" or similar.\n\n        If a PlaceHolder existed for the specified name [i.e. the logger\n        didn't exist but a child of it did], replace it with the created\n        logger and fix up the parent/child references which pointed to the\n        placeholder to now point to the logger.\n        \"\"\"\n        rv = None\n        if not isinstance(name, str):\n            raise TypeError('A logger name must be a string')\n        _acquireLock()\n        try:\n            if name in self.loggerDict:\n                rv = self.loggerDict[name]\n                if isinstance(rv, PlaceHolder):\n                    ph = rv\n                    rv = (self.loggerClass or _loggerClass)(name)\n                    rv.manager = self\n                    self.loggerDict[name] = rv\n                    self._fixupChildren(ph, rv)\n                    self._fixupParents(rv)\n            else:\n                rv = (self.loggerClass or _loggerClass)(name)\n                rv.manager = self\n                self.loggerDict[name] = rv\n                self._fixupParents(rv)\n        finally:\n            _releaseLock()\n        return rv\n\n    def setLoggerClass(self, klass):\n        \"\"\"\n        Set the class to be used when instantiating a logger with this Manager.\n        \"\"\"\n        if klass != Logger:\n            if not issubclass(klass, Logger):\n                raise TypeError(\"logger not derived from logging.Logger: \"\n                                + klass.__name__)\n        self.loggerClass = klass\n\n    def setLogRecordFactory(self, factory):\n        \"\"\"\n        Set the factory to be used when instantiating a log record with this\n        Manager.\n        \"\"\"\n        self.logRecordFactory = factory\n\n    def _fixupParents(self, alogger):\n        \"\"\"\n        Ensure that there are either loggers or placeholders all the way\n        from the specified logger to the root of the logger hierarchy.\n        \"\"\"\n        name = alogger.name\n        i = name.rfind(\".\")\n        rv = None\n        while (i > 0) and not rv:\n            substr = name[:i]\n            if substr not in self.loggerDict:\n                self.loggerDict[substr] = PlaceHolder(alogger)\n            else:\n                obj = self.loggerDict[substr]\n                if isinstance(obj, Logger):\n                    rv = obj\n                else:\n                    assert isinstance(obj, PlaceHolder)\n                    obj.append(alogger)\n            i = name.rfind(\".\", 0, i - 1)\n        if not rv:\n            rv = self.root\n        alogger.parent = rv\n\n    def _fixupChildren(self, ph, alogger):\n        \"\"\"\n        Ensure that children of the placeholder ph are connected to the\n        specified logger.\n        \"\"\"\n        name = alogger.name\n        namelen = len(name)\n        for c in ph.loggerMap.keys():\n            #The if means ... if not c.parent.name.startswith(nm)\n            if c.parent.name[:namelen] != name:\n                alogger.parent = c.parent\n                c.parent = alogger\n\n    def _clear_cache(self):\n        \"\"\"\n        Clear the cache for all loggers in loggerDict\n        Called when level changes are made\n        \"\"\"\n\n        _acquireLock()\n        for logger in self.loggerDict.values():\n            if isinstance(logger, Logger):\n                logger._cache.clear()\n        self.root._cache.clear()\n        _releaseLock()\n\n#---------------------------------------------------------------------------\n#   Logger classes and functions\n#---------------------------------------------------------------------------\n\nclass Logger(Filterer):\n    \"\"\"\n    Instances of the Logger class represent a single logging channel. A\n    \"logging channel\" indicates an area of an application. Exactly how an\n    \"area\" is defined is up to the application developer. Since an\n    application can have any number of areas, logging channels are identified\n    by a unique string. Application areas can be nested (e.g. an area\n    of \"input processing\" might include sub-areas \"read CSV files\", \"read\n    XLS files\" and \"read Gnumeric files\"). To cater for this natural nesting,\n    channel names are organized into a namespace hierarchy where levels are\n    separated by periods, much like the Java or Python package namespace. So\n    in the instance given above, channel names might be \"input\" for the upper\n    level, and \"input.csv\", \"input.xls\" and \"input.gnu\" for the sub-levels.\n    There is no arbitrary limit to the depth of nesting.\n    \"\"\"\n    def __init__(self, name, level=NOTSET):\n        \"\"\"\n        Initialize the logger with a name and an optional level.\n        \"\"\"\n        Filterer.__init__(self)\n        self.name = name\n        self.level = _checkLevel(level)\n        self.parent = None\n        self.propagate = True\n        self.handlers = []\n        self.disabled = False\n        self._cache = {}\n\n    def setLevel(self, level):\n        \"\"\"\n        Set the logging level of this logger.  level must be an int or a str.\n        \"\"\"\n        self.level = _checkLevel(level)\n        self.manager._clear_cache()\n\n    def debug(self, msg, *args, **kwargs):\n        \"\"\"\n        Log 'msg % args' with severity 'DEBUG'.\n\n        To pass exception information, use the keyword argument exc_info with\n        a true value, e.g.\n\n        logger.debug(\"Houston, we have a %s\", \"thorny problem\", exc_info=1)\n        \"\"\"\n        if self.isEnabledFor(DEBUG):\n            self._log(DEBUG, msg, args, **kwargs)\n\n    def info(self, msg, *args, **kwargs):\n        \"\"\"\n        Log 'msg % args' with severity 'INFO'.\n\n        To pass exception information, use the keyword argument exc_info with\n        a true value, e.g.\n\n        logger.info(\"Houston, we have a %s\", \"interesting problem\", exc_info=1)\n        \"\"\"\n        if self.isEnabledFor(INFO):\n            self._log(INFO, msg, args, **kwargs)\n\n    def warning(self, msg, *args, **kwargs):\n        \"\"\"\n        Log 'msg % args' with severity 'WARNING'.\n\n        To pass exception information, use the keyword argument exc_info with\n        a true value, e.g.\n\n        logger.warning(\"Houston, we have a %s\", \"bit of a problem\", exc_info=1)\n        \"\"\"\n        if self.isEnabledFor(WARNING):\n            self._log(WARNING, msg, args, **kwargs)\n\n    def warn(self, msg, *args, **kwargs):\n        warnings.warn(\"The 'warn' method is deprecated, \"\n            \"use 'warning' instead\", DeprecationWarning, 2)\n        self.warning(msg, *args, **kwargs)\n\n    def error(self, msg, *args, **kwargs):\n        \"\"\"\n        Log 'msg % args' with severity 'ERROR'.\n\n        To pass exception information, use the keyword argument exc_info with\n        a true value, e.g.\n\n        logger.error(\"Houston, we have a %s\", \"major problem\", exc_info=1)\n        \"\"\"\n        if self.isEnabledFor(ERROR):\n            self._log(ERROR, msg, args, **kwargs)\n\n    def exception(self, msg, *args, exc_info=True, **kwargs):\n        \"\"\"\n        Convenience method for logging an ERROR with exception information.\n        \"\"\"\n        self.error(msg, *args, exc_info=exc_info, **kwargs)\n\n    def critical(self, msg, *args, **kwargs):\n        \"\"\"\n        Log 'msg % args' with severity 'CRITICAL'.\n\n        To pass exception information, use the keyword argument exc_info with\n        a true value, e.g.\n\n        logger.critical(\"Houston, we have a %s\", \"major disaster\", exc_info=1)\n        \"\"\"\n        if self.isEnabledFor(CRITICAL):\n            self._log(CRITICAL, msg, args, **kwargs)\n\n    fatal = critical\n\n    def log(self, level, msg, *args, **kwargs):\n        \"\"\"\n        Log 'msg % args' with the integer severity 'level'.\n\n        To pass exception information, use the keyword argument exc_info with\n        a true value, e.g.\n\n        logger.log(level, \"We have a %s\", \"mysterious problem\", exc_info=1)\n        \"\"\"\n        if not isinstance(level, int):\n            if raiseExceptions:\n                raise TypeError(\"level must be an integer\")\n            else:\n                return\n        if self.isEnabledFor(level):\n            self._log(level, msg, args, **kwargs)\n\n    def findCaller(self, stack_info=False, stacklevel=1):\n        \"\"\"\n        Find the stack frame of the caller so that we can note the source\n        file name, line number and function name.\n        \"\"\"\n        f = currentframe()\n        #On some versions of IronPython, currentframe() returns None if\n        #IronPython isn't run with -X:Frames.\n        if f is not None:\n            f = f.f_back\n        orig_f = f\n        while f and stacklevel > 1:\n            f = f.f_back\n            stacklevel -= 1\n        if not f:\n            f = orig_f\n        rv = \"(unknown file)\", 0, \"(unknown function)\", None\n        while hasattr(f, \"f_code\"):\n            co = f.f_code\n            filename = os.path.normcase(co.co_filename)\n            if filename == _srcfile:\n                f = f.f_back\n                continue\n            sinfo = None\n            if stack_info:\n                sio = io.StringIO()\n                sio.write('Stack (most recent call last):\\n')\n                traceback.print_stack(f, file=sio)\n                sinfo = sio.getvalue()\n                if sinfo[-1] == '\\n':\n                    sinfo = sinfo[:-1]\n                sio.close()\n            rv = (co.co_filename, f.f_lineno, co.co_name, sinfo)\n            break\n        return rv\n\n    def makeRecord(self, name, level, fn, lno, msg, args, exc_info,\n                   func=None, extra=None, sinfo=None):\n        \"\"\"\n        A factory method which can be overridden in subclasses to create\n        specialized LogRecords.\n        \"\"\"\n        rv = _logRecordFactory(name, level, fn, lno, msg, args, exc_info, func,\n                             sinfo)\n        if extra is not None:\n            for key in extra:\n                if (key in [\"message\", \"asctime\"]) or (key in rv.__dict__):\n                    raise KeyError(\"Attempt to overwrite %r in LogRecord\" % key)\n                rv.__dict__[key] = extra[key]\n        return rv\n\n    def _log(self, level, msg, args, exc_info=None, extra=None, stack_info=False,\n             stacklevel=1):\n        \"\"\"\n        Low-level logging routine which creates a LogRecord and then calls\n        all the handlers of this logger to handle the record.\n        \"\"\"\n        sinfo = None\n        if _srcfile:\n            #IronPython doesn't track Python frames, so findCaller raises an\n            #exception on some versions of IronPython. We trap it here so that\n            #IronPython can use logging.\n            try:\n                fn, lno, func, sinfo = self.findCaller(stack_info, stacklevel)\n            except ValueError: # pragma: no cover\n                fn, lno, func = \"(unknown file)\", 0, \"(unknown function)\"\n        else: # pragma: no cover\n            fn, lno, func = \"(unknown file)\", 0, \"(unknown function)\"\n        if exc_info:\n            if isinstance(exc_info, BaseException):\n                exc_info = (type(exc_info), exc_info, exc_info.__traceback__)\n            elif not isinstance(exc_info, tuple):\n                exc_info = sys.exc_info()\n        record = self.makeRecord(self.name, level, fn, lno, msg, args,\n                                 exc_info, func, extra, sinfo)\n        self.handle(record)\n\n    def handle(self, record):\n        \"\"\"\n        Call the handlers for the specified record.\n\n        This method is used for unpickled records received from a socket, as\n        well as those created locally. Logger-level filtering is applied.\n        \"\"\"\n        if (not self.disabled) and self.filter(record):\n            self.callHandlers(record)\n\n    def addHandler(self, hdlr):\n        \"\"\"\n        Add the specified handler to this logger.\n        \"\"\"\n        _acquireLock()\n        try:\n            if not (hdlr in self.handlers):\n                self.handlers.append(hdlr)\n        finally:\n            _releaseLock()\n\n    def removeHandler(self, hdlr):\n        \"\"\"\n        Remove the specified handler from this logger.\n        \"\"\"\n        _acquireLock()\n        try:\n            if hdlr in self.handlers:\n                self.handlers.remove(hdlr)\n        finally:\n            _releaseLock()\n\n    def hasHandlers(self):\n        \"\"\"\n        See if this logger has any handlers configured.\n\n        Loop through all handlers for this logger and its parents in the\n        logger hierarchy. Return True if a handler was found, else False.\n        Stop searching up the hierarchy whenever a logger with the \"propagate\"\n        attribute set to zero is found - that will be the last logger which\n        is checked for the existence of handlers.\n        \"\"\"\n        c = self\n        rv = False\n        while c:\n            if c.handlers:\n                rv = True\n                break\n            if not c.propagate:\n                break\n            else:\n                c = c.parent\n        return rv\n\n    def callHandlers(self, record):\n        \"\"\"\n        Pass a record to all relevant handlers.\n\n        Loop through all handlers for this logger and its parents in the\n        logger hierarchy. If no handler was found, output a one-off error\n        message to sys.stderr. Stop searching up the hierarchy whenever a\n        logger with the \"propagate\" attribute set to zero is found - that\n        will be the last logger whose handlers are called.\n        \"\"\"\n        c = self\n        found = 0\n        while c:\n            for hdlr in c.handlers:\n                found = found + 1\n                if record.levelno >= hdlr.level:\n                    hdlr.handle(record)\n            if not c.propagate:\n                c = None    #break out\n            else:\n                c = c.parent\n        if (found == 0):\n            if lastResort:\n                if record.levelno >= lastResort.level:\n                    lastResort.handle(record)\n            elif raiseExceptions and not self.manager.emittedNoHandlerWarning:\n                sys.stderr.write(\"No handlers could be found for logger\"\n                                 \" \\\"%s\\\"\\n\" % self.name)\n                self.manager.emittedNoHandlerWarning = True\n\n    def getEffectiveLevel(self):\n        \"\"\"\n        Get the effective level for this logger.\n\n        Loop through this logger and its parents in the logger hierarchy,\n        looking for a non-zero logging level. Return the first one found.\n        \"\"\"\n        logger = self\n        while logger:\n            if logger.level:\n                return logger.level\n            logger = logger.parent\n        return NOTSET\n\n    def isEnabledFor(self, level):\n        \"\"\"\n        Is this logger enabled for level 'level'?\n        \"\"\"\n        if self.disabled:\n            return False\n\n        try:\n            return self._cache[level]\n        except KeyError:\n            _acquireLock()\n            try:\n                if self.manager.disable >= level:\n                    is_enabled = self._cache[level] = False\n                else:\n                    is_enabled = self._cache[level] = (\n                        level >= self.getEffectiveLevel()\n                    )\n            finally:\n                _releaseLock()\n            return is_enabled\n\n    def getChild(self, suffix):\n        \"\"\"\n        Get a logger which is a descendant to this one.\n\n        This is a convenience method, such that\n\n        logging.getLogger('abc').getChild('def.ghi')\n\n        is the same as\n\n        logging.getLogger('abc.def.ghi')\n\n        It's useful, for example, when the parent logger is named using\n        __name__ rather than a literal string.\n        \"\"\"\n        if self.root is not self:\n            suffix = '.'.join((self.name, suffix))\n        return self.manager.getLogger(suffix)\n\n    def __repr__(self):\n        level = getLevelName(self.getEffectiveLevel())\n        return '<%s %s (%s)>' % (self.__class__.__name__, self.name, level)\n\n    def __reduce__(self):\n        # In general, only the root logger will not be accessible via its name.\n        # However, the root logger's class has its own __reduce__ method.\n        if getLogger(self.name) is not self:\n            import pickle\n            raise pickle.PicklingError('logger cannot be pickled')\n        return getLogger, (self.name,)\n\n\nclass RootLogger(Logger):\n    \"\"\"\n    A root logger is not that different to any other logger, except that\n    it must have a logging level and there is only one instance of it in\n    the hierarchy.\n    \"\"\"\n    def __init__(self, level):\n        \"\"\"\n        Initialize the logger with the name \"root\".\n        \"\"\"\n        Logger.__init__(self, \"root\", level)\n\n    def __reduce__(self):\n        return getLogger, ()\n\n_loggerClass = Logger\n\nclass LoggerAdapter(object):\n    \"\"\"\n    An adapter for loggers which makes it easier to specify contextual\n    information in logging output.\n    \"\"\"\n\n    def __init__(self, logger, extra):\n        \"\"\"\n        Initialize the adapter with a logger and a dict-like object which\n        provides contextual information. This constructor signature allows\n        easy stacking of LoggerAdapters, if so desired.\n\n        You can effectively pass keyword arguments as shown in the\n        following example:\n\n        adapter = LoggerAdapter(someLogger, dict(p1=v1, p2=\"v2\"))\n        \"\"\"\n        self.logger = logger\n        self.extra = extra\n\n    def process(self, msg, kwargs):\n        \"\"\"\n        Process the logging message and keyword arguments passed in to\n        a logging call to insert contextual information. You can either\n        manipulate the message itself, the keyword args or both. Return\n        the message and kwargs modified (or not) to suit your needs.\n\n        Normally, you'll only need to override this one method in a\n        LoggerAdapter subclass for your specific needs.\n        \"\"\"\n        kwargs[\"extra\"] = self.extra\n        return msg, kwargs\n\n    #\n    # Boilerplate convenience methods\n    #\n    def debug(self, msg, *args, **kwargs):\n        \"\"\"\n        Delegate a debug call to the underlying logger.\n        \"\"\"\n        self.log(DEBUG, msg, *args, **kwargs)\n\n    def info(self, msg, *args, **kwargs):\n        \"\"\"\n        Delegate an info call to the underlying logger.\n        \"\"\"\n        self.log(INFO, msg, *args, **kwargs)\n\n    def warning(self, msg, *args, **kwargs):\n        \"\"\"\n        Delegate a warning call to the underlying logger.\n        \"\"\"\n        self.log(WARNING, msg, *args, **kwargs)\n\n    def warn(self, msg, *args, **kwargs):\n        warnings.warn(\"The 'warn' method is deprecated, \"\n            \"use 'warning' instead\", DeprecationWarning, 2)\n        self.warning(msg, *args, **kwargs)\n\n    def error(self, msg, *args, **kwargs):\n        \"\"\"\n        Delegate an error call to the underlying logger.\n        \"\"\"\n        self.log(ERROR, msg, *args, **kwargs)\n\n    def exception(self, msg, *args, exc_info=True, **kwargs):\n        \"\"\"\n        Delegate an exception call to the underlying logger.\n        \"\"\"\n        self.log(ERROR, msg, *args, exc_info=exc_info, **kwargs)\n\n    def critical(self, msg, *args, **kwargs):\n        \"\"\"\n        Delegate a critical call to the underlying logger.\n        \"\"\"\n        self.log(CRITICAL, msg, *args, **kwargs)\n\n    def log(self, level, msg, *args, **kwargs):\n        \"\"\"\n        Delegate a log call to the underlying logger, after adding\n        contextual information from this adapter instance.\n        \"\"\"\n        if self.isEnabledFor(level):\n            msg, kwargs = self.process(msg, kwargs)\n            self.logger.log(level, msg, *args, **kwargs)\n\n    def isEnabledFor(self, level):\n        \"\"\"\n        Is this logger enabled for level 'level'?\n        \"\"\"\n        return self.logger.isEnabledFor(level)\n\n    def setLevel(self, level):\n        \"\"\"\n        Set the specified level on the underlying logger.\n        \"\"\"\n        self.logger.setLevel(level)\n\n    def getEffectiveLevel(self):\n        \"\"\"\n        Get the effective level for the underlying logger.\n        \"\"\"\n        return self.logger.getEffectiveLevel()\n\n    def hasHandlers(self):\n        \"\"\"\n        See if the underlying logger has any handlers.\n        \"\"\"\n        return self.logger.hasHandlers()\n\n    def _log(self, level, msg, args, exc_info=None, extra=None, stack_info=False):\n        \"\"\"\n        Low-level log implementation, proxied to allow nested logger adapters.\n        \"\"\"\n        return self.logger._log(\n            level,\n            msg,\n            args,\n            exc_info=exc_info,\n            extra=extra,\n            stack_info=stack_info,\n        )\n\n    @property\n    def manager(self):\n        return self.logger.manager\n\n    @manager.setter\n    def manager(self, value):\n        self.logger.manager = value\n\n    @property\n    def name(self):\n        return self.logger.name\n\n    def __repr__(self):\n        logger = self.logger\n        level = getLevelName(logger.getEffectiveLevel())\n        return '<%s %s (%s)>' % (self.__class__.__name__, logger.name, level)\n\nroot = RootLogger(WARNING)\nLogger.root = root\nLogger.manager = Manager(Logger.root)\n\n#---------------------------------------------------------------------------\n# Configuration classes and functions\n#---------------------------------------------------------------------------\n\ndef basicConfig(**kwargs):\n    \"\"\"\n    Do basic configuration for the logging system.\n\n    This function does nothing if the root logger already has handlers\n    configured, unless the keyword argument *force* is set to ``True``.\n    It is a convenience method intended for use by simple scripts\n    to do one-shot configuration of the logging package.\n\n    The default behaviour is to create a StreamHandler which writes to\n    sys.stderr, set a formatter using the BASIC_FORMAT format string, and\n    add the handler to the root logger.\n\n    A number of optional keyword arguments may be specified, which can alter\n    the default behaviour.\n\n    filename  Specifies that a FileHandler be created, using the specified\n              filename, rather than a StreamHandler.\n    filemode  Specifies the mode to open the file, if filename is specified\n              (if filemode is unspecified, it defaults to 'a').\n    format    Use the specified format string for the handler.\n    datefmt   Use the specified date/time format.\n    style     If a format string is specified, use this to specify the\n              type of format string (possible values '%', '{', '$', for\n              %-formatting, :meth:`str.format` and :class:`string.Template`\n              - defaults to '%').\n    level     Set the root logger level to the specified level.\n    stream    Use the specified stream to initialize the StreamHandler. Note\n              that this argument is incompatible with 'filename' - if both\n              are present, 'stream' is ignored.\n    handlers  If specified, this should be an iterable of already created\n              handlers, which will be added to the root handler. Any handler\n              in the list which does not have a formatter assigned will be\n              assigned the formatter created in this function.\n    force     If this keyword  is specified as true, any existing handlers\n              attached to the root logger are removed and closed, before\n              carrying out the configuration as specified by the other\n              arguments.\n    encoding  If specified together with a filename, this encoding is passed to\n              the created FileHandler, causing it to be used when the file is\n              opened.\n    errors    If specified together with a filename, this value is passed to the\n              created FileHandler, causing it to be used when the file is\n              opened in text mode. If not specified, the default value is\n              `backslashreplace`.\n\n    Note that you could specify a stream created using open(filename, mode)\n    rather than passing the filename and mode in. However, it should be\n    remembered that StreamHandler does not close its stream (since it may be\n    using sys.stdout or sys.stderr), whereas FileHandler closes its stream\n    when the handler is closed.\n\n    .. versionchanged:: 3.2\n       Added the ``style`` parameter.\n\n    .. versionchanged:: 3.3\n       Added the ``handlers`` parameter. A ``ValueError`` is now thrown for\n       incompatible arguments (e.g. ``handlers`` specified together with\n       ``filename``/``filemode``, or ``filename``/``filemode`` specified\n       together with ``stream``, or ``handlers`` specified together with\n       ``stream``.\n\n    .. versionchanged:: 3.8\n       Added the ``force`` parameter.\n\n    .. versionchanged:: 3.9\n       Added the ``encoding`` and ``errors`` parameters.\n    \"\"\"\n    # Add thread safety in case someone mistakenly calls\n    # basicConfig() from multiple threads\n    _acquireLock()\n    try:\n        force = kwargs.pop('force', False)\n        encoding = kwargs.pop('encoding', None)\n        errors = kwargs.pop('errors', 'backslashreplace')\n        if force:\n            for h in root.handlers[:]:\n                root.removeHandler(h)\n                h.close()\n        if len(root.handlers) == 0:\n            handlers = kwargs.pop(\"handlers\", None)\n            if handlers is None:\n                if \"stream\" in kwargs and \"filename\" in kwargs:\n                    raise ValueError(\"'stream' and 'filename' should not be \"\n                                     \"specified together\")\n            else:\n                if \"stream\" in kwargs or \"filename\" in kwargs:\n                    raise ValueError(\"'stream' or 'filename' should not be \"\n                                     \"specified together with 'handlers'\")\n            if handlers is None:\n                filename = kwargs.pop(\"filename\", None)\n                mode = kwargs.pop(\"filemode\", 'a')\n                if filename:\n                    if 'b'in mode:\n                        errors = None\n                    h = FileHandler(filename, mode,\n                                    encoding=encoding, errors=errors)\n                else:\n                    stream = kwargs.pop(\"stream\", None)\n                    h = StreamHandler(stream)\n                handlers = [h]\n            dfs = kwargs.pop(\"datefmt\", None)\n            style = kwargs.pop(\"style\", '%')\n            if style not in _STYLES:\n                raise ValueError('Style must be one of: %s' % ','.join(\n                                 _STYLES.keys()))\n            fs = kwargs.pop(\"format\", _STYLES[style][1])\n            fmt = Formatter(fs, dfs, style)\n            for h in handlers:\n                if h.formatter is None:\n                    h.setFormatter(fmt)\n                root.addHandler(h)\n            level = kwargs.pop(\"level\", None)\n            if level is not None:\n                root.setLevel(level)\n            if kwargs:\n                keys = ', '.join(kwargs.keys())\n                raise ValueError('Unrecognised argument(s): %s' % keys)\n    finally:\n        _releaseLock()\n\n#---------------------------------------------------------------------------\n# Utility functions at module level.\n# Basically delegate everything to the root logger.\n#---------------------------------------------------------------------------\n\ndef getLogger(name=None):\n    \"\"\"\n    Return a logger with the specified name, creating it if necessary.\n\n    If no name is specified, return the root logger.\n    \"\"\"\n    if not name or isinstance(name, str) and name == root.name:\n        return root\n    return Logger.manager.getLogger(name)\n\ndef critical(msg, *args, **kwargs):\n    \"\"\"\n    Log a message with severity 'CRITICAL' on the root logger. If the logger\n    has no handlers, call basicConfig() to add a console handler with a\n    pre-defined format.\n    \"\"\"\n    if len(root.handlers) == 0:\n        basicConfig()\n    root.critical(msg, *args, **kwargs)\n\nfatal = critical\n\ndef error(msg, *args, **kwargs):\n    \"\"\"\n    Log a message with severity 'ERROR' on the root logger. If the logger has\n    no handlers, call basicConfig() to add a console handler with a pre-defined\n    format.\n    \"\"\"\n    if len(root.handlers) == 0:\n        basicConfig()\n    root.error(msg, *args, **kwargs)\n\ndef exception(msg, *args, exc_info=True, **kwargs):\n    \"\"\"\n    Log a message with severity 'ERROR' on the root logger, with exception\n    information. If the logger has no handlers, basicConfig() is called to add\n    a console handler with a pre-defined format.\n    \"\"\"\n    error(msg, *args, exc_info=exc_info, **kwargs)\n\ndef warning(msg, *args, **kwargs):\n    \"\"\"\n    Log a message with severity 'WARNING' on the root logger. If the logger has\n    no handlers, call basicConfig() to add a console handler with a pre-defined\n    format.\n    \"\"\"\n    if len(root.handlers) == 0:\n        basicConfig()\n    root.warning(msg, *args, **kwargs)\n\ndef warn(msg, *args, **kwargs):\n    warnings.warn(\"The 'warn' function is deprecated, \"\n        \"use 'warning' instead\", DeprecationWarning, 2)\n    warning(msg, *args, **kwargs)\n\ndef info(msg, *args, **kwargs):\n    \"\"\"\n    Log a message with severity 'INFO' on the root logger. If the logger has\n    no handlers, call basicConfig() to add a console handler with a pre-defined\n    format.\n    \"\"\"\n    if len(root.handlers) == 0:\n        basicConfig()\n    root.info(msg, *args, **kwargs)\n\ndef debug(msg, *args, **kwargs):\n    \"\"\"\n    Log a message with severity 'DEBUG' on the root logger. If the logger has\n    no handlers, call basicConfig() to add a console handler with a pre-defined\n    format.\n    \"\"\"\n    if len(root.handlers) == 0:\n        basicConfig()\n    root.debug(msg, *args, **kwargs)\n\ndef log(level, msg, *args, **kwargs):\n    \"\"\"\n    Log 'msg % args' with the integer severity 'level' on the root logger. If\n    the logger has no handlers, call basicConfig() to add a console handler\n    with a pre-defined format.\n    \"\"\"\n    if len(root.handlers) == 0:\n        basicConfig()\n    root.log(level, msg, *args, **kwargs)\n\ndef disable(level=CRITICAL):\n    \"\"\"\n    Disable all logging calls of severity 'level' and below.\n    \"\"\"\n    root.manager.disable = level\n    root.manager._clear_cache()\n\ndef shutdown(handlerList=_handlerList):\n    \"\"\"\n    Perform any cleanup actions in the logging system (e.g. flushing\n    buffers).\n\n    Should be called at application exit.\n    \"\"\"\n    for wr in reversed(handlerList[:]):\n        #errors might occur, for example, if files are locked\n        #we just ignore them if raiseExceptions is not set\n        try:\n            h = wr()\n            if h:\n                try:\n                    h.acquire()\n                    h.flush()\n                    h.close()\n                except (OSError, ValueError):\n                    # Ignore errors which might be caused\n                    # because handlers have been closed but\n                    # references to them are still around at\n                    # application exit.\n                    pass\n                finally:\n                    h.release()\n        except: # ignore everything, as we're shutting down\n            if raiseExceptions:\n                raise\n            #else, swallow\n\n#Let's try and shutdown automatically on application exit...\nimport atexit\natexit.register(shutdown)\n\n# Null handler\n\nclass NullHandler(Handler):\n    \"\"\"\n    This handler does nothing. It's intended to be used to avoid the\n    \"No handlers could be found for logger XXX\" one-off warning. This is\n    important for library code, which may contain code to log events. If a user\n    of the library does not configure logging, the one-off warning might be\n    produced; to avoid this, the library developer simply needs to instantiate\n    a NullHandler and add it to the top-level logger of the library module or\n    package.\n    \"\"\"\n    def handle(self, record):\n        \"\"\"Stub.\"\"\"\n\n    def emit(self, record):\n        \"\"\"Stub.\"\"\"\n\n    def createLock(self):\n        self.lock = None\n\n    def _at_fork_reinit(self):\n        pass\n\n# Warnings integration\n\n_warnings_showwarning = None\n\ndef _showwarning(message, category, filename, lineno, file=None, line=None):\n    \"\"\"\n    Implementation of showwarnings which redirects to logging, which will first\n    check to see if the file parameter is None. If a file is specified, it will\n    delegate to the original warnings implementation of showwarning. Otherwise,\n    it will call warnings.formatwarning and will log the resulting string to a\n    warnings logger named \"py.warnings\" with level logging.WARNING.\n    \"\"\"\n    if file is not None:\n        if _warnings_showwarning is not None:\n            _warnings_showwarning(message, category, filename, lineno, file, line)\n    else:\n        s = warnings.formatwarning(message, category, filename, lineno, line)\n        logger = getLogger(\"py.warnings\")\n        if not logger.handlers:\n            logger.addHandler(NullHandler())\n        logger.warning(\"%s\", s)\n\ndef captureWarnings(capture):\n    \"\"\"\n    If capture is true, redirect all warnings to the logging package.\n    If capture is False, ensure that warnings are not redirected to logging\n    but to their original destinations.\n    \"\"\"\n    global _warnings_showwarning\n    if capture:\n        if _warnings_showwarning is None:\n            _warnings_showwarning = warnings.showwarning\n            warnings.showwarning = _showwarning\n    else:\n        if _warnings_showwarning is not None:\n            warnings.showwarning = _warnings_showwarning\n            _warnings_showwarning = None\n", 2220], "/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/threading.py": ["\"\"\"Thread module emulating a subset of Java's threading model.\"\"\"\n\nimport os as _os\nimport sys as _sys\nimport _thread\nimport functools\n\nfrom time import monotonic as _time\nfrom _weakrefset import WeakSet\nfrom itertools import islice as _islice, count as _count\ntry:\n    from _collections import deque as _deque\nexcept ImportError:\n    from collections import deque as _deque\n\n# Note regarding PEP 8 compliant names\n#  This threading model was originally inspired by Java, and inherited\n# the convention of camelCase function and method names from that\n# language. Those original names are not in any imminent danger of\n# being deprecated (even for Py3k),so this module provides them as an\n# alias for the PEP 8 compliant names\n# Note that using the new PEP 8 compliant names facilitates substitution\n# with the multiprocessing module, which doesn't provide the old\n# Java inspired names.\n\n__all__ = ['get_ident', 'active_count', 'Condition', 'current_thread',\n           'enumerate', 'main_thread', 'TIMEOUT_MAX',\n           'Event', 'Lock', 'RLock', 'Semaphore', 'BoundedSemaphore', 'Thread',\n           'Barrier', 'BrokenBarrierError', 'Timer', 'ThreadError',\n           'setprofile', 'settrace', 'local', 'stack_size',\n           'excepthook', 'ExceptHookArgs']\n\n# Rename some stuff so \"from threading import *\" is safe\n_start_new_thread = _thread.start_new_thread\n_allocate_lock = _thread.allocate_lock\n_set_sentinel = _thread._set_sentinel\nget_ident = _thread.get_ident\ntry:\n    get_native_id = _thread.get_native_id\n    _HAVE_THREAD_NATIVE_ID = True\n    __all__.append('get_native_id')\nexcept AttributeError:\n    _HAVE_THREAD_NATIVE_ID = False\nThreadError = _thread.error\ntry:\n    _CRLock = _thread.RLock\nexcept AttributeError:\n    _CRLock = None\nTIMEOUT_MAX = _thread.TIMEOUT_MAX\ndel _thread\n\n\n# Support for profile and trace hooks\n\n_profile_hook = None\n_trace_hook = None\n\ndef setprofile(func):\n    \"\"\"Set a profile function for all threads started from the threading module.\n\n    The func will be passed to sys.setprofile() for each thread, before its\n    run() method is called.\n\n    \"\"\"\n    global _profile_hook\n    _profile_hook = func\n\ndef settrace(func):\n    \"\"\"Set a trace function for all threads started from the threading module.\n\n    The func will be passed to sys.settrace() for each thread, before its run()\n    method is called.\n\n    \"\"\"\n    global _trace_hook\n    _trace_hook = func\n\n# Synchronization classes\n\nLock = _allocate_lock\n\ndef RLock(*args, **kwargs):\n    \"\"\"Factory function that returns a new reentrant lock.\n\n    A reentrant lock must be released by the thread that acquired it. Once a\n    thread has acquired a reentrant lock, the same thread may acquire it again\n    without blocking; the thread must release it once for each time it has\n    acquired it.\n\n    \"\"\"\n    if _CRLock is None:\n        return _PyRLock(*args, **kwargs)\n    return _CRLock(*args, **kwargs)\n\nclass _RLock:\n    \"\"\"This class implements reentrant lock objects.\n\n    A reentrant lock must be released by the thread that acquired it. Once a\n    thread has acquired a reentrant lock, the same thread may acquire it\n    again without blocking; the thread must release it once for each time it\n    has acquired it.\n\n    \"\"\"\n\n    def __init__(self):\n        self._block = _allocate_lock()\n        self._owner = None\n        self._count = 0\n\n    def __repr__(self):\n        owner = self._owner\n        try:\n            owner = _active[owner].name\n        except KeyError:\n            pass\n        return \"<%s %s.%s object owner=%r count=%d at %s>\" % (\n            \"locked\" if self._block.locked() else \"unlocked\",\n            self.__class__.__module__,\n            self.__class__.__qualname__,\n            owner,\n            self._count,\n            hex(id(self))\n        )\n\n    def _at_fork_reinit(self):\n        self._block._at_fork_reinit()\n        self._owner = None\n        self._count = 0\n\n    def acquire(self, blocking=True, timeout=-1):\n        \"\"\"Acquire a lock, blocking or non-blocking.\n\n        When invoked without arguments: if this thread already owns the lock,\n        increment the recursion level by one, and return immediately. Otherwise,\n        if another thread owns the lock, block until the lock is unlocked. Once\n        the lock is unlocked (not owned by any thread), then grab ownership, set\n        the recursion level to one, and return. If more than one thread is\n        blocked waiting until the lock is unlocked, only one at a time will be\n        able to grab ownership of the lock. There is no return value in this\n        case.\n\n        When invoked with the blocking argument set to true, do the same thing\n        as when called without arguments, and return true.\n\n        When invoked with the blocking argument set to false, do not block. If a\n        call without an argument would block, return false immediately;\n        otherwise, do the same thing as when called without arguments, and\n        return true.\n\n        When invoked with the floating-point timeout argument set to a positive\n        value, block for at most the number of seconds specified by timeout\n        and as long as the lock cannot be acquired.  Return true if the lock has\n        been acquired, false if the timeout has elapsed.\n\n        \"\"\"\n        me = get_ident()\n        if self._owner == me:\n            self._count += 1\n            return 1\n        rc = self._block.acquire(blocking, timeout)\n        if rc:\n            self._owner = me\n            self._count = 1\n        return rc\n\n    __enter__ = acquire\n\n    def release(self):\n        \"\"\"Release a lock, decrementing the recursion level.\n\n        If after the decrement it is zero, reset the lock to unlocked (not owned\n        by any thread), and if any other threads are blocked waiting for the\n        lock to become unlocked, allow exactly one of them to proceed. If after\n        the decrement the recursion level is still nonzero, the lock remains\n        locked and owned by the calling thread.\n\n        Only call this method when the calling thread owns the lock. A\n        RuntimeError is raised if this method is called when the lock is\n        unlocked.\n\n        There is no return value.\n\n        \"\"\"\n        if self._owner != get_ident():\n            raise RuntimeError(\"cannot release un-acquired lock\")\n        self._count = count = self._count - 1\n        if not count:\n            self._owner = None\n            self._block.release()\n\n    def __exit__(self, t, v, tb):\n        self.release()\n\n    # Internal methods used by condition variables\n\n    def _acquire_restore(self, state):\n        self._block.acquire()\n        self._count, self._owner = state\n\n    def _release_save(self):\n        if self._count == 0:\n            raise RuntimeError(\"cannot release un-acquired lock\")\n        count = self._count\n        self._count = 0\n        owner = self._owner\n        self._owner = None\n        self._block.release()\n        return (count, owner)\n\n    def _is_owned(self):\n        return self._owner == get_ident()\n\n_PyRLock = _RLock\n\n\nclass Condition:\n    \"\"\"Class that implements a condition variable.\n\n    A condition variable allows one or more threads to wait until they are\n    notified by another thread.\n\n    If the lock argument is given and not None, it must be a Lock or RLock\n    object, and it is used as the underlying lock. Otherwise, a new RLock object\n    is created and used as the underlying lock.\n\n    \"\"\"\n\n    def __init__(self, lock=None):\n        if lock is None:\n            lock = RLock()\n        self._lock = lock\n        # Export the lock's acquire() and release() methods\n        self.acquire = lock.acquire\n        self.release = lock.release\n        # If the lock defines _release_save() and/or _acquire_restore(),\n        # these override the default implementations (which just call\n        # release() and acquire() on the lock).  Ditto for _is_owned().\n        try:\n            self._release_save = lock._release_save\n        except AttributeError:\n            pass\n        try:\n            self._acquire_restore = lock._acquire_restore\n        except AttributeError:\n            pass\n        try:\n            self._is_owned = lock._is_owned\n        except AttributeError:\n            pass\n        self._waiters = _deque()\n\n    def _at_fork_reinit(self):\n        self._lock._at_fork_reinit()\n        self._waiters.clear()\n\n    def __enter__(self):\n        return self._lock.__enter__()\n\n    def __exit__(self, *args):\n        return self._lock.__exit__(*args)\n\n    def __repr__(self):\n        return \"<Condition(%s, %d)>\" % (self._lock, len(self._waiters))\n\n    def _release_save(self):\n        self._lock.release()           # No state to save\n\n    def _acquire_restore(self, x):\n        self._lock.acquire()           # Ignore saved state\n\n    def _is_owned(self):\n        # Return True if lock is owned by current_thread.\n        # This method is called only if _lock doesn't have _is_owned().\n        if self._lock.acquire(False):\n            self._lock.release()\n            return False\n        else:\n            return True\n\n    def wait(self, timeout=None):\n        \"\"\"Wait until notified or until a timeout occurs.\n\n        If the calling thread has not acquired the lock when this method is\n        called, a RuntimeError is raised.\n\n        This method releases the underlying lock, and then blocks until it is\n        awakened by a notify() or notify_all() call for the same condition\n        variable in another thread, or until the optional timeout occurs. Once\n        awakened or timed out, it re-acquires the lock and returns.\n\n        When the timeout argument is present and not None, it should be a\n        floating point number specifying a timeout for the operation in seconds\n        (or fractions thereof).\n\n        When the underlying lock is an RLock, it is not released using its\n        release() method, since this may not actually unlock the lock when it\n        was acquired multiple times recursively. Instead, an internal interface\n        of the RLock class is used, which really unlocks it even when it has\n        been recursively acquired several times. Another internal interface is\n        then used to restore the recursion level when the lock is reacquired.\n\n        \"\"\"\n        if not self._is_owned():\n            raise RuntimeError(\"cannot wait on un-acquired lock\")\n        waiter = _allocate_lock()\n        waiter.acquire()\n        self._waiters.append(waiter)\n        saved_state = self._release_save()\n        gotit = False\n        try:    # restore state no matter what (e.g., KeyboardInterrupt)\n            if timeout is None:\n                waiter.acquire()\n                gotit = True\n            else:\n                if timeout > 0:\n                    gotit = waiter.acquire(True, timeout)\n                else:\n                    gotit = waiter.acquire(False)\n            return gotit\n        finally:\n            self._acquire_restore(saved_state)\n            if not gotit:\n                try:\n                    self._waiters.remove(waiter)\n                except ValueError:\n                    pass\n\n    def wait_for(self, predicate, timeout=None):\n        \"\"\"Wait until a condition evaluates to True.\n\n        predicate should be a callable which result will be interpreted as a\n        boolean value.  A timeout may be provided giving the maximum time to\n        wait.\n\n        \"\"\"\n        endtime = None\n        waittime = timeout\n        result = predicate()\n        while not result:\n            if waittime is not None:\n                if endtime is None:\n                    endtime = _time() + waittime\n                else:\n                    waittime = endtime - _time()\n                    if waittime <= 0:\n                        break\n            self.wait(waittime)\n            result = predicate()\n        return result\n\n    def notify(self, n=1):\n        \"\"\"Wake up one or more threads waiting on this condition, if any.\n\n        If the calling thread has not acquired the lock when this method is\n        called, a RuntimeError is raised.\n\n        This method wakes up at most n of the threads waiting for the condition\n        variable; it is a no-op if no threads are waiting.\n\n        \"\"\"\n        if not self._is_owned():\n            raise RuntimeError(\"cannot notify on un-acquired lock\")\n        all_waiters = self._waiters\n        waiters_to_notify = _deque(_islice(all_waiters, n))\n        if not waiters_to_notify:\n            return\n        for waiter in waiters_to_notify:\n            waiter.release()\n            try:\n                all_waiters.remove(waiter)\n            except ValueError:\n                pass\n\n    def notify_all(self):\n        \"\"\"Wake up all threads waiting on this condition.\n\n        If the calling thread has not acquired the lock when this method\n        is called, a RuntimeError is raised.\n\n        \"\"\"\n        self.notify(len(self._waiters))\n\n    notifyAll = notify_all\n\n\nclass Semaphore:\n    \"\"\"This class implements semaphore objects.\n\n    Semaphores manage a counter representing the number of release() calls minus\n    the number of acquire() calls, plus an initial value. The acquire() method\n    blocks if necessary until it can return without making the counter\n    negative. If not given, value defaults to 1.\n\n    \"\"\"\n\n    # After Tim Peters' semaphore class, but not quite the same (no maximum)\n\n    def __init__(self, value=1):\n        if value < 0:\n            raise ValueError(\"semaphore initial value must be >= 0\")\n        self._cond = Condition(Lock())\n        self._value = value\n\n    def acquire(self, blocking=True, timeout=None):\n        \"\"\"Acquire a semaphore, decrementing the internal counter by one.\n\n        When invoked without arguments: if the internal counter is larger than\n        zero on entry, decrement it by one and return immediately. If it is zero\n        on entry, block, waiting until some other thread has called release() to\n        make it larger than zero. This is done with proper interlocking so that\n        if multiple acquire() calls are blocked, release() will wake exactly one\n        of them up. The implementation may pick one at random, so the order in\n        which blocked threads are awakened should not be relied on. There is no\n        return value in this case.\n\n        When invoked with blocking set to true, do the same thing as when called\n        without arguments, and return true.\n\n        When invoked with blocking set to false, do not block. If a call without\n        an argument would block, return false immediately; otherwise, do the\n        same thing as when called without arguments, and return true.\n\n        When invoked with a timeout other than None, it will block for at\n        most timeout seconds.  If acquire does not complete successfully in\n        that interval, return false.  Return true otherwise.\n\n        \"\"\"\n        if not blocking and timeout is not None:\n            raise ValueError(\"can't specify timeout for non-blocking acquire\")\n        rc = False\n        endtime = None\n        with self._cond:\n            while self._value == 0:\n                if not blocking:\n                    break\n                if timeout is not None:\n                    if endtime is None:\n                        endtime = _time() + timeout\n                    else:\n                        timeout = endtime - _time()\n                        if timeout <= 0:\n                            break\n                self._cond.wait(timeout)\n            else:\n                self._value -= 1\n                rc = True\n        return rc\n\n    __enter__ = acquire\n\n    def release(self, n=1):\n        \"\"\"Release a semaphore, incrementing the internal counter by one or more.\n\n        When the counter is zero on entry and another thread is waiting for it\n        to become larger than zero again, wake up that thread.\n\n        \"\"\"\n        if n < 1:\n            raise ValueError('n must be one or more')\n        with self._cond:\n            self._value += n\n            for i in range(n):\n                self._cond.notify()\n\n    def __exit__(self, t, v, tb):\n        self.release()\n\n\nclass BoundedSemaphore(Semaphore):\n    \"\"\"Implements a bounded semaphore.\n\n    A bounded semaphore checks to make sure its current value doesn't exceed its\n    initial value. If it does, ValueError is raised. In most situations\n    semaphores are used to guard resources with limited capacity.\n\n    If the semaphore is released too many times it's a sign of a bug. If not\n    given, value defaults to 1.\n\n    Like regular semaphores, bounded semaphores manage a counter representing\n    the number of release() calls minus the number of acquire() calls, plus an\n    initial value. The acquire() method blocks if necessary until it can return\n    without making the counter negative. If not given, value defaults to 1.\n\n    \"\"\"\n\n    def __init__(self, value=1):\n        Semaphore.__init__(self, value)\n        self._initial_value = value\n\n    def release(self, n=1):\n        \"\"\"Release a semaphore, incrementing the internal counter by one or more.\n\n        When the counter is zero on entry and another thread is waiting for it\n        to become larger than zero again, wake up that thread.\n\n        If the number of releases exceeds the number of acquires,\n        raise a ValueError.\n\n        \"\"\"\n        if n < 1:\n            raise ValueError('n must be one or more')\n        with self._cond:\n            if self._value + n > self._initial_value:\n                raise ValueError(\"Semaphore released too many times\")\n            self._value += n\n            for i in range(n):\n                self._cond.notify()\n\n\nclass Event:\n    \"\"\"Class implementing event objects.\n\n    Events manage a flag that can be set to true with the set() method and reset\n    to false with the clear() method. The wait() method blocks until the flag is\n    true.  The flag is initially false.\n\n    \"\"\"\n\n    # After Tim Peters' event class (without is_posted())\n\n    def __init__(self):\n        self._cond = Condition(Lock())\n        self._flag = False\n\n    def _at_fork_reinit(self):\n        # Private method called by Thread._reset_internal_locks()\n        self._cond._at_fork_reinit()\n\n    def is_set(self):\n        \"\"\"Return true if and only if the internal flag is true.\"\"\"\n        return self._flag\n\n    isSet = is_set\n\n    def set(self):\n        \"\"\"Set the internal flag to true.\n\n        All threads waiting for it to become true are awakened. Threads\n        that call wait() once the flag is true will not block at all.\n\n        \"\"\"\n        with self._cond:\n            self._flag = True\n            self._cond.notify_all()\n\n    def clear(self):\n        \"\"\"Reset the internal flag to false.\n\n        Subsequently, threads calling wait() will block until set() is called to\n        set the internal flag to true again.\n\n        \"\"\"\n        with self._cond:\n            self._flag = False\n\n    def wait(self, timeout=None):\n        \"\"\"Block until the internal flag is true.\n\n        If the internal flag is true on entry, return immediately. Otherwise,\n        block until another thread calls set() to set the flag to true, or until\n        the optional timeout occurs.\n\n        When the timeout argument is present and not None, it should be a\n        floating point number specifying a timeout for the operation in seconds\n        (or fractions thereof).\n\n        This method returns the internal flag on exit, so it will always return\n        True except if a timeout is given and the operation times out.\n\n        \"\"\"\n        with self._cond:\n            signaled = self._flag\n            if not signaled:\n                signaled = self._cond.wait(timeout)\n            return signaled\n\n\n# A barrier class.  Inspired in part by the pthread_barrier_* api and\n# the CyclicBarrier class from Java.  See\n# http://sourceware.org/pthreads-win32/manual/pthread_barrier_init.html and\n# http://java.sun.com/j2se/1.5.0/docs/api/java/util/concurrent/\n#        CyclicBarrier.html\n# for information.\n# We maintain two main states, 'filling' and 'draining' enabling the barrier\n# to be cyclic.  Threads are not allowed into it until it has fully drained\n# since the previous cycle.  In addition, a 'resetting' state exists which is\n# similar to 'draining' except that threads leave with a BrokenBarrierError,\n# and a 'broken' state in which all threads get the exception.\nclass Barrier:\n    \"\"\"Implements a Barrier.\n\n    Useful for synchronizing a fixed number of threads at known synchronization\n    points.  Threads block on 'wait()' and are simultaneously awoken once they\n    have all made that call.\n\n    \"\"\"\n\n    def __init__(self, parties, action=None, timeout=None):\n        \"\"\"Create a barrier, initialised to 'parties' threads.\n\n        'action' is a callable which, when supplied, will be called by one of\n        the threads after they have all entered the barrier and just prior to\n        releasing them all. If a 'timeout' is provided, it is used as the\n        default for all subsequent 'wait()' calls.\n\n        \"\"\"\n        self._cond = Condition(Lock())\n        self._action = action\n        self._timeout = timeout\n        self._parties = parties\n        self._state = 0  # 0 filling, 1 draining, -1 resetting, -2 broken\n        self._count = 0\n\n    def wait(self, timeout=None):\n        \"\"\"Wait for the barrier.\n\n        When the specified number of threads have started waiting, they are all\n        simultaneously awoken. If an 'action' was provided for the barrier, one\n        of the threads will have executed that callback prior to returning.\n        Returns an individual index number from 0 to 'parties-1'.\n\n        \"\"\"\n        if timeout is None:\n            timeout = self._timeout\n        with self._cond:\n            self._enter() # Block while the barrier drains.\n            index = self._count\n            self._count += 1\n            try:\n                if index + 1 == self._parties:\n                    # We release the barrier\n                    self._release()\n                else:\n                    # We wait until someone releases us\n                    self._wait(timeout)\n                return index\n            finally:\n                self._count -= 1\n                # Wake up any threads waiting for barrier to drain.\n                self._exit()\n\n    # Block until the barrier is ready for us, or raise an exception\n    # if it is broken.\n    def _enter(self):\n        while self._state in (-1, 1):\n            # It is draining or resetting, wait until done\n            self._cond.wait()\n        #see if the barrier is in a broken state\n        if self._state < 0:\n            raise BrokenBarrierError\n        assert self._state == 0\n\n    # Optionally run the 'action' and release the threads waiting\n    # in the barrier.\n    def _release(self):\n        try:\n            if self._action:\n                self._action()\n            # enter draining state\n            self._state = 1\n            self._cond.notify_all()\n        except:\n            #an exception during the _action handler.  Break and reraise\n            self._break()\n            raise\n\n    # Wait in the barrier until we are released.  Raise an exception\n    # if the barrier is reset or broken.\n    def _wait(self, timeout):\n        if not self._cond.wait_for(lambda : self._state != 0, timeout):\n            #timed out.  Break the barrier\n            self._break()\n            raise BrokenBarrierError\n        if self._state < 0:\n            raise BrokenBarrierError\n        assert self._state == 1\n\n    # If we are the last thread to exit the barrier, signal any threads\n    # waiting for the barrier to drain.\n    def _exit(self):\n        if self._count == 0:\n            if self._state in (-1, 1):\n                #resetting or draining\n                self._state = 0\n                self._cond.notify_all()\n\n    def reset(self):\n        \"\"\"Reset the barrier to the initial state.\n\n        Any threads currently waiting will get the BrokenBarrier exception\n        raised.\n\n        \"\"\"\n        with self._cond:\n            if self._count > 0:\n                if self._state == 0:\n                    #reset the barrier, waking up threads\n                    self._state = -1\n                elif self._state == -2:\n                    #was broken, set it to reset state\n                    #which clears when the last thread exits\n                    self._state = -1\n            else:\n                self._state = 0\n            self._cond.notify_all()\n\n    def abort(self):\n        \"\"\"Place the barrier into a 'broken' state.\n\n        Useful in case of error.  Any currently waiting threads and threads\n        attempting to 'wait()' will have BrokenBarrierError raised.\n\n        \"\"\"\n        with self._cond:\n            self._break()\n\n    def _break(self):\n        # An internal error was detected.  The barrier is set to\n        # a broken state all parties awakened.\n        self._state = -2\n        self._cond.notify_all()\n\n    @property\n    def parties(self):\n        \"\"\"Return the number of threads required to trip the barrier.\"\"\"\n        return self._parties\n\n    @property\n    def n_waiting(self):\n        \"\"\"Return the number of threads currently waiting at the barrier.\"\"\"\n        # We don't need synchronization here since this is an ephemeral result\n        # anyway.  It returns the correct value in the steady state.\n        if self._state == 0:\n            return self._count\n        return 0\n\n    @property\n    def broken(self):\n        \"\"\"Return True if the barrier is in a broken state.\"\"\"\n        return self._state == -2\n\n# exception raised by the Barrier class\nclass BrokenBarrierError(RuntimeError):\n    pass\n\n\n# Helper to generate new thread names\n_counter = _count().__next__\n_counter() # Consume 0 so first non-main thread has id 1.\ndef _newname(template=\"Thread-%d\"):\n    return template % _counter()\n\n# Active thread administration.\n#\n# bpo-44422: Use a reentrant lock to allow reentrant calls to functions like\n# threading.enumerate().\n_active_limbo_lock = RLock()\n_active = {}    # maps thread id to Thread object\n_limbo = {}\n_dangling = WeakSet()\n\n# Set of Thread._tstate_lock locks of non-daemon threads used by _shutdown()\n# to wait until all Python thread states get deleted:\n# see Thread._set_tstate_lock().\n_shutdown_locks_lock = _allocate_lock()\n_shutdown_locks = set()\n\ndef _maintain_shutdown_locks():\n    \"\"\"\n    Drop any shutdown locks that don't correspond to running threads anymore.\n\n    Calling this from time to time avoids an ever-growing _shutdown_locks\n    set when Thread objects are not joined explicitly. See bpo-37788.\n\n    This must be called with _shutdown_locks_lock acquired.\n    \"\"\"\n    # If a lock was released, the corresponding thread has exited\n    to_remove = [lock for lock in _shutdown_locks if not lock.locked()]\n    _shutdown_locks.difference_update(to_remove)\n\n\n# Main class for threads\n\nclass Thread:\n    \"\"\"A class that represents a thread of control.\n\n    This class can be safely subclassed in a limited fashion. There are two ways\n    to specify the activity: by passing a callable object to the constructor, or\n    by overriding the run() method in a subclass.\n\n    \"\"\"\n\n    _initialized = False\n\n    def __init__(self, group=None, target=None, name=None,\n                 args=(), kwargs=None, *, daemon=None):\n        \"\"\"This constructor should always be called with keyword arguments. Arguments are:\n\n        *group* should be None; reserved for future extension when a ThreadGroup\n        class is implemented.\n\n        *target* is the callable object to be invoked by the run()\n        method. Defaults to None, meaning nothing is called.\n\n        *name* is the thread name. By default, a unique name is constructed of\n        the form \"Thread-N\" where N is a small decimal number.\n\n        *args* is the argument tuple for the target invocation. Defaults to ().\n\n        *kwargs* is a dictionary of keyword arguments for the target\n        invocation. Defaults to {}.\n\n        If a subclass overrides the constructor, it must make sure to invoke\n        the base class constructor (Thread.__init__()) before doing anything\n        else to the thread.\n\n        \"\"\"\n        assert group is None, \"group argument must be None for now\"\n        if kwargs is None:\n            kwargs = {}\n        self._target = target\n        self._name = str(name or _newname())\n        self._args = args\n        self._kwargs = kwargs\n        if daemon is not None:\n            self._daemonic = daemon\n        else:\n            self._daemonic = current_thread().daemon\n        self._ident = None\n        if _HAVE_THREAD_NATIVE_ID:\n            self._native_id = None\n        self._tstate_lock = None\n        self._started = Event()\n        self._is_stopped = False\n        self._initialized = True\n        # Copy of sys.stderr used by self._invoke_excepthook()\n        self._stderr = _sys.stderr\n        self._invoke_excepthook = _make_invoke_excepthook()\n        # For debugging and _after_fork()\n        _dangling.add(self)\n\n    def _reset_internal_locks(self, is_alive):\n        # private!  Called by _after_fork() to reset our internal locks as\n        # they may be in an invalid state leading to a deadlock or crash.\n        self._started._at_fork_reinit()\n        if is_alive:\n            # bpo-42350: If the fork happens when the thread is already stopped\n            # (ex: after threading._shutdown() has been called), _tstate_lock\n            # is None. Do nothing in this case.\n            if self._tstate_lock is not None:\n                self._tstate_lock._at_fork_reinit()\n                self._tstate_lock.acquire()\n        else:\n            # The thread isn't alive after fork: it doesn't have a tstate\n            # anymore.\n            self._is_stopped = True\n            self._tstate_lock = None\n\n    def __repr__(self):\n        assert self._initialized, \"Thread.__init__() was not called\"\n        status = \"initial\"\n        if self._started.is_set():\n            status = \"started\"\n        self.is_alive() # easy way to get ._is_stopped set when appropriate\n        if self._is_stopped:\n            status = \"stopped\"\n        if self._daemonic:\n            status += \" daemon\"\n        if self._ident is not None:\n            status += \" %s\" % self._ident\n        return \"<%s(%s, %s)>\" % (self.__class__.__name__, self._name, status)\n\n    def start(self):\n        \"\"\"Start the thread's activity.\n\n        It must be called at most once per thread object. It arranges for the\n        object's run() method to be invoked in a separate thread of control.\n\n        This method will raise a RuntimeError if called more than once on the\n        same thread object.\n\n        \"\"\"\n        if not self._initialized:\n            raise RuntimeError(\"thread.__init__() not called\")\n\n        if self._started.is_set():\n            raise RuntimeError(\"threads can only be started once\")\n\n        with _active_limbo_lock:\n            _limbo[self] = self\n        try:\n            _start_new_thread(self._bootstrap, ())\n        except Exception:\n            with _active_limbo_lock:\n                del _limbo[self]\n            raise\n        self._started.wait()\n\n    def run(self):\n        \"\"\"Method representing the thread's activity.\n\n        You may override this method in a subclass. The standard run() method\n        invokes the callable object passed to the object's constructor as the\n        target argument, if any, with sequential and keyword arguments taken\n        from the args and kwargs arguments, respectively.\n\n        \"\"\"\n        try:\n            if self._target:\n                self._target(*self._args, **self._kwargs)\n        finally:\n            # Avoid a refcycle if the thread is running a function with\n            # an argument that has a member that points to the thread.\n            del self._target, self._args, self._kwargs\n\n    def _bootstrap(self):\n        # Wrapper around the real bootstrap code that ignores\n        # exceptions during interpreter cleanup.  Those typically\n        # happen when a daemon thread wakes up at an unfortunate\n        # moment, finds the world around it destroyed, and raises some\n        # random exception *** while trying to report the exception in\n        # _bootstrap_inner() below ***.  Those random exceptions\n        # don't help anybody, and they confuse users, so we suppress\n        # them.  We suppress them only when it appears that the world\n        # indeed has already been destroyed, so that exceptions in\n        # _bootstrap_inner() during normal business hours are properly\n        # reported.  Also, we only suppress them for daemonic threads;\n        # if a non-daemonic encounters this, something else is wrong.\n        try:\n            self._bootstrap_inner()\n        except:\n            if self._daemonic and _sys is None:\n                return\n            raise\n\n    def _set_ident(self):\n        self._ident = get_ident()\n\n    if _HAVE_THREAD_NATIVE_ID:\n        def _set_native_id(self):\n            self._native_id = get_native_id()\n\n    def _set_tstate_lock(self):\n        \"\"\"\n        Set a lock object which will be released by the interpreter when\n        the underlying thread state (see pystate.h) gets deleted.\n        \"\"\"\n        self._tstate_lock = _set_sentinel()\n        self._tstate_lock.acquire()\n\n        if not self.daemon:\n            with _shutdown_locks_lock:\n                _maintain_shutdown_locks()\n                _shutdown_locks.add(self._tstate_lock)\n\n    def _bootstrap_inner(self):\n        try:\n            self._set_ident()\n            self._set_tstate_lock()\n            if _HAVE_THREAD_NATIVE_ID:\n                self._set_native_id()\n            self._started.set()\n            with _active_limbo_lock:\n                _active[self._ident] = self\n                del _limbo[self]\n\n            if _trace_hook:\n                _sys.settrace(_trace_hook)\n            if _profile_hook:\n                _sys.setprofile(_profile_hook)\n\n            try:\n                self.run()\n            except:\n                self._invoke_excepthook(self)\n        finally:\n            with _active_limbo_lock:\n                try:\n                    # We don't call self._delete() because it also\n                    # grabs _active_limbo_lock.\n                    del _active[get_ident()]\n                except:\n                    pass\n\n    def _stop(self):\n        # After calling ._stop(), .is_alive() returns False and .join() returns\n        # immediately.  ._tstate_lock must be released before calling ._stop().\n        #\n        # Normal case:  C code at the end of the thread's life\n        # (release_sentinel in _threadmodule.c) releases ._tstate_lock, and\n        # that's detected by our ._wait_for_tstate_lock(), called by .join()\n        # and .is_alive().  Any number of threads _may_ call ._stop()\n        # simultaneously (for example, if multiple threads are blocked in\n        # .join() calls), and they're not serialized.  That's harmless -\n        # they'll just make redundant rebindings of ._is_stopped and\n        # ._tstate_lock.  Obscure:  we rebind ._tstate_lock last so that the\n        # \"assert self._is_stopped\" in ._wait_for_tstate_lock() always works\n        # (the assert is executed only if ._tstate_lock is None).\n        #\n        # Special case:  _main_thread releases ._tstate_lock via this\n        # module's _shutdown() function.\n        lock = self._tstate_lock\n        if lock is not None:\n            assert not lock.locked()\n        self._is_stopped = True\n        self._tstate_lock = None\n        if not self.daemon:\n            with _shutdown_locks_lock:\n                # Remove our lock and other released locks from _shutdown_locks\n                _maintain_shutdown_locks()\n\n    def _delete(self):\n        \"Remove current thread from the dict of currently running threads.\"\n        with _active_limbo_lock:\n            del _active[get_ident()]\n            # There must not be any python code between the previous line\n            # and after the lock is released.  Otherwise a tracing function\n            # could try to acquire the lock again in the same thread, (in\n            # current_thread()), and would block.\n\n    def join(self, timeout=None):\n        \"\"\"Wait until the thread terminates.\n\n        This blocks the calling thread until the thread whose join() method is\n        called terminates -- either normally or through an unhandled exception\n        or until the optional timeout occurs.\n\n        When the timeout argument is present and not None, it should be a\n        floating point number specifying a timeout for the operation in seconds\n        (or fractions thereof). As join() always returns None, you must call\n        is_alive() after join() to decide whether a timeout happened -- if the\n        thread is still alive, the join() call timed out.\n\n        When the timeout argument is not present or None, the operation will\n        block until the thread terminates.\n\n        A thread can be join()ed many times.\n\n        join() raises a RuntimeError if an attempt is made to join the current\n        thread as that would cause a deadlock. It is also an error to join() a\n        thread before it has been started and attempts to do so raises the same\n        exception.\n\n        \"\"\"\n        if not self._initialized:\n            raise RuntimeError(\"Thread.__init__() not called\")\n        if not self._started.is_set():\n            raise RuntimeError(\"cannot join thread before it is started\")\n        if self is current_thread():\n            raise RuntimeError(\"cannot join current thread\")\n\n        if timeout is None:\n            self._wait_for_tstate_lock()\n        else:\n            # the behavior of a negative timeout isn't documented, but\n            # historically .join(timeout=x) for x<0 has acted as if timeout=0\n            self._wait_for_tstate_lock(timeout=max(timeout, 0))\n\n    def _wait_for_tstate_lock(self, block=True, timeout=-1):\n        # Issue #18808: wait for the thread state to be gone.\n        # At the end of the thread's life, after all knowledge of the thread\n        # is removed from C data structures, C code releases our _tstate_lock.\n        # This method passes its arguments to _tstate_lock.acquire().\n        # If the lock is acquired, the C code is done, and self._stop() is\n        # called.  That sets ._is_stopped to True, and ._tstate_lock to None.\n        lock = self._tstate_lock\n        if lock is None:\n            # already determined that the C code is done\n            assert self._is_stopped\n            return\n\n        try:\n            if lock.acquire(block, timeout):\n                lock.release()\n                self._stop()\n        except:\n            if lock.locked():\n                # bpo-45274: lock.acquire() acquired the lock, but the function\n                # was interrupted with an exception before reaching the\n                # lock.release(). It can happen if a signal handler raises an\n                # exception, like CTRL+C which raises KeyboardInterrupt.\n                lock.release()\n                self._stop()\n            raise\n\n    @property\n    def name(self):\n        \"\"\"A string used for identification purposes only.\n\n        It has no semantics. Multiple threads may be given the same name. The\n        initial name is set by the constructor.\n\n        \"\"\"\n        assert self._initialized, \"Thread.__init__() not called\"\n        return self._name\n\n    @name.setter\n    def name(self, name):\n        assert self._initialized, \"Thread.__init__() not called\"\n        self._name = str(name)\n\n    @property\n    def ident(self):\n        \"\"\"Thread identifier of this thread or None if it has not been started.\n\n        This is a nonzero integer. See the get_ident() function. Thread\n        identifiers may be recycled when a thread exits and another thread is\n        created. The identifier is available even after the thread has exited.\n\n        \"\"\"\n        assert self._initialized, \"Thread.__init__() not called\"\n        return self._ident\n\n    if _HAVE_THREAD_NATIVE_ID:\n        @property\n        def native_id(self):\n            \"\"\"Native integral thread ID of this thread, or None if it has not been started.\n\n            This is a non-negative integer. See the get_native_id() function.\n            This represents the Thread ID as reported by the kernel.\n\n            \"\"\"\n            assert self._initialized, \"Thread.__init__() not called\"\n            return self._native_id\n\n    def is_alive(self):\n        \"\"\"Return whether the thread is alive.\n\n        This method returns True just before the run() method starts until just\n        after the run() method terminates. See also the module function\n        enumerate().\n\n        \"\"\"\n        assert self._initialized, \"Thread.__init__() not called\"\n        if self._is_stopped or not self._started.is_set():\n            return False\n        self._wait_for_tstate_lock(False)\n        return not self._is_stopped\n\n    @property\n    def daemon(self):\n        \"\"\"A boolean value indicating whether this thread is a daemon thread.\n\n        This must be set before start() is called, otherwise RuntimeError is\n        raised. Its initial value is inherited from the creating thread; the\n        main thread is not a daemon thread and therefore all threads created in\n        the main thread default to daemon = False.\n\n        The entire Python program exits when only daemon threads are left.\n\n        \"\"\"\n        assert self._initialized, \"Thread.__init__() not called\"\n        return self._daemonic\n\n    @daemon.setter\n    def daemon(self, daemonic):\n        if not self._initialized:\n            raise RuntimeError(\"Thread.__init__() not called\")\n        if self._started.is_set():\n            raise RuntimeError(\"cannot set daemon status of active thread\")\n        self._daemonic = daemonic\n\n    def isDaemon(self):\n        return self.daemon\n\n    def setDaemon(self, daemonic):\n        self.daemon = daemonic\n\n    def getName(self):\n        return self.name\n\n    def setName(self, name):\n        self.name = name\n\n\ntry:\n    from _thread import (_excepthook as excepthook,\n                         _ExceptHookArgs as ExceptHookArgs)\nexcept ImportError:\n    # Simple Python implementation if _thread._excepthook() is not available\n    from traceback import print_exception as _print_exception\n    from collections import namedtuple\n\n    _ExceptHookArgs = namedtuple(\n        'ExceptHookArgs',\n        'exc_type exc_value exc_traceback thread')\n\n    def ExceptHookArgs(args):\n        return _ExceptHookArgs(*args)\n\n    def excepthook(args, /):\n        \"\"\"\n        Handle uncaught Thread.run() exception.\n        \"\"\"\n        if args.exc_type == SystemExit:\n            # silently ignore SystemExit\n            return\n\n        if _sys is not None and _sys.stderr is not None:\n            stderr = _sys.stderr\n        elif args.thread is not None:\n            stderr = args.thread._stderr\n            if stderr is None:\n                # do nothing if sys.stderr is None and sys.stderr was None\n                # when the thread was created\n                return\n        else:\n            # do nothing if sys.stderr is None and args.thread is None\n            return\n\n        if args.thread is not None:\n            name = args.thread.name\n        else:\n            name = get_ident()\n        print(f\"Exception in thread {name}:\",\n              file=stderr, flush=True)\n        _print_exception(args.exc_type, args.exc_value, args.exc_traceback,\n                         file=stderr)\n        stderr.flush()\n\n\ndef _make_invoke_excepthook():\n    # Create a local namespace to ensure that variables remain alive\n    # when _invoke_excepthook() is called, even if it is called late during\n    # Python shutdown. It is mostly needed for daemon threads.\n\n    old_excepthook = excepthook\n    old_sys_excepthook = _sys.excepthook\n    if old_excepthook is None:\n        raise RuntimeError(\"threading.excepthook is None\")\n    if old_sys_excepthook is None:\n        raise RuntimeError(\"sys.excepthook is None\")\n\n    sys_exc_info = _sys.exc_info\n    local_print = print\n    local_sys = _sys\n\n    def invoke_excepthook(thread):\n        global excepthook\n        try:\n            hook = excepthook\n            if hook is None:\n                hook = old_excepthook\n\n            args = ExceptHookArgs([*sys_exc_info(), thread])\n\n            hook(args)\n        except Exception as exc:\n            exc.__suppress_context__ = True\n            del exc\n\n            if local_sys is not None and local_sys.stderr is not None:\n                stderr = local_sys.stderr\n            else:\n                stderr = thread._stderr\n\n            local_print(\"Exception in threading.excepthook:\",\n                        file=stderr, flush=True)\n\n            if local_sys is not None and local_sys.excepthook is not None:\n                sys_excepthook = local_sys.excepthook\n            else:\n                sys_excepthook = old_sys_excepthook\n\n            sys_excepthook(*sys_exc_info())\n        finally:\n            # Break reference cycle (exception stored in a variable)\n            args = None\n\n    return invoke_excepthook\n\n\n# The timer class was contributed by Itamar Shtull-Trauring\n\nclass Timer(Thread):\n    \"\"\"Call a function after a specified number of seconds:\n\n            t = Timer(30.0, f, args=None, kwargs=None)\n            t.start()\n            t.cancel()     # stop the timer's action if it's still waiting\n\n    \"\"\"\n\n    def __init__(self, interval, function, args=None, kwargs=None):\n        Thread.__init__(self)\n        self.interval = interval\n        self.function = function\n        self.args = args if args is not None else []\n        self.kwargs = kwargs if kwargs is not None else {}\n        self.finished = Event()\n\n    def cancel(self):\n        \"\"\"Stop the timer if it hasn't finished yet.\"\"\"\n        self.finished.set()\n\n    def run(self):\n        self.finished.wait(self.interval)\n        if not self.finished.is_set():\n            self.function(*self.args, **self.kwargs)\n        self.finished.set()\n\n\n# Special thread class to represent the main thread\n\nclass _MainThread(Thread):\n\n    def __init__(self):\n        Thread.__init__(self, name=\"MainThread\", daemon=False)\n        self._set_tstate_lock()\n        self._started.set()\n        self._set_ident()\n        if _HAVE_THREAD_NATIVE_ID:\n            self._set_native_id()\n        with _active_limbo_lock:\n            _active[self._ident] = self\n\n\n# Dummy thread class to represent threads not started here.\n# These aren't garbage collected when they die, nor can they be waited for.\n# If they invoke anything in threading.py that calls current_thread(), they\n# leave an entry in the _active dict forever after.\n# Their purpose is to return *something* from current_thread().\n# They are marked as daemon threads so we won't wait for them\n# when we exit (conform previous semantics).\n\nclass _DummyThread(Thread):\n\n    def __init__(self):\n        Thread.__init__(self, name=_newname(\"Dummy-%d\"), daemon=True)\n\n        self._started.set()\n        self._set_ident()\n        if _HAVE_THREAD_NATIVE_ID:\n            self._set_native_id()\n        with _active_limbo_lock:\n            _active[self._ident] = self\n\n    def _stop(self):\n        pass\n\n    def is_alive(self):\n        assert not self._is_stopped and self._started.is_set()\n        return True\n\n    def join(self, timeout=None):\n        assert False, \"cannot join a dummy thread\"\n\n\n# Global API functions\n\ndef current_thread():\n    \"\"\"Return the current Thread object, corresponding to the caller's thread of control.\n\n    If the caller's thread of control was not created through the threading\n    module, a dummy thread object with limited functionality is returned.\n\n    \"\"\"\n    try:\n        return _active[get_ident()]\n    except KeyError:\n        return _DummyThread()\n\ncurrentThread = current_thread\n\ndef active_count():\n    \"\"\"Return the number of Thread objects currently alive.\n\n    The returned count is equal to the length of the list returned by\n    enumerate().\n\n    \"\"\"\n    with _active_limbo_lock:\n        return len(_active) + len(_limbo)\n\nactiveCount = active_count\n\ndef _enumerate():\n    # Same as enumerate(), but without the lock. Internal use only.\n    return list(_active.values()) + list(_limbo.values())\n\ndef enumerate():\n    \"\"\"Return a list of all Thread objects currently alive.\n\n    The list includes daemonic threads, dummy thread objects created by\n    current_thread(), and the main thread. It excludes terminated threads and\n    threads that have not yet been started.\n\n    \"\"\"\n    with _active_limbo_lock:\n        return list(_active.values()) + list(_limbo.values())\n\n\n_threading_atexits = []\n_SHUTTING_DOWN = False\n\ndef _register_atexit(func, *arg, **kwargs):\n    \"\"\"CPython internal: register *func* to be called before joining threads.\n\n    The registered *func* is called with its arguments just before all\n    non-daemon threads are joined in `_shutdown()`. It provides a similar\n    purpose to `atexit.register()`, but its functions are called prior to\n    threading shutdown instead of interpreter shutdown.\n\n    For similarity to atexit, the registered functions are called in reverse.\n    \"\"\"\n    if _SHUTTING_DOWN:\n        raise RuntimeError(\"can't register atexit after shutdown\")\n\n    call = functools.partial(func, *arg, **kwargs)\n    _threading_atexits.append(call)\n\n\nfrom _thread import stack_size\n\n# Create the main thread object,\n# and make it available for the interpreter\n# (Py_Main) as threading._shutdown.\n\n_main_thread = _MainThread()\n\ndef _shutdown():\n    \"\"\"\n    Wait until the Python thread state of all non-daemon threads get deleted.\n    \"\"\"\n    # Obscure:  other threads may be waiting to join _main_thread.  That's\n    # dubious, but some code does it.  We can't wait for C code to release\n    # the main thread's tstate_lock - that won't happen until the interpreter\n    # is nearly dead.  So we release it here.  Note that just calling _stop()\n    # isn't enough:  other threads may already be waiting on _tstate_lock.\n    if _main_thread._is_stopped:\n        # _shutdown() was already called\n        return\n\n    global _SHUTTING_DOWN\n    _SHUTTING_DOWN = True\n\n    # Call registered threading atexit functions before threads are joined.\n    # Order is reversed, similar to atexit.\n    for atexit_call in reversed(_threading_atexits):\n        atexit_call()\n\n    # Main thread\n    if _main_thread.ident == get_ident():\n        tlock = _main_thread._tstate_lock\n        # The main thread isn't finished yet, so its thread state lock can't\n        # have been released.\n        assert tlock is not None\n        assert tlock.locked()\n        tlock.release()\n        _main_thread._stop()\n    else:\n        # bpo-1596321: _shutdown() must be called in the main thread.\n        # If the threading module was not imported by the main thread,\n        # _main_thread is the thread which imported the threading module.\n        # In this case, ignore _main_thread, similar behavior than for threads\n        # spawned by C libraries or using _thread.start_new_thread().\n        pass\n\n    # Join all non-deamon threads\n    while True:\n        with _shutdown_locks_lock:\n            locks = list(_shutdown_locks)\n            _shutdown_locks.clear()\n\n        if not locks:\n            break\n\n        for lock in locks:\n            # mimic Thread.join()\n            lock.acquire()\n            lock.release()\n\n        # new threads can be spawned while we were waiting for the other\n        # threads to complete\n\n\ndef main_thread():\n    \"\"\"Return the main thread object.\n\n    In normal conditions, the main thread is the thread from which the\n    Python interpreter was started.\n    \"\"\"\n    return _main_thread\n\n# get thread-local implementation, either from the thread\n# module, or from the python fallback\n\ntry:\n    from _thread import _local as local\nexcept ImportError:\n    from _threading_local import local\n\n\ndef _after_fork():\n    \"\"\"\n    Cleanup threading module state that should not exist after a fork.\n    \"\"\"\n    # Reset _active_limbo_lock, in case we forked while the lock was held\n    # by another (non-forked) thread.  http://bugs.python.org/issue874900\n    global _active_limbo_lock, _main_thread\n    global _shutdown_locks_lock, _shutdown_locks\n    _active_limbo_lock = RLock()\n\n    # fork() only copied the current thread; clear references to others.\n    new_active = {}\n\n    try:\n        current = _active[get_ident()]\n    except KeyError:\n        # fork() was called in a thread which was not spawned\n        # by threading.Thread. For example, a thread spawned\n        # by thread.start_new_thread().\n        current = _MainThread()\n\n    _main_thread = current\n\n    # reset _shutdown() locks: threads re-register their _tstate_lock below\n    _shutdown_locks_lock = _allocate_lock()\n    _shutdown_locks = set()\n\n    with _active_limbo_lock:\n        # Dangling thread instances must still have their locks reset,\n        # because someone may join() them.\n        threads = set(_enumerate())\n        threads.update(_dangling)\n        for thread in threads:\n            # Any lock/condition variable may be currently locked or in an\n            # invalid state, so we reinitialize them.\n            if thread is current:\n                # There is only one active thread. We reset the ident to\n                # its new value since it can have changed.\n                thread._reset_internal_locks(True)\n                ident = get_ident()\n                thread._ident = ident\n                new_active[ident] = thread\n            else:\n                # All the others are already stopped.\n                thread._reset_internal_locks(False)\n                thread._stop()\n\n        _limbo.clear()\n        _active.clear()\n        _active.update(new_active)\n        assert len(_active) == 1\n\n\nif hasattr(_os, \"register_at_fork\"):\n    _os.register_at_fork(after_in_child=_after_fork)\n", 1548], "/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/_weakrefset.py": ["# Access WeakSet through the weakref module.\n# This code is separated-out because it is needed\n# by abc.py to load everything else at startup.\n\nfrom _weakref import ref\nfrom types import GenericAlias\n\n__all__ = ['WeakSet']\n\n\nclass _IterationGuard:\n    # This context manager registers itself in the current iterators of the\n    # weak container, such as to delay all removals until the context manager\n    # exits.\n    # This technique should be relatively thread-safe (since sets are).\n\n    def __init__(self, weakcontainer):\n        # Don't create cycles\n        self.weakcontainer = ref(weakcontainer)\n\n    def __enter__(self):\n        w = self.weakcontainer()\n        if w is not None:\n            w._iterating.add(self)\n        return self\n\n    def __exit__(self, e, t, b):\n        w = self.weakcontainer()\n        if w is not None:\n            s = w._iterating\n            s.remove(self)\n            if not s:\n                w._commit_removals()\n\n\nclass WeakSet:\n    def __init__(self, data=None):\n        self.data = set()\n        def _remove(item, selfref=ref(self)):\n            self = selfref()\n            if self is not None:\n                if self._iterating:\n                    self._pending_removals.append(item)\n                else:\n                    self.data.discard(item)\n        self._remove = _remove\n        # A list of keys to be removed\n        self._pending_removals = []\n        self._iterating = set()\n        if data is not None:\n            self.update(data)\n\n    def _commit_removals(self):\n        pop = self._pending_removals.pop\n        discard = self.data.discard\n        while True:\n            try:\n                item = pop()\n            except IndexError:\n                return\n            discard(item)\n\n    def __iter__(self):\n        with _IterationGuard(self):\n            for itemref in self.data:\n                item = itemref()\n                if item is not None:\n                    # Caveat: the iterator will keep a strong reference to\n                    # `item` until it is resumed or closed.\n                    yield item\n\n    def __len__(self):\n        return len(self.data) - len(self._pending_removals)\n\n    def __contains__(self, item):\n        try:\n            wr = ref(item)\n        except TypeError:\n            return False\n        return wr in self.data\n\n    def __reduce__(self):\n        return (self.__class__, (list(self),),\n                getattr(self, '__dict__', None))\n\n    def add(self, item):\n        if self._pending_removals:\n            self._commit_removals()\n        self.data.add(ref(item, self._remove))\n\n    def clear(self):\n        if self._pending_removals:\n            self._commit_removals()\n        self.data.clear()\n\n    def copy(self):\n        return self.__class__(self)\n\n    def pop(self):\n        if self._pending_removals:\n            self._commit_removals()\n        while True:\n            try:\n                itemref = self.data.pop()\n            except KeyError:\n                raise KeyError('pop from empty WeakSet') from None\n            item = itemref()\n            if item is not None:\n                return item\n\n    def remove(self, item):\n        if self._pending_removals:\n            self._commit_removals()\n        self.data.remove(ref(item))\n\n    def discard(self, item):\n        if self._pending_removals:\n            self._commit_removals()\n        self.data.discard(ref(item))\n\n    def update(self, other):\n        if self._pending_removals:\n            self._commit_removals()\n        for element in other:\n            self.add(element)\n\n    def __ior__(self, other):\n        self.update(other)\n        return self\n\n    def difference(self, other):\n        newset = self.copy()\n        newset.difference_update(other)\n        return newset\n    __sub__ = difference\n\n    def difference_update(self, other):\n        self.__isub__(other)\n    def __isub__(self, other):\n        if self._pending_removals:\n            self._commit_removals()\n        if self is other:\n            self.data.clear()\n        else:\n            self.data.difference_update(ref(item) for item in other)\n        return self\n\n    def intersection(self, other):\n        return self.__class__(item for item in other if item in self)\n    __and__ = intersection\n\n    def intersection_update(self, other):\n        self.__iand__(other)\n    def __iand__(self, other):\n        if self._pending_removals:\n            self._commit_removals()\n        self.data.intersection_update(ref(item) for item in other)\n        return self\n\n    def issubset(self, other):\n        return self.data.issubset(ref(item) for item in other)\n    __le__ = issubset\n\n    def __lt__(self, other):\n        return self.data < set(map(ref, other))\n\n    def issuperset(self, other):\n        return self.data.issuperset(ref(item) for item in other)\n    __ge__ = issuperset\n\n    def __gt__(self, other):\n        return self.data > set(map(ref, other))\n\n    def __eq__(self, other):\n        if not isinstance(other, self.__class__):\n            return NotImplemented\n        return self.data == set(map(ref, other))\n\n    def symmetric_difference(self, other):\n        newset = self.copy()\n        newset.symmetric_difference_update(other)\n        return newset\n    __xor__ = symmetric_difference\n\n    def symmetric_difference_update(self, other):\n        self.__ixor__(other)\n    def __ixor__(self, other):\n        if self._pending_removals:\n            self._commit_removals()\n        if self is other:\n            self.data.clear()\n        else:\n            self.data.symmetric_difference_update(ref(item, self._remove) for item in other)\n        return self\n\n    def union(self, other):\n        return self.__class__(e for s in (self, other) for e in s)\n    __or__ = union\n\n    def isdisjoint(self, other):\n        return len(self.intersection(other)) == 0\n\n    def __repr__(self):\n        return repr(self.data)\n\n    __class_getitem__ = classmethod(GenericAlias)\n", 206], "/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/genericpath.py": ["\"\"\"\nPath operations common to more than one OS\nDo not use directly.  The OS specific modules import the appropriate\nfunctions from this module themselves.\n\"\"\"\nimport os\nimport stat\n\n__all__ = ['commonprefix', 'exists', 'getatime', 'getctime', 'getmtime',\n           'getsize', 'isdir', 'isfile', 'samefile', 'sameopenfile',\n           'samestat']\n\n\n# Does a path exist?\n# This is false for dangling symbolic links on systems that support them.\ndef exists(path):\n    \"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\n    try:\n        os.stat(path)\n    except (OSError, ValueError):\n        return False\n    return True\n\n\n# This follows symbolic links, so both islink() and isdir() can be true\n# for the same path on systems that support symlinks\ndef isfile(path):\n    \"\"\"Test whether a path is a regular file\"\"\"\n    try:\n        st = os.stat(path)\n    except (OSError, ValueError):\n        return False\n    return stat.S_ISREG(st.st_mode)\n\n\n# Is a path a directory?\n# This follows symbolic links, so both islink() and isdir()\n# can be true for the same path on systems that support symlinks\ndef isdir(s):\n    \"\"\"Return true if the pathname refers to an existing directory.\"\"\"\n    try:\n        st = os.stat(s)\n    except (OSError, ValueError):\n        return False\n    return stat.S_ISDIR(st.st_mode)\n\n\ndef getsize(filename):\n    \"\"\"Return the size of a file, reported by os.stat().\"\"\"\n    return os.stat(filename).st_size\n\n\ndef getmtime(filename):\n    \"\"\"Return the last modification time of a file, reported by os.stat().\"\"\"\n    return os.stat(filename).st_mtime\n\n\ndef getatime(filename):\n    \"\"\"Return the last access time of a file, reported by os.stat().\"\"\"\n    return os.stat(filename).st_atime\n\n\ndef getctime(filename):\n    \"\"\"Return the metadata change time of a file, reported by os.stat().\"\"\"\n    return os.stat(filename).st_ctime\n\n\n# Return the longest prefix of all list elements.\ndef commonprefix(m):\n    \"Given a list of pathnames, returns the longest common leading component\"\n    if not m: return ''\n    # Some people pass in a list of pathname parts to operate in an OS-agnostic\n    # fashion; don't try to translate in that case as that's an abuse of the\n    # API and they are already doing what they need to be OS-agnostic and so\n    # they most likely won't be using an os.PathLike object in the sublists.\n    if not isinstance(m[0], (list, tuple)):\n        m = tuple(map(os.fspath, m))\n    s1 = min(m)\n    s2 = max(m)\n    for i, c in enumerate(s1):\n        if c != s2[i]:\n            return s1[:i]\n    return s1\n\n# Are two stat buffers (obtained from stat, fstat or lstat)\n# describing the same file?\ndef samestat(s1, s2):\n    \"\"\"Test whether two stat buffers reference the same file\"\"\"\n    return (s1.st_ino == s2.st_ino and\n            s1.st_dev == s2.st_dev)\n\n\n# Are two filenames really pointing to the same file?\ndef samefile(f1, f2):\n    \"\"\"Test whether two pathnames reference the same actual file or directory\n\n    This is determined by the device number and i-node number and\n    raises an exception if an os.stat() call on either pathname fails.\n    \"\"\"\n    s1 = os.stat(f1)\n    s2 = os.stat(f2)\n    return samestat(s1, s2)\n\n\n# Are two open files really referencing the same file?\n# (Not necessarily the same file descriptor!)\ndef sameopenfile(fp1, fp2):\n    \"\"\"Test whether two open file objects reference the same file\"\"\"\n    s1 = os.fstat(fp1)\n    s2 = os.fstat(fp2)\n    return samestat(s1, s2)\n\n\n# Split a path in root and extension.\n# The extension is everything starting at the last dot in the last\n# pathname component; the root is everything before that.\n# It is always true that root + ext == p.\n\n# Generic implementation of splitext, to be parametrized with\n# the separators\ndef _splitext(p, sep, altsep, extsep):\n    \"\"\"Split the extension from a pathname.\n\n    Extension is everything from the last dot to the end, ignoring\n    leading dots.  Returns \"(root, ext)\"; ext may be empty.\"\"\"\n    # NOTE: This code must work for text and bytes strings.\n\n    sepIndex = p.rfind(sep)\n    if altsep:\n        altsepIndex = p.rfind(altsep)\n        sepIndex = max(sepIndex, altsepIndex)\n\n    dotIndex = p.rfind(extsep)\n    if dotIndex > sepIndex:\n        # skip all leading dots\n        filenameIndex = sepIndex + 1\n        while filenameIndex < dotIndex:\n            if p[filenameIndex:filenameIndex+1] != extsep:\n                return p[:dotIndex], p[dotIndex:]\n            filenameIndex += 1\n\n    return p, p[:0]\n\ndef _check_arg_types(funcname, *args):\n    hasstr = hasbytes = False\n    for s in args:\n        if isinstance(s, str):\n            hasstr = True\n        elif isinstance(s, bytes):\n            hasbytes = True\n        else:\n            raise TypeError(f'{funcname}() argument must be str, bytes, or '\n                            f'os.PathLike object, not {s.__class__.__name__!r}') from None\n    if hasstr and hasbytes:\n        raise TypeError(\"Can't mix strings and bytes in path components\") from None\n", 155], "/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/_bootlocale.py": ["\"\"\"A minimal subset of the locale module used at interpreter startup\n(imported by the _io module), in order to reduce startup time.\n\nDon't import directly from third-party code; use the `locale` module instead!\n\"\"\"\n\nimport sys\nimport _locale\n\nif sys.platform.startswith(\"win\"):\n    def getpreferredencoding(do_setlocale=True):\n        if sys.flags.utf8_mode:\n            return 'UTF-8'\n        return _locale._getdefaultlocale()[1]\nelse:\n    try:\n        _locale.CODESET\n    except AttributeError:\n        if hasattr(sys, 'getandroidapilevel'):\n            # On Android langinfo.h and CODESET are missing, and UTF-8 is\n            # always used in mbstowcs() and wcstombs().\n            def getpreferredencoding(do_setlocale=True):\n                return 'UTF-8'\n        else:\n            def getpreferredencoding(do_setlocale=True):\n                if sys.flags.utf8_mode:\n                    return 'UTF-8'\n                # This path for legacy systems needs the more complex\n                # getdefaultlocale() function, import the full locale module.\n                import locale\n                return locale.getpreferredencoding(do_setlocale)\n    else:\n        def getpreferredencoding(do_setlocale=True):\n            assert not do_setlocale\n            if sys.flags.utf8_mode:\n                return 'UTF-8'\n            result = _locale.nl_langinfo(_locale.CODESET)\n            if not result and sys.platform == 'darwin':\n                # nl_langinfo can return an empty string\n                # when the setting has an invalid value.\n                # Default to UTF-8 in that case because\n                # UTF-8 is the default charset on OSX and\n                # returning nothing will crash the\n                # interpreter.\n                result = 'UTF-8'\n            return result\n", 46], "/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/codecs.py": ["\"\"\" codecs -- Python Codec Registry, API and helpers.\n\n\nWritten by Marc-Andre Lemburg (mal@lemburg.com).\n\n(c) Copyright CNRI, All Rights Reserved. NO WARRANTY.\n\n\"\"\"\n\nimport builtins\nimport sys\n\n### Registry and builtin stateless codec functions\n\ntry:\n    from _codecs import *\nexcept ImportError as why:\n    raise SystemError('Failed to load the builtin codecs: %s' % why)\n\n__all__ = [\"register\", \"lookup\", \"open\", \"EncodedFile\", \"BOM\", \"BOM_BE\",\n           \"BOM_LE\", \"BOM32_BE\", \"BOM32_LE\", \"BOM64_BE\", \"BOM64_LE\",\n           \"BOM_UTF8\", \"BOM_UTF16\", \"BOM_UTF16_LE\", \"BOM_UTF16_BE\",\n           \"BOM_UTF32\", \"BOM_UTF32_LE\", \"BOM_UTF32_BE\",\n           \"CodecInfo\", \"Codec\", \"IncrementalEncoder\", \"IncrementalDecoder\",\n           \"StreamReader\", \"StreamWriter\",\n           \"StreamReaderWriter\", \"StreamRecoder\",\n           \"getencoder\", \"getdecoder\", \"getincrementalencoder\",\n           \"getincrementaldecoder\", \"getreader\", \"getwriter\",\n           \"encode\", \"decode\", \"iterencode\", \"iterdecode\",\n           \"strict_errors\", \"ignore_errors\", \"replace_errors\",\n           \"xmlcharrefreplace_errors\",\n           \"backslashreplace_errors\", \"namereplace_errors\",\n           \"register_error\", \"lookup_error\"]\n\n### Constants\n\n#\n# Byte Order Mark (BOM = ZERO WIDTH NO-BREAK SPACE = U+FEFF)\n# and its possible byte string values\n# for UTF8/UTF16/UTF32 output and little/big endian machines\n#\n\n# UTF-8\nBOM_UTF8 = b'\\xef\\xbb\\xbf'\n\n# UTF-16, little endian\nBOM_LE = BOM_UTF16_LE = b'\\xff\\xfe'\n\n# UTF-16, big endian\nBOM_BE = BOM_UTF16_BE = b'\\xfe\\xff'\n\n# UTF-32, little endian\nBOM_UTF32_LE = b'\\xff\\xfe\\x00\\x00'\n\n# UTF-32, big endian\nBOM_UTF32_BE = b'\\x00\\x00\\xfe\\xff'\n\nif sys.byteorder == 'little':\n\n    # UTF-16, native endianness\n    BOM = BOM_UTF16 = BOM_UTF16_LE\n\n    # UTF-32, native endianness\n    BOM_UTF32 = BOM_UTF32_LE\n\nelse:\n\n    # UTF-16, native endianness\n    BOM = BOM_UTF16 = BOM_UTF16_BE\n\n    # UTF-32, native endianness\n    BOM_UTF32 = BOM_UTF32_BE\n\n# Old broken names (don't use in new code)\nBOM32_LE = BOM_UTF16_LE\nBOM32_BE = BOM_UTF16_BE\nBOM64_LE = BOM_UTF32_LE\nBOM64_BE = BOM_UTF32_BE\n\n\n### Codec base classes (defining the API)\n\nclass CodecInfo(tuple):\n    \"\"\"Codec details when looking up the codec registry\"\"\"\n\n    # Private API to allow Python 3.4 to blacklist the known non-Unicode\n    # codecs in the standard library. A more general mechanism to\n    # reliably distinguish test encodings from other codecs will hopefully\n    # be defined for Python 3.5\n    #\n    # See http://bugs.python.org/issue19619\n    _is_text_encoding = True # Assume codecs are text encodings by default\n\n    def __new__(cls, encode, decode, streamreader=None, streamwriter=None,\n        incrementalencoder=None, incrementaldecoder=None, name=None,\n        *, _is_text_encoding=None):\n        self = tuple.__new__(cls, (encode, decode, streamreader, streamwriter))\n        self.name = name\n        self.encode = encode\n        self.decode = decode\n        self.incrementalencoder = incrementalencoder\n        self.incrementaldecoder = incrementaldecoder\n        self.streamwriter = streamwriter\n        self.streamreader = streamreader\n        if _is_text_encoding is not None:\n            self._is_text_encoding = _is_text_encoding\n        return self\n\n    def __repr__(self):\n        return \"<%s.%s object for encoding %s at %#x>\" % \\\n                (self.__class__.__module__, self.__class__.__qualname__,\n                 self.name, id(self))\n\nclass Codec:\n\n    \"\"\" Defines the interface for stateless encoders/decoders.\n\n        The .encode()/.decode() methods may use different error\n        handling schemes by providing the errors argument. These\n        string values are predefined:\n\n         'strict' - raise a ValueError error (or a subclass)\n         'ignore' - ignore the character and continue with the next\n         'replace' - replace with a suitable replacement character;\n                    Python will use the official U+FFFD REPLACEMENT\n                    CHARACTER for the builtin Unicode codecs on\n                    decoding and '?' on encoding.\n         'surrogateescape' - replace with private code points U+DCnn.\n         'xmlcharrefreplace' - Replace with the appropriate XML\n                               character reference (only for encoding).\n         'backslashreplace'  - Replace with backslashed escape sequences.\n         'namereplace'       - Replace with \\\\N{...} escape sequences\n                               (only for encoding).\n\n        The set of allowed values can be extended via register_error.\n\n    \"\"\"\n    def encode(self, input, errors='strict'):\n\n        \"\"\" Encodes the object input and returns a tuple (output\n            object, length consumed).\n\n            errors defines the error handling to apply. It defaults to\n            'strict' handling.\n\n            The method may not store state in the Codec instance. Use\n            StreamWriter for codecs which have to keep state in order to\n            make encoding efficient.\n\n            The encoder must be able to handle zero length input and\n            return an empty object of the output object type in this\n            situation.\n\n        \"\"\"\n        raise NotImplementedError\n\n    def decode(self, input, errors='strict'):\n\n        \"\"\" Decodes the object input and returns a tuple (output\n            object, length consumed).\n\n            input must be an object which provides the bf_getreadbuf\n            buffer slot. Python strings, buffer objects and memory\n            mapped files are examples of objects providing this slot.\n\n            errors defines the error handling to apply. It defaults to\n            'strict' handling.\n\n            The method may not store state in the Codec instance. Use\n            StreamReader for codecs which have to keep state in order to\n            make decoding efficient.\n\n            The decoder must be able to handle zero length input and\n            return an empty object of the output object type in this\n            situation.\n\n        \"\"\"\n        raise NotImplementedError\n\nclass IncrementalEncoder(object):\n    \"\"\"\n    An IncrementalEncoder encodes an input in multiple steps. The input can\n    be passed piece by piece to the encode() method. The IncrementalEncoder\n    remembers the state of the encoding process between calls to encode().\n    \"\"\"\n    def __init__(self, errors='strict'):\n        \"\"\"\n        Creates an IncrementalEncoder instance.\n\n        The IncrementalEncoder may use different error handling schemes by\n        providing the errors keyword argument. See the module docstring\n        for a list of possible values.\n        \"\"\"\n        self.errors = errors\n        self.buffer = \"\"\n\n    def encode(self, input, final=False):\n        \"\"\"\n        Encodes input and returns the resulting object.\n        \"\"\"\n        raise NotImplementedError\n\n    def reset(self):\n        \"\"\"\n        Resets the encoder to the initial state.\n        \"\"\"\n\n    def getstate(self):\n        \"\"\"\n        Return the current state of the encoder.\n        \"\"\"\n        return 0\n\n    def setstate(self, state):\n        \"\"\"\n        Set the current state of the encoder. state must have been\n        returned by getstate().\n        \"\"\"\n\nclass BufferedIncrementalEncoder(IncrementalEncoder):\n    \"\"\"\n    This subclass of IncrementalEncoder can be used as the baseclass for an\n    incremental encoder if the encoder must keep some of the output in a\n    buffer between calls to encode().\n    \"\"\"\n    def __init__(self, errors='strict'):\n        IncrementalEncoder.__init__(self, errors)\n        # unencoded input that is kept between calls to encode()\n        self.buffer = \"\"\n\n    def _buffer_encode(self, input, errors, final):\n        # Overwrite this method in subclasses: It must encode input\n        # and return an (output, length consumed) tuple\n        raise NotImplementedError\n\n    def encode(self, input, final=False):\n        # encode input (taking the buffer into account)\n        data = self.buffer + input\n        (result, consumed) = self._buffer_encode(data, self.errors, final)\n        # keep unencoded input until the next call\n        self.buffer = data[consumed:]\n        return result\n\n    def reset(self):\n        IncrementalEncoder.reset(self)\n        self.buffer = \"\"\n\n    def getstate(self):\n        return self.buffer or 0\n\n    def setstate(self, state):\n        self.buffer = state or \"\"\n\nclass IncrementalDecoder(object):\n    \"\"\"\n    An IncrementalDecoder decodes an input in multiple steps. The input can\n    be passed piece by piece to the decode() method. The IncrementalDecoder\n    remembers the state of the decoding process between calls to decode().\n    \"\"\"\n    def __init__(self, errors='strict'):\n        \"\"\"\n        Create an IncrementalDecoder instance.\n\n        The IncrementalDecoder may use different error handling schemes by\n        providing the errors keyword argument. See the module docstring\n        for a list of possible values.\n        \"\"\"\n        self.errors = errors\n\n    def decode(self, input, final=False):\n        \"\"\"\n        Decode input and returns the resulting object.\n        \"\"\"\n        raise NotImplementedError\n\n    def reset(self):\n        \"\"\"\n        Reset the decoder to the initial state.\n        \"\"\"\n\n    def getstate(self):\n        \"\"\"\n        Return the current state of the decoder.\n\n        This must be a (buffered_input, additional_state_info) tuple.\n        buffered_input must be a bytes object containing bytes that\n        were passed to decode() that have not yet been converted.\n        additional_state_info must be a non-negative integer\n        representing the state of the decoder WITHOUT yet having\n        processed the contents of buffered_input.  In the initial state\n        and after reset(), getstate() must return (b\"\", 0).\n        \"\"\"\n        return (b\"\", 0)\n\n    def setstate(self, state):\n        \"\"\"\n        Set the current state of the decoder.\n\n        state must have been returned by getstate().  The effect of\n        setstate((b\"\", 0)) must be equivalent to reset().\n        \"\"\"\n\nclass BufferedIncrementalDecoder(IncrementalDecoder):\n    \"\"\"\n    This subclass of IncrementalDecoder can be used as the baseclass for an\n    incremental decoder if the decoder must be able to handle incomplete\n    byte sequences.\n    \"\"\"\n    def __init__(self, errors='strict'):\n        IncrementalDecoder.__init__(self, errors)\n        # undecoded input that is kept between calls to decode()\n        self.buffer = b\"\"\n\n    def _buffer_decode(self, input, errors, final):\n        # Overwrite this method in subclasses: It must decode input\n        # and return an (output, length consumed) tuple\n        raise NotImplementedError\n\n    def decode(self, input, final=False):\n        # decode input (taking the buffer into account)\n        data = self.buffer + input\n        (result, consumed) = self._buffer_decode(data, self.errors, final)\n        # keep undecoded input until the next call\n        self.buffer = data[consumed:]\n        return result\n\n    def reset(self):\n        IncrementalDecoder.reset(self)\n        self.buffer = b\"\"\n\n    def getstate(self):\n        # additional state info is always 0\n        return (self.buffer, 0)\n\n    def setstate(self, state):\n        # ignore additional state info\n        self.buffer = state[0]\n\n#\n# The StreamWriter and StreamReader class provide generic working\n# interfaces which can be used to implement new encoding submodules\n# very easily. See encodings/utf_8.py for an example on how this is\n# done.\n#\n\nclass StreamWriter(Codec):\n\n    def __init__(self, stream, errors='strict'):\n\n        \"\"\" Creates a StreamWriter instance.\n\n            stream must be a file-like object open for writing.\n\n            The StreamWriter may use different error handling\n            schemes by providing the errors keyword argument. These\n            parameters are predefined:\n\n             'strict' - raise a ValueError (or a subclass)\n             'ignore' - ignore the character and continue with the next\n             'replace'- replace with a suitable replacement character\n             'xmlcharrefreplace' - Replace with the appropriate XML\n                                   character reference.\n             'backslashreplace'  - Replace with backslashed escape\n                                   sequences.\n             'namereplace'       - Replace with \\\\N{...} escape sequences.\n\n            The set of allowed parameter values can be extended via\n            register_error.\n        \"\"\"\n        self.stream = stream\n        self.errors = errors\n\n    def write(self, object):\n\n        \"\"\" Writes the object's contents encoded to self.stream.\n        \"\"\"\n        data, consumed = self.encode(object, self.errors)\n        self.stream.write(data)\n\n    def writelines(self, list):\n\n        \"\"\" Writes the concatenated list of strings to the stream\n            using .write().\n        \"\"\"\n        self.write(''.join(list))\n\n    def reset(self):\n\n        \"\"\" Resets the codec buffers used for keeping internal state.\n\n            Calling this method should ensure that the data on the\n            output is put into a clean state, that allows appending\n            of new fresh data without having to rescan the whole\n            stream to recover state.\n\n        \"\"\"\n        pass\n\n    def seek(self, offset, whence=0):\n        self.stream.seek(offset, whence)\n        if whence == 0 and offset == 0:\n            self.reset()\n\n    def __getattr__(self, name,\n                    getattr=getattr):\n\n        \"\"\" Inherit all other methods from the underlying stream.\n        \"\"\"\n        return getattr(self.stream, name)\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, type, value, tb):\n        self.stream.close()\n\n###\n\nclass StreamReader(Codec):\n\n    charbuffertype = str\n\n    def __init__(self, stream, errors='strict'):\n\n        \"\"\" Creates a StreamReader instance.\n\n            stream must be a file-like object open for reading.\n\n            The StreamReader may use different error handling\n            schemes by providing the errors keyword argument. These\n            parameters are predefined:\n\n             'strict' - raise a ValueError (or a subclass)\n             'ignore' - ignore the character and continue with the next\n             'replace'- replace with a suitable replacement character\n             'backslashreplace' - Replace with backslashed escape sequences;\n\n            The set of allowed parameter values can be extended via\n            register_error.\n        \"\"\"\n        self.stream = stream\n        self.errors = errors\n        self.bytebuffer = b\"\"\n        self._empty_charbuffer = self.charbuffertype()\n        self.charbuffer = self._empty_charbuffer\n        self.linebuffer = None\n\n    def decode(self, input, errors='strict'):\n        raise NotImplementedError\n\n    def read(self, size=-1, chars=-1, firstline=False):\n\n        \"\"\" Decodes data from the stream self.stream and returns the\n            resulting object.\n\n            chars indicates the number of decoded code points or bytes to\n            return. read() will never return more data than requested,\n            but it might return less, if there is not enough available.\n\n            size indicates the approximate maximum number of decoded\n            bytes or code points to read for decoding. The decoder\n            can modify this setting as appropriate. The default value\n            -1 indicates to read and decode as much as possible.  size\n            is intended to prevent having to decode huge files in one\n            step.\n\n            If firstline is true, and a UnicodeDecodeError happens\n            after the first line terminator in the input only the first line\n            will be returned, the rest of the input will be kept until the\n            next call to read().\n\n            The method should use a greedy read strategy, meaning that\n            it should read as much data as is allowed within the\n            definition of the encoding and the given size, e.g.  if\n            optional encoding endings or state markers are available\n            on the stream, these should be read too.\n        \"\"\"\n        # If we have lines cached, first merge them back into characters\n        if self.linebuffer:\n            self.charbuffer = self._empty_charbuffer.join(self.linebuffer)\n            self.linebuffer = None\n\n        if chars < 0:\n            # For compatibility with other read() methods that take a\n            # single argument\n            chars = size\n\n        # read until we get the required number of characters (if available)\n        while True:\n            # can the request be satisfied from the character buffer?\n            if chars >= 0:\n                if len(self.charbuffer) >= chars:\n                    break\n            # we need more data\n            if size < 0:\n                newdata = self.stream.read()\n            else:\n                newdata = self.stream.read(size)\n            # decode bytes (those remaining from the last call included)\n            data = self.bytebuffer + newdata\n            if not data:\n                break\n            try:\n                newchars, decodedbytes = self.decode(data, self.errors)\n            except UnicodeDecodeError as exc:\n                if firstline:\n                    newchars, decodedbytes = \\\n                        self.decode(data[:exc.start], self.errors)\n                    lines = newchars.splitlines(keepends=True)\n                    if len(lines)<=1:\n                        raise\n                else:\n                    raise\n            # keep undecoded bytes until the next call\n            self.bytebuffer = data[decodedbytes:]\n            # put new characters in the character buffer\n            self.charbuffer += newchars\n            # there was no data available\n            if not newdata:\n                break\n        if chars < 0:\n            # Return everything we've got\n            result = self.charbuffer\n            self.charbuffer = self._empty_charbuffer\n        else:\n            # Return the first chars characters\n            result = self.charbuffer[:chars]\n            self.charbuffer = self.charbuffer[chars:]\n        return result\n\n    def readline(self, size=None, keepends=True):\n\n        \"\"\" Read one line from the input stream and return the\n            decoded data.\n\n            size, if given, is passed as size argument to the\n            read() method.\n\n        \"\"\"\n        # If we have lines cached from an earlier read, return\n        # them unconditionally\n        if self.linebuffer:\n            line = self.linebuffer[0]\n            del self.linebuffer[0]\n            if len(self.linebuffer) == 1:\n                # revert to charbuffer mode; we might need more data\n                # next time\n                self.charbuffer = self.linebuffer[0]\n                self.linebuffer = None\n            if not keepends:\n                line = line.splitlines(keepends=False)[0]\n            return line\n\n        readsize = size or 72\n        line = self._empty_charbuffer\n        # If size is given, we call read() only once\n        while True:\n            data = self.read(readsize, firstline=True)\n            if data:\n                # If we're at a \"\\r\" read one extra character (which might\n                # be a \"\\n\") to get a proper line ending. If the stream is\n                # temporarily exhausted we return the wrong line ending.\n                if (isinstance(data, str) and data.endswith(\"\\r\")) or \\\n                   (isinstance(data, bytes) and data.endswith(b\"\\r\")):\n                    data += self.read(size=1, chars=1)\n\n            line += data\n            lines = line.splitlines(keepends=True)\n            if lines:\n                if len(lines) > 1:\n                    # More than one line result; the first line is a full line\n                    # to return\n                    line = lines[0]\n                    del lines[0]\n                    if len(lines) > 1:\n                        # cache the remaining lines\n                        lines[-1] += self.charbuffer\n                        self.linebuffer = lines\n                        self.charbuffer = None\n                    else:\n                        # only one remaining line, put it back into charbuffer\n                        self.charbuffer = lines[0] + self.charbuffer\n                    if not keepends:\n                        line = line.splitlines(keepends=False)[0]\n                    break\n                line0withend = lines[0]\n                line0withoutend = lines[0].splitlines(keepends=False)[0]\n                if line0withend != line0withoutend: # We really have a line end\n                    # Put the rest back together and keep it until the next call\n                    self.charbuffer = self._empty_charbuffer.join(lines[1:]) + \\\n                                      self.charbuffer\n                    if keepends:\n                        line = line0withend\n                    else:\n                        line = line0withoutend\n                    break\n            # we didn't get anything or this was our only try\n            if not data or size is not None:\n                if line and not keepends:\n                    line = line.splitlines(keepends=False)[0]\n                break\n            if readsize < 8000:\n                readsize *= 2\n        return line\n\n    def readlines(self, sizehint=None, keepends=True):\n\n        \"\"\" Read all lines available on the input stream\n            and return them as a list.\n\n            Line breaks are implemented using the codec's decoder\n            method and are included in the list entries.\n\n            sizehint, if given, is ignored since there is no efficient\n            way to finding the true end-of-line.\n\n        \"\"\"\n        data = self.read()\n        return data.splitlines(keepends)\n\n    def reset(self):\n\n        \"\"\" Resets the codec buffers used for keeping internal state.\n\n            Note that no stream repositioning should take place.\n            This method is primarily intended to be able to recover\n            from decoding errors.\n\n        \"\"\"\n        self.bytebuffer = b\"\"\n        self.charbuffer = self._empty_charbuffer\n        self.linebuffer = None\n\n    def seek(self, offset, whence=0):\n        \"\"\" Set the input stream's current position.\n\n            Resets the codec buffers used for keeping state.\n        \"\"\"\n        self.stream.seek(offset, whence)\n        self.reset()\n\n    def __next__(self):\n\n        \"\"\" Return the next decoded line from the input stream.\"\"\"\n        line = self.readline()\n        if line:\n            return line\n        raise StopIteration\n\n    def __iter__(self):\n        return self\n\n    def __getattr__(self, name,\n                    getattr=getattr):\n\n        \"\"\" Inherit all other methods from the underlying stream.\n        \"\"\"\n        return getattr(self.stream, name)\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, type, value, tb):\n        self.stream.close()\n\n###\n\nclass StreamReaderWriter:\n\n    \"\"\" StreamReaderWriter instances allow wrapping streams which\n        work in both read and write modes.\n\n        The design is such that one can use the factory functions\n        returned by the codec.lookup() function to construct the\n        instance.\n\n    \"\"\"\n    # Optional attributes set by the file wrappers below\n    encoding = 'unknown'\n\n    def __init__(self, stream, Reader, Writer, errors='strict'):\n\n        \"\"\" Creates a StreamReaderWriter instance.\n\n            stream must be a Stream-like object.\n\n            Reader, Writer must be factory functions or classes\n            providing the StreamReader, StreamWriter interface resp.\n\n            Error handling is done in the same way as defined for the\n            StreamWriter/Readers.\n\n        \"\"\"\n        self.stream = stream\n        self.reader = Reader(stream, errors)\n        self.writer = Writer(stream, errors)\n        self.errors = errors\n\n    def read(self, size=-1):\n\n        return self.reader.read(size)\n\n    def readline(self, size=None):\n\n        return self.reader.readline(size)\n\n    def readlines(self, sizehint=None):\n\n        return self.reader.readlines(sizehint)\n\n    def __next__(self):\n\n        \"\"\" Return the next decoded line from the input stream.\"\"\"\n        return next(self.reader)\n\n    def __iter__(self):\n        return self\n\n    def write(self, data):\n\n        return self.writer.write(data)\n\n    def writelines(self, list):\n\n        return self.writer.writelines(list)\n\n    def reset(self):\n\n        self.reader.reset()\n        self.writer.reset()\n\n    def seek(self, offset, whence=0):\n        self.stream.seek(offset, whence)\n        self.reader.reset()\n        if whence == 0 and offset == 0:\n            self.writer.reset()\n\n    def __getattr__(self, name,\n                    getattr=getattr):\n\n        \"\"\" Inherit all other methods from the underlying stream.\n        \"\"\"\n        return getattr(self.stream, name)\n\n    # these are needed to make \"with StreamReaderWriter(...)\" work properly\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, type, value, tb):\n        self.stream.close()\n\n###\n\nclass StreamRecoder:\n\n    \"\"\" StreamRecoder instances translate data from one encoding to another.\n\n        They use the complete set of APIs returned by the\n        codecs.lookup() function to implement their task.\n\n        Data written to the StreamRecoder is first decoded into an\n        intermediate format (depending on the \"decode\" codec) and then\n        written to the underlying stream using an instance of the provided\n        Writer class.\n\n        In the other direction, data is read from the underlying stream using\n        a Reader instance and then encoded and returned to the caller.\n\n    \"\"\"\n    # Optional attributes set by the file wrappers below\n    data_encoding = 'unknown'\n    file_encoding = 'unknown'\n\n    def __init__(self, stream, encode, decode, Reader, Writer,\n                 errors='strict'):\n\n        \"\"\" Creates a StreamRecoder instance which implements a two-way\n            conversion: encode and decode work on the frontend (the\n            data visible to .read() and .write()) while Reader and Writer\n            work on the backend (the data in stream).\n\n            You can use these objects to do transparent\n            transcodings from e.g. latin-1 to utf-8 and back.\n\n            stream must be a file-like object.\n\n            encode and decode must adhere to the Codec interface; Reader and\n            Writer must be factory functions or classes providing the\n            StreamReader and StreamWriter interfaces resp.\n\n            Error handling is done in the same way as defined for the\n            StreamWriter/Readers.\n\n        \"\"\"\n        self.stream = stream\n        self.encode = encode\n        self.decode = decode\n        self.reader = Reader(stream, errors)\n        self.writer = Writer(stream, errors)\n        self.errors = errors\n\n    def read(self, size=-1):\n\n        data = self.reader.read(size)\n        data, bytesencoded = self.encode(data, self.errors)\n        return data\n\n    def readline(self, size=None):\n\n        if size is None:\n            data = self.reader.readline()\n        else:\n            data = self.reader.readline(size)\n        data, bytesencoded = self.encode(data, self.errors)\n        return data\n\n    def readlines(self, sizehint=None):\n\n        data = self.reader.read()\n        data, bytesencoded = self.encode(data, self.errors)\n        return data.splitlines(keepends=True)\n\n    def __next__(self):\n\n        \"\"\" Return the next decoded line from the input stream.\"\"\"\n        data = next(self.reader)\n        data, bytesencoded = self.encode(data, self.errors)\n        return data\n\n    def __iter__(self):\n        return self\n\n    def write(self, data):\n\n        data, bytesdecoded = self.decode(data, self.errors)\n        return self.writer.write(data)\n\n    def writelines(self, list):\n\n        data = b''.join(list)\n        data, bytesdecoded = self.decode(data, self.errors)\n        return self.writer.write(data)\n\n    def reset(self):\n\n        self.reader.reset()\n        self.writer.reset()\n\n    def seek(self, offset, whence=0):\n        # Seeks must be propagated to both the readers and writers\n        # as they might need to reset their internal buffers.\n        self.reader.seek(offset, whence)\n        self.writer.seek(offset, whence)\n\n    def __getattr__(self, name,\n                    getattr=getattr):\n\n        \"\"\" Inherit all other methods from the underlying stream.\n        \"\"\"\n        return getattr(self.stream, name)\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, type, value, tb):\n        self.stream.close()\n\n### Shortcuts\n\ndef open(filename, mode='r', encoding=None, errors='strict', buffering=-1):\n\n    \"\"\" Open an encoded file using the given mode and return\n        a wrapped version providing transparent encoding/decoding.\n\n        Note: The wrapped version will only accept the object format\n        defined by the codecs, i.e. Unicode objects for most builtin\n        codecs. Output is also codec dependent and will usually be\n        Unicode as well.\n\n        Underlying encoded files are always opened in binary mode.\n        The default file mode is 'r', meaning to open the file in read mode.\n\n        encoding specifies the encoding which is to be used for the\n        file.\n\n        errors may be given to define the error handling. It defaults\n        to 'strict' which causes ValueErrors to be raised in case an\n        encoding error occurs.\n\n        buffering has the same meaning as for the builtin open() API.\n        It defaults to -1 which means that the default buffer size will\n        be used.\n\n        The returned wrapped file object provides an extra attribute\n        .encoding which allows querying the used encoding. This\n        attribute is only available if an encoding was specified as\n        parameter.\n\n    \"\"\"\n    if encoding is not None and \\\n       'b' not in mode:\n        # Force opening of the file in binary mode\n        mode = mode + 'b'\n    file = builtins.open(filename, mode, buffering)\n    if encoding is None:\n        return file\n\n    try:\n        info = lookup(encoding)\n        srw = StreamReaderWriter(file, info.streamreader, info.streamwriter, errors)\n        # Add attributes to simplify introspection\n        srw.encoding = encoding\n        return srw\n    except:\n        file.close()\n        raise\n\ndef EncodedFile(file, data_encoding, file_encoding=None, errors='strict'):\n\n    \"\"\" Return a wrapped version of file which provides transparent\n        encoding translation.\n\n        Data written to the wrapped file is decoded according\n        to the given data_encoding and then encoded to the underlying\n        file using file_encoding. The intermediate data type\n        will usually be Unicode but depends on the specified codecs.\n\n        Bytes read from the file are decoded using file_encoding and then\n        passed back to the caller encoded using data_encoding.\n\n        If file_encoding is not given, it defaults to data_encoding.\n\n        errors may be given to define the error handling. It defaults\n        to 'strict' which causes ValueErrors to be raised in case an\n        encoding error occurs.\n\n        The returned wrapped file object provides two extra attributes\n        .data_encoding and .file_encoding which reflect the given\n        parameters of the same name. The attributes can be used for\n        introspection by Python programs.\n\n    \"\"\"\n    if file_encoding is None:\n        file_encoding = data_encoding\n    data_info = lookup(data_encoding)\n    file_info = lookup(file_encoding)\n    sr = StreamRecoder(file, data_info.encode, data_info.decode,\n                       file_info.streamreader, file_info.streamwriter, errors)\n    # Add attributes to simplify introspection\n    sr.data_encoding = data_encoding\n    sr.file_encoding = file_encoding\n    return sr\n\n### Helpers for codec lookup\n\ndef getencoder(encoding):\n\n    \"\"\" Lookup up the codec for the given encoding and return\n        its encoder function.\n\n        Raises a LookupError in case the encoding cannot be found.\n\n    \"\"\"\n    return lookup(encoding).encode\n\ndef getdecoder(encoding):\n\n    \"\"\" Lookup up the codec for the given encoding and return\n        its decoder function.\n\n        Raises a LookupError in case the encoding cannot be found.\n\n    \"\"\"\n    return lookup(encoding).decode\n\ndef getincrementalencoder(encoding):\n\n    \"\"\" Lookup up the codec for the given encoding and return\n        its IncrementalEncoder class or factory function.\n\n        Raises a LookupError in case the encoding cannot be found\n        or the codecs doesn't provide an incremental encoder.\n\n    \"\"\"\n    encoder = lookup(encoding).incrementalencoder\n    if encoder is None:\n        raise LookupError(encoding)\n    return encoder\n\ndef getincrementaldecoder(encoding):\n\n    \"\"\" Lookup up the codec for the given encoding and return\n        its IncrementalDecoder class or factory function.\n\n        Raises a LookupError in case the encoding cannot be found\n        or the codecs doesn't provide an incremental decoder.\n\n    \"\"\"\n    decoder = lookup(encoding).incrementaldecoder\n    if decoder is None:\n        raise LookupError(encoding)\n    return decoder\n\ndef getreader(encoding):\n\n    \"\"\" Lookup up the codec for the given encoding and return\n        its StreamReader class or factory function.\n\n        Raises a LookupError in case the encoding cannot be found.\n\n    \"\"\"\n    return lookup(encoding).streamreader\n\ndef getwriter(encoding):\n\n    \"\"\" Lookup up the codec for the given encoding and return\n        its StreamWriter class or factory function.\n\n        Raises a LookupError in case the encoding cannot be found.\n\n    \"\"\"\n    return lookup(encoding).streamwriter\n\ndef iterencode(iterator, encoding, errors='strict', **kwargs):\n    \"\"\"\n    Encoding iterator.\n\n    Encodes the input strings from the iterator using an IncrementalEncoder.\n\n    errors and kwargs are passed through to the IncrementalEncoder\n    constructor.\n    \"\"\"\n    encoder = getincrementalencoder(encoding)(errors, **kwargs)\n    for input in iterator:\n        output = encoder.encode(input)\n        if output:\n            yield output\n    output = encoder.encode(\"\", True)\n    if output:\n        yield output\n\ndef iterdecode(iterator, encoding, errors='strict', **kwargs):\n    \"\"\"\n    Decoding iterator.\n\n    Decodes the input strings from the iterator using an IncrementalDecoder.\n\n    errors and kwargs are passed through to the IncrementalDecoder\n    constructor.\n    \"\"\"\n    decoder = getincrementaldecoder(encoding)(errors, **kwargs)\n    for input in iterator:\n        output = decoder.decode(input)\n        if output:\n            yield output\n    output = decoder.decode(b\"\", True)\n    if output:\n        yield output\n\n### Helpers for charmap-based codecs\n\ndef make_identity_dict(rng):\n\n    \"\"\" make_identity_dict(rng) -> dict\n\n        Return a dictionary where elements of the rng sequence are\n        mapped to themselves.\n\n    \"\"\"\n    return {i:i for i in rng}\n\ndef make_encoding_map(decoding_map):\n\n    \"\"\" Creates an encoding map from a decoding map.\n\n        If a target mapping in the decoding map occurs multiple\n        times, then that target is mapped to None (undefined mapping),\n        causing an exception when encountered by the charmap codec\n        during translation.\n\n        One example where this happens is cp875.py which decodes\n        multiple character to \\\\u001a.\n\n    \"\"\"\n    m = {}\n    for k,v in decoding_map.items():\n        if not v in m:\n            m[v] = k\n        else:\n            m[v] = None\n    return m\n\n### error handlers\n\ntry:\n    strict_errors = lookup_error(\"strict\")\n    ignore_errors = lookup_error(\"ignore\")\n    replace_errors = lookup_error(\"replace\")\n    xmlcharrefreplace_errors = lookup_error(\"xmlcharrefreplace\")\n    backslashreplace_errors = lookup_error(\"backslashreplace\")\n    namereplace_errors = lookup_error(\"namereplace\")\nexcept LookupError:\n    # In --disable-unicode builds, these error handler are missing\n    strict_errors = None\n    ignore_errors = None\n    replace_errors = None\n    xmlcharrefreplace_errors = None\n    backslashreplace_errors = None\n    namereplace_errors = None\n\n# Tell modulefinder that using codecs probably needs the encodings\n# package\n_false = 0\nif _false:\n    import encodings\n\n### Tests\n\nif __name__ == '__main__':\n\n    # Make stdout translate Latin-1 output into UTF-8 output\n    sys.stdout = EncodedFile(sys.stdout, 'latin-1', 'utf-8')\n\n    # Have stdin translate Latin-1 input into UTF-8 input\n    sys.stdin = EncodedFile(sys.stdin, 'utf-8', 'latin-1')\n", 1126], "/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_compile.py": ["#\n# Secret Labs' Regular Expression Engine\n#\n# convert template to internal format\n#\n# Copyright (c) 1997-2001 by Secret Labs AB.  All rights reserved.\n#\n# See the sre.py file for information on usage and redistribution.\n#\n\n\"\"\"Internal support module for sre\"\"\"\n\nimport _sre\nimport sre_parse\nfrom sre_constants import *\n\nassert _sre.MAGIC == MAGIC, \"SRE module mismatch\"\n\n_LITERAL_CODES = {LITERAL, NOT_LITERAL}\n_REPEATING_CODES = {REPEAT, MIN_REPEAT, MAX_REPEAT}\n_SUCCESS_CODES = {SUCCESS, FAILURE}\n_ASSERT_CODES = {ASSERT, ASSERT_NOT}\n_UNIT_CODES = _LITERAL_CODES | {ANY, IN}\n\n# Sets of lowercase characters which have the same uppercase.\n_equivalences = (\n    # LATIN SMALL LETTER I, LATIN SMALL LETTER DOTLESS I\n    (0x69, 0x131), # i\u0131\n    # LATIN SMALL LETTER S, LATIN SMALL LETTER LONG S\n    (0x73, 0x17f), # s\u017f\n    # MICRO SIGN, GREEK SMALL LETTER MU\n    (0xb5, 0x3bc), # \u00b5\u03bc\n    # COMBINING GREEK YPOGEGRAMMENI, GREEK SMALL LETTER IOTA, GREEK PROSGEGRAMMENI\n    (0x345, 0x3b9, 0x1fbe), # \\u0345\u03b9\u1fbe\n    # GREEK SMALL LETTER IOTA WITH DIALYTIKA AND TONOS, GREEK SMALL LETTER IOTA WITH DIALYTIKA AND OXIA\n    (0x390, 0x1fd3), # \u0390\u1fd3\n    # GREEK SMALL LETTER UPSILON WITH DIALYTIKA AND TONOS, GREEK SMALL LETTER UPSILON WITH DIALYTIKA AND OXIA\n    (0x3b0, 0x1fe3), # \u03b0\u1fe3\n    # GREEK SMALL LETTER BETA, GREEK BETA SYMBOL\n    (0x3b2, 0x3d0), # \u03b2\u03d0\n    # GREEK SMALL LETTER EPSILON, GREEK LUNATE EPSILON SYMBOL\n    (0x3b5, 0x3f5), # \u03b5\u03f5\n    # GREEK SMALL LETTER THETA, GREEK THETA SYMBOL\n    (0x3b8, 0x3d1), # \u03b8\u03d1\n    # GREEK SMALL LETTER KAPPA, GREEK KAPPA SYMBOL\n    (0x3ba, 0x3f0), # \u03ba\u03f0\n    # GREEK SMALL LETTER PI, GREEK PI SYMBOL\n    (0x3c0, 0x3d6), # \u03c0\u03d6\n    # GREEK SMALL LETTER RHO, GREEK RHO SYMBOL\n    (0x3c1, 0x3f1), # \u03c1\u03f1\n    # GREEK SMALL LETTER FINAL SIGMA, GREEK SMALL LETTER SIGMA\n    (0x3c2, 0x3c3), # \u03c2\u03c3\n    # GREEK SMALL LETTER PHI, GREEK PHI SYMBOL\n    (0x3c6, 0x3d5), # \u03c6\u03d5\n    # LATIN SMALL LETTER S WITH DOT ABOVE, LATIN SMALL LETTER LONG S WITH DOT ABOVE\n    (0x1e61, 0x1e9b), # \u1e61\u1e9b\n    # LATIN SMALL LIGATURE LONG S T, LATIN SMALL LIGATURE ST\n    (0xfb05, 0xfb06), # \ufb05\ufb06\n)\n\n# Maps the lowercase code to lowercase codes which have the same uppercase.\n_ignorecase_fixes = {i: tuple(j for j in t if i != j)\n                     for t in _equivalences for i in t}\n\ndef _combine_flags(flags, add_flags, del_flags,\n                   TYPE_FLAGS=sre_parse.TYPE_FLAGS):\n    if add_flags & TYPE_FLAGS:\n        flags &= ~TYPE_FLAGS\n    return (flags | add_flags) & ~del_flags\n\ndef _compile(code, pattern, flags):\n    # internal: compile a (sub)pattern\n    emit = code.append\n    _len = len\n    LITERAL_CODES = _LITERAL_CODES\n    REPEATING_CODES = _REPEATING_CODES\n    SUCCESS_CODES = _SUCCESS_CODES\n    ASSERT_CODES = _ASSERT_CODES\n    iscased = None\n    tolower = None\n    fixes = None\n    if flags & SRE_FLAG_IGNORECASE and not flags & SRE_FLAG_LOCALE:\n        if flags & SRE_FLAG_UNICODE:\n            iscased = _sre.unicode_iscased\n            tolower = _sre.unicode_tolower\n            fixes = _ignorecase_fixes\n        else:\n            iscased = _sre.ascii_iscased\n            tolower = _sre.ascii_tolower\n    for op, av in pattern:\n        if op in LITERAL_CODES:\n            if not flags & SRE_FLAG_IGNORECASE:\n                emit(op)\n                emit(av)\n            elif flags & SRE_FLAG_LOCALE:\n                emit(OP_LOCALE_IGNORE[op])\n                emit(av)\n            elif not iscased(av):\n                emit(op)\n                emit(av)\n            else:\n                lo = tolower(av)\n                if not fixes:  # ascii\n                    emit(OP_IGNORE[op])\n                    emit(lo)\n                elif lo not in fixes:\n                    emit(OP_UNICODE_IGNORE[op])\n                    emit(lo)\n                else:\n                    emit(IN_UNI_IGNORE)\n                    skip = _len(code); emit(0)\n                    if op is NOT_LITERAL:\n                        emit(NEGATE)\n                    for k in (lo,) + fixes[lo]:\n                        emit(LITERAL)\n                        emit(k)\n                    emit(FAILURE)\n                    code[skip] = _len(code) - skip\n        elif op is IN:\n            charset, hascased = _optimize_charset(av, iscased, tolower, fixes)\n            if flags & SRE_FLAG_IGNORECASE and flags & SRE_FLAG_LOCALE:\n                emit(IN_LOC_IGNORE)\n            elif not hascased:\n                emit(IN)\n            elif not fixes:  # ascii\n                emit(IN_IGNORE)\n            else:\n                emit(IN_UNI_IGNORE)\n            skip = _len(code); emit(0)\n            _compile_charset(charset, flags, code)\n            code[skip] = _len(code) - skip\n        elif op is ANY:\n            if flags & SRE_FLAG_DOTALL:\n                emit(ANY_ALL)\n            else:\n                emit(ANY)\n        elif op in REPEATING_CODES:\n            if flags & SRE_FLAG_TEMPLATE:\n                raise error(\"internal: unsupported template operator %r\" % (op,))\n            if _simple(av[2]):\n                if op is MAX_REPEAT:\n                    emit(REPEAT_ONE)\n                else:\n                    emit(MIN_REPEAT_ONE)\n                skip = _len(code); emit(0)\n                emit(av[0])\n                emit(av[1])\n                _compile(code, av[2], flags)\n                emit(SUCCESS)\n                code[skip] = _len(code) - skip\n            else:\n                emit(REPEAT)\n                skip = _len(code); emit(0)\n                emit(av[0])\n                emit(av[1])\n                _compile(code, av[2], flags)\n                code[skip] = _len(code) - skip\n                if op is MAX_REPEAT:\n                    emit(MAX_UNTIL)\n                else:\n                    emit(MIN_UNTIL)\n        elif op is SUBPATTERN:\n            group, add_flags, del_flags, p = av\n            if group:\n                emit(MARK)\n                emit((group-1)*2)\n            # _compile_info(code, p, _combine_flags(flags, add_flags, del_flags))\n            _compile(code, p, _combine_flags(flags, add_flags, del_flags))\n            if group:\n                emit(MARK)\n                emit((group-1)*2+1)\n        elif op in SUCCESS_CODES:\n            emit(op)\n        elif op in ASSERT_CODES:\n            emit(op)\n            skip = _len(code); emit(0)\n            if av[0] >= 0:\n                emit(0) # look ahead\n            else:\n                lo, hi = av[1].getwidth()\n                if lo != hi:\n                    raise error(\"look-behind requires fixed-width pattern\")\n                emit(lo) # look behind\n            _compile(code, av[1], flags)\n            emit(SUCCESS)\n            code[skip] = _len(code) - skip\n        elif op is CALL:\n            emit(op)\n            skip = _len(code); emit(0)\n            _compile(code, av, flags)\n            emit(SUCCESS)\n            code[skip] = _len(code) - skip\n        elif op is AT:\n            emit(op)\n            if flags & SRE_FLAG_MULTILINE:\n                av = AT_MULTILINE.get(av, av)\n            if flags & SRE_FLAG_LOCALE:\n                av = AT_LOCALE.get(av, av)\n            elif flags & SRE_FLAG_UNICODE:\n                av = AT_UNICODE.get(av, av)\n            emit(av)\n        elif op is BRANCH:\n            emit(op)\n            tail = []\n            tailappend = tail.append\n            for av in av[1]:\n                skip = _len(code); emit(0)\n                # _compile_info(code, av, flags)\n                _compile(code, av, flags)\n                emit(JUMP)\n                tailappend(_len(code)); emit(0)\n                code[skip] = _len(code) - skip\n            emit(FAILURE) # end of branch\n            for tail in tail:\n                code[tail] = _len(code) - tail\n        elif op is CATEGORY:\n            emit(op)\n            if flags & SRE_FLAG_LOCALE:\n                av = CH_LOCALE[av]\n            elif flags & SRE_FLAG_UNICODE:\n                av = CH_UNICODE[av]\n            emit(av)\n        elif op is GROUPREF:\n            if not flags & SRE_FLAG_IGNORECASE:\n                emit(op)\n            elif flags & SRE_FLAG_LOCALE:\n                emit(GROUPREF_LOC_IGNORE)\n            elif not fixes:  # ascii\n                emit(GROUPREF_IGNORE)\n            else:\n                emit(GROUPREF_UNI_IGNORE)\n            emit(av-1)\n        elif op is GROUPREF_EXISTS:\n            emit(op)\n            emit(av[0]-1)\n            skipyes = _len(code); emit(0)\n            _compile(code, av[1], flags)\n            if av[2]:\n                emit(JUMP)\n                skipno = _len(code); emit(0)\n                code[skipyes] = _len(code) - skipyes + 1\n                _compile(code, av[2], flags)\n                code[skipno] = _len(code) - skipno\n            else:\n                code[skipyes] = _len(code) - skipyes + 1\n        else:\n            raise error(\"internal: unsupported operand type %r\" % (op,))\n\ndef _compile_charset(charset, flags, code):\n    # compile charset subprogram\n    emit = code.append\n    for op, av in charset:\n        emit(op)\n        if op is NEGATE:\n            pass\n        elif op is LITERAL:\n            emit(av)\n        elif op is RANGE or op is RANGE_UNI_IGNORE:\n            emit(av[0])\n            emit(av[1])\n        elif op is CHARSET:\n            code.extend(av)\n        elif op is BIGCHARSET:\n            code.extend(av)\n        elif op is CATEGORY:\n            if flags & SRE_FLAG_LOCALE:\n                emit(CH_LOCALE[av])\n            elif flags & SRE_FLAG_UNICODE:\n                emit(CH_UNICODE[av])\n            else:\n                emit(av)\n        else:\n            raise error(\"internal: unsupported set operator %r\" % (op,))\n    emit(FAILURE)\n\ndef _optimize_charset(charset, iscased=None, fixup=None, fixes=None):\n    # internal: optimize character set\n    out = []\n    tail = []\n    charmap = bytearray(256)\n    hascased = False\n    for op, av in charset:\n        while True:\n            try:\n                if op is LITERAL:\n                    if fixup:\n                        lo = fixup(av)\n                        charmap[lo] = 1\n                        if fixes and lo in fixes:\n                            for k in fixes[lo]:\n                                charmap[k] = 1\n                        if not hascased and iscased(av):\n                            hascased = True\n                    else:\n                        charmap[av] = 1\n                elif op is RANGE:\n                    r = range(av[0], av[1]+1)\n                    if fixup:\n                        if fixes:\n                            for i in map(fixup, r):\n                                charmap[i] = 1\n                                if i in fixes:\n                                    for k in fixes[i]:\n                                        charmap[k] = 1\n                        else:\n                            for i in map(fixup, r):\n                                charmap[i] = 1\n                        if not hascased:\n                            hascased = any(map(iscased, r))\n                    else:\n                        for i in r:\n                            charmap[i] = 1\n                elif op is NEGATE:\n                    out.append((op, av))\n                else:\n                    tail.append((op, av))\n            except IndexError:\n                if len(charmap) == 256:\n                    # character set contains non-UCS1 character codes\n                    charmap += b'\\0' * 0xff00\n                    continue\n                # Character set contains non-BMP character codes.\n                if fixup:\n                    hascased = True\n                    # There are only two ranges of cased non-BMP characters:\n                    # 10400-1044F (Deseret) and 118A0-118DF (Warang Citi),\n                    # and for both ranges RANGE_UNI_IGNORE works.\n                    if op is RANGE:\n                        op = RANGE_UNI_IGNORE\n                tail.append((op, av))\n            break\n\n    # compress character map\n    runs = []\n    q = 0\n    while True:\n        p = charmap.find(1, q)\n        if p < 0:\n            break\n        if len(runs) >= 2:\n            runs = None\n            break\n        q = charmap.find(0, p)\n        if q < 0:\n            runs.append((p, len(charmap)))\n            break\n        runs.append((p, q))\n    if runs is not None:\n        # use literal/range\n        for p, q in runs:\n            if q - p == 1:\n                out.append((LITERAL, p))\n            else:\n                out.append((RANGE, (p, q - 1)))\n        out += tail\n        # if the case was changed or new representation is more compact\n        if hascased or len(out) < len(charset):\n            return out, hascased\n        # else original character set is good enough\n        return charset, hascased\n\n    # use bitmap\n    if len(charmap) == 256:\n        data = _mk_bitmap(charmap)\n        out.append((CHARSET, data))\n        out += tail\n        return out, hascased\n\n    # To represent a big charset, first a bitmap of all characters in the\n    # set is constructed. Then, this bitmap is sliced into chunks of 256\n    # characters, duplicate chunks are eliminated, and each chunk is\n    # given a number. In the compiled expression, the charset is\n    # represented by a 32-bit word sequence, consisting of one word for\n    # the number of different chunks, a sequence of 256 bytes (64 words)\n    # of chunk numbers indexed by their original chunk position, and a\n    # sequence of 256-bit chunks (8 words each).\n\n    # Compression is normally good: in a typical charset, large ranges of\n    # Unicode will be either completely excluded (e.g. if only cyrillic\n    # letters are to be matched), or completely included (e.g. if large\n    # subranges of Kanji match). These ranges will be represented by\n    # chunks of all one-bits or all zero-bits.\n\n    # Matching can be also done efficiently: the more significant byte of\n    # the Unicode character is an index into the chunk number, and the\n    # less significant byte is a bit index in the chunk (just like the\n    # CHARSET matching).\n\n    charmap = bytes(charmap) # should be hashable\n    comps = {}\n    mapping = bytearray(256)\n    block = 0\n    data = bytearray()\n    for i in range(0, 65536, 256):\n        chunk = charmap[i: i + 256]\n        if chunk in comps:\n            mapping[i // 256] = comps[chunk]\n        else:\n            mapping[i // 256] = comps[chunk] = block\n            block += 1\n            data += chunk\n    data = _mk_bitmap(data)\n    data[0:0] = [block] + _bytes_to_codes(mapping)\n    out.append((BIGCHARSET, data))\n    out += tail\n    return out, hascased\n\n_CODEBITS = _sre.CODESIZE * 8\nMAXCODE = (1 << _CODEBITS) - 1\n_BITS_TRANS = b'0' + b'1' * 255\ndef _mk_bitmap(bits, _CODEBITS=_CODEBITS, _int=int):\n    s = bits.translate(_BITS_TRANS)[::-1]\n    return [_int(s[i - _CODEBITS: i], 2)\n            for i in range(len(s), 0, -_CODEBITS)]\n\ndef _bytes_to_codes(b):\n    # Convert block indices to word array\n    a = memoryview(b).cast('I')\n    assert a.itemsize == _sre.CODESIZE\n    assert len(a) * a.itemsize == len(b)\n    return a.tolist()\n\ndef _simple(p):\n    # check if this subpattern is a \"simple\" operator\n    if len(p) != 1:\n        return False\n    op, av = p[0]\n    if op is SUBPATTERN:\n        return av[0] is None and _simple(av[-1])\n    return op in _UNIT_CODES\n\ndef _generate_overlap_table(prefix):\n    \"\"\"\n    Generate an overlap table for the following prefix.\n    An overlap table is a table of the same size as the prefix which\n    informs about the potential self-overlap for each index in the prefix:\n    - if overlap[i] == 0, prefix[i:] can't overlap prefix[0:...]\n    - if overlap[i] == k with 0 < k <= i, prefix[i-k+1:i+1] overlaps with\n      prefix[0:k]\n    \"\"\"\n    table = [0] * len(prefix)\n    for i in range(1, len(prefix)):\n        idx = table[i - 1]\n        while prefix[i] != prefix[idx]:\n            if idx == 0:\n                table[i] = 0\n                break\n            idx = table[idx - 1]\n        else:\n            table[i] = idx + 1\n    return table\n\ndef _get_iscased(flags):\n    if not flags & SRE_FLAG_IGNORECASE:\n        return None\n    elif flags & SRE_FLAG_UNICODE:\n        return _sre.unicode_iscased\n    else:\n        return _sre.ascii_iscased\n\ndef _get_literal_prefix(pattern, flags):\n    # look for literal prefix\n    prefix = []\n    prefixappend = prefix.append\n    prefix_skip = None\n    iscased = _get_iscased(flags)\n    for op, av in pattern.data:\n        if op is LITERAL:\n            if iscased and iscased(av):\n                break\n            prefixappend(av)\n        elif op is SUBPATTERN:\n            group, add_flags, del_flags, p = av\n            flags1 = _combine_flags(flags, add_flags, del_flags)\n            if flags1 & SRE_FLAG_IGNORECASE and flags1 & SRE_FLAG_LOCALE:\n                break\n            prefix1, prefix_skip1, got_all = _get_literal_prefix(p, flags1)\n            if prefix_skip is None:\n                if group is not None:\n                    prefix_skip = len(prefix)\n                elif prefix_skip1 is not None:\n                    prefix_skip = len(prefix) + prefix_skip1\n            prefix.extend(prefix1)\n            if not got_all:\n                break\n        else:\n            break\n    else:\n        return prefix, prefix_skip, True\n    return prefix, prefix_skip, False\n\ndef _get_charset_prefix(pattern, flags):\n    while True:\n        if not pattern.data:\n            return None\n        op, av = pattern.data[0]\n        if op is not SUBPATTERN:\n            break\n        group, add_flags, del_flags, pattern = av\n        flags = _combine_flags(flags, add_flags, del_flags)\n        if flags & SRE_FLAG_IGNORECASE and flags & SRE_FLAG_LOCALE:\n            return None\n\n    iscased = _get_iscased(flags)\n    if op is LITERAL:\n        if iscased and iscased(av):\n            return None\n        return [(op, av)]\n    elif op is BRANCH:\n        charset = []\n        charsetappend = charset.append\n        for p in av[1]:\n            if not p:\n                return None\n            op, av = p[0]\n            if op is LITERAL and not (iscased and iscased(av)):\n                charsetappend((op, av))\n            else:\n                return None\n        return charset\n    elif op is IN:\n        charset = av\n        if iscased:\n            for op, av in charset:\n                if op is LITERAL:\n                    if iscased(av):\n                        return None\n                elif op is RANGE:\n                    if av[1] > 0xffff:\n                        return None\n                    if any(map(iscased, range(av[0], av[1]+1))):\n                        return None\n        return charset\n    return None\n\ndef _compile_info(code, pattern, flags):\n    # internal: compile an info block.  in the current version,\n    # this contains min/max pattern width, and an optional literal\n    # prefix or a character map\n    lo, hi = pattern.getwidth()\n    if hi > MAXCODE:\n        hi = MAXCODE\n    if lo == 0:\n        code.extend([INFO, 4, 0, lo, hi])\n        return\n    # look for a literal prefix\n    prefix = []\n    prefix_skip = 0\n    charset = [] # not used\n    if not (flags & SRE_FLAG_IGNORECASE and flags & SRE_FLAG_LOCALE):\n        # look for literal prefix\n        prefix, prefix_skip, got_all = _get_literal_prefix(pattern, flags)\n        # if no prefix, look for charset prefix\n        if not prefix:\n            charset = _get_charset_prefix(pattern, flags)\n##     if prefix:\n##         print(\"*** PREFIX\", prefix, prefix_skip)\n##     if charset:\n##         print(\"*** CHARSET\", charset)\n    # add an info block\n    emit = code.append\n    emit(INFO)\n    skip = len(code); emit(0)\n    # literal flag\n    mask = 0\n    if prefix:\n        mask = SRE_INFO_PREFIX\n        if prefix_skip is None and got_all:\n            mask = mask | SRE_INFO_LITERAL\n    elif charset:\n        mask = mask | SRE_INFO_CHARSET\n    emit(mask)\n    # pattern length\n    if lo < MAXCODE:\n        emit(lo)\n    else:\n        emit(MAXCODE)\n        prefix = prefix[:MAXCODE]\n    emit(min(hi, MAXCODE))\n    # add literal prefix\n    if prefix:\n        emit(len(prefix)) # length\n        if prefix_skip is None:\n            prefix_skip =  len(prefix)\n        emit(prefix_skip) # skip\n        code.extend(prefix)\n        # generate overlap table\n        code.extend(_generate_overlap_table(prefix))\n    elif charset:\n        charset, hascased = _optimize_charset(charset)\n        assert not hascased\n        _compile_charset(charset, flags, code)\n    code[skip] = len(code) - skip\n\ndef isstring(obj):\n    return isinstance(obj, (str, bytes))\n\ndef _code(p, flags):\n\n    flags = p.state.flags | flags\n    code = []\n\n    # compile info block\n    _compile_info(code, p, flags)\n\n    # compile the pattern\n    _compile(code, p.data, flags)\n\n    code.append(SUCCESS)\n\n    return code\n\ndef _hex_code(code):\n    return '[%s]' % ', '.join('%#0*x' % (_sre.CODESIZE*2+2, x) for x in code)\n\ndef dis(code):\n    import sys\n\n    labels = set()\n    level = 0\n    offset_width = len(str(len(code) - 1))\n\n    def dis_(start, end):\n        def print_(*args, to=None):\n            if to is not None:\n                labels.add(to)\n                args += ('(to %d)' % (to,),)\n            print('%*d%s ' % (offset_width, start, ':' if start in labels else '.'),\n                  end='  '*(level-1))\n            print(*args)\n\n        def print_2(*args):\n            print(end=' '*(offset_width + 2*level))\n            print(*args)\n\n        nonlocal level\n        level += 1\n        i = start\n        while i < end:\n            start = i\n            op = code[i]\n            i += 1\n            op = OPCODES[op]\n            if op in (SUCCESS, FAILURE, ANY, ANY_ALL,\n                      MAX_UNTIL, MIN_UNTIL, NEGATE):\n                print_(op)\n            elif op in (LITERAL, NOT_LITERAL,\n                        LITERAL_IGNORE, NOT_LITERAL_IGNORE,\n                        LITERAL_UNI_IGNORE, NOT_LITERAL_UNI_IGNORE,\n                        LITERAL_LOC_IGNORE, NOT_LITERAL_LOC_IGNORE):\n                arg = code[i]\n                i += 1\n                print_(op, '%#02x (%r)' % (arg, chr(arg)))\n            elif op is AT:\n                arg = code[i]\n                i += 1\n                arg = str(ATCODES[arg])\n                assert arg[:3] == 'AT_'\n                print_(op, arg[3:])\n            elif op is CATEGORY:\n                arg = code[i]\n                i += 1\n                arg = str(CHCODES[arg])\n                assert arg[:9] == 'CATEGORY_'\n                print_(op, arg[9:])\n            elif op in (IN, IN_IGNORE, IN_UNI_IGNORE, IN_LOC_IGNORE):\n                skip = code[i]\n                print_(op, skip, to=i+skip)\n                dis_(i+1, i+skip)\n                i += skip\n            elif op in (RANGE, RANGE_UNI_IGNORE):\n                lo, hi = code[i: i+2]\n                i += 2\n                print_(op, '%#02x %#02x (%r-%r)' % (lo, hi, chr(lo), chr(hi)))\n            elif op is CHARSET:\n                print_(op, _hex_code(code[i: i + 256//_CODEBITS]))\n                i += 256//_CODEBITS\n            elif op is BIGCHARSET:\n                arg = code[i]\n                i += 1\n                mapping = list(b''.join(x.to_bytes(_sre.CODESIZE, sys.byteorder)\n                                        for x in code[i: i + 256//_sre.CODESIZE]))\n                print_(op, arg, mapping)\n                i += 256//_sre.CODESIZE\n                level += 1\n                for j in range(arg):\n                    print_2(_hex_code(code[i: i + 256//_CODEBITS]))\n                    i += 256//_CODEBITS\n                level -= 1\n            elif op in (MARK, GROUPREF, GROUPREF_IGNORE, GROUPREF_UNI_IGNORE,\n                        GROUPREF_LOC_IGNORE):\n                arg = code[i]\n                i += 1\n                print_(op, arg)\n            elif op is JUMP:\n                skip = code[i]\n                print_(op, skip, to=i+skip)\n                i += 1\n            elif op is BRANCH:\n                skip = code[i]\n                print_(op, skip, to=i+skip)\n                while skip:\n                    dis_(i+1, i+skip)\n                    i += skip\n                    start = i\n                    skip = code[i]\n                    if skip:\n                        print_('branch', skip, to=i+skip)\n                    else:\n                        print_(FAILURE)\n                i += 1\n            elif op in (REPEAT, REPEAT_ONE, MIN_REPEAT_ONE):\n                skip, min, max = code[i: i+3]\n                if max == MAXREPEAT:\n                    max = 'MAXREPEAT'\n                print_(op, skip, min, max, to=i+skip)\n                dis_(i+3, i+skip)\n                i += skip\n            elif op is GROUPREF_EXISTS:\n                arg, skip = code[i: i+2]\n                print_(op, arg, skip, to=i+skip)\n                i += 2\n            elif op in (ASSERT, ASSERT_NOT):\n                skip, arg = code[i: i+2]\n                print_(op, skip, arg, to=i+skip)\n                dis_(i+2, i+skip)\n                i += skip\n            elif op is INFO:\n                skip, flags, min, max = code[i: i+4]\n                if max == MAXREPEAT:\n                    max = 'MAXREPEAT'\n                print_(op, skip, bin(flags), min, max, to=i+skip)\n                start = i+4\n                if flags & SRE_INFO_PREFIX:\n                    prefix_len, prefix_skip = code[i+4: i+6]\n                    print_2('  prefix_skip', prefix_skip)\n                    start = i + 6\n                    prefix = code[start: start+prefix_len]\n                    print_2('  prefix',\n                            '[%s]' % ', '.join('%#02x' % x for x in prefix),\n                            '(%r)' % ''.join(map(chr, prefix)))\n                    start += prefix_len\n                    print_2('  overlap', code[start: start+prefix_len])\n                    start += prefix_len\n                if flags & SRE_INFO_CHARSET:\n                    level += 1\n                    print_2('in')\n                    dis_(start, i+skip)\n                    level -= 1\n                i += skip\n            else:\n                raise ValueError(op)\n\n        level -= 1\n\n    dis_(0, len(code))\n\n\ndef compile(p, flags=0):\n    # internal: convert pattern list to internal format\n\n    if isstring(p):\n        pattern = p\n        p = sre_parse.parse(p, flags)\n    else:\n        pattern = None\n\n    code = _code(p, flags)\n\n    if flags & SRE_FLAG_DEBUG:\n        print()\n        dis(code)\n\n    # map in either direction\n    groupindex = p.state.groupdict\n    indexgroup = [None] * p.state.groups\n    for k, i in groupindex.items():\n        indexgroup[i] = k\n\n    return _sre.compile(\n        pattern, flags | p.state.flags, code,\n        p.state.groups-1,\n        groupindex, tuple(indexgroup)\n        )\n", 784], "/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py": ["#\n# Secret Labs' Regular Expression Engine\n#\n# convert re-style regular expression to sre pattern\n#\n# Copyright (c) 1998-2001 by Secret Labs AB.  All rights reserved.\n#\n# See the sre.py file for information on usage and redistribution.\n#\n\n\"\"\"Internal support module for sre\"\"\"\n\n# XXX: show string offset and offending character for all errors\n\nfrom sre_constants import *\n\nSPECIAL_CHARS = \".\\\\[{()*+?^$|\"\nREPEAT_CHARS = \"*+?{\"\n\nDIGITS = frozenset(\"0123456789\")\n\nOCTDIGITS = frozenset(\"01234567\")\nHEXDIGITS = frozenset(\"0123456789abcdefABCDEF\")\nASCIILETTERS = frozenset(\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\")\n\nWHITESPACE = frozenset(\" \\t\\n\\r\\v\\f\")\n\n_REPEATCODES = frozenset({MIN_REPEAT, MAX_REPEAT})\n_UNITCODES = frozenset({ANY, RANGE, IN, LITERAL, NOT_LITERAL, CATEGORY})\n\nESCAPES = {\n    r\"\\a\": (LITERAL, ord(\"\\a\")),\n    r\"\\b\": (LITERAL, ord(\"\\b\")),\n    r\"\\f\": (LITERAL, ord(\"\\f\")),\n    r\"\\n\": (LITERAL, ord(\"\\n\")),\n    r\"\\r\": (LITERAL, ord(\"\\r\")),\n    r\"\\t\": (LITERAL, ord(\"\\t\")),\n    r\"\\v\": (LITERAL, ord(\"\\v\")),\n    r\"\\\\\": (LITERAL, ord(\"\\\\\"))\n}\n\nCATEGORIES = {\n    r\"\\A\": (AT, AT_BEGINNING_STRING), # start of string\n    r\"\\b\": (AT, AT_BOUNDARY),\n    r\"\\B\": (AT, AT_NON_BOUNDARY),\n    r\"\\d\": (IN, [(CATEGORY, CATEGORY_DIGIT)]),\n    r\"\\D\": (IN, [(CATEGORY, CATEGORY_NOT_DIGIT)]),\n    r\"\\s\": (IN, [(CATEGORY, CATEGORY_SPACE)]),\n    r\"\\S\": (IN, [(CATEGORY, CATEGORY_NOT_SPACE)]),\n    r\"\\w\": (IN, [(CATEGORY, CATEGORY_WORD)]),\n    r\"\\W\": (IN, [(CATEGORY, CATEGORY_NOT_WORD)]),\n    r\"\\Z\": (AT, AT_END_STRING), # end of string\n}\n\nFLAGS = {\n    # standard flags\n    \"i\": SRE_FLAG_IGNORECASE,\n    \"L\": SRE_FLAG_LOCALE,\n    \"m\": SRE_FLAG_MULTILINE,\n    \"s\": SRE_FLAG_DOTALL,\n    \"x\": SRE_FLAG_VERBOSE,\n    # extensions\n    \"a\": SRE_FLAG_ASCII,\n    \"t\": SRE_FLAG_TEMPLATE,\n    \"u\": SRE_FLAG_UNICODE,\n}\n\nTYPE_FLAGS = SRE_FLAG_ASCII | SRE_FLAG_LOCALE | SRE_FLAG_UNICODE\nGLOBAL_FLAGS = SRE_FLAG_DEBUG | SRE_FLAG_TEMPLATE\n\nclass Verbose(Exception):\n    pass\n\nclass State:\n    # keeps track of state for parsing\n    def __init__(self):\n        self.flags = 0\n        self.groupdict = {}\n        self.groupwidths = [None]  # group 0\n        self.lookbehindgroups = None\n    @property\n    def groups(self):\n        return len(self.groupwidths)\n    def opengroup(self, name=None):\n        gid = self.groups\n        self.groupwidths.append(None)\n        if self.groups > MAXGROUPS:\n            raise error(\"too many groups\")\n        if name is not None:\n            ogid = self.groupdict.get(name, None)\n            if ogid is not None:\n                raise error(\"redefinition of group name %r as group %d; \"\n                            \"was group %d\" % (name, gid,  ogid))\n            self.groupdict[name] = gid\n        return gid\n    def closegroup(self, gid, p):\n        self.groupwidths[gid] = p.getwidth()\n    def checkgroup(self, gid):\n        return gid < self.groups and self.groupwidths[gid] is not None\n\n    def checklookbehindgroup(self, gid, source):\n        if self.lookbehindgroups is not None:\n            if not self.checkgroup(gid):\n                raise source.error('cannot refer to an open group')\n            if gid >= self.lookbehindgroups:\n                raise source.error('cannot refer to group defined in the same '\n                                   'lookbehind subpattern')\n\nclass SubPattern:\n    # a subpattern, in intermediate form\n    def __init__(self, state, data=None):\n        self.state = state\n        if data is None:\n            data = []\n        self.data = data\n        self.width = None\n\n    def dump(self, level=0):\n        nl = True\n        seqtypes = (tuple, list)\n        for op, av in self.data:\n            print(level*\"  \" + str(op), end='')\n            if op is IN:\n                # member sublanguage\n                print()\n                for op, a in av:\n                    print((level+1)*\"  \" + str(op), a)\n            elif op is BRANCH:\n                print()\n                for i, a in enumerate(av[1]):\n                    if i:\n                        print(level*\"  \" + \"OR\")\n                    a.dump(level+1)\n            elif op is GROUPREF_EXISTS:\n                condgroup, item_yes, item_no = av\n                print('', condgroup)\n                item_yes.dump(level+1)\n                if item_no:\n                    print(level*\"  \" + \"ELSE\")\n                    item_no.dump(level+1)\n            elif isinstance(av, seqtypes):\n                nl = False\n                for a in av:\n                    if isinstance(a, SubPattern):\n                        if not nl:\n                            print()\n                        a.dump(level+1)\n                        nl = True\n                    else:\n                        if not nl:\n                            print(' ', end='')\n                        print(a, end='')\n                        nl = False\n                if not nl:\n                    print()\n            else:\n                print('', av)\n    def __repr__(self):\n        return repr(self.data)\n    def __len__(self):\n        return len(self.data)\n    def __delitem__(self, index):\n        del self.data[index]\n    def __getitem__(self, index):\n        if isinstance(index, slice):\n            return SubPattern(self.state, self.data[index])\n        return self.data[index]\n    def __setitem__(self, index, code):\n        self.data[index] = code\n    def insert(self, index, code):\n        self.data.insert(index, code)\n    def append(self, code):\n        self.data.append(code)\n    def getwidth(self):\n        # determine the width (min, max) for this subpattern\n        if self.width is not None:\n            return self.width\n        lo = hi = 0\n        for op, av in self.data:\n            if op is BRANCH:\n                i = MAXREPEAT - 1\n                j = 0\n                for av in av[1]:\n                    l, h = av.getwidth()\n                    i = min(i, l)\n                    j = max(j, h)\n                lo = lo + i\n                hi = hi + j\n            elif op is CALL:\n                i, j = av.getwidth()\n                lo = lo + i\n                hi = hi + j\n            elif op is SUBPATTERN:\n                i, j = av[-1].getwidth()\n                lo = lo + i\n                hi = hi + j\n            elif op in _REPEATCODES:\n                i, j = av[2].getwidth()\n                lo = lo + i * av[0]\n                hi = hi + j * av[1]\n            elif op in _UNITCODES:\n                lo = lo + 1\n                hi = hi + 1\n            elif op is GROUPREF:\n                i, j = self.state.groupwidths[av]\n                lo = lo + i\n                hi = hi + j\n            elif op is GROUPREF_EXISTS:\n                i, j = av[1].getwidth()\n                if av[2] is not None:\n                    l, h = av[2].getwidth()\n                    i = min(i, l)\n                    j = max(j, h)\n                else:\n                    i = 0\n                lo = lo + i\n                hi = hi + j\n            elif op is SUCCESS:\n                break\n        self.width = min(lo, MAXREPEAT - 1), min(hi, MAXREPEAT)\n        return self.width\n\nclass Tokenizer:\n    def __init__(self, string):\n        self.istext = isinstance(string, str)\n        self.string = string\n        if not self.istext:\n            string = str(string, 'latin1')\n        self.decoded_string = string\n        self.index = 0\n        self.next = None\n        self.__next()\n    def __next(self):\n        index = self.index\n        try:\n            char = self.decoded_string[index]\n        except IndexError:\n            self.next = None\n            return\n        if char == \"\\\\\":\n            index += 1\n            try:\n                char += self.decoded_string[index]\n            except IndexError:\n                raise error(\"bad escape (end of pattern)\",\n                            self.string, len(self.string) - 1) from None\n        self.index = index + 1\n        self.next = char\n    def match(self, char):\n        if char == self.next:\n            self.__next()\n            return True\n        return False\n    def get(self):\n        this = self.next\n        self.__next()\n        return this\n    def getwhile(self, n, charset):\n        result = ''\n        for _ in range(n):\n            c = self.next\n            if c not in charset:\n                break\n            result += c\n            self.__next()\n        return result\n    def getuntil(self, terminator, name):\n        result = ''\n        while True:\n            c = self.next\n            self.__next()\n            if c is None:\n                if not result:\n                    raise self.error(\"missing \" + name)\n                raise self.error(\"missing %s, unterminated name\" % terminator,\n                                 len(result))\n            if c == terminator:\n                if not result:\n                    raise self.error(\"missing \" + name, 1)\n                break\n            result += c\n        return result\n    @property\n    def pos(self):\n        return self.index - len(self.next or '')\n    def tell(self):\n        return self.index - len(self.next or '')\n    def seek(self, index):\n        self.index = index\n        self.__next()\n\n    def error(self, msg, offset=0):\n        return error(msg, self.string, self.tell() - offset)\n\ndef _class_escape(source, escape):\n    # handle escape code inside character class\n    code = ESCAPES.get(escape)\n    if code:\n        return code\n    code = CATEGORIES.get(escape)\n    if code and code[0] is IN:\n        return code\n    try:\n        c = escape[1:2]\n        if c == \"x\":\n            # hexadecimal escape (exactly two digits)\n            escape += source.getwhile(2, HEXDIGITS)\n            if len(escape) != 4:\n                raise source.error(\"incomplete escape %s\" % escape, len(escape))\n            return LITERAL, int(escape[2:], 16)\n        elif c == \"u\" and source.istext:\n            # unicode escape (exactly four digits)\n            escape += source.getwhile(4, HEXDIGITS)\n            if len(escape) != 6:\n                raise source.error(\"incomplete escape %s\" % escape, len(escape))\n            return LITERAL, int(escape[2:], 16)\n        elif c == \"U\" and source.istext:\n            # unicode escape (exactly eight digits)\n            escape += source.getwhile(8, HEXDIGITS)\n            if len(escape) != 10:\n                raise source.error(\"incomplete escape %s\" % escape, len(escape))\n            c = int(escape[2:], 16)\n            chr(c) # raise ValueError for invalid code\n            return LITERAL, c\n        elif c == \"N\" and source.istext:\n            import unicodedata\n            # named unicode escape e.g. \\N{EM DASH}\n            if not source.match('{'):\n                raise source.error(\"missing {\")\n            charname = source.getuntil('}', 'character name')\n            try:\n                c = ord(unicodedata.lookup(charname))\n            except KeyError:\n                raise source.error(\"undefined character name %r\" % charname,\n                                   len(charname) + len(r'\\N{}'))\n            return LITERAL, c\n        elif c in OCTDIGITS:\n            # octal escape (up to three digits)\n            escape += source.getwhile(2, OCTDIGITS)\n            c = int(escape[1:], 8)\n            if c > 0o377:\n                raise source.error('octal escape value %s outside of '\n                                   'range 0-0o377' % escape, len(escape))\n            return LITERAL, c\n        elif c in DIGITS:\n            raise ValueError\n        if len(escape) == 2:\n            if c in ASCIILETTERS:\n                raise source.error('bad escape %s' % escape, len(escape))\n            return LITERAL, ord(escape[1])\n    except ValueError:\n        pass\n    raise source.error(\"bad escape %s\" % escape, len(escape))\n\ndef _escape(source, escape, state):\n    # handle escape code in expression\n    code = CATEGORIES.get(escape)\n    if code:\n        return code\n    code = ESCAPES.get(escape)\n    if code:\n        return code\n    try:\n        c = escape[1:2]\n        if c == \"x\":\n            # hexadecimal escape\n            escape += source.getwhile(2, HEXDIGITS)\n            if len(escape) != 4:\n                raise source.error(\"incomplete escape %s\" % escape, len(escape))\n            return LITERAL, int(escape[2:], 16)\n        elif c == \"u\" and source.istext:\n            # unicode escape (exactly four digits)\n            escape += source.getwhile(4, HEXDIGITS)\n            if len(escape) != 6:\n                raise source.error(\"incomplete escape %s\" % escape, len(escape))\n            return LITERAL, int(escape[2:], 16)\n        elif c == \"U\" and source.istext:\n            # unicode escape (exactly eight digits)\n            escape += source.getwhile(8, HEXDIGITS)\n            if len(escape) != 10:\n                raise source.error(\"incomplete escape %s\" % escape, len(escape))\n            c = int(escape[2:], 16)\n            chr(c) # raise ValueError for invalid code\n            return LITERAL, c\n        elif c == \"N\" and source.istext:\n            import unicodedata\n            # named unicode escape e.g. \\N{EM DASH}\n            if not source.match('{'):\n                raise source.error(\"missing {\")\n            charname = source.getuntil('}', 'character name')\n            try:\n                c = ord(unicodedata.lookup(charname))\n            except KeyError:\n                raise source.error(\"undefined character name %r\" % charname,\n                                   len(charname) + len(r'\\N{}'))\n            return LITERAL, c\n        elif c == \"0\":\n            # octal escape\n            escape += source.getwhile(2, OCTDIGITS)\n            return LITERAL, int(escape[1:], 8)\n        elif c in DIGITS:\n            # octal escape *or* decimal group reference (sigh)\n            if source.next in DIGITS:\n                escape += source.get()\n                if (escape[1] in OCTDIGITS and escape[2] in OCTDIGITS and\n                    source.next in OCTDIGITS):\n                    # got three octal digits; this is an octal escape\n                    escape += source.get()\n                    c = int(escape[1:], 8)\n                    if c > 0o377:\n                        raise source.error('octal escape value %s outside of '\n                                           'range 0-0o377' % escape,\n                                           len(escape))\n                    return LITERAL, c\n            # not an octal escape, so this is a group reference\n            group = int(escape[1:])\n            if group < state.groups:\n                if not state.checkgroup(group):\n                    raise source.error(\"cannot refer to an open group\",\n                                       len(escape))\n                state.checklookbehindgroup(group, source)\n                return GROUPREF, group\n            raise source.error(\"invalid group reference %d\" % group, len(escape) - 1)\n        if len(escape) == 2:\n            if c in ASCIILETTERS:\n                raise source.error(\"bad escape %s\" % escape, len(escape))\n            return LITERAL, ord(escape[1])\n    except ValueError:\n        pass\n    raise source.error(\"bad escape %s\" % escape, len(escape))\n\ndef _uniq(items):\n    return list(dict.fromkeys(items))\n\ndef _parse_sub(source, state, verbose, nested):\n    # parse an alternation: a|b|c\n\n    items = []\n    itemsappend = items.append\n    sourcematch = source.match\n    start = source.tell()\n    while True:\n        itemsappend(_parse(source, state, verbose, nested + 1,\n                           not nested and not items))\n        if not sourcematch(\"|\"):\n            break\n\n    if len(items) == 1:\n        return items[0]\n\n    subpattern = SubPattern(state)\n\n    # check if all items share a common prefix\n    while True:\n        prefix = None\n        for item in items:\n            if not item:\n                break\n            if prefix is None:\n                prefix = item[0]\n            elif item[0] != prefix:\n                break\n        else:\n            # all subitems start with a common \"prefix\".\n            # move it out of the branch\n            for item in items:\n                del item[0]\n            subpattern.append(prefix)\n            continue # check next one\n        break\n\n    # check if the branch can be replaced by a character set\n    set = []\n    for item in items:\n        if len(item) != 1:\n            break\n        op, av = item[0]\n        if op is LITERAL:\n            set.append((op, av))\n        elif op is IN and av[0][0] is not NEGATE:\n            set.extend(av)\n        else:\n            break\n    else:\n        # we can store this as a character set instead of a\n        # branch (the compiler may optimize this even more)\n        subpattern.append((IN, _uniq(set)))\n        return subpattern\n\n    subpattern.append((BRANCH, (None, items)))\n    return subpattern\n\ndef _parse(source, state, verbose, nested, first=False):\n    # parse a simple pattern\n    subpattern = SubPattern(state)\n\n    # precompute constants into local variables\n    subpatternappend = subpattern.append\n    sourceget = source.get\n    sourcematch = source.match\n    _len = len\n    _ord = ord\n\n    while True:\n\n        this = source.next\n        if this is None:\n            break # end of pattern\n        if this in \"|)\":\n            break # end of subpattern\n        sourceget()\n\n        if verbose:\n            # skip whitespace and comments\n            if this in WHITESPACE:\n                continue\n            if this == \"#\":\n                while True:\n                    this = sourceget()\n                    if this is None or this == \"\\n\":\n                        break\n                continue\n\n        if this[0] == \"\\\\\":\n            code = _escape(source, this, state)\n            subpatternappend(code)\n\n        elif this not in SPECIAL_CHARS:\n            subpatternappend((LITERAL, _ord(this)))\n\n        elif this == \"[\":\n            here = source.tell() - 1\n            # character set\n            set = []\n            setappend = set.append\n##          if sourcematch(\":\"):\n##              pass # handle character classes\n            if source.next == '[':\n                import warnings\n                warnings.warn(\n                    'Possible nested set at position %d' % source.tell(),\n                    FutureWarning, stacklevel=nested + 6\n                )\n            negate = sourcematch(\"^\")\n            # check remaining characters\n            while True:\n                this = sourceget()\n                if this is None:\n                    raise source.error(\"unterminated character set\",\n                                       source.tell() - here)\n                if this == \"]\" and set:\n                    break\n                elif this[0] == \"\\\\\":\n                    code1 = _class_escape(source, this)\n                else:\n                    if set and this in '-&~|' and source.next == this:\n                        import warnings\n                        warnings.warn(\n                            'Possible set %s at position %d' % (\n                                'difference' if this == '-' else\n                                'intersection' if this == '&' else\n                                'symmetric difference' if this == '~' else\n                                'union',\n                                source.tell() - 1),\n                            FutureWarning, stacklevel=nested + 6\n                        )\n                    code1 = LITERAL, _ord(this)\n                if sourcematch(\"-\"):\n                    # potential range\n                    that = sourceget()\n                    if that is None:\n                        raise source.error(\"unterminated character set\",\n                                           source.tell() - here)\n                    if that == \"]\":\n                        if code1[0] is IN:\n                            code1 = code1[1][0]\n                        setappend(code1)\n                        setappend((LITERAL, _ord(\"-\")))\n                        break\n                    if that[0] == \"\\\\\":\n                        code2 = _class_escape(source, that)\n                    else:\n                        if that == '-':\n                            import warnings\n                            warnings.warn(\n                                'Possible set difference at position %d' % (\n                                    source.tell() - 2),\n                                FutureWarning, stacklevel=nested + 6\n                            )\n                        code2 = LITERAL, _ord(that)\n                    if code1[0] != LITERAL or code2[0] != LITERAL:\n                        msg = \"bad character range %s-%s\" % (this, that)\n                        raise source.error(msg, len(this) + 1 + len(that))\n                    lo = code1[1]\n                    hi = code2[1]\n                    if hi < lo:\n                        msg = \"bad character range %s-%s\" % (this, that)\n                        raise source.error(msg, len(this) + 1 + len(that))\n                    setappend((RANGE, (lo, hi)))\n                else:\n                    if code1[0] is IN:\n                        code1 = code1[1][0]\n                    setappend(code1)\n\n            set = _uniq(set)\n            # XXX: <fl> should move set optimization to compiler!\n            if _len(set) == 1 and set[0][0] is LITERAL:\n                # optimization\n                if negate:\n                    subpatternappend((NOT_LITERAL, set[0][1]))\n                else:\n                    subpatternappend(set[0])\n            else:\n                if negate:\n                    set.insert(0, (NEGATE, None))\n                # charmap optimization can't be added here because\n                # global flags still are not known\n                subpatternappend((IN, set))\n\n        elif this in REPEAT_CHARS:\n            # repeat previous item\n            here = source.tell()\n            if this == \"?\":\n                min, max = 0, 1\n            elif this == \"*\":\n                min, max = 0, MAXREPEAT\n\n            elif this == \"+\":\n                min, max = 1, MAXREPEAT\n            elif this == \"{\":\n                if source.next == \"}\":\n                    subpatternappend((LITERAL, _ord(this)))\n                    continue\n\n                min, max = 0, MAXREPEAT\n                lo = hi = \"\"\n                while source.next in DIGITS:\n                    lo += sourceget()\n                if sourcematch(\",\"):\n                    while source.next in DIGITS:\n                        hi += sourceget()\n                else:\n                    hi = lo\n                if not sourcematch(\"}\"):\n                    subpatternappend((LITERAL, _ord(this)))\n                    source.seek(here)\n                    continue\n\n                if lo:\n                    min = int(lo)\n                    if min >= MAXREPEAT:\n                        raise OverflowError(\"the repetition number is too large\")\n                if hi:\n                    max = int(hi)\n                    if max >= MAXREPEAT:\n                        raise OverflowError(\"the repetition number is too large\")\n                    if max < min:\n                        raise source.error(\"min repeat greater than max repeat\",\n                                           source.tell() - here)\n            else:\n                raise AssertionError(\"unsupported quantifier %r\" % (char,))\n            # figure out which item to repeat\n            if subpattern:\n                item = subpattern[-1:]\n            else:\n                item = None\n            if not item or item[0][0] is AT:\n                raise source.error(\"nothing to repeat\",\n                                   source.tell() - here + len(this))\n            if item[0][0] in _REPEATCODES:\n                raise source.error(\"multiple repeat\",\n                                   source.tell() - here + len(this))\n            if item[0][0] is SUBPATTERN:\n                group, add_flags, del_flags, p = item[0][1]\n                if group is None and not add_flags and not del_flags:\n                    item = p\n            if sourcematch(\"?\"):\n                subpattern[-1] = (MIN_REPEAT, (min, max, item))\n            else:\n                subpattern[-1] = (MAX_REPEAT, (min, max, item))\n\n        elif this == \".\":\n            subpatternappend((ANY, None))\n\n        elif this == \"(\":\n            start = source.tell() - 1\n            group = True\n            name = None\n            add_flags = 0\n            del_flags = 0\n            if sourcematch(\"?\"):\n                # options\n                char = sourceget()\n                if char is None:\n                    raise source.error(\"unexpected end of pattern\")\n                if char == \"P\":\n                    # python extensions\n                    if sourcematch(\"<\"):\n                        # named group: skip forward to end of name\n                        name = source.getuntil(\">\", \"group name\")\n                        if not name.isidentifier():\n                            msg = \"bad character in group name %r\" % name\n                            raise source.error(msg, len(name) + 1)\n                    elif sourcematch(\"=\"):\n                        # named backreference\n                        name = source.getuntil(\")\", \"group name\")\n                        if not name.isidentifier():\n                            msg = \"bad character in group name %r\" % name\n                            raise source.error(msg, len(name) + 1)\n                        gid = state.groupdict.get(name)\n                        if gid is None:\n                            msg = \"unknown group name %r\" % name\n                            raise source.error(msg, len(name) + 1)\n                        if not state.checkgroup(gid):\n                            raise source.error(\"cannot refer to an open group\",\n                                               len(name) + 1)\n                        state.checklookbehindgroup(gid, source)\n                        subpatternappend((GROUPREF, gid))\n                        continue\n\n                    else:\n                        char = sourceget()\n                        if char is None:\n                            raise source.error(\"unexpected end of pattern\")\n                        raise source.error(\"unknown extension ?P\" + char,\n                                           len(char) + 2)\n                elif char == \":\":\n                    # non-capturing group\n                    group = None\n                elif char == \"#\":\n                    # comment\n                    while True:\n                        if source.next is None:\n                            raise source.error(\"missing ), unterminated comment\",\n                                               source.tell() - start)\n                        if sourceget() == \")\":\n                            break\n                    continue\n\n                elif char in \"=!<\":\n                    # lookahead assertions\n                    dir = 1\n                    if char == \"<\":\n                        char = sourceget()\n                        if char is None:\n                            raise source.error(\"unexpected end of pattern\")\n                        if char not in \"=!\":\n                            raise source.error(\"unknown extension ?<\" + char,\n                                               len(char) + 2)\n                        dir = -1 # lookbehind\n                        lookbehindgroups = state.lookbehindgroups\n                        if lookbehindgroups is None:\n                            state.lookbehindgroups = state.groups\n                    p = _parse_sub(source, state, verbose, nested + 1)\n                    if dir < 0:\n                        if lookbehindgroups is None:\n                            state.lookbehindgroups = None\n                    if not sourcematch(\")\"):\n                        raise source.error(\"missing ), unterminated subpattern\",\n                                           source.tell() - start)\n                    if char == \"=\":\n                        subpatternappend((ASSERT, (dir, p)))\n                    else:\n                        subpatternappend((ASSERT_NOT, (dir, p)))\n                    continue\n\n                elif char == \"(\":\n                    # conditional backreference group\n                    condname = source.getuntil(\")\", \"group name\")\n                    if condname.isidentifier():\n                        condgroup = state.groupdict.get(condname)\n                        if condgroup is None:\n                            msg = \"unknown group name %r\" % condname\n                            raise source.error(msg, len(condname) + 1)\n                    else:\n                        try:\n                            condgroup = int(condname)\n                            if condgroup < 0:\n                                raise ValueError\n                        except ValueError:\n                            msg = \"bad character in group name %r\" % condname\n                            raise source.error(msg, len(condname) + 1) from None\n                        if not condgroup:\n                            raise source.error(\"bad group number\",\n                                               len(condname) + 1)\n                        if condgroup >= MAXGROUPS:\n                            msg = \"invalid group reference %d\" % condgroup\n                            raise source.error(msg, len(condname) + 1)\n                    state.checklookbehindgroup(condgroup, source)\n                    item_yes = _parse(source, state, verbose, nested + 1)\n                    if source.match(\"|\"):\n                        item_no = _parse(source, state, verbose, nested + 1)\n                        if source.next == \"|\":\n                            raise source.error(\"conditional backref with more than two branches\")\n                    else:\n                        item_no = None\n                    if not source.match(\")\"):\n                        raise source.error(\"missing ), unterminated subpattern\",\n                                           source.tell() - start)\n                    subpatternappend((GROUPREF_EXISTS, (condgroup, item_yes, item_no)))\n                    continue\n\n                elif char in FLAGS or char == \"-\":\n                    # flags\n                    flags = _parse_flags(source, state, char)\n                    if flags is None:  # global flags\n                        if not first or subpattern:\n                            import warnings\n                            warnings.warn(\n                                'Flags not at the start of the expression %r%s' % (\n                                    source.string[:20],  # truncate long regexes\n                                    ' (truncated)' if len(source.string) > 20 else '',\n                                ),\n                                DeprecationWarning, stacklevel=nested + 6\n                            )\n                        if (state.flags & SRE_FLAG_VERBOSE) and not verbose:\n                            raise Verbose\n                        continue\n\n                    add_flags, del_flags = flags\n                    group = None\n                else:\n                    raise source.error(\"unknown extension ?\" + char,\n                                       len(char) + 1)\n\n            # parse group contents\n            if group is not None:\n                try:\n                    group = state.opengroup(name)\n                except error as err:\n                    raise source.error(err.msg, len(name) + 1) from None\n            sub_verbose = ((verbose or (add_flags & SRE_FLAG_VERBOSE)) and\n                           not (del_flags & SRE_FLAG_VERBOSE))\n            p = _parse_sub(source, state, sub_verbose, nested + 1)\n            if not source.match(\")\"):\n                raise source.error(\"missing ), unterminated subpattern\",\n                                   source.tell() - start)\n            if group is not None:\n                state.closegroup(group, p)\n            subpatternappend((SUBPATTERN, (group, add_flags, del_flags, p)))\n\n        elif this == \"^\":\n            subpatternappend((AT, AT_BEGINNING))\n\n        elif this == \"$\":\n            subpatternappend((AT, AT_END))\n\n        else:\n            raise AssertionError(\"unsupported special character %r\" % (char,))\n\n    # unpack non-capturing groups\n    for i in range(len(subpattern))[::-1]:\n        op, av = subpattern[i]\n        if op is SUBPATTERN:\n            group, add_flags, del_flags, p = av\n            if group is None and not add_flags and not del_flags:\n                subpattern[i: i+1] = p\n\n    return subpattern\n\ndef _parse_flags(source, state, char):\n    sourceget = source.get\n    add_flags = 0\n    del_flags = 0\n    if char != \"-\":\n        while True:\n            flag = FLAGS[char]\n            if source.istext:\n                if char == 'L':\n                    msg = \"bad inline flags: cannot use 'L' flag with a str pattern\"\n                    raise source.error(msg)\n            else:\n                if char == 'u':\n                    msg = \"bad inline flags: cannot use 'u' flag with a bytes pattern\"\n                    raise source.error(msg)\n            add_flags |= flag\n            if (flag & TYPE_FLAGS) and (add_flags & TYPE_FLAGS) != flag:\n                msg = \"bad inline flags: flags 'a', 'u' and 'L' are incompatible\"\n                raise source.error(msg)\n            char = sourceget()\n            if char is None:\n                raise source.error(\"missing -, : or )\")\n            if char in \")-:\":\n                break\n            if char not in FLAGS:\n                msg = \"unknown flag\" if char.isalpha() else \"missing -, : or )\"\n                raise source.error(msg, len(char))\n    if char == \")\":\n        state.flags |= add_flags\n        return None\n    if add_flags & GLOBAL_FLAGS:\n        raise source.error(\"bad inline flags: cannot turn on global flag\", 1)\n    if char == \"-\":\n        char = sourceget()\n        if char is None:\n            raise source.error(\"missing flag\")\n        if char not in FLAGS:\n            msg = \"unknown flag\" if char.isalpha() else \"missing flag\"\n            raise source.error(msg, len(char))\n        while True:\n            flag = FLAGS[char]\n            if flag & TYPE_FLAGS:\n                msg = \"bad inline flags: cannot turn off flags 'a', 'u' and 'L'\"\n                raise source.error(msg)\n            del_flags |= flag\n            char = sourceget()\n            if char is None:\n                raise source.error(\"missing :\")\n            if char == \":\":\n                break\n            if char not in FLAGS:\n                msg = \"unknown flag\" if char.isalpha() else \"missing :\"\n                raise source.error(msg, len(char))\n    assert char == \":\"\n    if del_flags & GLOBAL_FLAGS:\n        raise source.error(\"bad inline flags: cannot turn off global flag\", 1)\n    if add_flags & del_flags:\n        raise source.error(\"bad inline flags: flag turned on and off\", 1)\n    return add_flags, del_flags\n\ndef fix_flags(src, flags):\n    # Check and fix flags according to the type of pattern (str or bytes)\n    if isinstance(src, str):\n        if flags & SRE_FLAG_LOCALE:\n            raise ValueError(\"cannot use LOCALE flag with a str pattern\")\n        if not flags & SRE_FLAG_ASCII:\n            flags |= SRE_FLAG_UNICODE\n        elif flags & SRE_FLAG_UNICODE:\n            raise ValueError(\"ASCII and UNICODE flags are incompatible\")\n    else:\n        if flags & SRE_FLAG_UNICODE:\n            raise ValueError(\"cannot use UNICODE flag with a bytes pattern\")\n        if flags & SRE_FLAG_LOCALE and flags & SRE_FLAG_ASCII:\n            raise ValueError(\"ASCII and LOCALE flags are incompatible\")\n    return flags\n\ndef parse(str, flags=0, state=None):\n    # parse 're' pattern into list of (opcode, argument) tuples\n\n    source = Tokenizer(str)\n\n    if state is None:\n        state = State()\n    state.flags = flags\n    state.str = str\n\n    try:\n        p = _parse_sub(source, state, flags & SRE_FLAG_VERBOSE, 0)\n    except Verbose:\n        # the VERBOSE flag was switched on inside the pattern.  to be\n        # on the safe side, we'll parse the whole thing again...\n        state = State()\n        state.flags = flags | SRE_FLAG_VERBOSE\n        state.str = str\n        source.seek(0)\n        p = _parse_sub(source, state, True, 0)\n\n    p.state.flags = fix_flags(str, p.state.flags)\n\n    if source.next is not None:\n        assert source.next == \")\"\n        raise source.error(\"unbalanced parenthesis\")\n\n    if flags & SRE_FLAG_DEBUG:\n        p.dump()\n\n    return p\n\ndef parse_template(source, state):\n    # parse 're' replacement string into list of literals and\n    # group references\n    s = Tokenizer(source)\n    sget = s.get\n    groups = []\n    literals = []\n    literal = []\n    lappend = literal.append\n    def addgroup(index, pos):\n        if index > state.groups:\n            raise s.error(\"invalid group reference %d\" % index, pos)\n        if literal:\n            literals.append(''.join(literal))\n            del literal[:]\n        groups.append((len(literals), index))\n        literals.append(None)\n    groupindex = state.groupindex\n    while True:\n        this = sget()\n        if this is None:\n            break # end of replacement string\n        if this[0] == \"\\\\\":\n            # group\n            c = this[1]\n            if c == \"g\":\n                name = \"\"\n                if not s.match(\"<\"):\n                    raise s.error(\"missing <\")\n                name = s.getuntil(\">\", \"group name\")\n                if name.isidentifier():\n                    try:\n                        index = groupindex[name]\n                    except KeyError:\n                        raise IndexError(\"unknown group name %r\" % name)\n                else:\n                    try:\n                        index = int(name)\n                        if index < 0:\n                            raise ValueError\n                    except ValueError:\n                        raise s.error(\"bad character in group name %r\" % name,\n                                      len(name) + 1) from None\n                    if index >= MAXGROUPS:\n                        raise s.error(\"invalid group reference %d\" % index,\n                                      len(name) + 1)\n                addgroup(index, len(name) + 1)\n            elif c == \"0\":\n                if s.next in OCTDIGITS:\n                    this += sget()\n                    if s.next in OCTDIGITS:\n                        this += sget()\n                lappend(chr(int(this[1:], 8) & 0xff))\n            elif c in DIGITS:\n                isoctal = False\n                if s.next in DIGITS:\n                    this += sget()\n                    if (c in OCTDIGITS and this[2] in OCTDIGITS and\n                        s.next in OCTDIGITS):\n                        this += sget()\n                        isoctal = True\n                        c = int(this[1:], 8)\n                        if c > 0o377:\n                            raise s.error('octal escape value %s outside of '\n                                          'range 0-0o377' % this, len(this))\n                        lappend(chr(c))\n                if not isoctal:\n                    addgroup(int(this[1:]), len(this) - 1)\n            else:\n                try:\n                    this = chr(ESCAPES[this][1])\n                except KeyError:\n                    if c in ASCIILETTERS:\n                        raise s.error('bad escape %s' % this, len(this))\n                lappend(this)\n        else:\n            lappend(this)\n    if literal:\n        literals.append(''.join(literal))\n    if not isinstance(source, str):\n        # The tokenizer implicitly decodes bytes objects as latin-1, we must\n        # therefore re-encode the final representation.\n        literals = [None if s is None else s.encode('latin-1') for s in literals]\n    return groups, literals\n\ndef expand_template(template, match):\n    g = match.group\n    empty = match.string[:0]\n    groups, literals = template\n    literals = literals[:]\n    try:\n        for index, group in groups:\n            literals[index] = g(group) or empty\n    except IndexError:\n        raise error(\"invalid group reference %d\" % index)\n    return empty.join(literals)\n", 1064], "/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/enum.py": ["import sys\nfrom types import MappingProxyType, DynamicClassAttribute\n\n\n__all__ = [\n        'EnumMeta',\n        'Enum', 'IntEnum', 'Flag', 'IntFlag',\n        'auto', 'unique',\n        ]\n\n\ndef _is_descriptor(obj):\n    \"\"\"\n    Returns True if obj is a descriptor, False otherwise.\n    \"\"\"\n    return (\n            hasattr(obj, '__get__') or\n            hasattr(obj, '__set__') or\n            hasattr(obj, '__delete__')\n            )\n\ndef _is_dunder(name):\n    \"\"\"\n    Returns True if a __dunder__ name, False otherwise.\n    \"\"\"\n    return (\n            len(name) > 4 and\n            name[:2] == name[-2:] == '__' and\n            name[2] != '_' and\n            name[-3] != '_'\n            )\n\ndef _is_sunder(name):\n    \"\"\"\n    Returns True if a _sunder_ name, False otherwise.\n    \"\"\"\n    return (\n            len(name) > 2 and\n            name[0] == name[-1] == '_' and\n            name[1:2] != '_' and\n            name[-2:-1] != '_'\n            )\n\ndef _is_private(cls_name, name):\n    # do not use `re` as `re` imports `enum`\n    pattern = '_%s__' % (cls_name, )\n    if (\n            len(name) >= 5\n            and name.startswith(pattern)\n            and name[len(pattern)] != '_'\n            and (name[-1] != '_' or name[-2] != '_')\n        ):\n        return True\n    else:\n        return False\n\ndef _make_class_unpicklable(cls):\n    \"\"\"\n    Make the given class un-picklable.\n    \"\"\"\n    def _break_on_call_reduce(self, proto):\n        raise TypeError('%r cannot be pickled' % self)\n    cls.__reduce_ex__ = _break_on_call_reduce\n    cls.__module__ = '<unknown>'\n\n_auto_null = object()\nclass auto:\n    \"\"\"\n    Instances are replaced with an appropriate value in Enum class suites.\n    \"\"\"\n    value = _auto_null\n\n\nclass _EnumDict(dict):\n    \"\"\"\n    Track enum member order and ensure member names are not reused.\n\n    EnumMeta will use the names found in self._member_names as the\n    enumeration member names.\n    \"\"\"\n    def __init__(self):\n        super().__init__()\n        self._member_names = []\n        self._last_values = []\n        self._ignore = []\n        self._auto_called = False\n\n    def __setitem__(self, key, value):\n        \"\"\"\n        Changes anything not dundered or not a descriptor.\n\n        If an enum member name is used twice, an error is raised; duplicate\n        values are not checked for.\n\n        Single underscore (sunder) names are reserved.\n        \"\"\"\n        if _is_private(self._cls_name, key):\n            import warnings\n            warnings.warn(\n                    \"private variables, such as %r, will be normal attributes in 3.10\"\n                        % (key, ),\n                    DeprecationWarning,\n                    stacklevel=2,\n                    )\n        if _is_sunder(key):\n            if key not in (\n                    '_order_', '_create_pseudo_member_',\n                    '_generate_next_value_', '_missing_', '_ignore_',\n                    ):\n                raise ValueError('_names_ are reserved for future Enum use')\n            if key == '_generate_next_value_':\n                # check if members already defined as auto()\n                if self._auto_called:\n                    raise TypeError(\"_generate_next_value_ must be defined before members\")\n                setattr(self, '_generate_next_value', value)\n            elif key == '_ignore_':\n                if isinstance(value, str):\n                    value = value.replace(',',' ').split()\n                else:\n                    value = list(value)\n                self._ignore = value\n                already = set(value) & set(self._member_names)\n                if already:\n                    raise ValueError(\n                            '_ignore_ cannot specify already set names: %r'\n                            % (already, )\n                            )\n        elif _is_dunder(key):\n            if key == '__order__':\n                key = '_order_'\n        elif key in self._member_names:\n            # descriptor overwriting an enum?\n            raise TypeError('Attempted to reuse key: %r' % key)\n        elif key in self._ignore:\n            pass\n        elif not _is_descriptor(value):\n            if key in self:\n                # enum overwriting a descriptor?\n                raise TypeError('%r already defined as: %r' % (key, self[key]))\n            if isinstance(value, auto):\n                if value.value == _auto_null:\n                    value.value = self._generate_next_value(\n                            key,\n                            1,\n                            len(self._member_names),\n                            self._last_values[:],\n                            )\n                    self._auto_called = True\n                value = value.value\n            self._member_names.append(key)\n            self._last_values.append(value)\n        super().__setitem__(key, value)\n\n\n# Dummy value for Enum as EnumMeta explicitly checks for it, but of course\n# until EnumMeta finishes running the first time the Enum class doesn't exist.\n# This is also why there are checks in EnumMeta like `if Enum is not None`\nEnum = None\n\nclass EnumMeta(type):\n    \"\"\"\n    Metaclass for Enum\n    \"\"\"\n    @classmethod\n    def __prepare__(metacls, cls, bases, **kwds):\n        # check that previous enum members do not exist\n        metacls._check_for_existing_members(cls, bases)\n        # create the namespace dict\n        enum_dict = _EnumDict()\n        enum_dict._cls_name = cls\n        # inherit previous flags and _generate_next_value_ function\n        member_type, first_enum = metacls._get_mixins_(cls, bases)\n        if first_enum is not None:\n            enum_dict['_generate_next_value_'] = getattr(\n                    first_enum, '_generate_next_value_', None,\n                    )\n        return enum_dict\n\n    def __new__(metacls, cls, bases, classdict, **kwds):\n        # an Enum class is final once enumeration items have been defined; it\n        # cannot be mixed with other types (int, float, etc.) if it has an\n        # inherited __new__ unless a new __new__ is defined (or the resulting\n        # class will fail).\n        #\n        # remove any keys listed in _ignore_\n        classdict.setdefault('_ignore_', []).append('_ignore_')\n        ignore = classdict['_ignore_']\n        for key in ignore:\n            classdict.pop(key, None)\n        member_type, first_enum = metacls._get_mixins_(cls, bases)\n        __new__, save_new, use_args = metacls._find_new_(\n                classdict, member_type, first_enum,\n                )\n\n        # save enum items into separate mapping so they don't get baked into\n        # the new class\n        enum_members = {k: classdict[k] for k in classdict._member_names}\n        for name in classdict._member_names:\n            del classdict[name]\n\n        # adjust the sunders\n        _order_ = classdict.pop('_order_', None)\n\n        # check for illegal enum names (any others?)\n        invalid_names = set(enum_members) & {'mro', ''}\n        if invalid_names:\n            raise ValueError('Invalid enum member name: {0}'.format(\n                ','.join(invalid_names)))\n\n        # create a default docstring if one has not been provided\n        if '__doc__' not in classdict:\n            classdict['__doc__'] = 'An enumeration.'\n\n        enum_class = super().__new__(metacls, cls, bases, classdict, **kwds)\n        enum_class._member_names_ = []               # names in definition order\n        enum_class._member_map_ = {}                 # name->value map\n        enum_class._member_type_ = member_type\n\n        # save DynamicClassAttribute attributes from super classes so we know\n        # if we can take the shortcut of storing members in the class dict\n        dynamic_attributes = {\n                k for c in enum_class.mro()\n                for k, v in c.__dict__.items()\n                if isinstance(v, DynamicClassAttribute)\n                }\n\n        # Reverse value->name map for hashable values.\n        enum_class._value2member_map_ = {}\n\n        # If a custom type is mixed into the Enum, and it does not know how\n        # to pickle itself, pickle.dumps will succeed but pickle.loads will\n        # fail.  Rather than have the error show up later and possibly far\n        # from the source, sabotage the pickle protocol for this class so\n        # that pickle.dumps also fails.\n        #\n        # However, if the new class implements its own __reduce_ex__, do not\n        # sabotage -- it's on them to make sure it works correctly.  We use\n        # __reduce_ex__ instead of any of the others as it is preferred by\n        # pickle over __reduce__, and it handles all pickle protocols.\n        if '__reduce_ex__' not in classdict:\n            if member_type is not object:\n                methods = ('__getnewargs_ex__', '__getnewargs__',\n                        '__reduce_ex__', '__reduce__')\n                if not any(m in member_type.__dict__ for m in methods):\n                    if '__new__' in classdict:\n                        # too late, sabotage\n                        _make_class_unpicklable(enum_class)\n                    else:\n                        # final attempt to verify that pickling would work:\n                        # travel mro until __new__ is found, checking for\n                        # __reduce__ and friends along the way -- if any of them\n                        # are found before/when __new__ is found, pickling should\n                        # work\n                        sabotage = None\n                        for chain in bases:\n                            for base in chain.__mro__:\n                                if base is object:\n                                    continue\n                                elif any(m in base.__dict__ for m in methods):\n                                    # found one, we're good\n                                    sabotage = False\n                                    break\n                                elif '__new__' in base.__dict__:\n                                    # not good\n                                    sabotage = True\n                                    break\n                            if sabotage is not None:\n                                break\n                        if sabotage:\n                            _make_class_unpicklable(enum_class)\n        # instantiate them, checking for duplicates as we go\n        # we instantiate first instead of checking for duplicates first in case\n        # a custom __new__ is doing something funky with the values -- such as\n        # auto-numbering ;)\n        for member_name in classdict._member_names:\n            value = enum_members[member_name]\n            if not isinstance(value, tuple):\n                args = (value, )\n            else:\n                args = value\n            if member_type is tuple:   # special case for tuple enums\n                args = (args, )     # wrap it one more time\n            if not use_args:\n                enum_member = __new__(enum_class)\n                if not hasattr(enum_member, '_value_'):\n                    enum_member._value_ = value\n            else:\n                enum_member = __new__(enum_class, *args)\n                if not hasattr(enum_member, '_value_'):\n                    if member_type is object:\n                        enum_member._value_ = value\n                    else:\n                        enum_member._value_ = member_type(*args)\n            value = enum_member._value_\n            enum_member._name_ = member_name\n            enum_member.__objclass__ = enum_class\n            enum_member.__init__(*args)\n            # If another member with the same value was already defined, the\n            # new member becomes an alias to the existing one.\n            for name, canonical_member in enum_class._member_map_.items():\n                if canonical_member._value_ == enum_member._value_:\n                    enum_member = canonical_member\n                    break\n            else:\n                # Aliases don't appear in member names (only in __members__).\n                enum_class._member_names_.append(member_name)\n            # performance boost for any member that would not shadow\n            # a DynamicClassAttribute\n            if member_name not in dynamic_attributes:\n                setattr(enum_class, member_name, enum_member)\n            # now add to _member_map_\n            enum_class._member_map_[member_name] = enum_member\n            try:\n                # This may fail if value is not hashable. We can't add the value\n                # to the map, and by-value lookups for this value will be\n                # linear.\n                enum_class._value2member_map_[value] = enum_member\n            except TypeError:\n                pass\n\n        # double check that repr and friends are not the mixin's or various\n        # things break (such as pickle)\n        # however, if the method is defined in the Enum itself, don't replace\n        # it\n        for name in ('__repr__', '__str__', '__format__', '__reduce_ex__'):\n            if name in classdict:\n                continue\n            class_method = getattr(enum_class, name)\n            obj_method = getattr(member_type, name, None)\n            enum_method = getattr(first_enum, name, None)\n            if obj_method is not None and obj_method is class_method:\n                setattr(enum_class, name, enum_method)\n\n        # replace any other __new__ with our own (as long as Enum is not None,\n        # anyway) -- again, this is to support pickle\n        if Enum is not None:\n            # if the user defined their own __new__, save it before it gets\n            # clobbered in case they subclass later\n            if save_new:\n                enum_class.__new_member__ = __new__\n            enum_class.__new__ = Enum.__new__\n\n        # py3 support for definition order (helps keep py2/py3 code in sync)\n        if _order_ is not None:\n            if isinstance(_order_, str):\n                _order_ = _order_.replace(',', ' ').split()\n            if _order_ != enum_class._member_names_:\n                raise TypeError('member order does not match _order_')\n\n        return enum_class\n\n    def __bool__(self):\n        \"\"\"\n        classes/types should always be True.\n        \"\"\"\n        return True\n\n    def __call__(cls, value, names=None, *, module=None, qualname=None, type=None, start=1):\n        \"\"\"\n        Either returns an existing member, or creates a new enum class.\n\n        This method is used both when an enum class is given a value to match\n        to an enumeration member (i.e. Color(3)) and for the functional API\n        (i.e. Color = Enum('Color', names='RED GREEN BLUE')).\n\n        When used for the functional API:\n\n        `value` will be the name of the new class.\n\n        `names` should be either a string of white-space/comma delimited names\n        (values will start at `start`), or an iterator/mapping of name, value pairs.\n\n        `module` should be set to the module this class is being created in;\n        if it is not set, an attempt to find that module will be made, but if\n        it fails the class will not be picklable.\n\n        `qualname` should be set to the actual location this class can be found\n        at in its module; by default it is set to the global scope.  If this is\n        not correct, unpickling will fail in some circumstances.\n\n        `type`, if set, will be mixed in as the first base class.\n        \"\"\"\n        if names is None:  # simple value lookup\n            return cls.__new__(cls, value)\n        # otherwise, functional API: we're creating a new Enum type\n        return cls._create_(\n                value,\n                names,\n                module=module,\n                qualname=qualname,\n                type=type,\n                start=start,\n                )\n\n    def __contains__(cls, member):\n        if not isinstance(member, Enum):\n            raise TypeError(\n                \"unsupported operand type(s) for 'in': '%s' and '%s'\" % (\n                    type(member).__qualname__, cls.__class__.__qualname__))\n        return isinstance(member, cls) and member._name_ in cls._member_map_\n\n    def __delattr__(cls, attr):\n        # nicer error message when someone tries to delete an attribute\n        # (see issue19025).\n        if attr in cls._member_map_:\n            raise AttributeError(\"%s: cannot delete Enum member.\" % cls.__name__)\n        super().__delattr__(attr)\n\n    def __dir__(self):\n        return (\n                ['__class__', '__doc__', '__members__', '__module__']\n                + self._member_names_\n                )\n\n    def __getattr__(cls, name):\n        \"\"\"\n        Return the enum member matching `name`\n\n        We use __getattr__ instead of descriptors or inserting into the enum\n        class' __dict__ in order to support `name` and `value` being both\n        properties for enum members (which live in the class' __dict__) and\n        enum members themselves.\n        \"\"\"\n        if _is_dunder(name):\n            raise AttributeError(name)\n        try:\n            return cls._member_map_[name]\n        except KeyError:\n            raise AttributeError(name) from None\n\n    def __getitem__(cls, name):\n        return cls._member_map_[name]\n\n    def __iter__(cls):\n        \"\"\"\n        Returns members in definition order.\n        \"\"\"\n        return (cls._member_map_[name] for name in cls._member_names_)\n\n    def __len__(cls):\n        return len(cls._member_names_)\n\n    @property\n    def __members__(cls):\n        \"\"\"\n        Returns a mapping of member name->value.\n\n        This mapping lists all enum members, including aliases. Note that this\n        is a read-only view of the internal mapping.\n        \"\"\"\n        return MappingProxyType(cls._member_map_)\n\n    def __repr__(cls):\n        return \"<enum %r>\" % cls.__name__\n\n    def __reversed__(cls):\n        \"\"\"\n        Returns members in reverse definition order.\n        \"\"\"\n        return (cls._member_map_[name] for name in reversed(cls._member_names_))\n\n    def __setattr__(cls, name, value):\n        \"\"\"\n        Block attempts to reassign Enum members.\n\n        A simple assignment to the class namespace only changes one of the\n        several possible ways to get an Enum member from the Enum class,\n        resulting in an inconsistent Enumeration.\n        \"\"\"\n        member_map = cls.__dict__.get('_member_map_', {})\n        if name in member_map:\n            raise AttributeError('Cannot reassign members.')\n        super().__setattr__(name, value)\n\n    def _create_(cls, class_name, names, *, module=None, qualname=None, type=None, start=1):\n        \"\"\"\n        Convenience method to create a new Enum class.\n\n        `names` can be:\n\n        * A string containing member names, separated either with spaces or\n          commas.  Values are incremented by 1 from `start`.\n        * An iterable of member names.  Values are incremented by 1 from `start`.\n        * An iterable of (member name, value) pairs.\n        * A mapping of member name -> value pairs.\n        \"\"\"\n        metacls = cls.__class__\n        bases = (cls, ) if type is None else (type, cls)\n        _, first_enum = cls._get_mixins_(cls, bases)\n        classdict = metacls.__prepare__(class_name, bases)\n\n        # special processing needed for names?\n        if isinstance(names, str):\n            names = names.replace(',', ' ').split()\n        if isinstance(names, (tuple, list)) and names and isinstance(names[0], str):\n            original_names, names = names, []\n            last_values = []\n            for count, name in enumerate(original_names):\n                value = first_enum._generate_next_value_(name, start, count, last_values[:])\n                last_values.append(value)\n                names.append((name, value))\n\n        # Here, names is either an iterable of (name, value) or a mapping.\n        for item in names:\n            if isinstance(item, str):\n                member_name, member_value = item, names[item]\n            else:\n                member_name, member_value = item\n            classdict[member_name] = member_value\n        enum_class = metacls.__new__(metacls, class_name, bases, classdict)\n\n        # TODO: replace the frame hack if a blessed way to know the calling\n        # module is ever developed\n        if module is None:\n            try:\n                module = sys._getframe(2).f_globals['__name__']\n            except (AttributeError, ValueError, KeyError):\n                pass\n        if module is None:\n            _make_class_unpicklable(enum_class)\n        else:\n            enum_class.__module__ = module\n        if qualname is not None:\n            enum_class.__qualname__ = qualname\n\n        return enum_class\n\n    def _convert_(cls, name, module, filter, source=None):\n        \"\"\"\n        Create a new Enum subclass that replaces a collection of global constants\n        \"\"\"\n        # convert all constants from source (or module) that pass filter() to\n        # a new Enum called name, and export the enum and its members back to\n        # module;\n        # also, replace the __reduce_ex__ method so unpickling works in\n        # previous Python versions\n        module_globals = vars(sys.modules[module])\n        if source:\n            source = vars(source)\n        else:\n            source = module_globals\n        # _value2member_map_ is populated in the same order every time\n        # for a consistent reverse mapping of number to name when there\n        # are multiple names for the same number.\n        members = [\n                (name, value)\n                for name, value in source.items()\n                if filter(name)]\n        try:\n            # sort by value\n            members.sort(key=lambda t: (t[1], t[0]))\n        except TypeError:\n            # unless some values aren't comparable, in which case sort by name\n            members.sort(key=lambda t: t[0])\n        cls = cls(name, members, module=module)\n        cls.__reduce_ex__ = _reduce_ex_by_name\n        module_globals.update(cls.__members__)\n        module_globals[name] = cls\n        return cls\n\n    @staticmethod\n    def _check_for_existing_members(class_name, bases):\n        for chain in bases:\n            for base in chain.__mro__:\n                if issubclass(base, Enum) and base._member_names_:\n                    raise TypeError(\n                            \"%s: cannot extend enumeration %r\"\n                            % (class_name, base.__name__)\n                            )\n\n    @staticmethod\n    def _get_mixins_(class_name, bases):\n        \"\"\"\n        Returns the type for creating enum members, and the first inherited\n        enum class.\n\n        bases: the tuple of bases that was given to __new__\n        \"\"\"\n        if not bases:\n            return object, Enum\n\n        def _find_data_type(bases):\n            data_types = set()\n            for chain in bases:\n                candidate = None\n                for base in chain.__mro__:\n                    if base is object:\n                        continue\n                    elif issubclass(base, Enum):\n                        if base._member_type_ is not object:\n                            data_types.add(base._member_type_)\n                            break\n                    elif '__new__' in base.__dict__:\n                        if issubclass(base, Enum):\n                            continue\n                        data_types.add(candidate or base)\n                        break\n                    else:\n                        candidate = candidate or base\n            if len(data_types) > 1:\n                raise TypeError('%r: too many data types: %r' % (class_name, data_types))\n            elif data_types:\n                return data_types.pop()\n            else:\n                return None\n\n        # ensure final parent class is an Enum derivative, find any concrete\n        # data type, and check that Enum has no members\n        first_enum = bases[-1]\n        if not issubclass(first_enum, Enum):\n            raise TypeError(\"new enumerations should be created as \"\n                    \"`EnumName([mixin_type, ...] [data_type,] enum_type)`\")\n        member_type = _find_data_type(bases) or object\n        if first_enum._member_names_:\n            raise TypeError(\"Cannot extend enumerations\")\n        return member_type, first_enum\n\n    @staticmethod\n    def _find_new_(classdict, member_type, first_enum):\n        \"\"\"\n        Returns the __new__ to be used for creating the enum members.\n\n        classdict: the class dictionary given to __new__\n        member_type: the data type whose __new__ will be used by default\n        first_enum: enumeration to check for an overriding __new__\n        \"\"\"\n        # now find the correct __new__, checking to see of one was defined\n        # by the user; also check earlier enum classes in case a __new__ was\n        # saved as __new_member__\n        __new__ = classdict.get('__new__', None)\n\n        # should __new__ be saved as __new_member__ later?\n        save_new = __new__ is not None\n\n        if __new__ is None:\n            # check all possibles for __new_member__ before falling back to\n            # __new__\n            for method in ('__new_member__', '__new__'):\n                for possible in (member_type, first_enum):\n                    target = getattr(possible, method, None)\n                    if target not in {\n                            None,\n                            None.__new__,\n                            object.__new__,\n                            Enum.__new__,\n                            }:\n                        __new__ = target\n                        break\n                if __new__ is not None:\n                    break\n            else:\n                __new__ = object.__new__\n\n        # if a non-object.__new__ is used then whatever value/tuple was\n        # assigned to the enum member name will be passed to __new__ and to the\n        # new enum member's __init__\n        if __new__ is object.__new__:\n            use_args = False\n        else:\n            use_args = True\n        return __new__, save_new, use_args\n\n\nclass Enum(metaclass=EnumMeta):\n    \"\"\"\n    Generic enumeration.\n\n    Derive from this class to define new enumerations.\n    \"\"\"\n    def __new__(cls, value):\n        # all enum instances are actually created during class construction\n        # without calling this method; this method is called by the metaclass'\n        # __call__ (i.e. Color(3) ), and by pickle\n        if type(value) is cls:\n            # For lookups like Color(Color.RED)\n            return value\n        # by-value search for a matching enum member\n        # see if it's in the reverse mapping (for hashable values)\n        try:\n            return cls._value2member_map_[value]\n        except KeyError:\n            # Not found, no need to do long O(n) search\n            pass\n        except TypeError:\n            # not there, now do long search -- O(n) behavior\n            for member in cls._member_map_.values():\n                if member._value_ == value:\n                    return member\n        # still not found -- try _missing_ hook\n        try:\n            exc = None\n            result = cls._missing_(value)\n        except Exception as e:\n            exc = e\n            result = None\n        try:\n            if isinstance(result, cls):\n                return result\n            else:\n                ve_exc = ValueError(\"%r is not a valid %s\" % (value, cls.__qualname__))\n                if result is None and exc is None:\n                    raise ve_exc\n                elif exc is None:\n                    exc = TypeError(\n                            'error in %s._missing_: returned %r instead of None or a valid member'\n                            % (cls.__name__, result)\n                            )\n                exc.__context__ = ve_exc\n                raise exc\n        finally:\n            # ensure all variables that could hold an exception are destroyed\n            exc = None\n            ve_exc = None\n\n    def _generate_next_value_(name, start, count, last_values):\n        \"\"\"\n        Generate the next value when not given.\n\n        name: the name of the member\n        start: the initial start value or None\n        count: the number of existing members\n        last_value: the last value assigned or None\n        \"\"\"\n        for last_value in reversed(last_values):\n            try:\n                return last_value + 1\n            except TypeError:\n                pass\n        else:\n            return start\n\n    @classmethod\n    def _missing_(cls, value):\n        return None\n\n    def __repr__(self):\n        return \"<%s.%s: %r>\" % (\n                self.__class__.__name__, self._name_, self._value_)\n\n    def __str__(self):\n        return \"%s.%s\" % (self.__class__.__name__, self._name_)\n\n    def __dir__(self):\n        \"\"\"\n        Returns all members and all public methods\n        \"\"\"\n        added_behavior = [\n                m\n                for cls in self.__class__.mro()\n                for m in cls.__dict__\n                if m[0] != '_' and m not in self._member_map_\n                ] + [m for m in self.__dict__ if m[0] != '_']\n        return (['__class__', '__doc__', '__module__'] + added_behavior)\n\n    def __format__(self, format_spec):\n        \"\"\"\n        Returns format using actual value type unless __str__ has been overridden.\n        \"\"\"\n        # mixed-in Enums should use the mixed-in type's __format__, otherwise\n        # we can get strange results with the Enum name showing up instead of\n        # the value\n\n        # pure Enum branch, or branch with __str__ explicitly overridden\n        str_overridden = type(self).__str__ not in (Enum.__str__, Flag.__str__)\n        if self._member_type_ is object or str_overridden:\n            cls = str\n            val = str(self)\n        # mix-in branch\n        else:\n            cls = self._member_type_\n            val = self._value_\n        return cls.__format__(val, format_spec)\n\n    def __hash__(self):\n        return hash(self._name_)\n\n    def __reduce_ex__(self, proto):\n        return self.__class__, (self._value_, )\n\n    # DynamicClassAttribute is used to provide access to the `name` and\n    # `value` properties of enum members while keeping some measure of\n    # protection from modification, while still allowing for an enumeration\n    # to have members named `name` and `value`.  This works because enumeration\n    # members are not set directly on the enum class -- __getattr__ is\n    # used to look them up.\n\n    @DynamicClassAttribute\n    def name(self):\n        \"\"\"The name of the Enum member.\"\"\"\n        return self._name_\n\n    @DynamicClassAttribute\n    def value(self):\n        \"\"\"The value of the Enum member.\"\"\"\n        return self._value_\n\n\nclass IntEnum(int, Enum):\n    \"\"\"Enum where members are also (and must be) ints\"\"\"\n\n\ndef _reduce_ex_by_name(self, proto):\n    return self.name\n\nclass Flag(Enum):\n    \"\"\"\n    Support for flags\n    \"\"\"\n\n    def _generate_next_value_(name, start, count, last_values):\n        \"\"\"\n        Generate the next value when not given.\n\n        name: the name of the member\n        start: the initial start value or None\n        count: the number of existing members\n        last_value: the last value assigned or None\n        \"\"\"\n        if not count:\n            return start if start is not None else 1\n        for last_value in reversed(last_values):\n            try:\n                high_bit = _high_bit(last_value)\n                break\n            except Exception:\n                raise TypeError('Invalid Flag value: %r' % last_value) from None\n        return 2 ** (high_bit+1)\n\n    @classmethod\n    def _missing_(cls, value):\n        \"\"\"\n        Returns member (possibly creating it) if one can be found for value.\n        \"\"\"\n        original_value = value\n        if value < 0:\n            value = ~value\n        possible_member = cls._create_pseudo_member_(value)\n        if original_value < 0:\n            possible_member = ~possible_member\n        return possible_member\n\n    @classmethod\n    def _create_pseudo_member_(cls, value):\n        \"\"\"\n        Create a composite member iff value contains only members.\n        \"\"\"\n        pseudo_member = cls._value2member_map_.get(value, None)\n        if pseudo_member is None:\n            # verify all bits are accounted for\n            _, extra_flags = _decompose(cls, value)\n            if extra_flags:\n                raise ValueError(\"%r is not a valid %s\" % (value, cls.__qualname__))\n            # construct a singleton enum pseudo-member\n            pseudo_member = object.__new__(cls)\n            pseudo_member._name_ = None\n            pseudo_member._value_ = value\n            # use setdefault in case another thread already created a composite\n            # with this value\n            pseudo_member = cls._value2member_map_.setdefault(value, pseudo_member)\n        return pseudo_member\n\n    def __contains__(self, other):\n        \"\"\"\n        Returns True if self has at least the same flags set as other.\n        \"\"\"\n        if not isinstance(other, self.__class__):\n            raise TypeError(\n                \"unsupported operand type(s) for 'in': '%s' and '%s'\" % (\n                    type(other).__qualname__, self.__class__.__qualname__))\n        return other._value_ & self._value_ == other._value_\n\n    def __repr__(self):\n        cls = self.__class__\n        if self._name_ is not None:\n            return '<%s.%s: %r>' % (cls.__name__, self._name_, self._value_)\n        members, uncovered = _decompose(cls, self._value_)\n        return '<%s.%s: %r>' % (\n                cls.__name__,\n                '|'.join([str(m._name_ or m._value_) for m in members]),\n                self._value_,\n                )\n\n    def __str__(self):\n        cls = self.__class__\n        if self._name_ is not None:\n            return '%s.%s' % (cls.__name__, self._name_)\n        members, uncovered = _decompose(cls, self._value_)\n        if len(members) == 1 and members[0]._name_ is None:\n            return '%s.%r' % (cls.__name__, members[0]._value_)\n        else:\n            return '%s.%s' % (\n                    cls.__name__,\n                    '|'.join([str(m._name_ or m._value_) for m in members]),\n                    )\n\n    def __bool__(self):\n        return bool(self._value_)\n\n    def __or__(self, other):\n        if not isinstance(other, self.__class__):\n            return NotImplemented\n        return self.__class__(self._value_ | other._value_)\n\n    def __and__(self, other):\n        if not isinstance(other, self.__class__):\n            return NotImplemented\n        return self.__class__(self._value_ & other._value_)\n\n    def __xor__(self, other):\n        if not isinstance(other, self.__class__):\n            return NotImplemented\n        return self.__class__(self._value_ ^ other._value_)\n\n    def __invert__(self):\n        members, uncovered = _decompose(self.__class__, self._value_)\n        inverted = self.__class__(0)\n        for m in self.__class__:\n            if m not in members and not (m._value_ & self._value_):\n                inverted = inverted | m\n        return self.__class__(inverted)\n\n\nclass IntFlag(int, Flag):\n    \"\"\"\n    Support for integer-based Flags\n    \"\"\"\n\n    @classmethod\n    def _missing_(cls, value):\n        \"\"\"\n        Returns member (possibly creating it) if one can be found for value.\n        \"\"\"\n        if not isinstance(value, int):\n            raise ValueError(\"%r is not a valid %s\" % (value, cls.__qualname__))\n        new_member = cls._create_pseudo_member_(value)\n        return new_member\n\n    @classmethod\n    def _create_pseudo_member_(cls, value):\n        \"\"\"\n        Create a composite member iff value contains only members.\n        \"\"\"\n        pseudo_member = cls._value2member_map_.get(value, None)\n        if pseudo_member is None:\n            need_to_create = [value]\n            # get unaccounted for bits\n            _, extra_flags = _decompose(cls, value)\n            # timer = 10\n            while extra_flags:\n                # timer -= 1\n                bit = _high_bit(extra_flags)\n                flag_value = 2 ** bit\n                if (flag_value not in cls._value2member_map_ and\n                        flag_value not in need_to_create\n                        ):\n                    need_to_create.append(flag_value)\n                if extra_flags == -flag_value:\n                    extra_flags = 0\n                else:\n                    extra_flags ^= flag_value\n            for value in reversed(need_to_create):\n                # construct singleton pseudo-members\n                pseudo_member = int.__new__(cls, value)\n                pseudo_member._name_ = None\n                pseudo_member._value_ = value\n                # use setdefault in case another thread already created a composite\n                # with this value\n                pseudo_member = cls._value2member_map_.setdefault(value, pseudo_member)\n        return pseudo_member\n\n    def __or__(self, other):\n        if not isinstance(other, (self.__class__, int)):\n            return NotImplemented\n        result = self.__class__(self._value_ | self.__class__(other)._value_)\n        return result\n\n    def __and__(self, other):\n        if not isinstance(other, (self.__class__, int)):\n            return NotImplemented\n        return self.__class__(self._value_ & self.__class__(other)._value_)\n\n    def __xor__(self, other):\n        if not isinstance(other, (self.__class__, int)):\n            return NotImplemented\n        return self.__class__(self._value_ ^ self.__class__(other)._value_)\n\n    __ror__ = __or__\n    __rand__ = __and__\n    __rxor__ = __xor__\n\n    def __invert__(self):\n        result = self.__class__(~self._value_)\n        return result\n\n\ndef _high_bit(value):\n    \"\"\"\n    returns index of highest bit, or -1 if value is zero or negative\n    \"\"\"\n    return value.bit_length() - 1\n\ndef unique(enumeration):\n    \"\"\"\n    Class decorator for enumerations ensuring unique member values.\n    \"\"\"\n    duplicates = []\n    for name, member in enumeration.__members__.items():\n        if name != member.name:\n            duplicates.append((name, member.name))\n    if duplicates:\n        alias_details = ', '.join(\n                [\"%s -> %s\" % (alias, name) for (alias, name) in duplicates])\n        raise ValueError('duplicate values found in %r: %s' %\n                (enumeration, alias_details))\n    return enumeration\n\ndef _decompose(flag, value):\n    \"\"\"\n    Extract all members from the value.\n    \"\"\"\n    # _decompose is only called if the value is not named\n    not_covered = value\n    negative = value < 0\n    members = []\n    for member in flag:\n        member_value = member.value\n        if member_value and member_value & value == member_value:\n            members.append(member)\n            not_covered &= ~member_value\n    if not negative:\n        tmp = not_covered\n        while tmp:\n            flag_value = 2 ** _high_bit(tmp)\n            if flag_value in flag._value2member_map_:\n                members.append(flag._value2member_map_[flag_value])\n                not_covered &= ~flag_value\n            tmp &= ~flag_value\n    if not members and value in flag._value2member_map_:\n        members.append(flag._value2member_map_[value])\n    members.sort(key=lambda m: m._value_, reverse=True)\n    if len(members) > 1 and members[0].value == value:\n        # we have the breakdown, don't need the value member itself\n        members.pop(0)\n    return members, not_covered\n", 1044], "/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/re.py": ["#\n# Secret Labs' Regular Expression Engine\n#\n# re-compatible interface for the sre matching engine\n#\n# Copyright (c) 1998-2001 by Secret Labs AB.  All rights reserved.\n#\n# This version of the SRE library can be redistributed under CNRI's\n# Python 1.6 license.  For any other use, please contact Secret Labs\n# AB (info@pythonware.com).\n#\n# Portions of this engine have been developed in cooperation with\n# CNRI.  Hewlett-Packard provided funding for 1.6 integration and\n# other compatibility work.\n#\n\nr\"\"\"Support for regular expressions (RE).\n\nThis module provides regular expression matching operations similar to\nthose found in Perl.  It supports both 8-bit and Unicode strings; both\nthe pattern and the strings being processed can contain null bytes and\ncharacters outside the US ASCII range.\n\nRegular expressions can contain both special and ordinary characters.\nMost ordinary characters, like \"A\", \"a\", or \"0\", are the simplest\nregular expressions; they simply match themselves.  You can\nconcatenate ordinary characters, so last matches the string 'last'.\n\nThe special characters are:\n    \".\"      Matches any character except a newline.\n    \"^\"      Matches the start of the string.\n    \"$\"      Matches the end of the string or just before the newline at\n             the end of the string.\n    \"*\"      Matches 0 or more (greedy) repetitions of the preceding RE.\n             Greedy means that it will match as many repetitions as possible.\n    \"+\"      Matches 1 or more (greedy) repetitions of the preceding RE.\n    \"?\"      Matches 0 or 1 (greedy) of the preceding RE.\n    *?,+?,?? Non-greedy versions of the previous three special characters.\n    {m,n}    Matches from m to n repetitions of the preceding RE.\n    {m,n}?   Non-greedy version of the above.\n    \"\\\\\"     Either escapes special characters or signals a special sequence.\n    []       Indicates a set of characters.\n             A \"^\" as the first character indicates a complementing set.\n    \"|\"      A|B, creates an RE that will match either A or B.\n    (...)    Matches the RE inside the parentheses.\n             The contents can be retrieved or matched later in the string.\n    (?aiLmsux) The letters set the corresponding flags defined below.\n    (?:...)  Non-grouping version of regular parentheses.\n    (?P<name>...) The substring matched by the group is accessible by name.\n    (?P=name)     Matches the text matched earlier by the group named name.\n    (?#...)  A comment; ignored.\n    (?=...)  Matches if ... matches next, but doesn't consume the string.\n    (?!...)  Matches if ... doesn't match next.\n    (?<=...) Matches if preceded by ... (must be fixed length).\n    (?<!...) Matches if not preceded by ... (must be fixed length).\n    (?(id/name)yes|no) Matches yes pattern if the group with id/name matched,\n                       the (optional) no pattern otherwise.\n\nThe special sequences consist of \"\\\\\" and a character from the list\nbelow.  If the ordinary character is not on the list, then the\nresulting RE will match the second character.\n    \\number  Matches the contents of the group of the same number.\n    \\A       Matches only at the start of the string.\n    \\Z       Matches only at the end of the string.\n    \\b       Matches the empty string, but only at the start or end of a word.\n    \\B       Matches the empty string, but not at the start or end of a word.\n    \\d       Matches any decimal digit; equivalent to the set [0-9] in\n             bytes patterns or string patterns with the ASCII flag.\n             In string patterns without the ASCII flag, it will match the whole\n             range of Unicode digits.\n    \\D       Matches any non-digit character; equivalent to [^\\d].\n    \\s       Matches any whitespace character; equivalent to [ \\t\\n\\r\\f\\v] in\n             bytes patterns or string patterns with the ASCII flag.\n             In string patterns without the ASCII flag, it will match the whole\n             range of Unicode whitespace characters.\n    \\S       Matches any non-whitespace character; equivalent to [^\\s].\n    \\w       Matches any alphanumeric character; equivalent to [a-zA-Z0-9_]\n             in bytes patterns or string patterns with the ASCII flag.\n             In string patterns without the ASCII flag, it will match the\n             range of Unicode alphanumeric characters (letters plus digits\n             plus underscore).\n             With LOCALE, it will match the set [0-9_] plus characters defined\n             as letters for the current locale.\n    \\W       Matches the complement of \\w.\n    \\\\       Matches a literal backslash.\n\nThis module exports the following functions:\n    match     Match a regular expression pattern to the beginning of a string.\n    fullmatch Match a regular expression pattern to all of a string.\n    search    Search a string for the presence of a pattern.\n    sub       Substitute occurrences of a pattern found in a string.\n    subn      Same as sub, but also return the number of substitutions made.\n    split     Split a string by the occurrences of a pattern.\n    findall   Find all occurrences of a pattern in a string.\n    finditer  Return an iterator yielding a Match object for each match.\n    compile   Compile a pattern into a Pattern object.\n    purge     Clear the regular expression cache.\n    escape    Backslash all non-alphanumerics in a string.\n\nEach function other than purge and escape can take an optional 'flags' argument\nconsisting of one or more of the following module constants, joined by \"|\".\nA, L, and U are mutually exclusive.\n    A  ASCII       For string patterns, make \\w, \\W, \\b, \\B, \\d, \\D\n                   match the corresponding ASCII character categories\n                   (rather than the whole Unicode categories, which is the\n                   default).\n                   For bytes patterns, this flag is the only available\n                   behaviour and needn't be specified.\n    I  IGNORECASE  Perform case-insensitive matching.\n    L  LOCALE      Make \\w, \\W, \\b, \\B, dependent on the current locale.\n    M  MULTILINE   \"^\" matches the beginning of lines (after a newline)\n                   as well as the string.\n                   \"$\" matches the end of lines (before a newline) as well\n                   as the end of the string.\n    S  DOTALL      \".\" matches any character at all, including the newline.\n    X  VERBOSE     Ignore whitespace and comments for nicer looking RE's.\n    U  UNICODE     For compatibility only. Ignored for string patterns (it\n                   is the default), and forbidden for bytes patterns.\n\nThis module also defines an exception 'error'.\n\n\"\"\"\n\nimport enum\nimport sre_compile\nimport sre_parse\nimport functools\ntry:\n    import _locale\nexcept ImportError:\n    _locale = None\n\n\n# public symbols\n__all__ = [\n    \"match\", \"fullmatch\", \"search\", \"sub\", \"subn\", \"split\",\n    \"findall\", \"finditer\", \"compile\", \"purge\", \"template\", \"escape\",\n    \"error\", \"Pattern\", \"Match\", \"A\", \"I\", \"L\", \"M\", \"S\", \"X\", \"U\",\n    \"ASCII\", \"IGNORECASE\", \"LOCALE\", \"MULTILINE\", \"DOTALL\", \"VERBOSE\",\n    \"UNICODE\",\n]\n\n__version__ = \"2.2.1\"\n\nclass RegexFlag(enum.IntFlag):\n    ASCII = A = sre_compile.SRE_FLAG_ASCII # assume ascii \"locale\"\n    IGNORECASE = I = sre_compile.SRE_FLAG_IGNORECASE # ignore case\n    LOCALE = L = sre_compile.SRE_FLAG_LOCALE # assume current 8-bit locale\n    UNICODE = U = sre_compile.SRE_FLAG_UNICODE # assume unicode \"locale\"\n    MULTILINE = M = sre_compile.SRE_FLAG_MULTILINE # make anchors look for newline\n    DOTALL = S = sre_compile.SRE_FLAG_DOTALL # make dot match newline\n    VERBOSE = X = sre_compile.SRE_FLAG_VERBOSE # ignore whitespace and comments\n    # sre extensions (experimental, don't rely on these)\n    TEMPLATE = T = sre_compile.SRE_FLAG_TEMPLATE # disable backtracking\n    DEBUG = sre_compile.SRE_FLAG_DEBUG # dump pattern after compilation\n\n    def __repr__(self):\n        if self._name_ is not None:\n            return f're.{self._name_}'\n        value = self._value_\n        members = []\n        negative = value < 0\n        if negative:\n            value = ~value\n        for m in self.__class__:\n            if value & m._value_:\n                value &= ~m._value_\n                members.append(f're.{m._name_}')\n        if value:\n            members.append(hex(value))\n        res = '|'.join(members)\n        if negative:\n            if len(members) > 1:\n                res = f'~({res})'\n            else:\n                res = f'~{res}'\n        return res\n    __str__ = object.__str__\n\nglobals().update(RegexFlag.__members__)\n\n# sre exception\nerror = sre_compile.error\n\n# --------------------------------------------------------------------\n# public interface\n\ndef match(pattern, string, flags=0):\n    \"\"\"Try to apply the pattern at the start of the string, returning\n    a Match object, or None if no match was found.\"\"\"\n    return _compile(pattern, flags).match(string)\n\ndef fullmatch(pattern, string, flags=0):\n    \"\"\"Try to apply the pattern to all of the string, returning\n    a Match object, or None if no match was found.\"\"\"\n    return _compile(pattern, flags).fullmatch(string)\n\ndef search(pattern, string, flags=0):\n    \"\"\"Scan through string looking for a match to the pattern, returning\n    a Match object, or None if no match was found.\"\"\"\n    return _compile(pattern, flags).search(string)\n\ndef sub(pattern, repl, string, count=0, flags=0):\n    \"\"\"Return the string obtained by replacing the leftmost\n    non-overlapping occurrences of the pattern in string by the\n    replacement repl.  repl can be either a string or a callable;\n    if a string, backslash escapes in it are processed.  If it is\n    a callable, it's passed the Match object and must return\n    a replacement string to be used.\"\"\"\n    return _compile(pattern, flags).sub(repl, string, count)\n\ndef subn(pattern, repl, string, count=0, flags=0):\n    \"\"\"Return a 2-tuple containing (new_string, number).\n    new_string is the string obtained by replacing the leftmost\n    non-overlapping occurrences of the pattern in the source\n    string by the replacement repl.  number is the number of\n    substitutions that were made. repl can be either a string or a\n    callable; if a string, backslash escapes in it are processed.\n    If it is a callable, it's passed the Match object and must\n    return a replacement string to be used.\"\"\"\n    return _compile(pattern, flags).subn(repl, string, count)\n\ndef split(pattern, string, maxsplit=0, flags=0):\n    \"\"\"Split the source string by the occurrences of the pattern,\n    returning a list containing the resulting substrings.  If\n    capturing parentheses are used in pattern, then the text of all\n    groups in the pattern are also returned as part of the resulting\n    list.  If maxsplit is nonzero, at most maxsplit splits occur,\n    and the remainder of the string is returned as the final element\n    of the list.\"\"\"\n    return _compile(pattern, flags).split(string, maxsplit)\n\ndef findall(pattern, string, flags=0):\n    \"\"\"Return a list of all non-overlapping matches in the string.\n\n    If one or more capturing groups are present in the pattern, return\n    a list of groups; this will be a list of tuples if the pattern\n    has more than one group.\n\n    Empty matches are included in the result.\"\"\"\n    return _compile(pattern, flags).findall(string)\n\ndef finditer(pattern, string, flags=0):\n    \"\"\"Return an iterator over all non-overlapping matches in the\n    string.  For each match, the iterator returns a Match object.\n\n    Empty matches are included in the result.\"\"\"\n    return _compile(pattern, flags).finditer(string)\n\ndef compile(pattern, flags=0):\n    \"Compile a regular expression pattern, returning a Pattern object.\"\n    return _compile(pattern, flags)\n\ndef purge():\n    \"Clear the regular expression caches\"\n    _cache.clear()\n    _compile_repl.cache_clear()\n\ndef template(pattern, flags=0):\n    \"Compile a template pattern, returning a Pattern object\"\n    return _compile(pattern, flags|T)\n\n# SPECIAL_CHARS\n# closing ')', '}' and ']'\n# '-' (a range in character set)\n# '&', '~', (extended character set operations)\n# '#' (comment) and WHITESPACE (ignored) in verbose mode\n_special_chars_map = {i: '\\\\' + chr(i) for i in b'()[]{}?*+-|^$\\\\.&~# \\t\\n\\r\\v\\f'}\n\ndef escape(pattern):\n    \"\"\"\n    Escape special characters in a string.\n    \"\"\"\n    if isinstance(pattern, str):\n        return pattern.translate(_special_chars_map)\n    else:\n        pattern = str(pattern, 'latin1')\n        return pattern.translate(_special_chars_map).encode('latin1')\n\nPattern = type(sre_compile.compile('', 0))\nMatch = type(sre_compile.compile('', 0).match(''))\n\n# --------------------------------------------------------------------\n# internals\n\n_cache = {}  # ordered!\n\n_MAXCACHE = 512\ndef _compile(pattern, flags):\n    # internal: compile pattern\n    if isinstance(flags, RegexFlag):\n        flags = flags.value\n    try:\n        return _cache[type(pattern), pattern, flags]\n    except KeyError:\n        pass\n    if isinstance(pattern, Pattern):\n        if flags:\n            raise ValueError(\n                \"cannot process flags argument with a compiled pattern\")\n        return pattern\n    if not sre_compile.isstring(pattern):\n        raise TypeError(\"first argument must be string or compiled pattern\")\n    p = sre_compile.compile(pattern, flags)\n    if not (flags & DEBUG):\n        if len(_cache) >= _MAXCACHE:\n            # Drop the oldest item\n            try:\n                del _cache[next(iter(_cache))]\n            except (StopIteration, RuntimeError, KeyError):\n                pass\n        _cache[type(pattern), pattern, flags] = p\n    return p\n\n@functools.lru_cache(_MAXCACHE)\ndef _compile_repl(repl, pattern):\n    # internal: compile replacement pattern\n    return sre_parse.parse_template(repl, pattern)\n\ndef _expand(pattern, match, template):\n    # internal: Match.expand implementation hook\n    template = sre_parse.parse_template(template, pattern)\n    return sre_parse.expand_template(template, match)\n\ndef _subx(pattern, template):\n    # internal: Pattern.sub/subn implementation helper\n    template = _compile_repl(template, pattern)\n    if not template[0] and len(template[1]) == 1:\n        # literal replacement\n        return template[1][0]\n    def filter(match, template=template):\n        return sre_parse.expand_template(template, match)\n    return filter\n\n# register myself for pickling\n\nimport copyreg\n\ndef _pickle(p):\n    return _compile, (p.pattern, p.flags)\n\ncopyreg.pickle(Pattern, _pickle, _compile)\n\n# --------------------------------------------------------------------\n# experimental stuff (see python-dev discussions for details)\n\nclass Scanner:\n    def __init__(self, lexicon, flags=0):\n        from sre_constants import BRANCH, SUBPATTERN\n        if isinstance(flags, RegexFlag):\n            flags = flags.value\n        self.lexicon = lexicon\n        # combine phrases into a compound pattern\n        p = []\n        s = sre_parse.State()\n        s.flags = flags\n        for phrase, action in lexicon:\n            gid = s.opengroup()\n            p.append(sre_parse.SubPattern(s, [\n                (SUBPATTERN, (gid, 0, 0, sre_parse.parse(phrase, flags))),\n                ]))\n            s.closegroup(gid, p[-1])\n        p = sre_parse.SubPattern(s, [(BRANCH, (None, p))])\n        self.scanner = sre_compile.compile(p)\n    def scan(self, string):\n        result = []\n        append = result.append\n        match = self.scanner.scanner(string).match\n        i = 0\n        while True:\n            m = match()\n            if not m:\n                break\n            j = m.end()\n            if i == j:\n                break\n            action = self.lexicon[m.lastindex-1][1]\n            if callable(action):\n                self.match = m\n                action = action(self, m.group())\n            if action is not None:\n                append(action)\n            i = j\n        return result, string[i:]\n", 384], "/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py": ["\"\"\"Python part of the warnings subsystem.\"\"\"\n\nimport sys\n\n\n__all__ = [\"warn\", \"warn_explicit\", \"showwarning\",\n           \"formatwarning\", \"filterwarnings\", \"simplefilter\",\n           \"resetwarnings\", \"catch_warnings\"]\n\ndef showwarning(message, category, filename, lineno, file=None, line=None):\n    \"\"\"Hook to write a warning to a file; replace if you like.\"\"\"\n    msg = WarningMessage(message, category, filename, lineno, file, line)\n    _showwarnmsg_impl(msg)\n\ndef formatwarning(message, category, filename, lineno, line=None):\n    \"\"\"Function to format a warning the standard way.\"\"\"\n    msg = WarningMessage(message, category, filename, lineno, None, line)\n    return _formatwarnmsg_impl(msg)\n\ndef _showwarnmsg_impl(msg):\n    file = msg.file\n    if file is None:\n        file = sys.stderr\n        if file is None:\n            # sys.stderr is None when run with pythonw.exe:\n            # warnings get lost\n            return\n    text = _formatwarnmsg(msg)\n    try:\n        file.write(text)\n    except OSError:\n        # the file (probably stderr) is invalid - this warning gets lost.\n        pass\n\ndef _formatwarnmsg_impl(msg):\n    category = msg.category.__name__\n    s =  f\"{msg.filename}:{msg.lineno}: {category}: {msg.message}\\n\"\n\n    if msg.line is None:\n        try:\n            import linecache\n            line = linecache.getline(msg.filename, msg.lineno)\n        except Exception:\n            # When a warning is logged during Python shutdown, linecache\n            # and the import machinery don't work anymore\n            line = None\n            linecache = None\n    else:\n        line = msg.line\n    if line:\n        line = line.strip()\n        s += \"  %s\\n\" % line\n\n    if msg.source is not None:\n        try:\n            import tracemalloc\n        # Logging a warning should not raise a new exception:\n        # catch Exception, not only ImportError and RecursionError.\n        except Exception:\n            # don't suggest to enable tracemalloc if it's not available\n            tracing = True\n            tb = None\n        else:\n            tracing = tracemalloc.is_tracing()\n            try:\n                tb = tracemalloc.get_object_traceback(msg.source)\n            except Exception:\n                # When a warning is logged during Python shutdown, tracemalloc\n                # and the import machinery don't work anymore\n                tb = None\n\n        if tb is not None:\n            s += 'Object allocated at (most recent call last):\\n'\n            for frame in tb:\n                s += ('  File \"%s\", lineno %s\\n'\n                      % (frame.filename, frame.lineno))\n\n                try:\n                    if linecache is not None:\n                        line = linecache.getline(frame.filename, frame.lineno)\n                    else:\n                        line = None\n                except Exception:\n                    line = None\n                if line:\n                    line = line.strip()\n                    s += '    %s\\n' % line\n        elif not tracing:\n            s += (f'{category}: Enable tracemalloc to get the object '\n                  f'allocation traceback\\n')\n    return s\n\n# Keep a reference to check if the function was replaced\n_showwarning_orig = showwarning\n\ndef _showwarnmsg(msg):\n    \"\"\"Hook to write a warning to a file; replace if you like.\"\"\"\n    try:\n        sw = showwarning\n    except NameError:\n        pass\n    else:\n        if sw is not _showwarning_orig:\n            # warnings.showwarning() was replaced\n            if not callable(sw):\n                raise TypeError(\"warnings.showwarning() must be set to a \"\n                                \"function or method\")\n\n            sw(msg.message, msg.category, msg.filename, msg.lineno,\n               msg.file, msg.line)\n            return\n    _showwarnmsg_impl(msg)\n\n# Keep a reference to check if the function was replaced\n_formatwarning_orig = formatwarning\n\ndef _formatwarnmsg(msg):\n    \"\"\"Function to format a warning the standard way.\"\"\"\n    try:\n        fw = formatwarning\n    except NameError:\n        pass\n    else:\n        if fw is not _formatwarning_orig:\n            # warnings.formatwarning() was replaced\n            return fw(msg.message, msg.category,\n                      msg.filename, msg.lineno, msg.line)\n    return _formatwarnmsg_impl(msg)\n\ndef filterwarnings(action, message=\"\", category=Warning, module=\"\", lineno=0,\n                   append=False):\n    \"\"\"Insert an entry into the list of warnings filters (at the front).\n\n    'action' -- one of \"error\", \"ignore\", \"always\", \"default\", \"module\",\n                or \"once\"\n    'message' -- a regex that the warning message must match\n    'category' -- a class that the warning must be a subclass of\n    'module' -- a regex that the module name must match\n    'lineno' -- an integer line number, 0 matches all warnings\n    'append' -- if true, append to the list of filters\n    \"\"\"\n    assert action in (\"error\", \"ignore\", \"always\", \"default\", \"module\",\n                      \"once\"), \"invalid action: %r\" % (action,)\n    assert isinstance(message, str), \"message must be a string\"\n    assert isinstance(category, type), \"category must be a class\"\n    assert issubclass(category, Warning), \"category must be a Warning subclass\"\n    assert isinstance(module, str), \"module must be a string\"\n    assert isinstance(lineno, int) and lineno >= 0, \\\n           \"lineno must be an int >= 0\"\n\n    if message or module:\n        import re\n\n    if message:\n        message = re.compile(message, re.I)\n    else:\n        message = None\n    if module:\n        module = re.compile(module)\n    else:\n        module = None\n\n    _add_filter(action, message, category, module, lineno, append=append)\n\ndef simplefilter(action, category=Warning, lineno=0, append=False):\n    \"\"\"Insert a simple entry into the list of warnings filters (at the front).\n\n    A simple filter matches all modules and messages.\n    'action' -- one of \"error\", \"ignore\", \"always\", \"default\", \"module\",\n                or \"once\"\n    'category' -- a class that the warning must be a subclass of\n    'lineno' -- an integer line number, 0 matches all warnings\n    'append' -- if true, append to the list of filters\n    \"\"\"\n    assert action in (\"error\", \"ignore\", \"always\", \"default\", \"module\",\n                      \"once\"), \"invalid action: %r\" % (action,)\n    assert isinstance(lineno, int) and lineno >= 0, \\\n           \"lineno must be an int >= 0\"\n    _add_filter(action, None, category, None, lineno, append=append)\n\ndef _add_filter(*item, append):\n    # Remove possible duplicate filters, so new one will be placed\n    # in correct place. If append=True and duplicate exists, do nothing.\n    if not append:\n        try:\n            filters.remove(item)\n        except ValueError:\n            pass\n        filters.insert(0, item)\n    else:\n        if item not in filters:\n            filters.append(item)\n    _filters_mutated()\n\ndef resetwarnings():\n    \"\"\"Clear the list of warning filters, so that no filters are active.\"\"\"\n    filters[:] = []\n    _filters_mutated()\n\nclass _OptionError(Exception):\n    \"\"\"Exception used by option processing helpers.\"\"\"\n    pass\n\n# Helper to process -W options passed via sys.warnoptions\ndef _processoptions(args):\n    for arg in args:\n        try:\n            _setoption(arg)\n        except _OptionError as msg:\n            print(\"Invalid -W option ignored:\", msg, file=sys.stderr)\n\n# Helper for _processoptions()\ndef _setoption(arg):\n    parts = arg.split(':')\n    if len(parts) > 5:\n        raise _OptionError(\"too many fields (max 5): %r\" % (arg,))\n    while len(parts) < 5:\n        parts.append('')\n    action, message, category, module, lineno = [s.strip()\n                                                 for s in parts]\n    action = _getaction(action)\n    category = _getcategory(category)\n    if message or module:\n        import re\n    if message:\n        message = re.escape(message)\n    if module:\n        module = re.escape(module) + r'\\Z'\n    if lineno:\n        try:\n            lineno = int(lineno)\n            if lineno < 0:\n                raise ValueError\n        except (ValueError, OverflowError):\n            raise _OptionError(\"invalid lineno %r\" % (lineno,)) from None\n    else:\n        lineno = 0\n    filterwarnings(action, message, category, module, lineno)\n\n# Helper for _setoption()\ndef _getaction(action):\n    if not action:\n        return \"default\"\n    if action == \"all\": return \"always\" # Alias\n    for a in ('default', 'always', 'ignore', 'module', 'once', 'error'):\n        if a.startswith(action):\n            return a\n    raise _OptionError(\"invalid action: %r\" % (action,))\n\n# Helper for _setoption()\ndef _getcategory(category):\n    if not category:\n        return Warning\n    if '.' not in category:\n        import builtins as m\n        klass = category\n    else:\n        module, _, klass = category.rpartition('.')\n        try:\n            m = __import__(module, None, None, [klass])\n        except ImportError:\n            raise _OptionError(\"invalid module name: %r\" % (module,)) from None\n    try:\n        cat = getattr(m, klass)\n    except AttributeError:\n        raise _OptionError(\"unknown warning category: %r\" % (category,)) from None\n    if not issubclass(cat, Warning):\n        raise _OptionError(\"invalid warning category: %r\" % (category,))\n    return cat\n\n\ndef _is_internal_frame(frame):\n    \"\"\"Signal whether the frame is an internal CPython implementation detail.\"\"\"\n    filename = frame.f_code.co_filename\n    return 'importlib' in filename and '_bootstrap' in filename\n\n\ndef _next_external_frame(frame):\n    \"\"\"Find the next frame that doesn't involve CPython internals.\"\"\"\n    frame = frame.f_back\n    while frame is not None and _is_internal_frame(frame):\n        frame = frame.f_back\n    return frame\n\n\n# Code typically replaced by _warnings\ndef warn(message, category=None, stacklevel=1, source=None):\n    \"\"\"Issue a warning, or maybe ignore it or raise an exception.\"\"\"\n    # Check if message is already a Warning object\n    if isinstance(message, Warning):\n        category = message.__class__\n    # Check category argument\n    if category is None:\n        category = UserWarning\n    if not (isinstance(category, type) and issubclass(category, Warning)):\n        raise TypeError(\"category must be a Warning subclass, \"\n                        \"not '{:s}'\".format(type(category).__name__))\n    # Get context information\n    try:\n        if stacklevel <= 1 or _is_internal_frame(sys._getframe(1)):\n            # If frame is too small to care or if the warning originated in\n            # internal code, then do not try to hide any frames.\n            frame = sys._getframe(stacklevel)\n        else:\n            frame = sys._getframe(1)\n            # Look for one frame less since the above line starts us off.\n            for x in range(stacklevel-1):\n                frame = _next_external_frame(frame)\n                if frame is None:\n                    raise ValueError\n    except ValueError:\n        globals = sys.__dict__\n        filename = \"sys\"\n        lineno = 1\n    else:\n        globals = frame.f_globals\n        filename = frame.f_code.co_filename\n        lineno = frame.f_lineno\n    if '__name__' in globals:\n        module = globals['__name__']\n    else:\n        module = \"<string>\"\n    registry = globals.setdefault(\"__warningregistry__\", {})\n    warn_explicit(message, category, filename, lineno, module, registry,\n                  globals, source)\n\ndef warn_explicit(message, category, filename, lineno,\n                  module=None, registry=None, module_globals=None,\n                  source=None):\n    lineno = int(lineno)\n    if module is None:\n        module = filename or \"<unknown>\"\n        if module[-3:].lower() == \".py\":\n            module = module[:-3] # XXX What about leading pathname?\n    if registry is None:\n        registry = {}\n    if registry.get('version', 0) != _filters_version:\n        registry.clear()\n        registry['version'] = _filters_version\n    if isinstance(message, Warning):\n        text = str(message)\n        category = message.__class__\n    else:\n        text = message\n        message = category(message)\n    key = (text, category, lineno)\n    # Quick test for common case\n    if registry.get(key):\n        return\n    # Search the filters\n    for item in filters:\n        action, msg, cat, mod, ln = item\n        if ((msg is None or msg.match(text)) and\n            issubclass(category, cat) and\n            (mod is None or mod.match(module)) and\n            (ln == 0 or lineno == ln)):\n            break\n    else:\n        action = defaultaction\n    # Early exit actions\n    if action == \"ignore\":\n        return\n\n    # Prime the linecache for formatting, in case the\n    # \"file\" is actually in a zipfile or something.\n    import linecache\n    linecache.getlines(filename, module_globals)\n\n    if action == \"error\":\n        raise message\n    # Other actions\n    if action == \"once\":\n        registry[key] = 1\n        oncekey = (text, category)\n        if onceregistry.get(oncekey):\n            return\n        onceregistry[oncekey] = 1\n    elif action == \"always\":\n        pass\n    elif action == \"module\":\n        registry[key] = 1\n        altkey = (text, category, 0)\n        if registry.get(altkey):\n            return\n        registry[altkey] = 1\n    elif action == \"default\":\n        registry[key] = 1\n    else:\n        # Unrecognized actions are errors\n        raise RuntimeError(\n              \"Unrecognized action (%r) in warnings.filters:\\n %s\" %\n              (action, item))\n    # Print message and context\n    msg = WarningMessage(message, category, filename, lineno, source)\n    _showwarnmsg(msg)\n\n\nclass WarningMessage(object):\n\n    _WARNING_DETAILS = (\"message\", \"category\", \"filename\", \"lineno\", \"file\",\n                        \"line\", \"source\")\n\n    def __init__(self, message, category, filename, lineno, file=None,\n                 line=None, source=None):\n        self.message = message\n        self.category = category\n        self.filename = filename\n        self.lineno = lineno\n        self.file = file\n        self.line = line\n        self.source = source\n        self._category_name = category.__name__ if category else None\n\n    def __str__(self):\n        return (\"{message : %r, category : %r, filename : %r, lineno : %s, \"\n                    \"line : %r}\" % (self.message, self._category_name,\n                                    self.filename, self.lineno, self.line))\n\n\nclass catch_warnings(object):\n\n    \"\"\"A context manager that copies and restores the warnings filter upon\n    exiting the context.\n\n    The 'record' argument specifies whether warnings should be captured by a\n    custom implementation of warnings.showwarning() and be appended to a list\n    returned by the context manager. Otherwise None is returned by the context\n    manager. The objects appended to the list are arguments whose attributes\n    mirror the arguments to showwarning().\n\n    The 'module' argument is to specify an alternative module to the module\n    named 'warnings' and imported under that name. This argument is only useful\n    when testing the warnings module itself.\n\n    \"\"\"\n\n    def __init__(self, *, record=False, module=None):\n        \"\"\"Specify whether to record warnings and if an alternative module\n        should be used other than sys.modules['warnings'].\n\n        For compatibility with Python 3.0, please consider all arguments to be\n        keyword-only.\n\n        \"\"\"\n        self._record = record\n        self._module = sys.modules['warnings'] if module is None else module\n        self._entered = False\n\n    def __repr__(self):\n        args = []\n        if self._record:\n            args.append(\"record=True\")\n        if self._module is not sys.modules['warnings']:\n            args.append(\"module=%r\" % self._module)\n        name = type(self).__name__\n        return \"%s(%s)\" % (name, \", \".join(args))\n\n    def __enter__(self):\n        if self._entered:\n            raise RuntimeError(\"Cannot enter %r twice\" % self)\n        self._entered = True\n        self._filters = self._module.filters\n        self._module.filters = self._filters[:]\n        self._module._filters_mutated()\n        self._showwarning = self._module.showwarning\n        self._showwarnmsg_impl = self._module._showwarnmsg_impl\n        if self._record:\n            log = []\n            self._module._showwarnmsg_impl = log.append\n            # Reset showwarning() to the default implementation to make sure\n            # that _showwarnmsg() calls _showwarnmsg_impl()\n            self._module.showwarning = self._module._showwarning_orig\n            return log\n        else:\n            return None\n\n    def __exit__(self, *exc_info):\n        if not self._entered:\n            raise RuntimeError(\"Cannot exit %r without entering first\" % self)\n        self._module.filters = self._filters\n        self._module._filters_mutated()\n        self._module.showwarning = self._showwarning\n        self._module._showwarnmsg_impl = self._showwarnmsg_impl\n\n\n# Private utility function called by _PyErr_WarnUnawaitedCoroutine\ndef _warn_unawaited_coroutine(coro):\n    msg_lines = [\n        f\"coroutine '{coro.__qualname__}' was never awaited\\n\"\n    ]\n    if coro.cr_origin is not None:\n        import linecache, traceback\n        def extract():\n            for filename, lineno, funcname in reversed(coro.cr_origin):\n                line = linecache.getline(filename, lineno)\n                yield (filename, lineno, funcname, line)\n        msg_lines.append(\"Coroutine created at (most recent call last)\\n\")\n        msg_lines += traceback.format_list(list(extract()))\n    msg = \"\".join(msg_lines).rstrip(\"\\n\")\n    # Passing source= here means that if the user happens to have tracemalloc\n    # enabled and tracking where the coroutine was created, the warning will\n    # contain that traceback. This does mean that if they have *both*\n    # coroutine origin tracking *and* tracemalloc enabled, they'll get two\n    # partially-redundant tracebacks. If we wanted to be clever we could\n    # probably detect this case and avoid it, but for now we don't bother.\n    warn(msg, category=RuntimeWarning, stacklevel=2, source=coro)\n\n\n# filters contains a sequence of filter 5-tuples\n# The components of the 5-tuple are:\n# - an action: error, ignore, always, default, module, or once\n# - a compiled regex that must match the warning message\n# - a class representing the warning category\n# - a compiled regex that must match the module that is being warned\n# - a line number for the line being warning, or 0 to mean any line\n# If either if the compiled regexs are None, match anything.\ntry:\n    from _warnings import (filters, _defaultaction, _onceregistry,\n                           warn, warn_explicit, _filters_mutated)\n    defaultaction = _defaultaction\n    onceregistry = _onceregistry\n    _warnings_defaults = True\nexcept ImportError:\n    filters = []\n    defaultaction = \"default\"\n    onceregistry = {}\n\n    _filters_version = 1\n\n    def _filters_mutated():\n        global _filters_version\n        _filters_version += 1\n\n    _warnings_defaults = False\n\n\n# Module initialization\n_processoptions(sys.warnoptions)\nif not _warnings_defaults:\n    # Several warning categories are ignored by default in regular builds\n    if not hasattr(sys, 'gettotalrefcount'):\n        filterwarnings(\"default\", category=DeprecationWarning,\n                       module=\"__main__\", append=1)\n        simplefilter(\"ignore\", category=DeprecationWarning, append=1)\n        simplefilter(\"ignore\", category=PendingDeprecationWarning, append=1)\n        simplefilter(\"ignore\", category=ImportWarning, append=1)\n        simplefilter(\"ignore\", category=ResourceWarning, append=1)\n\ndel _warnings_defaults\n", 549], "/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/linecache.py": ["\"\"\"Cache lines from Python source files.\n\nThis is intended to read lines from modules imported -- hence if a filename\nis not found, it will look down the module search path for a file by\nthat name.\n\"\"\"\n\nimport functools\nimport sys\nimport os\nimport tokenize\n\n__all__ = [\"getline\", \"clearcache\", \"checkcache\", \"lazycache\"]\n\n\n# The cache. Maps filenames to either a thunk which will provide source code,\n# or a tuple (size, mtime, lines, fullname) once loaded.\ncache = {}\n\n\ndef clearcache():\n    \"\"\"Clear the cache entirely.\"\"\"\n    cache.clear()\n\n\ndef getline(filename, lineno, module_globals=None):\n    \"\"\"Get a line for a Python source file from the cache.\n    Update the cache if it doesn't contain an entry for this file already.\"\"\"\n\n    lines = getlines(filename, module_globals)\n    if 1 <= lineno <= len(lines):\n        return lines[lineno - 1]\n    return ''\n\n\ndef getlines(filename, module_globals=None):\n    \"\"\"Get the lines for a Python source file from the cache.\n    Update the cache if it doesn't contain an entry for this file already.\"\"\"\n\n    if filename in cache:\n        entry = cache[filename]\n        if len(entry) != 1:\n            return cache[filename][2]\n\n    try:\n        return updatecache(filename, module_globals)\n    except MemoryError:\n        clearcache()\n        return []\n\n\ndef checkcache(filename=None):\n    \"\"\"Discard cache entries that are out of date.\n    (This is not checked upon each call!)\"\"\"\n\n    if filename is None:\n        filenames = list(cache.keys())\n    elif filename in cache:\n        filenames = [filename]\n    else:\n        return\n\n    for filename in filenames:\n        entry = cache[filename]\n        if len(entry) == 1:\n            # lazy cache entry, leave it lazy.\n            continue\n        size, mtime, lines, fullname = entry\n        if mtime is None:\n            continue   # no-op for files loaded via a __loader__\n        try:\n            stat = os.stat(fullname)\n        except OSError:\n            cache.pop(filename, None)\n            continue\n        if size != stat.st_size or mtime != stat.st_mtime:\n            cache.pop(filename, None)\n\n\ndef updatecache(filename, module_globals=None):\n    \"\"\"Update a cache entry and return its list of lines.\n    If something's wrong, print a message, discard the cache entry,\n    and return an empty list.\"\"\"\n\n    if filename in cache:\n        if len(cache[filename]) != 1:\n            cache.pop(filename, None)\n    if not filename or (filename.startswith('<') and filename.endswith('>')):\n        return []\n\n    fullname = filename\n    try:\n        stat = os.stat(fullname)\n    except OSError:\n        basename = filename\n\n        # Realise a lazy loader based lookup if there is one\n        # otherwise try to lookup right now.\n        if lazycache(filename, module_globals):\n            try:\n                data = cache[filename][0]()\n            except (ImportError, OSError):\n                pass\n            else:\n                if data is None:\n                    # No luck, the PEP302 loader cannot find the source\n                    # for this module.\n                    return []\n                cache[filename] = (\n                    len(data),\n                    None,\n                    [line + '\\n' for line in data.splitlines()],\n                    fullname\n                )\n                return cache[filename][2]\n\n        # Try looking through the module search path, which is only useful\n        # when handling a relative filename.\n        if os.path.isabs(filename):\n            return []\n\n        for dirname in sys.path:\n            try:\n                fullname = os.path.join(dirname, basename)\n            except (TypeError, AttributeError):\n                # Not sufficiently string-like to do anything useful with.\n                continue\n            try:\n                stat = os.stat(fullname)\n                break\n            except OSError:\n                pass\n        else:\n            return []\n    try:\n        with tokenize.open(fullname) as fp:\n            lines = fp.readlines()\n    except OSError:\n        return []\n    if lines and not lines[-1].endswith('\\n'):\n        lines[-1] += '\\n'\n    size, mtime = stat.st_size, stat.st_mtime\n    cache[filename] = size, mtime, lines, fullname\n    return lines\n\n\ndef lazycache(filename, module_globals):\n    \"\"\"Seed the cache for filename with module_globals.\n\n    The module loader will be asked for the source only when getlines is\n    called, not immediately.\n\n    If there is an entry in the cache already, it is not altered.\n\n    :return: True if a lazy load is registered in the cache,\n        otherwise False. To register such a load a module loader with a\n        get_source method must be found, the filename must be a cacheable\n        filename, and the filename must not be already cached.\n    \"\"\"\n    if filename in cache:\n        if len(cache[filename]) == 1:\n            return True\n        else:\n            return False\n    if not filename or (filename.startswith('<') and filename.endswith('>')):\n        return False\n    # Try for a __loader__, if available\n    if module_globals and '__loader__' in module_globals:\n        name = module_globals.get('__name__')\n        loader = module_globals['__loader__']\n        get_source = getattr(loader, 'get_source', None)\n\n        if name and get_source:\n            get_lines = functools.partial(get_source, name)\n            cache[filename] = (get_lines,)\n            return True\n    return False\n", 177], "/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/bokeh/__init__.py": ["#-----------------------------------------------------------------------------\n# Copyright (c) 2012 - 2021, Anaconda, Inc., and Bokeh Contributors.\n# All rights reserved.\n#\n# The full license is in the file LICENSE.txt, distributed with this software.\n#-----------------------------------------------------------------------------\n''' Bokeh is a Python library for creating interactive visualizations for modern\nweb browsers.\n\nBokeh helps you build beautiful graphics, ranging from simple plots to complex\ndashboards with streaming datasets. With Bokeh, you can create JavaScript-powered\nvisualizations without writing any JavaScript yourself.\n\nMost of the functionality of Bokeh is accessed through submodules such as\n|bokeh.plotting| and |bokeh.models|.\n\nFor full documentation, please visit https://docs.bokeh.org\n\n----\n\nThe top-level ``bokeh`` module itself contains a few useful functions and\nattributes:\n\n.. attribute:: __version__\n  :annotation: = currently installed version of Bokeh\n\n.. autofunction:: bokeh.license\n\n'''\n\n#-----------------------------------------------------------------------------\n# Boilerplate\n#-----------------------------------------------------------------------------\nfrom __future__ import annotations\n\nimport logging # isort:skip\nlog = logging.getLogger(__name__)\n\n#-----------------------------------------------------------------------------\n# Imports\n#-----------------------------------------------------------------------------\n\n#-----------------------------------------------------------------------------\n# Globals and constants\n#-----------------------------------------------------------------------------\n\n__all__ = (\n    '__version__',\n    'license',\n    'sampledata',\n)\n\n#-----------------------------------------------------------------------------\n# General API\n#-----------------------------------------------------------------------------\n\ndef license():\n    ''' Print the Bokeh license to the console.\n\n    Returns:\n        None\n\n    '''\n    from os.path import join\n    with open(join(__path__[0], 'LICENSE.txt')) as lic:\n        print(lic.read())\n\n#-----------------------------------------------------------------------------\n# Dev API\n#-----------------------------------------------------------------------------\n\n#-----------------------------------------------------------------------------\n# Private API\n#-----------------------------------------------------------------------------\n\n#-----------------------------------------------------------------------------\n# Code\n#-----------------------------------------------------------------------------\n\n# expose Bokeh version\nfrom .util.version import __version__; __version__\n\n# expose sample data module\nfrom . import sampledata; sampledata\n\n# configure Bokeh logger\nfrom .util import logconfig # isort:skip\ndel logconfig\n\n# Configure warnings to always show nice mssages, despite Python's active\n# efforts to hide them from users.\nimport warnings # isort:skip\nfrom .util.warnings import BokehDeprecationWarning, BokehUserWarning # isort:skip\nwarnings.simplefilter('always', BokehDeprecationWarning)\nwarnings.simplefilter('always', BokehUserWarning)\n\noriginal_formatwarning = warnings.formatwarning\ndef _formatwarning(message, category, filename, lineno, line=None):\n    from .util.warnings import BokehDeprecationWarning, BokehUserWarning\n    if category not in (BokehDeprecationWarning, BokehUserWarning):\n        return original_formatwarning(message, category, filename, lineno, line)\n    return \"%s: %s\\n\" % (category.__name__, message)\nwarnings.formatwarning = _formatwarning\n\ndel _formatwarning\ndel BokehDeprecationWarning, BokehUserWarning\ndel warnings\n", 107], "/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/platform.py": ["#!/usr/bin/env python3\n\n\"\"\" This module tries to retrieve as much platform-identifying data as\n    possible. It makes this information available via function APIs.\n\n    If called from the command line, it prints the platform\n    information concatenated as single string to stdout. The output\n    format is useable as part of a filename.\n\n\"\"\"\n#    This module is maintained by Marc-Andre Lemburg <mal@egenix.com>.\n#    If you find problems, please submit bug reports/patches via the\n#    Python bug tracker (http://bugs.python.org) and assign them to \"lemburg\".\n#\n#    Still needed:\n#    * support for MS-DOS (PythonDX ?)\n#    * support for Amiga and other still unsupported platforms running Python\n#    * support for additional Linux distributions\n#\n#    Many thanks to all those who helped adding platform-specific\n#    checks (in no particular order):\n#\n#      Charles G Waldman, David Arnold, Gordon McMillan, Ben Darnell,\n#      Jeff Bauer, Cliff Crawford, Ivan Van Laningham, Josef\n#      Betancourt, Randall Hopper, Karl Putland, John Farrell, Greg\n#      Andruk, Just van Rossum, Thomas Heller, Mark R. Levinson, Mark\n#      Hammond, Bill Tutt, Hans Nowak, Uwe Zessin (OpenVMS support),\n#      Colin Kong, Trent Mick, Guido van Rossum, Anthony Baxter, Steve\n#      Dower\n#\n#    History:\n#\n#    <see CVS and SVN checkin messages for history>\n#\n#    1.0.8 - changed Windows support to read version from kernel32.dll\n#    1.0.7 - added DEV_NULL\n#    1.0.6 - added linux_distribution()\n#    1.0.5 - fixed Java support to allow running the module on Jython\n#    1.0.4 - added IronPython support\n#    1.0.3 - added normalization of Windows system name\n#    1.0.2 - added more Windows support\n#    1.0.1 - reformatted to make doc.py happy\n#    1.0.0 - reformatted a bit and checked into Python CVS\n#    0.8.0 - added sys.version parser and various new access\n#            APIs (python_version(), python_compiler(), etc.)\n#    0.7.2 - fixed architecture() to use sizeof(pointer) where available\n#    0.7.1 - added support for Caldera OpenLinux\n#    0.7.0 - some fixes for WinCE; untabified the source file\n#    0.6.2 - support for OpenVMS - requires version 1.5.2-V006 or higher and\n#            vms_lib.getsyi() configured\n#    0.6.1 - added code to prevent 'uname -p' on platforms which are\n#            known not to support it\n#    0.6.0 - fixed win32_ver() to hopefully work on Win95,98,NT and Win2k;\n#            did some cleanup of the interfaces - some APIs have changed\n#    0.5.5 - fixed another type in the MacOS code... should have\n#            used more coffee today ;-)\n#    0.5.4 - fixed a few typos in the MacOS code\n#    0.5.3 - added experimental MacOS support; added better popen()\n#            workarounds in _syscmd_ver() -- still not 100% elegant\n#            though\n#    0.5.2 - fixed uname() to return '' instead of 'unknown' in all\n#            return values (the system uname command tends to return\n#            'unknown' instead of just leaving the field empty)\n#    0.5.1 - included code for slackware dist; added exception handlers\n#            to cover up situations where platforms don't have os.popen\n#            (e.g. Mac) or fail on socket.gethostname(); fixed libc\n#            detection RE\n#    0.5.0 - changed the API names referring to system commands to *syscmd*;\n#            added java_ver(); made syscmd_ver() a private\n#            API (was system_ver() in previous versions) -- use uname()\n#            instead; extended the win32_ver() to also return processor\n#            type information\n#    0.4.0 - added win32_ver() and modified the platform() output for WinXX\n#    0.3.4 - fixed a bug in _follow_symlinks()\n#    0.3.3 - fixed popen() and \"file\" command invocation bugs\n#    0.3.2 - added architecture() API and support for it in platform()\n#    0.3.1 - fixed syscmd_ver() RE to support Windows NT\n#    0.3.0 - added system alias support\n#    0.2.3 - removed 'wince' again... oh well.\n#    0.2.2 - added 'wince' to syscmd_ver() supported platforms\n#    0.2.1 - added cache logic and changed the platform string format\n#    0.2.0 - changed the API to use functions instead of module globals\n#            since some action take too long to be run on module import\n#    0.1.0 - first release\n#\n#    You can always get the latest version of this module at:\n#\n#             http://www.egenix.com/files/python/platform.py\n#\n#    If that URL should fail, try contacting the author.\n\n__copyright__ = \"\"\"\n    Copyright (c) 1999-2000, Marc-Andre Lemburg; mailto:mal@lemburg.com\n    Copyright (c) 2000-2010, eGenix.com Software GmbH; mailto:info@egenix.com\n\n    Permission to use, copy, modify, and distribute this software and its\n    documentation for any purpose and without fee or royalty is hereby granted,\n    provided that the above copyright notice appear in all copies and that\n    both that copyright notice and this permission notice appear in\n    supporting documentation or portions thereof, including modifications,\n    that you make.\n\n    EGENIX.COM SOFTWARE GMBH DISCLAIMS ALL WARRANTIES WITH REGARD TO\n    THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n    FITNESS, IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL,\n    INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING\n    FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT,\n    NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION\n    WITH THE USE OR PERFORMANCE OF THIS SOFTWARE !\n\n\"\"\"\n\n__version__ = '1.0.8'\n\nimport collections\nimport os\nimport re\nimport sys\nimport subprocess\nimport functools\nimport itertools\n\n### Globals & Constants\n\n# Helper for comparing two version number strings.\n# Based on the description of the PHP's version_compare():\n# http://php.net/manual/en/function.version-compare.php\n\n_ver_stages = {\n    # any string not found in this dict, will get 0 assigned\n    'dev': 10,\n    'alpha': 20, 'a': 20,\n    'beta': 30, 'b': 30,\n    'c': 40,\n    'RC': 50, 'rc': 50,\n    # number, will get 100 assigned\n    'pl': 200, 'p': 200,\n}\n\n_component_re = re.compile(r'([0-9]+|[._+-])')\n\ndef _comparable_version(version):\n    result = []\n    for v in _component_re.split(version):\n        if v not in '._+-':\n            try:\n                v = int(v, 10)\n                t = 100\n            except ValueError:\n                t = _ver_stages.get(v, 0)\n            result.extend((t, v))\n    return result\n\n### Platform specific APIs\n\n_libc_search = re.compile(b'(__libc_init)'\n                          b'|'\n                          b'(GLIBC_([0-9.]+))'\n                          b'|'\n                          br'(libc(_\\w+)?\\.so(?:\\.(\\d[0-9.]*))?)', re.ASCII)\n\ndef libc_ver(executable=None, lib='', version='', chunksize=16384):\n\n    \"\"\" Tries to determine the libc version that the file executable\n        (which defaults to the Python interpreter) is linked against.\n\n        Returns a tuple of strings (lib,version) which default to the\n        given parameters in case the lookup fails.\n\n        Note that the function has intimate knowledge of how different\n        libc versions add symbols to the executable and thus is probably\n        only useable for executables compiled using gcc.\n\n        The file is read and scanned in chunks of chunksize bytes.\n\n    \"\"\"\n    if executable is None:\n        try:\n            ver = os.confstr('CS_GNU_LIBC_VERSION')\n            # parse 'glibc 2.28' as ('glibc', '2.28')\n            parts = ver.split(maxsplit=1)\n            if len(parts) == 2:\n                return tuple(parts)\n        except (AttributeError, ValueError, OSError):\n            # os.confstr() or CS_GNU_LIBC_VERSION value not available\n            pass\n\n        executable = sys.executable\n\n    V = _comparable_version\n    if hasattr(os.path, 'realpath'):\n        # Python 2.2 introduced os.path.realpath(); it is used\n        # here to work around problems with Cygwin not being\n        # able to open symlinks for reading\n        executable = os.path.realpath(executable)\n    with open(executable, 'rb') as f:\n        binary = f.read(chunksize)\n        pos = 0\n        while pos < len(binary):\n            if b'libc' in binary or b'GLIBC' in binary:\n                m = _libc_search.search(binary, pos)\n            else:\n                m = None\n            if not m or m.end() == len(binary):\n                chunk = f.read(chunksize)\n                if chunk:\n                    binary = binary[max(pos, len(binary) - 1000):] + chunk\n                    pos = 0\n                    continue\n                if not m:\n                    break\n            libcinit, glibc, glibcversion, so, threads, soversion = [\n                s.decode('latin1') if s is not None else s\n                for s in m.groups()]\n            if libcinit and not lib:\n                lib = 'libc'\n            elif glibc:\n                if lib != 'glibc':\n                    lib = 'glibc'\n                    version = glibcversion\n                elif V(glibcversion) > V(version):\n                    version = glibcversion\n            elif so:\n                if lib != 'glibc':\n                    lib = 'libc'\n                    if soversion and (not version or V(soversion) > V(version)):\n                        version = soversion\n                    if threads and version[-len(threads):] != threads:\n                        version = version + threads\n            pos = m.end()\n    return lib, version\n\ndef _norm_version(version, build=''):\n\n    \"\"\" Normalize the version and build strings and return a single\n        version string using the format major.minor.build (or patchlevel).\n    \"\"\"\n    l = version.split('.')\n    if build:\n        l.append(build)\n    try:\n        strings = list(map(str, map(int, l)))\n    except ValueError:\n        strings = l\n    version = '.'.join(strings[:3])\n    return version\n\n_ver_output = re.compile(r'(?:([\\w ]+) ([\\w.]+) '\n                         r'.*'\n                         r'\\[.* ([\\d.]+)\\])')\n\n# Examples of VER command output:\n#\n#   Windows 2000:  Microsoft Windows 2000 [Version 5.00.2195]\n#   Windows XP:    Microsoft Windows XP [Version 5.1.2600]\n#   Windows Vista: Microsoft Windows [Version 6.0.6002]\n#\n# Note that the \"Version\" string gets localized on different\n# Windows versions.\n\ndef _syscmd_ver(system='', release='', version='',\n\n               supported_platforms=('win32', 'win16', 'dos')):\n\n    \"\"\" Tries to figure out the OS version used and returns\n        a tuple (system, release, version).\n\n        It uses the \"ver\" shell command for this which is known\n        to exists on Windows, DOS. XXX Others too ?\n\n        In case this fails, the given parameters are used as\n        defaults.\n\n    \"\"\"\n    if sys.platform not in supported_platforms:\n        return system, release, version\n\n    # Try some common cmd strings\n    import subprocess\n    for cmd in ('ver', 'command /c ver', 'cmd /c ver'):\n        try:\n            info = subprocess.check_output(cmd,\n                                           stdin=subprocess.DEVNULL,\n                                           stderr=subprocess.DEVNULL,\n                                           text=True,\n                                           shell=True)\n        except (OSError, subprocess.CalledProcessError) as why:\n            #print('Command %s failed: %s' % (cmd, why))\n            continue\n        else:\n            break\n    else:\n        return system, release, version\n\n    # Parse the output\n    info = info.strip()\n    m = _ver_output.match(info)\n    if m is not None:\n        system, release, version = m.groups()\n        # Strip trailing dots from version and release\n        if release[-1] == '.':\n            release = release[:-1]\n        if version[-1] == '.':\n            version = version[:-1]\n        # Normalize the version and build strings (eliminating additional\n        # zeros)\n        version = _norm_version(version)\n    return system, release, version\n\n_WIN32_CLIENT_RELEASES = {\n    (5, 0): \"2000\",\n    (5, 1): \"XP\",\n    # Strictly, 5.2 client is XP 64-bit, but platform.py historically\n    # has always called it 2003 Server\n    (5, 2): \"2003Server\",\n    (5, None): \"post2003\",\n\n    (6, 0): \"Vista\",\n    (6, 1): \"7\",\n    (6, 2): \"8\",\n    (6, 3): \"8.1\",\n    (6, None): \"post8.1\",\n\n    (10, 0): \"10\",\n    (10, None): \"post10\",\n}\n\n# Server release name lookup will default to client names if necessary\n_WIN32_SERVER_RELEASES = {\n    (5, 2): \"2003Server\",\n\n    (6, 0): \"2008Server\",\n    (6, 1): \"2008ServerR2\",\n    (6, 2): \"2012Server\",\n    (6, 3): \"2012ServerR2\",\n    (6, None): \"post2012ServerR2\",\n}\n\ndef win32_is_iot():\n    return win32_edition() in ('IoTUAP', 'NanoServer', 'WindowsCoreHeadless', 'IoTEdgeOS')\n\ndef win32_edition():\n    try:\n        try:\n            import winreg\n        except ImportError:\n            import _winreg as winreg\n    except ImportError:\n        pass\n    else:\n        try:\n            cvkey = r'SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion'\n            with winreg.OpenKeyEx(winreg.HKEY_LOCAL_MACHINE, cvkey) as key:\n                return winreg.QueryValueEx(key, 'EditionId')[0]\n        except OSError:\n            pass\n\n    return None\n\ndef win32_ver(release='', version='', csd='', ptype=''):\n    try:\n        from sys import getwindowsversion\n    except ImportError:\n        return release, version, csd, ptype\n\n    winver = getwindowsversion()\n    try:\n        major, minor, build = map(int, _syscmd_ver()[2].split('.'))\n    except ValueError:\n        major, minor, build = winver.platform_version or winver[:3]\n    version = '{0}.{1}.{2}'.format(major, minor, build)\n\n    release = (_WIN32_CLIENT_RELEASES.get((major, minor)) or\n               _WIN32_CLIENT_RELEASES.get((major, None)) or\n               release)\n\n    # getwindowsversion() reflect the compatibility mode Python is\n    # running under, and so the service pack value is only going to be\n    # valid if the versions match.\n    if winver[:2] == (major, minor):\n        try:\n            csd = 'SP{}'.format(winver.service_pack_major)\n        except AttributeError:\n            if csd[:13] == 'Service Pack ':\n                csd = 'SP' + csd[13:]\n\n    # VER_NT_SERVER = 3\n    if getattr(winver, 'product_type', None) == 3:\n        release = (_WIN32_SERVER_RELEASES.get((major, minor)) or\n                   _WIN32_SERVER_RELEASES.get((major, None)) or\n                   release)\n\n    try:\n        try:\n            import winreg\n        except ImportError:\n            import _winreg as winreg\n    except ImportError:\n        pass\n    else:\n        try:\n            cvkey = r'SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion'\n            with winreg.OpenKeyEx(winreg.HKEY_LOCAL_MACHINE, cvkey) as key:\n                ptype = winreg.QueryValueEx(key, 'CurrentType')[0]\n        except OSError:\n            pass\n\n    return release, version, csd, ptype\n\n\ndef _mac_ver_xml():\n    fn = '/System/Library/CoreServices/SystemVersion.plist'\n    if not os.path.exists(fn):\n        return None\n\n    try:\n        import plistlib\n    except ImportError:\n        return None\n\n    with open(fn, 'rb') as f:\n        pl = plistlib.load(f)\n    release = pl['ProductVersion']\n    versioninfo = ('', '', '')\n    machine = os.uname().machine\n    if machine in ('ppc', 'Power Macintosh'):\n        # Canonical name\n        machine = 'PowerPC'\n\n    return release, versioninfo, machine\n\n\ndef mac_ver(release='', versioninfo=('', '', ''), machine=''):\n\n    \"\"\" Get macOS version information and return it as tuple (release,\n        versioninfo, machine) with versioninfo being a tuple (version,\n        dev_stage, non_release_version).\n\n        Entries which cannot be determined are set to the parameter values\n        which default to ''. All tuple entries are strings.\n    \"\"\"\n\n    # First try reading the information from an XML file which should\n    # always be present\n    info = _mac_ver_xml()\n    if info is not None:\n        return info\n\n    # If that also doesn't work return the default values\n    return release, versioninfo, machine\n\ndef _java_getprop(name, default):\n\n    from java.lang import System\n    try:\n        value = System.getProperty(name)\n        if value is None:\n            return default\n        return value\n    except AttributeError:\n        return default\n\ndef java_ver(release='', vendor='', vminfo=('', '', ''), osinfo=('', '', '')):\n\n    \"\"\" Version interface for Jython.\n\n        Returns a tuple (release, vendor, vminfo, osinfo) with vminfo being\n        a tuple (vm_name, vm_release, vm_vendor) and osinfo being a\n        tuple (os_name, os_version, os_arch).\n\n        Values which cannot be determined are set to the defaults\n        given as parameters (which all default to '').\n\n    \"\"\"\n    # Import the needed APIs\n    try:\n        import java.lang\n    except ImportError:\n        return release, vendor, vminfo, osinfo\n\n    vendor = _java_getprop('java.vendor', vendor)\n    release = _java_getprop('java.version', release)\n    vm_name, vm_release, vm_vendor = vminfo\n    vm_name = _java_getprop('java.vm.name', vm_name)\n    vm_vendor = _java_getprop('java.vm.vendor', vm_vendor)\n    vm_release = _java_getprop('java.vm.version', vm_release)\n    vminfo = vm_name, vm_release, vm_vendor\n    os_name, os_version, os_arch = osinfo\n    os_arch = _java_getprop('java.os.arch', os_arch)\n    os_name = _java_getprop('java.os.name', os_name)\n    os_version = _java_getprop('java.os.version', os_version)\n    osinfo = os_name, os_version, os_arch\n\n    return release, vendor, vminfo, osinfo\n\n### System name aliasing\n\ndef system_alias(system, release, version):\n\n    \"\"\" Returns (system, release, version) aliased to common\n        marketing names used for some systems.\n\n        It also does some reordering of the information in some cases\n        where it would otherwise cause confusion.\n\n    \"\"\"\n    if system == 'SunOS':\n        # Sun's OS\n        if release < '5':\n            # These releases use the old name SunOS\n            return system, release, version\n        # Modify release (marketing release = SunOS release - 3)\n        l = release.split('.')\n        if l:\n            try:\n                major = int(l[0])\n            except ValueError:\n                pass\n            else:\n                major = major - 3\n                l[0] = str(major)\n                release = '.'.join(l)\n        if release < '6':\n            system = 'Solaris'\n        else:\n            # XXX Whatever the new SunOS marketing name is...\n            system = 'Solaris'\n\n    elif system == 'IRIX64':\n        # IRIX reports IRIX64 on platforms with 64-bit support; yet it\n        # is really a version and not a different platform, since 32-bit\n        # apps are also supported..\n        system = 'IRIX'\n        if version:\n            version = version + ' (64bit)'\n        else:\n            version = '64bit'\n\n    elif system in ('win32', 'win16'):\n        # In case one of the other tricks\n        system = 'Windows'\n\n    # bpo-35516: Don't replace Darwin with macOS since input release and\n    # version arguments can be different than the currently running version.\n\n    return system, release, version\n\n### Various internal helpers\n\ndef _platform(*args):\n\n    \"\"\" Helper to format the platform string in a filename\n        compatible format e.g. \"system-version-machine\".\n    \"\"\"\n    # Format the platform string\n    platform = '-'.join(x.strip() for x in filter(len, args))\n\n    # Cleanup some possible filename obstacles...\n    platform = platform.replace(' ', '_')\n    platform = platform.replace('/', '-')\n    platform = platform.replace('\\\\', '-')\n    platform = platform.replace(':', '-')\n    platform = platform.replace(';', '-')\n    platform = platform.replace('\"', '-')\n    platform = platform.replace('(', '-')\n    platform = platform.replace(')', '-')\n\n    # No need to report 'unknown' information...\n    platform = platform.replace('unknown', '')\n\n    # Fold '--'s and remove trailing '-'\n    while 1:\n        cleaned = platform.replace('--', '-')\n        if cleaned == platform:\n            break\n        platform = cleaned\n    while platform[-1] == '-':\n        platform = platform[:-1]\n\n    return platform\n\ndef _node(default=''):\n\n    \"\"\" Helper to determine the node name of this machine.\n    \"\"\"\n    try:\n        import socket\n    except ImportError:\n        # No sockets...\n        return default\n    try:\n        return socket.gethostname()\n    except OSError:\n        # Still not working...\n        return default\n\ndef _follow_symlinks(filepath):\n\n    \"\"\" In case filepath is a symlink, follow it until a\n        real file is reached.\n    \"\"\"\n    filepath = os.path.abspath(filepath)\n    while os.path.islink(filepath):\n        filepath = os.path.normpath(\n            os.path.join(os.path.dirname(filepath), os.readlink(filepath)))\n    return filepath\n\n\ndef _syscmd_file(target, default=''):\n\n    \"\"\" Interface to the system's file command.\n\n        The function uses the -b option of the file command to have it\n        omit the filename in its output. Follow the symlinks. It returns\n        default in case the command should fail.\n\n    \"\"\"\n    if sys.platform in ('dos', 'win32', 'win16'):\n        # XXX Others too ?\n        return default\n\n    import subprocess\n    target = _follow_symlinks(target)\n    # \"file\" output is locale dependent: force the usage of the C locale\n    # to get deterministic behavior.\n    env = dict(os.environ, LC_ALL='C')\n    try:\n        # -b: do not prepend filenames to output lines (brief mode)\n        output = subprocess.check_output(['file', '-b', target],\n                                         stderr=subprocess.DEVNULL,\n                                         env=env)\n    except (OSError, subprocess.CalledProcessError):\n        return default\n    if not output:\n        return default\n    # With the C locale, the output should be mostly ASCII-compatible.\n    # Decode from Latin-1 to prevent Unicode decode error.\n    return output.decode('latin-1')\n\n### Information about the used architecture\n\n# Default values for architecture; non-empty strings override the\n# defaults given as parameters\n_default_architecture = {\n    'win32': ('', 'WindowsPE'),\n    'win16': ('', 'Windows'),\n    'dos': ('', 'MSDOS'),\n}\n\ndef architecture(executable=sys.executable, bits='', linkage=''):\n\n    \"\"\" Queries the given executable (defaults to the Python interpreter\n        binary) for various architecture information.\n\n        Returns a tuple (bits, linkage) which contains information about\n        the bit architecture and the linkage format used for the\n        executable. Both values are returned as strings.\n\n        Values that cannot be determined are returned as given by the\n        parameter presets. If bits is given as '', the sizeof(pointer)\n        (or sizeof(long) on Python version < 1.5.2) is used as\n        indicator for the supported pointer size.\n\n        The function relies on the system's \"file\" command to do the\n        actual work. This is available on most if not all Unix\n        platforms. On some non-Unix platforms where the \"file\" command\n        does not exist and the executable is set to the Python interpreter\n        binary defaults from _default_architecture are used.\n\n    \"\"\"\n    # Use the sizeof(pointer) as default number of bits if nothing\n    # else is given as default.\n    if not bits:\n        import struct\n        size = struct.calcsize('P')\n        bits = str(size * 8) + 'bit'\n\n    # Get data from the 'file' system command\n    if executable:\n        fileout = _syscmd_file(executable, '')\n    else:\n        fileout = ''\n\n    if not fileout and \\\n       executable == sys.executable:\n        # \"file\" command did not return anything; we'll try to provide\n        # some sensible defaults then...\n        if sys.platform in _default_architecture:\n            b, l = _default_architecture[sys.platform]\n            if b:\n                bits = b\n            if l:\n                linkage = l\n        return bits, linkage\n\n    if 'executable' not in fileout and 'shared object' not in fileout:\n        # Format not supported\n        return bits, linkage\n\n    # Bits\n    if '32-bit' in fileout:\n        bits = '32bit'\n    elif 'N32' in fileout:\n        # On Irix only\n        bits = 'n32bit'\n    elif '64-bit' in fileout:\n        bits = '64bit'\n\n    # Linkage\n    if 'ELF' in fileout:\n        linkage = 'ELF'\n    elif 'PE' in fileout:\n        # E.g. Windows uses this format\n        if 'Windows' in fileout:\n            linkage = 'WindowsPE'\n        else:\n            linkage = 'PE'\n    elif 'COFF' in fileout:\n        linkage = 'COFF'\n    elif 'MS-DOS' in fileout:\n        linkage = 'MSDOS'\n    else:\n        # XXX the A.OUT format also falls under this class...\n        pass\n\n    return bits, linkage\n\n\ndef _get_machine_win32():\n    # Try to use the PROCESSOR_* environment variables\n    # available on Win XP and later; see\n    # http://support.microsoft.com/kb/888731 and\n    # http://www.geocities.com/rick_lively/MANUALS/ENV/MSWIN/PROCESSI.HTM\n\n    # WOW64 processes mask the native architecture\n    return (\n        os.environ.get('PROCESSOR_ARCHITEW6432', '') or\n        os.environ.get('PROCESSOR_ARCHITECTURE', '')\n    )\n\n\nclass _Processor:\n    @classmethod\n    def get(cls):\n        func = getattr(cls, f'get_{sys.platform}', cls.from_subprocess)\n        return func() or ''\n\n    def get_win32():\n        return os.environ.get('PROCESSOR_IDENTIFIER', _get_machine_win32())\n\n    def get_OpenVMS():\n        try:\n            import vms_lib\n        except ImportError:\n            pass\n        else:\n            csid, cpu_number = vms_lib.getsyi('SYI$_CPU', 0)\n            return 'Alpha' if cpu_number >= 128 else 'VAX'\n\n    def from_subprocess():\n        \"\"\"\n        Fall back to `uname -p`\n        \"\"\"\n        try:\n            return subprocess.check_output(\n                ['uname', '-p'],\n                stderr=subprocess.DEVNULL,\n                text=True,\n            ).strip()\n        except (OSError, subprocess.CalledProcessError):\n            pass\n\n\ndef _unknown_as_blank(val):\n    return '' if val == 'unknown' else val\n\n\n### Portable uname() interface\n\nclass uname_result(\n    collections.namedtuple(\n        \"uname_result_base\",\n        \"system node release version machine\")\n        ):\n    \"\"\"\n    A uname_result that's largely compatible with a\n    simple namedtuple except that 'processor' is\n    resolved late and cached to avoid calling \"uname\"\n    except when needed.\n    \"\"\"\n\n    @functools.cached_property\n    def processor(self):\n        return _unknown_as_blank(_Processor.get())\n\n    def __iter__(self):\n        return itertools.chain(\n            super().__iter__(),\n            (self.processor,)\n        )\n\n    @classmethod\n    def _make(cls, iterable):\n        # override factory to affect length check\n        num_fields = len(cls._fields)\n        result = cls.__new__(cls, *iterable)\n        if len(result) != num_fields + 1:\n            msg = f'Expected {num_fields} arguments, got {len(result)}'\n            raise TypeError(msg)\n        return result\n\n    def __getitem__(self, key):\n        return tuple(self)[key]\n\n    def __len__(self):\n        return len(tuple(iter(self)))\n\n    def __reduce__(self):\n        return uname_result, tuple(self)[:len(self._fields)]\n\n\n_uname_cache = None\n\n\ndef uname():\n\n    \"\"\" Fairly portable uname interface. Returns a tuple\n        of strings (system, node, release, version, machine, processor)\n        identifying the underlying platform.\n\n        Note that unlike the os.uname function this also returns\n        possible processor information as an additional tuple entry.\n\n        Entries which cannot be determined are set to ''.\n\n    \"\"\"\n    global _uname_cache\n\n    if _uname_cache is not None:\n        return _uname_cache\n\n    # Get some infos from the builtin os.uname API...\n    try:\n        system, node, release, version, machine = infos = os.uname()\n    except AttributeError:\n        system = sys.platform\n        node = _node()\n        release = version = machine = ''\n        infos = ()\n\n    if not any(infos):\n        # uname is not available\n\n        # Try win32_ver() on win32 platforms\n        if system == 'win32':\n            release, version, csd, ptype = win32_ver()\n            machine = machine or _get_machine_win32()\n\n        # Try the 'ver' system command available on some\n        # platforms\n        if not (release and version):\n            system, release, version = _syscmd_ver(system)\n            # Normalize system to what win32_ver() normally returns\n            # (_syscmd_ver() tends to return the vendor name as well)\n            if system == 'Microsoft Windows':\n                system = 'Windows'\n            elif system == 'Microsoft' and release == 'Windows':\n                # Under Windows Vista and Windows Server 2008,\n                # Microsoft changed the output of the ver command. The\n                # release is no longer printed.  This causes the\n                # system and release to be misidentified.\n                system = 'Windows'\n                if '6.0' == version[:3]:\n                    release = 'Vista'\n                else:\n                    release = ''\n\n        # In case we still don't know anything useful, we'll try to\n        # help ourselves\n        if system in ('win32', 'win16'):\n            if not version:\n                if system == 'win32':\n                    version = '32bit'\n                else:\n                    version = '16bit'\n            system = 'Windows'\n\n        elif system[:4] == 'java':\n            release, vendor, vminfo, osinfo = java_ver()\n            system = 'Java'\n            version = ', '.join(vminfo)\n            if not version:\n                version = vendor\n\n    # System specific extensions\n    if system == 'OpenVMS':\n        # OpenVMS seems to have release and version mixed up\n        if not release or release == '0':\n            release = version\n            version = ''\n\n    #  normalize name\n    if system == 'Microsoft' and release == 'Windows':\n        system = 'Windows'\n        release = 'Vista'\n\n    vals = system, node, release, version, machine\n    # Replace 'unknown' values with the more portable ''\n    _uname_cache = uname_result(*map(_unknown_as_blank, vals))\n    return _uname_cache\n\n### Direct interfaces to some of the uname() return values\n\ndef system():\n\n    \"\"\" Returns the system/OS name, e.g. 'Linux', 'Windows' or 'Java'.\n\n        An empty string is returned if the value cannot be determined.\n\n    \"\"\"\n    return uname().system\n\ndef node():\n\n    \"\"\" Returns the computer's network name (which may not be fully\n        qualified)\n\n        An empty string is returned if the value cannot be determined.\n\n    \"\"\"\n    return uname().node\n\ndef release():\n\n    \"\"\" Returns the system's release, e.g. '2.2.0' or 'NT'\n\n        An empty string is returned if the value cannot be determined.\n\n    \"\"\"\n    return uname().release\n\ndef version():\n\n    \"\"\" Returns the system's release version, e.g. '#3 on degas'\n\n        An empty string is returned if the value cannot be determined.\n\n    \"\"\"\n    return uname().version\n\ndef machine():\n\n    \"\"\" Returns the machine type, e.g. 'i386'\n\n        An empty string is returned if the value cannot be determined.\n\n    \"\"\"\n    return uname().machine\n\ndef processor():\n\n    \"\"\" Returns the (true) processor name, e.g. 'amdk6'\n\n        An empty string is returned if the value cannot be\n        determined. Note that many platforms do not provide this\n        information or simply return the same value as for machine(),\n        e.g.  NetBSD does this.\n\n    \"\"\"\n    return uname().processor\n\n### Various APIs for extracting information from sys.version\n\n_sys_version_parser = re.compile(\n    r'([\\w.+]+)\\s*'  # \"version<space>\"\n    r'\\(#?([^,]+)'  # \"(#buildno\"\n    r'(?:,\\s*([\\w ]*)'  # \", builddate\"\n    r'(?:,\\s*([\\w :]*))?)?\\)\\s*'  # \", buildtime)<space>\"\n    r'\\[([^\\]]+)\\]?', re.ASCII)  # \"[compiler]\"\n\n_ironpython_sys_version_parser = re.compile(\n    r'IronPython\\s*'\n    r'([\\d\\.]+)'\n    r'(?: \\(([\\d\\.]+)\\))?'\n    r' on (.NET [\\d\\.]+)', re.ASCII)\n\n# IronPython covering 2.6 and 2.7\n_ironpython26_sys_version_parser = re.compile(\n    r'([\\d.]+)\\s*'\n    r'\\(IronPython\\s*'\n    r'[\\d.]+\\s*'\n    r'\\(([\\d.]+)\\) on ([\\w.]+ [\\d.]+(?: \\(\\d+-bit\\))?)\\)'\n)\n\n_pypy_sys_version_parser = re.compile(\n    r'([\\w.+]+)\\s*'\n    r'\\(#?([^,]+),\\s*([\\w ]+),\\s*([\\w :]+)\\)\\s*'\n    r'\\[PyPy [^\\]]+\\]?')\n\n_sys_version_cache = {}\n\ndef _sys_version(sys_version=None):\n\n    \"\"\" Returns a parsed version of Python's sys.version as tuple\n        (name, version, branch, revision, buildno, builddate, compiler)\n        referring to the Python implementation name, version, branch,\n        revision, build number, build date/time as string and the compiler\n        identification string.\n\n        Note that unlike the Python sys.version, the returned value\n        for the Python version will always include the patchlevel (it\n        defaults to '.0').\n\n        The function returns empty strings for tuple entries that\n        cannot be determined.\n\n        sys_version may be given to parse an alternative version\n        string, e.g. if the version was read from a different Python\n        interpreter.\n\n    \"\"\"\n    # Get the Python version\n    if sys_version is None:\n        sys_version = sys.version\n\n    # Try the cache first\n    result = _sys_version_cache.get(sys_version, None)\n    if result is not None:\n        return result\n\n    # Parse it\n    if 'IronPython' in sys_version:\n        # IronPython\n        name = 'IronPython'\n        if sys_version.startswith('IronPython'):\n            match = _ironpython_sys_version_parser.match(sys_version)\n        else:\n            match = _ironpython26_sys_version_parser.match(sys_version)\n\n        if match is None:\n            raise ValueError(\n                'failed to parse IronPython sys.version: %s' %\n                repr(sys_version))\n\n        version, alt_version, compiler = match.groups()\n        buildno = ''\n        builddate = ''\n\n    elif sys.platform.startswith('java'):\n        # Jython\n        name = 'Jython'\n        match = _sys_version_parser.match(sys_version)\n        if match is None:\n            raise ValueError(\n                'failed to parse Jython sys.version: %s' %\n                repr(sys_version))\n        version, buildno, builddate, buildtime, _ = match.groups()\n        if builddate is None:\n            builddate = ''\n        compiler = sys.platform\n\n    elif \"PyPy\" in sys_version:\n        # PyPy\n        name = \"PyPy\"\n        match = _pypy_sys_version_parser.match(sys_version)\n        if match is None:\n            raise ValueError(\"failed to parse PyPy sys.version: %s\" %\n                             repr(sys_version))\n        version, buildno, builddate, buildtime = match.groups()\n        compiler = \"\"\n\n    else:\n        # CPython\n        match = _sys_version_parser.match(sys_version)\n        if match is None:\n            raise ValueError(\n                'failed to parse CPython sys.version: %s' %\n                repr(sys_version))\n        version, buildno, builddate, buildtime, compiler = \\\n              match.groups()\n        name = 'CPython'\n        if builddate is None:\n            builddate = ''\n        elif buildtime:\n            builddate = builddate + ' ' + buildtime\n\n    if hasattr(sys, '_git'):\n        _, branch, revision = sys._git\n    elif hasattr(sys, '_mercurial'):\n        _, branch, revision = sys._mercurial\n    else:\n        branch = ''\n        revision = ''\n\n    # Add the patchlevel version if missing\n    l = version.split('.')\n    if len(l) == 2:\n        l.append('0')\n        version = '.'.join(l)\n\n    # Build and cache the result\n    result = (name, version, branch, revision, buildno, builddate, compiler)\n    _sys_version_cache[sys_version] = result\n    return result\n\ndef python_implementation():\n\n    \"\"\" Returns a string identifying the Python implementation.\n\n        Currently, the following implementations are identified:\n          'CPython' (C implementation of Python),\n          'IronPython' (.NET implementation of Python),\n          'Jython' (Java implementation of Python),\n          'PyPy' (Python implementation of Python).\n\n    \"\"\"\n    return _sys_version()[0]\n\ndef python_version():\n\n    \"\"\" Returns the Python version as string 'major.minor.patchlevel'\n\n        Note that unlike the Python sys.version, the returned value\n        will always include the patchlevel (it defaults to 0).\n\n    \"\"\"\n    return _sys_version()[1]\n\ndef python_version_tuple():\n\n    \"\"\" Returns the Python version as tuple (major, minor, patchlevel)\n        of strings.\n\n        Note that unlike the Python sys.version, the returned value\n        will always include the patchlevel (it defaults to 0).\n\n    \"\"\"\n    return tuple(_sys_version()[1].split('.'))\n\ndef python_branch():\n\n    \"\"\" Returns a string identifying the Python implementation\n        branch.\n\n        For CPython this is the SCM branch from which the\n        Python binary was built.\n\n        If not available, an empty string is returned.\n\n    \"\"\"\n\n    return _sys_version()[2]\n\ndef python_revision():\n\n    \"\"\" Returns a string identifying the Python implementation\n        revision.\n\n        For CPython this is the SCM revision from which the\n        Python binary was built.\n\n        If not available, an empty string is returned.\n\n    \"\"\"\n    return _sys_version()[3]\n\ndef python_build():\n\n    \"\"\" Returns a tuple (buildno, builddate) stating the Python\n        build number and date as strings.\n\n    \"\"\"\n    return _sys_version()[4:6]\n\ndef python_compiler():\n\n    \"\"\" Returns a string identifying the compiler used for compiling\n        Python.\n\n    \"\"\"\n    return _sys_version()[6]\n\n### The Opus Magnum of platform strings :-)\n\n_platform_cache = {}\n\ndef platform(aliased=0, terse=0):\n\n    \"\"\" Returns a single string identifying the underlying platform\n        with as much useful information as possible (but no more :).\n\n        The output is intended to be human readable rather than\n        machine parseable. It may look different on different\n        platforms and this is intended.\n\n        If \"aliased\" is true, the function will use aliases for\n        various platforms that report system names which differ from\n        their common names, e.g. SunOS will be reported as\n        Solaris. The system_alias() function is used to implement\n        this.\n\n        Setting terse to true causes the function to return only the\n        absolute minimum information needed to identify the platform.\n\n    \"\"\"\n    result = _platform_cache.get((aliased, terse), None)\n    if result is not None:\n        return result\n\n    # Get uname information and then apply platform specific cosmetics\n    # to it...\n    system, node, release, version, machine, processor = uname()\n    if machine == processor:\n        processor = ''\n    if aliased:\n        system, release, version = system_alias(system, release, version)\n\n    if system == 'Darwin':\n        # macOS (darwin kernel)\n        macos_release = mac_ver()[0]\n        if macos_release:\n            system = 'macOS'\n            release = macos_release\n\n    if system == 'Windows':\n        # MS platforms\n        rel, vers, csd, ptype = win32_ver(version)\n        if terse:\n            platform = _platform(system, release)\n        else:\n            platform = _platform(system, release, version, csd)\n\n    elif system in ('Linux',):\n        # check for libc vs. glibc\n        libcname, libcversion = libc_ver()\n        platform = _platform(system, release, machine, processor,\n                             'with',\n                             libcname+libcversion)\n    elif system == 'Java':\n        # Java platforms\n        r, v, vminfo, (os_name, os_version, os_arch) = java_ver()\n        if terse or not os_name:\n            platform = _platform(system, release, version)\n        else:\n            platform = _platform(system, release, version,\n                                 'on',\n                                 os_name, os_version, os_arch)\n\n    else:\n        # Generic handler\n        if terse:\n            platform = _platform(system, release)\n        else:\n            bits, linkage = architecture(sys.executable)\n            platform = _platform(system, release, machine,\n                                 processor, bits, linkage)\n\n    _platform_cache[(aliased, terse)] = platform\n    return platform\n\n### Command line interface\n\nif __name__ == '__main__':\n    # Default is to print the aliased verbose platform string\n    terse = ('terse' in sys.argv or '--terse' in sys.argv)\n    aliased = (not 'nonaliased' in sys.argv and not '--nonaliased' in sys.argv)\n    print(platform(aliased, terse))\n    sys.exit(0)\n", 1268], "/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py": ["# subprocess - Subprocesses with accessible I/O streams\n#\n# For more information about this module, see PEP 324.\n#\n# Copyright (c) 2003-2005 by Peter Astrand <astrand@lysator.liu.se>\n#\n# Licensed to PSF under a Contributor Agreement.\n# See http://www.python.org/2.4/license for licensing details.\n\nr\"\"\"Subprocesses with accessible I/O streams\n\nThis module allows you to spawn processes, connect to their\ninput/output/error pipes, and obtain their return codes.\n\nFor a complete description of this module see the Python documentation.\n\nMain API\n========\nrun(...): Runs a command, waits for it to complete, then returns a\n          CompletedProcess instance.\nPopen(...): A class for flexibly executing a command in a new process\n\nConstants\n---------\nDEVNULL: Special value that indicates that os.devnull should be used\nPIPE:    Special value that indicates a pipe should be created\nSTDOUT:  Special value that indicates that stderr should go to stdout\n\n\nOlder API\n=========\ncall(...): Runs a command, waits for it to complete, then returns\n    the return code.\ncheck_call(...): Same as call() but raises CalledProcessError()\n    if return code is not 0\ncheck_output(...): Same as check_call() but returns the contents of\n    stdout instead of a return code\ngetoutput(...): Runs a command in the shell, waits for it to complete,\n    then returns the output\ngetstatusoutput(...): Runs a command in the shell, waits for it to complete,\n    then returns a (exitcode, output) tuple\n\"\"\"\n\nimport builtins\nimport errno\nimport io\nimport os\nimport time\nimport signal\nimport sys\nimport threading\nimport warnings\nimport contextlib\nfrom time import monotonic as _time\nimport types\n\ntry:\n    import pwd\nexcept ImportError:\n    pwd = None\ntry:\n    import grp\nexcept ImportError:\n    grp = None\n\n__all__ = [\"Popen\", \"PIPE\", \"STDOUT\", \"call\", \"check_call\", \"getstatusoutput\",\n           \"getoutput\", \"check_output\", \"run\", \"CalledProcessError\", \"DEVNULL\",\n           \"SubprocessError\", \"TimeoutExpired\", \"CompletedProcess\"]\n           # NOTE: We intentionally exclude list2cmdline as it is\n           # considered an internal implementation detail.  issue10838.\n\ntry:\n    import msvcrt\n    import _winapi\n    _mswindows = True\nexcept ModuleNotFoundError:\n    _mswindows = False\n    import _posixsubprocess\n    import select\n    import selectors\nelse:\n    from _winapi import (CREATE_NEW_CONSOLE, CREATE_NEW_PROCESS_GROUP,\n                         STD_INPUT_HANDLE, STD_OUTPUT_HANDLE,\n                         STD_ERROR_HANDLE, SW_HIDE,\n                         STARTF_USESTDHANDLES, STARTF_USESHOWWINDOW,\n                         ABOVE_NORMAL_PRIORITY_CLASS, BELOW_NORMAL_PRIORITY_CLASS,\n                         HIGH_PRIORITY_CLASS, IDLE_PRIORITY_CLASS,\n                         NORMAL_PRIORITY_CLASS, REALTIME_PRIORITY_CLASS,\n                         CREATE_NO_WINDOW, DETACHED_PROCESS,\n                         CREATE_DEFAULT_ERROR_MODE, CREATE_BREAKAWAY_FROM_JOB)\n\n    __all__.extend([\"CREATE_NEW_CONSOLE\", \"CREATE_NEW_PROCESS_GROUP\",\n                    \"STD_INPUT_HANDLE\", \"STD_OUTPUT_HANDLE\",\n                    \"STD_ERROR_HANDLE\", \"SW_HIDE\",\n                    \"STARTF_USESTDHANDLES\", \"STARTF_USESHOWWINDOW\",\n                    \"STARTUPINFO\",\n                    \"ABOVE_NORMAL_PRIORITY_CLASS\", \"BELOW_NORMAL_PRIORITY_CLASS\",\n                    \"HIGH_PRIORITY_CLASS\", \"IDLE_PRIORITY_CLASS\",\n                    \"NORMAL_PRIORITY_CLASS\", \"REALTIME_PRIORITY_CLASS\",\n                    \"CREATE_NO_WINDOW\", \"DETACHED_PROCESS\",\n                    \"CREATE_DEFAULT_ERROR_MODE\", \"CREATE_BREAKAWAY_FROM_JOB\"])\n\n\n# Exception classes used by this module.\nclass SubprocessError(Exception): pass\n\n\nclass CalledProcessError(SubprocessError):\n    \"\"\"Raised when run() is called with check=True and the process\n    returns a non-zero exit status.\n\n    Attributes:\n      cmd, returncode, stdout, stderr, output\n    \"\"\"\n    def __init__(self, returncode, cmd, output=None, stderr=None):\n        self.returncode = returncode\n        self.cmd = cmd\n        self.output = output\n        self.stderr = stderr\n\n    def __str__(self):\n        if self.returncode and self.returncode < 0:\n            try:\n                return \"Command '%s' died with %r.\" % (\n                        self.cmd, signal.Signals(-self.returncode))\n            except ValueError:\n                return \"Command '%s' died with unknown signal %d.\" % (\n                        self.cmd, -self.returncode)\n        else:\n            return \"Command '%s' returned non-zero exit status %d.\" % (\n                    self.cmd, self.returncode)\n\n    @property\n    def stdout(self):\n        \"\"\"Alias for output attribute, to match stderr\"\"\"\n        return self.output\n\n    @stdout.setter\n    def stdout(self, value):\n        # There's no obvious reason to set this, but allow it anyway so\n        # .stdout is a transparent alias for .output\n        self.output = value\n\n\nclass TimeoutExpired(SubprocessError):\n    \"\"\"This exception is raised when the timeout expires while waiting for a\n    child process.\n\n    Attributes:\n        cmd, output, stdout, stderr, timeout\n    \"\"\"\n    def __init__(self, cmd, timeout, output=None, stderr=None):\n        self.cmd = cmd\n        self.timeout = timeout\n        self.output = output\n        self.stderr = stderr\n\n    def __str__(self):\n        return (\"Command '%s' timed out after %s seconds\" %\n                (self.cmd, self.timeout))\n\n    @property\n    def stdout(self):\n        return self.output\n\n    @stdout.setter\n    def stdout(self, value):\n        # There's no obvious reason to set this, but allow it anyway so\n        # .stdout is a transparent alias for .output\n        self.output = value\n\n\nif _mswindows:\n    class STARTUPINFO:\n        def __init__(self, *, dwFlags=0, hStdInput=None, hStdOutput=None,\n                     hStdError=None, wShowWindow=0, lpAttributeList=None):\n            self.dwFlags = dwFlags\n            self.hStdInput = hStdInput\n            self.hStdOutput = hStdOutput\n            self.hStdError = hStdError\n            self.wShowWindow = wShowWindow\n            self.lpAttributeList = lpAttributeList or {\"handle_list\": []}\n\n        def copy(self):\n            attr_list = self.lpAttributeList.copy()\n            if 'handle_list' in attr_list:\n                attr_list['handle_list'] = list(attr_list['handle_list'])\n\n            return STARTUPINFO(dwFlags=self.dwFlags,\n                               hStdInput=self.hStdInput,\n                               hStdOutput=self.hStdOutput,\n                               hStdError=self.hStdError,\n                               wShowWindow=self.wShowWindow,\n                               lpAttributeList=attr_list)\n\n\n    class Handle(int):\n        closed = False\n\n        def Close(self, CloseHandle=_winapi.CloseHandle):\n            if not self.closed:\n                self.closed = True\n                CloseHandle(self)\n\n        def Detach(self):\n            if not self.closed:\n                self.closed = True\n                return int(self)\n            raise ValueError(\"already closed\")\n\n        def __repr__(self):\n            return \"%s(%d)\" % (self.__class__.__name__, int(self))\n\n        __del__ = Close\nelse:\n    # When select or poll has indicated that the file is writable,\n    # we can write up to _PIPE_BUF bytes without risk of blocking.\n    # POSIX defines PIPE_BUF as >= 512.\n    _PIPE_BUF = getattr(select, 'PIPE_BUF', 512)\n\n    # poll/select have the advantage of not requiring any extra file\n    # descriptor, contrarily to epoll/kqueue (also, they require a single\n    # syscall).\n    if hasattr(selectors, 'PollSelector'):\n        _PopenSelector = selectors.PollSelector\n    else:\n        _PopenSelector = selectors.SelectSelector\n\n\nif _mswindows:\n    # On Windows we just need to close `Popen._handle` when we no longer need\n    # it, so that the kernel can free it. `Popen._handle` gets closed\n    # implicitly when the `Popen` instance is finalized (see `Handle.__del__`,\n    # which is calling `CloseHandle` as requested in [1]), so there is nothing\n    # for `_cleanup` to do.\n    #\n    # [1] https://docs.microsoft.com/en-us/windows/desktop/ProcThread/\n    # creating-processes\n    _active = None\n\n    def _cleanup():\n        pass\nelse:\n    # This lists holds Popen instances for which the underlying process had not\n    # exited at the time its __del__ method got called: those processes are\n    # wait()ed for synchronously from _cleanup() when a new Popen object is\n    # created, to avoid zombie processes.\n    _active = []\n\n    def _cleanup():\n        if _active is None:\n            return\n        for inst in _active[:]:\n            res = inst._internal_poll(_deadstate=sys.maxsize)\n            if res is not None:\n                try:\n                    _active.remove(inst)\n                except ValueError:\n                    # This can happen if two threads create a new Popen instance.\n                    # It's harmless that it was already removed, so ignore.\n                    pass\n\nPIPE = -1\nSTDOUT = -2\nDEVNULL = -3\n\n\n# XXX This function is only used by multiprocessing and the test suite,\n# but it's here so that it can be imported when Python is compiled without\n# threads.\n\ndef _optim_args_from_interpreter_flags():\n    \"\"\"Return a list of command-line arguments reproducing the current\n    optimization settings in sys.flags.\"\"\"\n    args = []\n    value = sys.flags.optimize\n    if value > 0:\n        args.append('-' + 'O' * value)\n    return args\n\n\ndef _args_from_interpreter_flags():\n    \"\"\"Return a list of command-line arguments reproducing the current\n    settings in sys.flags, sys.warnoptions and sys._xoptions.\"\"\"\n    flag_opt_map = {\n        'debug': 'd',\n        # 'inspect': 'i',\n        # 'interactive': 'i',\n        'dont_write_bytecode': 'B',\n        'no_site': 'S',\n        'verbose': 'v',\n        'bytes_warning': 'b',\n        'quiet': 'q',\n        # -O is handled in _optim_args_from_interpreter_flags()\n    }\n    args = _optim_args_from_interpreter_flags()\n    for flag, opt in flag_opt_map.items():\n        v = getattr(sys.flags, flag)\n        if v > 0:\n            args.append('-' + opt * v)\n\n    if sys.flags.isolated:\n        args.append('-I')\n    else:\n        if sys.flags.ignore_environment:\n            args.append('-E')\n        if sys.flags.no_user_site:\n            args.append('-s')\n\n    # -W options\n    warnopts = sys.warnoptions[:]\n    bytes_warning = sys.flags.bytes_warning\n    xoptions = getattr(sys, '_xoptions', {})\n    dev_mode = ('dev' in xoptions)\n\n    if bytes_warning > 1:\n        warnopts.remove(\"error::BytesWarning\")\n    elif bytes_warning:\n        warnopts.remove(\"default::BytesWarning\")\n    if dev_mode:\n        warnopts.remove('default')\n    for opt in warnopts:\n        args.append('-W' + opt)\n\n    # -X options\n    if dev_mode:\n        args.extend(('-X', 'dev'))\n    for opt in ('faulthandler', 'tracemalloc', 'importtime',\n                'showrefcount', 'utf8', 'oldparser'):\n        if opt in xoptions:\n            value = xoptions[opt]\n            if value is True:\n                arg = opt\n            else:\n                arg = '%s=%s' % (opt, value)\n            args.extend(('-X', arg))\n\n    return args\n\n\ndef call(*popenargs, timeout=None, **kwargs):\n    \"\"\"Run command with arguments.  Wait for command to complete or\n    timeout, then return the returncode attribute.\n\n    The arguments are the same as for the Popen constructor.  Example:\n\n    retcode = call([\"ls\", \"-l\"])\n    \"\"\"\n    with Popen(*popenargs, **kwargs) as p:\n        try:\n            return p.wait(timeout=timeout)\n        except:  # Including KeyboardInterrupt, wait handled that.\n            p.kill()\n            # We don't call p.wait() again as p.__exit__ does that for us.\n            raise\n\n\ndef check_call(*popenargs, **kwargs):\n    \"\"\"Run command with arguments.  Wait for command to complete.  If\n    the exit code was zero then return, otherwise raise\n    CalledProcessError.  The CalledProcessError object will have the\n    return code in the returncode attribute.\n\n    The arguments are the same as for the call function.  Example:\n\n    check_call([\"ls\", \"-l\"])\n    \"\"\"\n    retcode = call(*popenargs, **kwargs)\n    if retcode:\n        cmd = kwargs.get(\"args\")\n        if cmd is None:\n            cmd = popenargs[0]\n        raise CalledProcessError(retcode, cmd)\n    return 0\n\n\ndef check_output(*popenargs, timeout=None, **kwargs):\n    r\"\"\"Run command with arguments and return its output.\n\n    If the exit code was non-zero it raises a CalledProcessError.  The\n    CalledProcessError object will have the return code in the returncode\n    attribute and output in the output attribute.\n\n    The arguments are the same as for the Popen constructor.  Example:\n\n    >>> check_output([\"ls\", \"-l\", \"/dev/null\"])\n    b'crw-rw-rw- 1 root root 1, 3 Oct 18  2007 /dev/null\\n'\n\n    The stdout argument is not allowed as it is used internally.\n    To capture standard error in the result, use stderr=STDOUT.\n\n    >>> check_output([\"/bin/sh\", \"-c\",\n    ...               \"ls -l non_existent_file ; exit 0\"],\n    ...              stderr=STDOUT)\n    b'ls: non_existent_file: No such file or directory\\n'\n\n    There is an additional optional argument, \"input\", allowing you to\n    pass a string to the subprocess's stdin.  If you use this argument\n    you may not also use the Popen constructor's \"stdin\" argument, as\n    it too will be used internally.  Example:\n\n    >>> check_output([\"sed\", \"-e\", \"s/foo/bar/\"],\n    ...              input=b\"when in the course of fooman events\\n\")\n    b'when in the course of barman events\\n'\n\n    By default, all communication is in bytes, and therefore any \"input\"\n    should be bytes, and the return value will be bytes.  If in text mode,\n    any \"input\" should be a string, and the return value will be a string\n    decoded according to locale encoding, or by \"encoding\" if set. Text mode\n    is triggered by setting any of text, encoding, errors or universal_newlines.\n    \"\"\"\n    if 'stdout' in kwargs:\n        raise ValueError('stdout argument not allowed, it will be overridden.')\n\n    if 'input' in kwargs and kwargs['input'] is None:\n        # Explicitly passing input=None was previously equivalent to passing an\n        # empty string. That is maintained here for backwards compatibility.\n        if kwargs.get('universal_newlines') or kwargs.get('text'):\n            empty = ''\n        else:\n            empty = b''\n        kwargs['input'] = empty\n\n    return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n               **kwargs).stdout\n\n\nclass CompletedProcess(object):\n    \"\"\"A process that has finished running.\n\n    This is returned by run().\n\n    Attributes:\n      args: The list or str args passed to run().\n      returncode: The exit code of the process, negative for signals.\n      stdout: The standard output (None if not captured).\n      stderr: The standard error (None if not captured).\n    \"\"\"\n    def __init__(self, args, returncode, stdout=None, stderr=None):\n        self.args = args\n        self.returncode = returncode\n        self.stdout = stdout\n        self.stderr = stderr\n\n    def __repr__(self):\n        args = ['args={!r}'.format(self.args),\n                'returncode={!r}'.format(self.returncode)]\n        if self.stdout is not None:\n            args.append('stdout={!r}'.format(self.stdout))\n        if self.stderr is not None:\n            args.append('stderr={!r}'.format(self.stderr))\n        return \"{}({})\".format(type(self).__name__, ', '.join(args))\n\n    __class_getitem__ = classmethod(types.GenericAlias)\n\n\n    def check_returncode(self):\n        \"\"\"Raise CalledProcessError if the exit code is non-zero.\"\"\"\n        if self.returncode:\n            raise CalledProcessError(self.returncode, self.args, self.stdout,\n                                     self.stderr)\n\n\ndef run(*popenargs,\n        input=None, capture_output=False, timeout=None, check=False, **kwargs):\n    \"\"\"Run command with arguments and return a CompletedProcess instance.\n\n    The returned instance will have attributes args, returncode, stdout and\n    stderr. By default, stdout and stderr are not captured, and those attributes\n    will be None. Pass stdout=PIPE and/or stderr=PIPE in order to capture them.\n\n    If check is True and the exit code was non-zero, it raises a\n    CalledProcessError. The CalledProcessError object will have the return code\n    in the returncode attribute, and output & stderr attributes if those streams\n    were captured.\n\n    If timeout is given, and the process takes too long, a TimeoutExpired\n    exception will be raised.\n\n    There is an optional argument \"input\", allowing you to\n    pass bytes or a string to the subprocess's stdin.  If you use this argument\n    you may not also use the Popen constructor's \"stdin\" argument, as\n    it will be used internally.\n\n    By default, all communication is in bytes, and therefore any \"input\" should\n    be bytes, and the stdout and stderr will be bytes. If in text mode, any\n    \"input\" should be a string, and stdout and stderr will be strings decoded\n    according to locale encoding, or by \"encoding\" if set. Text mode is\n    triggered by setting any of text, encoding, errors or universal_newlines.\n\n    The other arguments are the same as for the Popen constructor.\n    \"\"\"\n    if input is not None:\n        if kwargs.get('stdin') is not None:\n            raise ValueError('stdin and input arguments may not both be used.')\n        kwargs['stdin'] = PIPE\n\n    if capture_output:\n        if kwargs.get('stdout') is not None or kwargs.get('stderr') is not None:\n            raise ValueError('stdout and stderr arguments may not be used '\n                             'with capture_output.')\n        kwargs['stdout'] = PIPE\n        kwargs['stderr'] = PIPE\n\n    with Popen(*popenargs, **kwargs) as process:\n        try:\n            stdout, stderr = process.communicate(input, timeout=timeout)\n        except TimeoutExpired as exc:\n            process.kill()\n            if _mswindows:\n                # Windows accumulates the output in a single blocking\n                # read() call run on child threads, with the timeout\n                # being done in a join() on those threads.  communicate()\n                # _after_ kill() is required to collect that and add it\n                # to the exception.\n                exc.stdout, exc.stderr = process.communicate()\n            else:\n                # POSIX _communicate already populated the output so\n                # far into the TimeoutExpired exception.\n                process.wait()\n            raise\n        except:  # Including KeyboardInterrupt, communicate handled that.\n            process.kill()\n            # We don't call process.wait() as .__exit__ does that for us.\n            raise\n        retcode = process.poll()\n        if check and retcode:\n            raise CalledProcessError(retcode, process.args,\n                                     output=stdout, stderr=stderr)\n    return CompletedProcess(process.args, retcode, stdout, stderr)\n\n\ndef list2cmdline(seq):\n    \"\"\"\n    Translate a sequence of arguments into a command line\n    string, using the same rules as the MS C runtime:\n\n    1) Arguments are delimited by white space, which is either a\n       space or a tab.\n\n    2) A string surrounded by double quotation marks is\n       interpreted as a single argument, regardless of white space\n       contained within.  A quoted string can be embedded in an\n       argument.\n\n    3) A double quotation mark preceded by a backslash is\n       interpreted as a literal double quotation mark.\n\n    4) Backslashes are interpreted literally, unless they\n       immediately precede a double quotation mark.\n\n    5) If backslashes immediately precede a double quotation mark,\n       every pair of backslashes is interpreted as a literal\n       backslash.  If the number of backslashes is odd, the last\n       backslash escapes the next double quotation mark as\n       described in rule 3.\n    \"\"\"\n\n    # See\n    # http://msdn.microsoft.com/en-us/library/17w5ykft.aspx\n    # or search http://msdn.microsoft.com for\n    # \"Parsing C++ Command-Line Arguments\"\n    result = []\n    needquote = False\n    for arg in map(os.fsdecode, seq):\n        bs_buf = []\n\n        # Add a space to separate this argument from the others\n        if result:\n            result.append(' ')\n\n        needquote = (\" \" in arg) or (\"\\t\" in arg) or not arg\n        if needquote:\n            result.append('\"')\n\n        for c in arg:\n            if c == '\\\\':\n                # Don't know if we need to double yet.\n                bs_buf.append(c)\n            elif c == '\"':\n                # Double backslashes.\n                result.append('\\\\' * len(bs_buf)*2)\n                bs_buf = []\n                result.append('\\\\\"')\n            else:\n                # Normal char\n                if bs_buf:\n                    result.extend(bs_buf)\n                    bs_buf = []\n                result.append(c)\n\n        # Add remaining backslashes, if any.\n        if bs_buf:\n            result.extend(bs_buf)\n\n        if needquote:\n            result.extend(bs_buf)\n            result.append('\"')\n\n    return ''.join(result)\n\n\n# Various tools for executing commands and looking at their output and status.\n#\n\ndef getstatusoutput(cmd):\n    \"\"\"Return (exitcode, output) of executing cmd in a shell.\n\n    Execute the string 'cmd' in a shell with 'check_output' and\n    return a 2-tuple (status, output). The locale encoding is used\n    to decode the output and process newlines.\n\n    A trailing newline is stripped from the output.\n    The exit status for the command can be interpreted\n    according to the rules for the function 'wait'. Example:\n\n    >>> import subprocess\n    >>> subprocess.getstatusoutput('ls /bin/ls')\n    (0, '/bin/ls')\n    >>> subprocess.getstatusoutput('cat /bin/junk')\n    (1, 'cat: /bin/junk: No such file or directory')\n    >>> subprocess.getstatusoutput('/bin/junk')\n    (127, 'sh: /bin/junk: not found')\n    >>> subprocess.getstatusoutput('/bin/kill $$')\n    (-15, '')\n    \"\"\"\n    try:\n        data = check_output(cmd, shell=True, text=True, stderr=STDOUT)\n        exitcode = 0\n    except CalledProcessError as ex:\n        data = ex.output\n        exitcode = ex.returncode\n    if data[-1:] == '\\n':\n        data = data[:-1]\n    return exitcode, data\n\ndef getoutput(cmd):\n    \"\"\"Return output (stdout or stderr) of executing cmd in a shell.\n\n    Like getstatusoutput(), except the exit status is ignored and the return\n    value is a string containing the command's output.  Example:\n\n    >>> import subprocess\n    >>> subprocess.getoutput('ls /bin/ls')\n    '/bin/ls'\n    \"\"\"\n    return getstatusoutput(cmd)[1]\n\n\ndef _use_posix_spawn():\n    \"\"\"Check if posix_spawn() can be used for subprocess.\n\n    subprocess requires a posix_spawn() implementation that properly reports\n    errors to the parent process, & sets errno on the following failures:\n\n    * Process attribute actions failed.\n    * File actions failed.\n    * exec() failed.\n\n    Prefer an implementation which can use vfork() in some cases for best\n    performance.\n    \"\"\"\n    if _mswindows or not hasattr(os, 'posix_spawn'):\n        # os.posix_spawn() is not available\n        return False\n\n    if sys.platform == 'darwin':\n        # posix_spawn() is a syscall on macOS and properly reports errors\n        return True\n\n    # Check libc name and runtime libc version\n    try:\n        ver = os.confstr('CS_GNU_LIBC_VERSION')\n        # parse 'glibc 2.28' as ('glibc', (2, 28))\n        parts = ver.split(maxsplit=1)\n        if len(parts) != 2:\n            # reject unknown format\n            raise ValueError\n        libc = parts[0]\n        version = tuple(map(int, parts[1].split('.')))\n\n        if sys.platform == 'linux' and libc == 'glibc' and version >= (2, 24):\n            # glibc 2.24 has a new Linux posix_spawn implementation using vfork\n            # which properly reports errors to the parent process.\n            return True\n        # Note: Don't use the implementation in earlier glibc because it doesn't\n        # use vfork (even if glibc 2.26 added a pipe to properly report errors\n        # to the parent process).\n    except (AttributeError, ValueError, OSError):\n        # os.confstr() or CS_GNU_LIBC_VERSION value not available\n        pass\n\n    # By default, assume that posix_spawn() does not properly report errors.\n    return False\n\n\n_USE_POSIX_SPAWN = _use_posix_spawn()\n\n\nclass Popen(object):\n    \"\"\" Execute a child program in a new process.\n\n    For a complete description of the arguments see the Python documentation.\n\n    Arguments:\n      args: A string, or a sequence of program arguments.\n\n      bufsize: supplied as the buffering argument to the open() function when\n          creating the stdin/stdout/stderr pipe file objects\n\n      executable: A replacement program to execute.\n\n      stdin, stdout and stderr: These specify the executed programs' standard\n          input, standard output and standard error file handles, respectively.\n\n      preexec_fn: (POSIX only) An object to be called in the child process\n          just before the child is executed.\n\n      close_fds: Controls closing or inheriting of file descriptors.\n\n      shell: If true, the command will be executed through the shell.\n\n      cwd: Sets the current directory before the child is executed.\n\n      env: Defines the environment variables for the new process.\n\n      text: If true, decode stdin, stdout and stderr using the given encoding\n          (if set) or the system default otherwise.\n\n      universal_newlines: Alias of text, provided for backwards compatibility.\n\n      startupinfo and creationflags (Windows only)\n\n      restore_signals (POSIX only)\n\n      start_new_session (POSIX only)\n\n      group (POSIX only)\n\n      extra_groups (POSIX only)\n\n      user (POSIX only)\n\n      umask (POSIX only)\n\n      pass_fds (POSIX only)\n\n      encoding and errors: Text mode encoding and error handling to use for\n          file objects stdin, stdout and stderr.\n\n    Attributes:\n        stdin, stdout, stderr, pid, returncode\n    \"\"\"\n    _child_created = False  # Set here since __del__ checks it\n\n    def __init__(self, args, bufsize=-1, executable=None,\n                 stdin=None, stdout=None, stderr=None,\n                 preexec_fn=None, close_fds=True,\n                 shell=False, cwd=None, env=None, universal_newlines=None,\n                 startupinfo=None, creationflags=0,\n                 restore_signals=True, start_new_session=False,\n                 pass_fds=(), *, user=None, group=None, extra_groups=None,\n                 encoding=None, errors=None, text=None, umask=-1):\n        \"\"\"Create new Popen instance.\"\"\"\n        _cleanup()\n        # Held while anything is calling waitpid before returncode has been\n        # updated to prevent clobbering returncode if wait() or poll() are\n        # called from multiple threads at once.  After acquiring the lock,\n        # code must re-check self.returncode to see if another thread just\n        # finished a waitpid() call.\n        self._waitpid_lock = threading.Lock()\n\n        self._input = None\n        self._communication_started = False\n        if bufsize is None:\n            bufsize = -1  # Restore default\n        if not isinstance(bufsize, int):\n            raise TypeError(\"bufsize must be an integer\")\n\n        if _mswindows:\n            if preexec_fn is not None:\n                raise ValueError(\"preexec_fn is not supported on Windows \"\n                                 \"platforms\")\n        else:\n            # POSIX\n            if pass_fds and not close_fds:\n                warnings.warn(\"pass_fds overriding close_fds.\", RuntimeWarning)\n                close_fds = True\n            if startupinfo is not None:\n                raise ValueError(\"startupinfo is only supported on Windows \"\n                                 \"platforms\")\n            if creationflags != 0:\n                raise ValueError(\"creationflags is only supported on Windows \"\n                                 \"platforms\")\n\n        self.args = args\n        self.stdin = None\n        self.stdout = None\n        self.stderr = None\n        self.pid = None\n        self.returncode = None\n        self.encoding = encoding\n        self.errors = errors\n\n        # Validate the combinations of text and universal_newlines\n        if (text is not None and universal_newlines is not None\n            and bool(universal_newlines) != bool(text)):\n            raise SubprocessError('Cannot disambiguate when both text '\n                                  'and universal_newlines are supplied but '\n                                  'different. Pass one or the other.')\n\n        # Input and output objects. The general principle is like\n        # this:\n        #\n        # Parent                   Child\n        # ------                   -----\n        # p2cwrite   ---stdin--->  p2cread\n        # c2pread    <--stdout---  c2pwrite\n        # errread    <--stderr---  errwrite\n        #\n        # On POSIX, the child objects are file descriptors.  On\n        # Windows, these are Windows file handles.  The parent objects\n        # are file descriptors on both platforms.  The parent objects\n        # are -1 when not using PIPEs. The child objects are -1\n        # when not redirecting.\n\n        (p2cread, p2cwrite,\n         c2pread, c2pwrite,\n         errread, errwrite) = self._get_handles(stdin, stdout, stderr)\n\n        # We wrap OS handles *before* launching the child, otherwise a\n        # quickly terminating child could make our fds unwrappable\n        # (see #8458).\n\n        if _mswindows:\n            if p2cwrite != -1:\n                p2cwrite = msvcrt.open_osfhandle(p2cwrite.Detach(), 0)\n            if c2pread != -1:\n                c2pread = msvcrt.open_osfhandle(c2pread.Detach(), 0)\n            if errread != -1:\n                errread = msvcrt.open_osfhandle(errread.Detach(), 0)\n\n        self.text_mode = encoding or errors or text or universal_newlines\n\n        # How long to resume waiting on a child after the first ^C.\n        # There is no right value for this.  The purpose is to be polite\n        # yet remain good for interactive users trying to exit a tool.\n        self._sigint_wait_secs = 0.25  # 1/xkcd221.getRandomNumber()\n\n        self._closed_child_pipe_fds = False\n\n        if self.text_mode:\n            if bufsize == 1:\n                line_buffering = True\n                # Use the default buffer size for the underlying binary streams\n                # since they don't support line buffering.\n                bufsize = -1\n            else:\n                line_buffering = False\n\n        gid = None\n        if group is not None:\n            if not hasattr(os, 'setregid'):\n                raise ValueError(\"The 'group' parameter is not supported on the \"\n                                 \"current platform\")\n\n            elif isinstance(group, str):\n                if grp is None:\n                    raise ValueError(\"The group parameter cannot be a string \"\n                                     \"on systems without the grp module\")\n\n                gid = grp.getgrnam(group).gr_gid\n            elif isinstance(group, int):\n                gid = group\n            else:\n                raise TypeError(\"Group must be a string or an integer, not {}\"\n                                .format(type(group)))\n\n            if gid < 0:\n                raise ValueError(f\"Group ID cannot be negative, got {gid}\")\n\n        gids = None\n        if extra_groups is not None:\n            if not hasattr(os, 'setgroups'):\n                raise ValueError(\"The 'extra_groups' parameter is not \"\n                                 \"supported on the current platform\")\n\n            elif isinstance(extra_groups, str):\n                raise ValueError(\"Groups must be a list, not a string\")\n\n            gids = []\n            for extra_group in extra_groups:\n                if isinstance(extra_group, str):\n                    if grp is None:\n                        raise ValueError(\"Items in extra_groups cannot be \"\n                                         \"strings on systems without the \"\n                                         \"grp module\")\n\n                    gids.append(grp.getgrnam(extra_group).gr_gid)\n                elif isinstance(extra_group, int):\n                    gids.append(extra_group)\n                else:\n                    raise TypeError(\"Items in extra_groups must be a string \"\n                                    \"or integer, not {}\"\n                                    .format(type(extra_group)))\n\n            # make sure that the gids are all positive here so we can do less\n            # checking in the C code\n            for gid_check in gids:\n                if gid_check < 0:\n                    raise ValueError(f\"Group ID cannot be negative, got {gid_check}\")\n\n        uid = None\n        if user is not None:\n            if not hasattr(os, 'setreuid'):\n                raise ValueError(\"The 'user' parameter is not supported on \"\n                                 \"the current platform\")\n\n            elif isinstance(user, str):\n                if pwd is None:\n                    raise ValueError(\"The user parameter cannot be a string \"\n                                     \"on systems without the pwd module\")\n\n                uid = pwd.getpwnam(user).pw_uid\n            elif isinstance(user, int):\n                uid = user\n            else:\n                raise TypeError(\"User must be a string or an integer\")\n\n            if uid < 0:\n                raise ValueError(f\"User ID cannot be negative, got {uid}\")\n\n        try:\n            if p2cwrite != -1:\n                self.stdin = io.open(p2cwrite, 'wb', bufsize)\n                if self.text_mode:\n                    self.stdin = io.TextIOWrapper(self.stdin, write_through=True,\n                            line_buffering=line_buffering,\n                            encoding=encoding, errors=errors)\n            if c2pread != -1:\n                self.stdout = io.open(c2pread, 'rb', bufsize)\n                if self.text_mode:\n                    self.stdout = io.TextIOWrapper(self.stdout,\n                            encoding=encoding, errors=errors)\n            if errread != -1:\n                self.stderr = io.open(errread, 'rb', bufsize)\n                if self.text_mode:\n                    self.stderr = io.TextIOWrapper(self.stderr,\n                            encoding=encoding, errors=errors)\n\n            self._execute_child(args, executable, preexec_fn, close_fds,\n                                pass_fds, cwd, env,\n                                startupinfo, creationflags, shell,\n                                p2cread, p2cwrite,\n                                c2pread, c2pwrite,\n                                errread, errwrite,\n                                restore_signals,\n                                gid, gids, uid, umask,\n                                start_new_session)\n        except:\n            # Cleanup if the child failed starting.\n            for f in filter(None, (self.stdin, self.stdout, self.stderr)):\n                try:\n                    f.close()\n                except OSError:\n                    pass  # Ignore EBADF or other errors.\n\n            if not self._closed_child_pipe_fds:\n                to_close = []\n                if stdin == PIPE:\n                    to_close.append(p2cread)\n                if stdout == PIPE:\n                    to_close.append(c2pwrite)\n                if stderr == PIPE:\n                    to_close.append(errwrite)\n                if hasattr(self, '_devnull'):\n                    to_close.append(self._devnull)\n                for fd in to_close:\n                    try:\n                        if _mswindows and isinstance(fd, Handle):\n                            fd.Close()\n                        else:\n                            os.close(fd)\n                    except OSError:\n                        pass\n\n            raise\n\n    def __repr__(self):\n        obj_repr = (\n            f\"<{self.__class__.__name__}: \"\n            f\"returncode: {self.returncode} args: {self.args!r}>\"\n        )\n        if len(obj_repr) > 80:\n            obj_repr = obj_repr[:76] + \"...>\"\n        return obj_repr\n\n    __class_getitem__ = classmethod(types.GenericAlias)\n\n    @property\n    def universal_newlines(self):\n        # universal_newlines as retained as an alias of text_mode for API\n        # compatibility. bpo-31756\n        return self.text_mode\n\n    @universal_newlines.setter\n    def universal_newlines(self, universal_newlines):\n        self.text_mode = bool(universal_newlines)\n\n    def _translate_newlines(self, data, encoding, errors):\n        data = data.decode(encoding, errors)\n        return data.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, value, traceback):\n        if self.stdout:\n            self.stdout.close()\n        if self.stderr:\n            self.stderr.close()\n        try:  # Flushing a BufferedWriter may raise an error\n            if self.stdin:\n                self.stdin.close()\n        finally:\n            if exc_type == KeyboardInterrupt:\n                # https://bugs.python.org/issue25942\n                # In the case of a KeyboardInterrupt we assume the SIGINT\n                # was also already sent to our child processes.  We can't\n                # block indefinitely as that is not user friendly.\n                # If we have not already waited a brief amount of time in\n                # an interrupted .wait() or .communicate() call, do so here\n                # for consistency.\n                if self._sigint_wait_secs > 0:\n                    try:\n                        self._wait(timeout=self._sigint_wait_secs)\n                    except TimeoutExpired:\n                        pass\n                self._sigint_wait_secs = 0  # Note that this has been done.\n                return  # resume the KeyboardInterrupt\n\n            # Wait for the process to terminate, to avoid zombies.\n            self.wait()\n\n    def __del__(self, _maxsize=sys.maxsize, _warn=warnings.warn):\n        if not self._child_created:\n            # We didn't get to successfully create a child process.\n            return\n        if self.returncode is None:\n            # Not reading subprocess exit status creates a zombie process which\n            # is only destroyed at the parent python process exit\n            _warn(\"subprocess %s is still running\" % self.pid,\n                  ResourceWarning, source=self)\n        # In case the child hasn't been waited on, check if it's done.\n        self._internal_poll(_deadstate=_maxsize)\n        if self.returncode is None and _active is not None:\n            # Child is still running, keep us alive until we can wait on it.\n            _active.append(self)\n\n    def _get_devnull(self):\n        if not hasattr(self, '_devnull'):\n            self._devnull = os.open(os.devnull, os.O_RDWR)\n        return self._devnull\n\n    def _stdin_write(self, input):\n        if input:\n            try:\n                self.stdin.write(input)\n            except BrokenPipeError:\n                pass  # communicate() must ignore broken pipe errors.\n            except OSError as exc:\n                if exc.errno == errno.EINVAL:\n                    # bpo-19612, bpo-30418: On Windows, stdin.write() fails\n                    # with EINVAL if the child process exited or if the child\n                    # process is still running but closed the pipe.\n                    pass\n                else:\n                    raise\n\n        try:\n            self.stdin.close()\n        except BrokenPipeError:\n            pass  # communicate() must ignore broken pipe errors.\n        except OSError as exc:\n            if exc.errno == errno.EINVAL:\n                pass\n            else:\n                raise\n\n    def communicate(self, input=None, timeout=None):\n        \"\"\"Interact with process: Send data to stdin and close it.\n        Read data from stdout and stderr, until end-of-file is\n        reached.  Wait for process to terminate.\n\n        The optional \"input\" argument should be data to be sent to the\n        child process, or None, if no data should be sent to the child.\n        communicate() returns a tuple (stdout, stderr).\n\n        By default, all communication is in bytes, and therefore any\n        \"input\" should be bytes, and the (stdout, stderr) will be bytes.\n        If in text mode (indicated by self.text_mode), any \"input\" should\n        be a string, and (stdout, stderr) will be strings decoded\n        according to locale encoding, or by \"encoding\" if set. Text mode\n        is triggered by setting any of text, encoding, errors or\n        universal_newlines.\n        \"\"\"\n\n        if self._communication_started and input:\n            raise ValueError(\"Cannot send input after starting communication\")\n\n        # Optimization: If we are not worried about timeouts, we haven't\n        # started communicating, and we have one or zero pipes, using select()\n        # or threads is unnecessary.\n        if (timeout is None and not self._communication_started and\n            [self.stdin, self.stdout, self.stderr].count(None) >= 2):\n            stdout = None\n            stderr = None\n            if self.stdin:\n                self._stdin_write(input)\n            elif self.stdout:\n                stdout = self.stdout.read()\n                self.stdout.close()\n            elif self.stderr:\n                stderr = self.stderr.read()\n                self.stderr.close()\n            self.wait()\n        else:\n            if timeout is not None:\n                endtime = _time() + timeout\n            else:\n                endtime = None\n\n            try:\n                stdout, stderr = self._communicate(input, endtime, timeout)\n            except KeyboardInterrupt:\n                # https://bugs.python.org/issue25942\n                # See the detailed comment in .wait().\n                if timeout is not None:\n                    sigint_timeout = min(self._sigint_wait_secs,\n                                         self._remaining_time(endtime))\n                else:\n                    sigint_timeout = self._sigint_wait_secs\n                self._sigint_wait_secs = 0  # nothing else should wait.\n                try:\n                    self._wait(timeout=sigint_timeout)\n                except TimeoutExpired:\n                    pass\n                raise  # resume the KeyboardInterrupt\n\n            finally:\n                self._communication_started = True\n\n            sts = self.wait(timeout=self._remaining_time(endtime))\n\n        return (stdout, stderr)\n\n\n    def poll(self):\n        \"\"\"Check if child process has terminated. Set and return returncode\n        attribute.\"\"\"\n        return self._internal_poll()\n\n\n    def _remaining_time(self, endtime):\n        \"\"\"Convenience for _communicate when computing timeouts.\"\"\"\n        if endtime is None:\n            return None\n        else:\n            return endtime - _time()\n\n\n    def _check_timeout(self, endtime, orig_timeout, stdout_seq, stderr_seq,\n                       skip_check_and_raise=False):\n        \"\"\"Convenience for checking if a timeout has expired.\"\"\"\n        if endtime is None:\n            return\n        if skip_check_and_raise or _time() > endtime:\n            raise TimeoutExpired(\n                    self.args, orig_timeout,\n                    output=b''.join(stdout_seq) if stdout_seq else None,\n                    stderr=b''.join(stderr_seq) if stderr_seq else None)\n\n\n    def wait(self, timeout=None):\n        \"\"\"Wait for child process to terminate; returns self.returncode.\"\"\"\n        if timeout is not None:\n            endtime = _time() + timeout\n        try:\n            return self._wait(timeout=timeout)\n        except KeyboardInterrupt:\n            # https://bugs.python.org/issue25942\n            # The first keyboard interrupt waits briefly for the child to\n            # exit under the common assumption that it also received the ^C\n            # generated SIGINT and will exit rapidly.\n            if timeout is not None:\n                sigint_timeout = min(self._sigint_wait_secs,\n                                     self._remaining_time(endtime))\n            else:\n                sigint_timeout = self._sigint_wait_secs\n            self._sigint_wait_secs = 0  # nothing else should wait.\n            try:\n                self._wait(timeout=sigint_timeout)\n            except TimeoutExpired:\n                pass\n            raise  # resume the KeyboardInterrupt\n\n    def _close_pipe_fds(self,\n                        p2cread, p2cwrite,\n                        c2pread, c2pwrite,\n                        errread, errwrite):\n        # self._devnull is not always defined.\n        devnull_fd = getattr(self, '_devnull', None)\n\n        with contextlib.ExitStack() as stack:\n            if _mswindows:\n                if p2cread != -1:\n                    stack.callback(p2cread.Close)\n                if c2pwrite != -1:\n                    stack.callback(c2pwrite.Close)\n                if errwrite != -1:\n                    stack.callback(errwrite.Close)\n            else:\n                if p2cread != -1 and p2cwrite != -1 and p2cread != devnull_fd:\n                    stack.callback(os.close, p2cread)\n                if c2pwrite != -1 and c2pread != -1 and c2pwrite != devnull_fd:\n                    stack.callback(os.close, c2pwrite)\n                if errwrite != -1 and errread != -1 and errwrite != devnull_fd:\n                    stack.callback(os.close, errwrite)\n\n            if devnull_fd is not None:\n                stack.callback(os.close, devnull_fd)\n\n        # Prevent a double close of these handles/fds from __init__ on error.\n        self._closed_child_pipe_fds = True\n\n    if _mswindows:\n        #\n        # Windows methods\n        #\n        def _get_handles(self, stdin, stdout, stderr):\n            \"\"\"Construct and return tuple with IO objects:\n            p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite\n            \"\"\"\n            if stdin is None and stdout is None and stderr is None:\n                return (-1, -1, -1, -1, -1, -1)\n\n            p2cread, p2cwrite = -1, -1\n            c2pread, c2pwrite = -1, -1\n            errread, errwrite = -1, -1\n\n            if stdin is None:\n                p2cread = _winapi.GetStdHandle(_winapi.STD_INPUT_HANDLE)\n                if p2cread is None:\n                    p2cread, _ = _winapi.CreatePipe(None, 0)\n                    p2cread = Handle(p2cread)\n                    _winapi.CloseHandle(_)\n            elif stdin == PIPE:\n                p2cread, p2cwrite = _winapi.CreatePipe(None, 0)\n                p2cread, p2cwrite = Handle(p2cread), Handle(p2cwrite)\n            elif stdin == DEVNULL:\n                p2cread = msvcrt.get_osfhandle(self._get_devnull())\n            elif isinstance(stdin, int):\n                p2cread = msvcrt.get_osfhandle(stdin)\n            else:\n                # Assuming file-like object\n                p2cread = msvcrt.get_osfhandle(stdin.fileno())\n            p2cread = self._make_inheritable(p2cread)\n\n            if stdout is None:\n                c2pwrite = _winapi.GetStdHandle(_winapi.STD_OUTPUT_HANDLE)\n                if c2pwrite is None:\n                    _, c2pwrite = _winapi.CreatePipe(None, 0)\n                    c2pwrite = Handle(c2pwrite)\n                    _winapi.CloseHandle(_)\n            elif stdout == PIPE:\n                c2pread, c2pwrite = _winapi.CreatePipe(None, 0)\n                c2pread, c2pwrite = Handle(c2pread), Handle(c2pwrite)\n            elif stdout == DEVNULL:\n                c2pwrite = msvcrt.get_osfhandle(self._get_devnull())\n            elif isinstance(stdout, int):\n                c2pwrite = msvcrt.get_osfhandle(stdout)\n            else:\n                # Assuming file-like object\n                c2pwrite = msvcrt.get_osfhandle(stdout.fileno())\n            c2pwrite = self._make_inheritable(c2pwrite)\n\n            if stderr is None:\n                errwrite = _winapi.GetStdHandle(_winapi.STD_ERROR_HANDLE)\n                if errwrite is None:\n                    _, errwrite = _winapi.CreatePipe(None, 0)\n                    errwrite = Handle(errwrite)\n                    _winapi.CloseHandle(_)\n            elif stderr == PIPE:\n                errread, errwrite = _winapi.CreatePipe(None, 0)\n                errread, errwrite = Handle(errread), Handle(errwrite)\n            elif stderr == STDOUT:\n                errwrite = c2pwrite\n            elif stderr == DEVNULL:\n                errwrite = msvcrt.get_osfhandle(self._get_devnull())\n            elif isinstance(stderr, int):\n                errwrite = msvcrt.get_osfhandle(stderr)\n            else:\n                # Assuming file-like object\n                errwrite = msvcrt.get_osfhandle(stderr.fileno())\n            errwrite = self._make_inheritable(errwrite)\n\n            return (p2cread, p2cwrite,\n                    c2pread, c2pwrite,\n                    errread, errwrite)\n\n\n        def _make_inheritable(self, handle):\n            \"\"\"Return a duplicate of handle, which is inheritable\"\"\"\n            h = _winapi.DuplicateHandle(\n                _winapi.GetCurrentProcess(), handle,\n                _winapi.GetCurrentProcess(), 0, 1,\n                _winapi.DUPLICATE_SAME_ACCESS)\n            return Handle(h)\n\n\n        def _filter_handle_list(self, handle_list):\n            \"\"\"Filter out console handles that can't be used\n            in lpAttributeList[\"handle_list\"] and make sure the list\n            isn't empty. This also removes duplicate handles.\"\"\"\n            # An handle with it's lowest two bits set might be a special console\n            # handle that if passed in lpAttributeList[\"handle_list\"], will\n            # cause it to fail.\n            return list({handle for handle in handle_list\n                         if handle & 0x3 != 0x3\n                         or _winapi.GetFileType(handle) !=\n                            _winapi.FILE_TYPE_CHAR})\n\n\n        def _execute_child(self, args, executable, preexec_fn, close_fds,\n                           pass_fds, cwd, env,\n                           startupinfo, creationflags, shell,\n                           p2cread, p2cwrite,\n                           c2pread, c2pwrite,\n                           errread, errwrite,\n                           unused_restore_signals,\n                           unused_gid, unused_gids, unused_uid,\n                           unused_umask,\n                           unused_start_new_session):\n            \"\"\"Execute program (MS Windows version)\"\"\"\n\n            assert not pass_fds, \"pass_fds not supported on Windows.\"\n\n            if isinstance(args, str):\n                pass\n            elif isinstance(args, bytes):\n                if shell:\n                    raise TypeError('bytes args is not allowed on Windows')\n                args = list2cmdline([args])\n            elif isinstance(args, os.PathLike):\n                if shell:\n                    raise TypeError('path-like args is not allowed when '\n                                    'shell is true')\n                args = list2cmdline([args])\n            else:\n                args = list2cmdline(args)\n\n            if executable is not None:\n                executable = os.fsdecode(executable)\n\n            # Process startup details\n            if startupinfo is None:\n                startupinfo = STARTUPINFO()\n            else:\n                # bpo-34044: Copy STARTUPINFO since it is modified above,\n                # so the caller can reuse it multiple times.\n                startupinfo = startupinfo.copy()\n\n            use_std_handles = -1 not in (p2cread, c2pwrite, errwrite)\n            if use_std_handles:\n                startupinfo.dwFlags |= _winapi.STARTF_USESTDHANDLES\n                startupinfo.hStdInput = p2cread\n                startupinfo.hStdOutput = c2pwrite\n                startupinfo.hStdError = errwrite\n\n            attribute_list = startupinfo.lpAttributeList\n            have_handle_list = bool(attribute_list and\n                                    \"handle_list\" in attribute_list and\n                                    attribute_list[\"handle_list\"])\n\n            # If we were given an handle_list or need to create one\n            if have_handle_list or (use_std_handles and close_fds):\n                if attribute_list is None:\n                    attribute_list = startupinfo.lpAttributeList = {}\n                handle_list = attribute_list[\"handle_list\"] = \\\n                    list(attribute_list.get(\"handle_list\", []))\n\n                if use_std_handles:\n                    handle_list += [int(p2cread), int(c2pwrite), int(errwrite)]\n\n                handle_list[:] = self._filter_handle_list(handle_list)\n\n                if handle_list:\n                    if not close_fds:\n                        warnings.warn(\"startupinfo.lpAttributeList['handle_list'] \"\n                                      \"overriding close_fds\", RuntimeWarning)\n\n                    # When using the handle_list we always request to inherit\n                    # handles but the only handles that will be inherited are\n                    # the ones in the handle_list\n                    close_fds = False\n\n            if shell:\n                startupinfo.dwFlags |= _winapi.STARTF_USESHOWWINDOW\n                startupinfo.wShowWindow = _winapi.SW_HIDE\n                comspec = os.environ.get(\"COMSPEC\", \"cmd.exe\")\n                args = '{} /c \"{}\"'.format (comspec, args)\n\n            if cwd is not None:\n                cwd = os.fsdecode(cwd)\n\n            sys.audit(\"subprocess.Popen\", executable, args, cwd, env)\n\n            # Start the process\n            try:\n                hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n                                         # no special security\n                                         None, None,\n                                         int(not close_fds),\n                                         creationflags,\n                                         env,\n                                         cwd,\n                                         startupinfo)\n            finally:\n                # Child is launched. Close the parent's copy of those pipe\n                # handles that only the child should have open.  You need\n                # to make sure that no handles to the write end of the\n                # output pipe are maintained in this process or else the\n                # pipe will not close when the child process exits and the\n                # ReadFile will hang.\n                self._close_pipe_fds(p2cread, p2cwrite,\n                                     c2pread, c2pwrite,\n                                     errread, errwrite)\n\n            # Retain the process handle, but close the thread handle\n            self._child_created = True\n            self._handle = Handle(hp)\n            self.pid = pid\n            _winapi.CloseHandle(ht)\n\n        def _internal_poll(self, _deadstate=None,\n                _WaitForSingleObject=_winapi.WaitForSingleObject,\n                _WAIT_OBJECT_0=_winapi.WAIT_OBJECT_0,\n                _GetExitCodeProcess=_winapi.GetExitCodeProcess):\n            \"\"\"Check if child process has terminated.  Returns returncode\n            attribute.\n\n            This method is called by __del__, so it can only refer to objects\n            in its local scope.\n\n            \"\"\"\n            if self.returncode is None:\n                if _WaitForSingleObject(self._handle, 0) == _WAIT_OBJECT_0:\n                    self.returncode = _GetExitCodeProcess(self._handle)\n            return self.returncode\n\n\n        def _wait(self, timeout):\n            \"\"\"Internal implementation of wait() on Windows.\"\"\"\n            if timeout is None:\n                timeout_millis = _winapi.INFINITE\n            else:\n                timeout_millis = int(timeout * 1000)\n            if self.returncode is None:\n                # API note: Returns immediately if timeout_millis == 0.\n                result = _winapi.WaitForSingleObject(self._handle,\n                                                     timeout_millis)\n                if result == _winapi.WAIT_TIMEOUT:\n                    raise TimeoutExpired(self.args, timeout)\n                self.returncode = _winapi.GetExitCodeProcess(self._handle)\n            return self.returncode\n\n\n        def _readerthread(self, fh, buffer):\n            buffer.append(fh.read())\n            fh.close()\n\n\n        def _communicate(self, input, endtime, orig_timeout):\n            # Start reader threads feeding into a list hanging off of this\n            # object, unless they've already been started.\n            if self.stdout and not hasattr(self, \"_stdout_buff\"):\n                self._stdout_buff = []\n                self.stdout_thread = \\\n                        threading.Thread(target=self._readerthread,\n                                         args=(self.stdout, self._stdout_buff))\n                self.stdout_thread.daemon = True\n                self.stdout_thread.start()\n            if self.stderr and not hasattr(self, \"_stderr_buff\"):\n                self._stderr_buff = []\n                self.stderr_thread = \\\n                        threading.Thread(target=self._readerthread,\n                                         args=(self.stderr, self._stderr_buff))\n                self.stderr_thread.daemon = True\n                self.stderr_thread.start()\n\n            if self.stdin:\n                self._stdin_write(input)\n\n            # Wait for the reader threads, or time out.  If we time out, the\n            # threads remain reading and the fds left open in case the user\n            # calls communicate again.\n            if self.stdout is not None:\n                self.stdout_thread.join(self._remaining_time(endtime))\n                if self.stdout_thread.is_alive():\n                    raise TimeoutExpired(self.args, orig_timeout)\n            if self.stderr is not None:\n                self.stderr_thread.join(self._remaining_time(endtime))\n                if self.stderr_thread.is_alive():\n                    raise TimeoutExpired(self.args, orig_timeout)\n\n            # Collect the output from and close both pipes, now that we know\n            # both have been read successfully.\n            stdout = None\n            stderr = None\n            if self.stdout:\n                stdout = self._stdout_buff\n                self.stdout.close()\n            if self.stderr:\n                stderr = self._stderr_buff\n                self.stderr.close()\n\n            # All data exchanged.  Translate lists into strings.\n            stdout = stdout[0] if stdout else None\n            stderr = stderr[0] if stderr else None\n\n            return (stdout, stderr)\n\n        def send_signal(self, sig):\n            \"\"\"Send a signal to the process.\"\"\"\n            # Don't signal a process that we know has already died.\n            if self.returncode is not None:\n                return\n            if sig == signal.SIGTERM:\n                self.terminate()\n            elif sig == signal.CTRL_C_EVENT:\n                os.kill(self.pid, signal.CTRL_C_EVENT)\n            elif sig == signal.CTRL_BREAK_EVENT:\n                os.kill(self.pid, signal.CTRL_BREAK_EVENT)\n            else:\n                raise ValueError(\"Unsupported signal: {}\".format(sig))\n\n        def terminate(self):\n            \"\"\"Terminates the process.\"\"\"\n            # Don't terminate a process that we know has already died.\n            if self.returncode is not None:\n                return\n            try:\n                _winapi.TerminateProcess(self._handle, 1)\n            except PermissionError:\n                # ERROR_ACCESS_DENIED (winerror 5) is received when the\n                # process already died.\n                rc = _winapi.GetExitCodeProcess(self._handle)\n                if rc == _winapi.STILL_ACTIVE:\n                    raise\n                self.returncode = rc\n\n        kill = terminate\n\n    else:\n        #\n        # POSIX methods\n        #\n        def _get_handles(self, stdin, stdout, stderr):\n            \"\"\"Construct and return tuple with IO objects:\n            p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite\n            \"\"\"\n            p2cread, p2cwrite = -1, -1\n            c2pread, c2pwrite = -1, -1\n            errread, errwrite = -1, -1\n\n            if stdin is None:\n                pass\n            elif stdin == PIPE:\n                p2cread, p2cwrite = os.pipe()\n            elif stdin == DEVNULL:\n                p2cread = self._get_devnull()\n            elif isinstance(stdin, int):\n                p2cread = stdin\n            else:\n                # Assuming file-like object\n                p2cread = stdin.fileno()\n\n            if stdout is None:\n                pass\n            elif stdout == PIPE:\n                c2pread, c2pwrite = os.pipe()\n            elif stdout == DEVNULL:\n                c2pwrite = self._get_devnull()\n            elif isinstance(stdout, int):\n                c2pwrite = stdout\n            else:\n                # Assuming file-like object\n                c2pwrite = stdout.fileno()\n\n            if stderr is None:\n                pass\n            elif stderr == PIPE:\n                errread, errwrite = os.pipe()\n            elif stderr == STDOUT:\n                if c2pwrite != -1:\n                    errwrite = c2pwrite\n                else: # child's stdout is not set, use parent's stdout\n                    errwrite = sys.__stdout__.fileno()\n            elif stderr == DEVNULL:\n                errwrite = self._get_devnull()\n            elif isinstance(stderr, int):\n                errwrite = stderr\n            else:\n                # Assuming file-like object\n                errwrite = stderr.fileno()\n\n            return (p2cread, p2cwrite,\n                    c2pread, c2pwrite,\n                    errread, errwrite)\n\n\n        def _posix_spawn(self, args, executable, env, restore_signals,\n                         p2cread, p2cwrite,\n                         c2pread, c2pwrite,\n                         errread, errwrite):\n            \"\"\"Execute program using os.posix_spawn().\"\"\"\n            if env is None:\n                env = os.environ\n\n            kwargs = {}\n            if restore_signals:\n                # See _Py_RestoreSignals() in Python/pylifecycle.c\n                sigset = []\n                for signame in ('SIGPIPE', 'SIGXFZ', 'SIGXFSZ'):\n                    signum = getattr(signal, signame, None)\n                    if signum is not None:\n                        sigset.append(signum)\n                kwargs['setsigdef'] = sigset\n\n            file_actions = []\n            for fd in (p2cwrite, c2pread, errread):\n                if fd != -1:\n                    file_actions.append((os.POSIX_SPAWN_CLOSE, fd))\n            for fd, fd2 in (\n                (p2cread, 0),\n                (c2pwrite, 1),\n                (errwrite, 2),\n            ):\n                if fd != -1:\n                    file_actions.append((os.POSIX_SPAWN_DUP2, fd, fd2))\n            if file_actions:\n                kwargs['file_actions'] = file_actions\n\n            self.pid = os.posix_spawn(executable, args, env, **kwargs)\n            self._child_created = True\n\n            self._close_pipe_fds(p2cread, p2cwrite,\n                                 c2pread, c2pwrite,\n                                 errread, errwrite)\n\n        def _execute_child(self, args, executable, preexec_fn, close_fds,\n                           pass_fds, cwd, env,\n                           startupinfo, creationflags, shell,\n                           p2cread, p2cwrite,\n                           c2pread, c2pwrite,\n                           errread, errwrite,\n                           restore_signals,\n                           gid, gids, uid, umask,\n                           start_new_session):\n            \"\"\"Execute program (POSIX version)\"\"\"\n\n            if isinstance(args, (str, bytes)):\n                args = [args]\n            elif isinstance(args, os.PathLike):\n                if shell:\n                    raise TypeError('path-like args is not allowed when '\n                                    'shell is true')\n                args = [args]\n            else:\n                args = list(args)\n\n            if shell:\n                # On Android the default shell is at '/system/bin/sh'.\n                unix_shell = ('/system/bin/sh' if\n                          hasattr(sys, 'getandroidapilevel') else '/bin/sh')\n                args = [unix_shell, \"-c\"] + args\n                if executable:\n                    args[0] = executable\n\n            if executable is None:\n                executable = args[0]\n\n            sys.audit(\"subprocess.Popen\", executable, args, cwd, env)\n\n            if (_USE_POSIX_SPAWN\n                    and os.path.dirname(executable)\n                    and preexec_fn is None\n                    and not close_fds\n                    and not pass_fds\n                    and cwd is None\n                    and (p2cread == -1 or p2cread > 2)\n                    and (c2pwrite == -1 or c2pwrite > 2)\n                    and (errwrite == -1 or errwrite > 2)\n                    and not start_new_session\n                    and gid is None\n                    and gids is None\n                    and uid is None\n                    and umask < 0):\n                self._posix_spawn(args, executable, env, restore_signals,\n                                  p2cread, p2cwrite,\n                                  c2pread, c2pwrite,\n                                  errread, errwrite)\n                return\n\n            orig_executable = executable\n\n            # For transferring possible exec failure from child to parent.\n            # Data format: \"exception name:hex errno:description\"\n            # Pickle is not used; it is complex and involves memory allocation.\n            errpipe_read, errpipe_write = os.pipe()\n            # errpipe_write must not be in the standard io 0, 1, or 2 fd range.\n            low_fds_to_close = []\n            while errpipe_write < 3:\n                low_fds_to_close.append(errpipe_write)\n                errpipe_write = os.dup(errpipe_write)\n            for low_fd in low_fds_to_close:\n                os.close(low_fd)\n            try:\n                try:\n                    # We must avoid complex work that could involve\n                    # malloc or free in the child process to avoid\n                    # potential deadlocks, thus we do all this here.\n                    # and pass it to fork_exec()\n\n                    if env is not None:\n                        env_list = []\n                        for k, v in env.items():\n                            k = os.fsencode(k)\n                            if b'=' in k:\n                                raise ValueError(\"illegal environment variable name\")\n                            env_list.append(k + b'=' + os.fsencode(v))\n                    else:\n                        env_list = None  # Use execv instead of execve.\n                    executable = os.fsencode(executable)\n                    if os.path.dirname(executable):\n                        executable_list = (executable,)\n                    else:\n                        # This matches the behavior of os._execvpe().\n                        executable_list = tuple(\n                            os.path.join(os.fsencode(dir), executable)\n                            for dir in os.get_exec_path(env))\n                    fds_to_keep = set(pass_fds)\n                    fds_to_keep.add(errpipe_write)\n                    self.pid = _posixsubprocess.fork_exec(\n                            args, executable_list,\n                            close_fds, tuple(sorted(map(int, fds_to_keep))),\n                            cwd, env_list,\n                            p2cread, p2cwrite, c2pread, c2pwrite,\n                            errread, errwrite,\n                            errpipe_read, errpipe_write,\n                            restore_signals, start_new_session,\n                            gid, gids, uid, umask,\n                            preexec_fn)\n                    self._child_created = True\n                finally:\n                    # be sure the FD is closed no matter what\n                    os.close(errpipe_write)\n\n                self._close_pipe_fds(p2cread, p2cwrite,\n                                     c2pread, c2pwrite,\n                                     errread, errwrite)\n\n                # Wait for exec to fail or succeed; possibly raising an\n                # exception (limited in size)\n                errpipe_data = bytearray()\n                while True:\n                    part = os.read(errpipe_read, 50000)\n                    errpipe_data += part\n                    if not part or len(errpipe_data) > 50000:\n                        break\n            finally:\n                # be sure the FD is closed no matter what\n                os.close(errpipe_read)\n\n            if errpipe_data:\n                try:\n                    pid, sts = os.waitpid(self.pid, 0)\n                    if pid == self.pid:\n                        self._handle_exitstatus(sts)\n                    else:\n                        self.returncode = sys.maxsize\n                except ChildProcessError:\n                    pass\n\n                try:\n                    exception_name, hex_errno, err_msg = (\n                            errpipe_data.split(b':', 2))\n                    # The encoding here should match the encoding\n                    # written in by the subprocess implementations\n                    # like _posixsubprocess\n                    err_msg = err_msg.decode()\n                except ValueError:\n                    exception_name = b'SubprocessError'\n                    hex_errno = b'0'\n                    err_msg = 'Bad exception data from child: {!r}'.format(\n                                  bytes(errpipe_data))\n                child_exception_type = getattr(\n                        builtins, exception_name.decode('ascii'),\n                        SubprocessError)\n                if issubclass(child_exception_type, OSError) and hex_errno:\n                    errno_num = int(hex_errno, 16)\n                    child_exec_never_called = (err_msg == \"noexec\")\n                    if child_exec_never_called:\n                        err_msg = \"\"\n                        # The error must be from chdir(cwd).\n                        err_filename = cwd\n                    else:\n                        err_filename = orig_executable\n                    if errno_num != 0:\n                        err_msg = os.strerror(errno_num)\n                    raise child_exception_type(errno_num, err_msg, err_filename)\n                raise child_exception_type(err_msg)\n\n\n        def _handle_exitstatus(self, sts,\n                               waitstatus_to_exitcode=os.waitstatus_to_exitcode,\n                               _WIFSTOPPED=os.WIFSTOPPED,\n                               _WSTOPSIG=os.WSTOPSIG):\n            \"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\n            # This method is called (indirectly) by __del__, so it cannot\n            # refer to anything outside of its local scope.\n            if _WIFSTOPPED(sts):\n                self.returncode = -_WSTOPSIG(sts)\n            else:\n                self.returncode = waitstatus_to_exitcode(sts)\n\n        def _internal_poll(self, _deadstate=None, _waitpid=os.waitpid,\n                _WNOHANG=os.WNOHANG, _ECHILD=errno.ECHILD):\n            \"\"\"Check if child process has terminated.  Returns returncode\n            attribute.\n\n            This method is called by __del__, so it cannot reference anything\n            outside of the local scope (nor can any methods it calls).\n\n            \"\"\"\n            if self.returncode is None:\n                if not self._waitpid_lock.acquire(False):\n                    # Something else is busy calling waitpid.  Don't allow two\n                    # at once.  We know nothing yet.\n                    return None\n                try:\n                    if self.returncode is not None:\n                        return self.returncode  # Another thread waited.\n                    pid, sts = _waitpid(self.pid, _WNOHANG)\n                    if pid == self.pid:\n                        self._handle_exitstatus(sts)\n                except OSError as e:\n                    if _deadstate is not None:\n                        self.returncode = _deadstate\n                    elif e.errno == _ECHILD:\n                        # This happens if SIGCLD is set to be ignored or\n                        # waiting for child processes has otherwise been\n                        # disabled for our process.  This child is dead, we\n                        # can't get the status.\n                        # http://bugs.python.org/issue15756\n                        self.returncode = 0\n                finally:\n                    self._waitpid_lock.release()\n            return self.returncode\n\n\n        def _try_wait(self, wait_flags):\n            \"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\n            try:\n                (pid, sts) = os.waitpid(self.pid, wait_flags)\n            except ChildProcessError:\n                # This happens if SIGCLD is set to be ignored or waiting\n                # for child processes has otherwise been disabled for our\n                # process.  This child is dead, we can't get the status.\n                pid = self.pid\n                sts = 0\n            return (pid, sts)\n\n\n        def _wait(self, timeout):\n            \"\"\"Internal implementation of wait() on POSIX.\"\"\"\n            if self.returncode is not None:\n                return self.returncode\n\n            if timeout is not None:\n                endtime = _time() + timeout\n                # Enter a busy loop if we have a timeout.  This busy loop was\n                # cribbed from Lib/threading.py in Thread.wait() at r71065.\n                delay = 0.0005 # 500 us -> initial delay of 1 ms\n                while True:\n                    if self._waitpid_lock.acquire(False):\n                        try:\n                            if self.returncode is not None:\n                                break  # Another thread waited.\n                            (pid, sts) = self._try_wait(os.WNOHANG)\n                            assert pid == self.pid or pid == 0\n                            if pid == self.pid:\n                                self._handle_exitstatus(sts)\n                                break\n                        finally:\n                            self._waitpid_lock.release()\n                    remaining = self._remaining_time(endtime)\n                    if remaining <= 0:\n                        raise TimeoutExpired(self.args, timeout)\n                    delay = min(delay * 2, remaining, .05)\n                    time.sleep(delay)\n            else:\n                while self.returncode is None:\n                    with self._waitpid_lock:\n                        if self.returncode is not None:\n                            break  # Another thread waited.\n                        (pid, sts) = self._try_wait(0)\n                        # Check the pid and loop as waitpid has been known to\n                        # return 0 even without WNOHANG in odd situations.\n                        # http://bugs.python.org/issue14396.\n                        if pid == self.pid:\n                            self._handle_exitstatus(sts)\n            return self.returncode\n\n\n        def _communicate(self, input, endtime, orig_timeout):\n            if self.stdin and not self._communication_started:\n                # Flush stdio buffer.  This might block, if the user has\n                # been writing to .stdin in an uncontrolled fashion.\n                try:\n                    self.stdin.flush()\n                except BrokenPipeError:\n                    pass  # communicate() must ignore BrokenPipeError.\n                if not input:\n                    try:\n                        self.stdin.close()\n                    except BrokenPipeError:\n                        pass  # communicate() must ignore BrokenPipeError.\n\n            stdout = None\n            stderr = None\n\n            # Only create this mapping if we haven't already.\n            if not self._communication_started:\n                self._fileobj2output = {}\n                if self.stdout:\n                    self._fileobj2output[self.stdout] = []\n                if self.stderr:\n                    self._fileobj2output[self.stderr] = []\n\n            if self.stdout:\n                stdout = self._fileobj2output[self.stdout]\n            if self.stderr:\n                stderr = self._fileobj2output[self.stderr]\n\n            self._save_input(input)\n\n            if self._input:\n                input_view = memoryview(self._input)\n\n            with _PopenSelector() as selector:\n                if self.stdin and input:\n                    selector.register(self.stdin, selectors.EVENT_WRITE)\n                if self.stdout and not self.stdout.closed:\n                    selector.register(self.stdout, selectors.EVENT_READ)\n                if self.stderr and not self.stderr.closed:\n                    selector.register(self.stderr, selectors.EVENT_READ)\n\n                while selector.get_map():\n                    timeout = self._remaining_time(endtime)\n                    if timeout is not None and timeout < 0:\n                        self._check_timeout(endtime, orig_timeout,\n                                            stdout, stderr,\n                                            skip_check_and_raise=True)\n                        raise RuntimeError(  # Impossible :)\n                            '_check_timeout(..., skip_check_and_raise=True) '\n                            'failed to raise TimeoutExpired.')\n\n                    ready = selector.select(timeout)\n                    self._check_timeout(endtime, orig_timeout, stdout, stderr)\n\n                    # XXX Rewrite these to use non-blocking I/O on the file\n                    # objects; they are no longer using C stdio!\n\n                    for key, events in ready:\n                        if key.fileobj is self.stdin:\n                            chunk = input_view[self._input_offset :\n                                               self._input_offset + _PIPE_BUF]\n                            try:\n                                self._input_offset += os.write(key.fd, chunk)\n                            except BrokenPipeError:\n                                selector.unregister(key.fileobj)\n                                key.fileobj.close()\n                            else:\n                                if self._input_offset >= len(self._input):\n                                    selector.unregister(key.fileobj)\n                                    key.fileobj.close()\n                        elif key.fileobj in (self.stdout, self.stderr):\n                            data = os.read(key.fd, 32768)\n                            if not data:\n                                selector.unregister(key.fileobj)\n                                key.fileobj.close()\n                            self._fileobj2output[key.fileobj].append(data)\n\n            self.wait(timeout=self._remaining_time(endtime))\n\n            # All data exchanged.  Translate lists into strings.\n            if stdout is not None:\n                stdout = b''.join(stdout)\n            if stderr is not None:\n                stderr = b''.join(stderr)\n\n            # Translate newlines, if requested.\n            # This also turns bytes into strings.\n            if self.text_mode:\n                if stdout is not None:\n                    stdout = self._translate_newlines(stdout,\n                                                      self.stdout.encoding,\n                                                      self.stdout.errors)\n                if stderr is not None:\n                    stderr = self._translate_newlines(stderr,\n                                                      self.stderr.encoding,\n                                                      self.stderr.errors)\n\n            return (stdout, stderr)\n\n\n        def _save_input(self, input):\n            # This method is called from the _communicate_with_*() methods\n            # so that if we time out while communicating, we can continue\n            # sending input if we retry.\n            if self.stdin and self._input is None:\n                self._input_offset = 0\n                self._input = input\n                if input is not None and self.text_mode:\n                    self._input = self._input.encode(self.stdin.encoding,\n                                                     self.stdin.errors)\n\n\n        def send_signal(self, sig):\n            \"\"\"Send a signal to the process.\"\"\"\n            # bpo-38630: Polling reduces the risk of sending a signal to the\n            # wrong process if the process completed, the Popen.returncode\n            # attribute is still None, and the pid has been reassigned\n            # (recycled) to a new different process. This race condition can\n            # happens in two cases.\n            #\n            # Case 1. Thread A calls Popen.poll(), thread B calls\n            # Popen.send_signal(). In thread A, waitpid() succeed and returns\n            # the exit status. Thread B calls kill() because poll() in thread A\n            # did not set returncode yet. Calling poll() in thread B prevents\n            # the race condition thanks to Popen._waitpid_lock.\n            #\n            # Case 2. waitpid(pid, 0) has been called directly, without\n            # using Popen methods: returncode is still None is this case.\n            # Calling Popen.poll() will set returncode to a default value,\n            # since waitpid() fails with ProcessLookupError.\n            self.poll()\n            if self.returncode is not None:\n                # Skip signalling a process that we know has already died.\n                return\n\n            # The race condition can still happen if the race condition\n            # described above happens between the returncode test\n            # and the kill() call.\n            try:\n                os.kill(self.pid, sig)\n            except ProcessLookupError:\n                # Supress the race condition error; bpo-40550.\n                pass\n\n        def terminate(self):\n            \"\"\"Terminate the process with SIGTERM\n            \"\"\"\n            self.send_signal(signal.SIGTERM)\n\n        def kill(self):\n            \"\"\"Kill the process with SIGKILL\n            \"\"\"\n            self.send_signal(signal.SIGKILL)\n", 2080], "/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/functools.py": ["\"\"\"functools.py - Tools for working with functions and callable objects\n\"\"\"\n# Python module wrapper for _functools C module\n# to allow utilities written in Python to be added\n# to the functools module.\n# Written by Nick Coghlan <ncoghlan at gmail.com>,\n# Raymond Hettinger <python at rcn.com>,\n# and \u0141ukasz Langa <lukasz at langa.pl>.\n#   Copyright (C) 2006-2013 Python Software Foundation.\n# See C source code for _functools credits/copyright\n\n__all__ = ['update_wrapper', 'wraps', 'WRAPPER_ASSIGNMENTS', 'WRAPPER_UPDATES',\n           'total_ordering', 'cache', 'cmp_to_key', 'lru_cache', 'reduce',\n           'partial', 'partialmethod', 'singledispatch', 'singledispatchmethod',\n           'cached_property']\n\nfrom abc import get_cache_token\nfrom collections import namedtuple\n# import types, weakref  # Deferred to single_dispatch()\nfrom reprlib import recursive_repr\nfrom _thread import RLock\nfrom types import GenericAlias\n\n\n################################################################################\n### update_wrapper() and wraps() decorator\n################################################################################\n\n# update_wrapper() and wraps() are tools to help write\n# wrapper functions that can handle naive introspection\n\nWRAPPER_ASSIGNMENTS = ('__module__', '__name__', '__qualname__', '__doc__',\n                       '__annotations__')\nWRAPPER_UPDATES = ('__dict__',)\ndef update_wrapper(wrapper,\n                   wrapped,\n                   assigned = WRAPPER_ASSIGNMENTS,\n                   updated = WRAPPER_UPDATES):\n    \"\"\"Update a wrapper function to look like the wrapped function\n\n       wrapper is the function to be updated\n       wrapped is the original function\n       assigned is a tuple naming the attributes assigned directly\n       from the wrapped function to the wrapper function (defaults to\n       functools.WRAPPER_ASSIGNMENTS)\n       updated is a tuple naming the attributes of the wrapper that\n       are updated with the corresponding attribute from the wrapped\n       function (defaults to functools.WRAPPER_UPDATES)\n    \"\"\"\n    for attr in assigned:\n        try:\n            value = getattr(wrapped, attr)\n        except AttributeError:\n            pass\n        else:\n            setattr(wrapper, attr, value)\n    for attr in updated:\n        getattr(wrapper, attr).update(getattr(wrapped, attr, {}))\n    # Issue #17482: set __wrapped__ last so we don't inadvertently copy it\n    # from the wrapped function when updating __dict__\n    wrapper.__wrapped__ = wrapped\n    # Return the wrapper so this can be used as a decorator via partial()\n    return wrapper\n\ndef wraps(wrapped,\n          assigned = WRAPPER_ASSIGNMENTS,\n          updated = WRAPPER_UPDATES):\n    \"\"\"Decorator factory to apply update_wrapper() to a wrapper function\n\n       Returns a decorator that invokes update_wrapper() with the decorated\n       function as the wrapper argument and the arguments to wraps() as the\n       remaining arguments. Default arguments are as for update_wrapper().\n       This is a convenience function to simplify applying partial() to\n       update_wrapper().\n    \"\"\"\n    return partial(update_wrapper, wrapped=wrapped,\n                   assigned=assigned, updated=updated)\n\n\n################################################################################\n### total_ordering class decorator\n################################################################################\n\n# The total ordering functions all invoke the root magic method directly\n# rather than using the corresponding operator.  This avoids possible\n# infinite recursion that could occur when the operator dispatch logic\n# detects a NotImplemented result and then calls a reflected method.\n\ndef _gt_from_lt(self, other, NotImplemented=NotImplemented):\n    'Return a > b.  Computed by @total_ordering from (not a < b) and (a != b).'\n    op_result = type(self).__lt__(self, other)\n    if op_result is NotImplemented:\n        return op_result\n    return not op_result and self != other\n\ndef _le_from_lt(self, other, NotImplemented=NotImplemented):\n    'Return a <= b.  Computed by @total_ordering from (a < b) or (a == b).'\n    op_result = type(self).__lt__(self, other)\n    if op_result is NotImplemented:\n        return op_result\n    return op_result or self == other\n\ndef _ge_from_lt(self, other, NotImplemented=NotImplemented):\n    'Return a >= b.  Computed by @total_ordering from (not a < b).'\n    op_result = type(self).__lt__(self, other)\n    if op_result is NotImplemented:\n        return op_result\n    return not op_result\n\ndef _ge_from_le(self, other, NotImplemented=NotImplemented):\n    'Return a >= b.  Computed by @total_ordering from (not a <= b) or (a == b).'\n    op_result = type(self).__le__(self, other)\n    if op_result is NotImplemented:\n        return op_result\n    return not op_result or self == other\n\ndef _lt_from_le(self, other, NotImplemented=NotImplemented):\n    'Return a < b.  Computed by @total_ordering from (a <= b) and (a != b).'\n    op_result = type(self).__le__(self, other)\n    if op_result is NotImplemented:\n        return op_result\n    return op_result and self != other\n\ndef _gt_from_le(self, other, NotImplemented=NotImplemented):\n    'Return a > b.  Computed by @total_ordering from (not a <= b).'\n    op_result = type(self).__le__(self, other)\n    if op_result is NotImplemented:\n        return op_result\n    return not op_result\n\ndef _lt_from_gt(self, other, NotImplemented=NotImplemented):\n    'Return a < b.  Computed by @total_ordering from (not a > b) and (a != b).'\n    op_result = type(self).__gt__(self, other)\n    if op_result is NotImplemented:\n        return op_result\n    return not op_result and self != other\n\ndef _ge_from_gt(self, other, NotImplemented=NotImplemented):\n    'Return a >= b.  Computed by @total_ordering from (a > b) or (a == b).'\n    op_result = type(self).__gt__(self, other)\n    if op_result is NotImplemented:\n        return op_result\n    return op_result or self == other\n\ndef _le_from_gt(self, other, NotImplemented=NotImplemented):\n    'Return a <= b.  Computed by @total_ordering from (not a > b).'\n    op_result = type(self).__gt__(self, other)\n    if op_result is NotImplemented:\n        return op_result\n    return not op_result\n\ndef _le_from_ge(self, other, NotImplemented=NotImplemented):\n    'Return a <= b.  Computed by @total_ordering from (not a >= b) or (a == b).'\n    op_result = type(self).__ge__(self, other)\n    if op_result is NotImplemented:\n        return op_result\n    return not op_result or self == other\n\ndef _gt_from_ge(self, other, NotImplemented=NotImplemented):\n    'Return a > b.  Computed by @total_ordering from (a >= b) and (a != b).'\n    op_result = type(self).__ge__(self, other)\n    if op_result is NotImplemented:\n        return op_result\n    return op_result and self != other\n\ndef _lt_from_ge(self, other, NotImplemented=NotImplemented):\n    'Return a < b.  Computed by @total_ordering from (not a >= b).'\n    op_result = type(self).__ge__(self, other)\n    if op_result is NotImplemented:\n        return op_result\n    return not op_result\n\n_convert = {\n    '__lt__': [('__gt__', _gt_from_lt),\n               ('__le__', _le_from_lt),\n               ('__ge__', _ge_from_lt)],\n    '__le__': [('__ge__', _ge_from_le),\n               ('__lt__', _lt_from_le),\n               ('__gt__', _gt_from_le)],\n    '__gt__': [('__lt__', _lt_from_gt),\n               ('__ge__', _ge_from_gt),\n               ('__le__', _le_from_gt)],\n    '__ge__': [('__le__', _le_from_ge),\n               ('__gt__', _gt_from_ge),\n               ('__lt__', _lt_from_ge)]\n}\n\ndef total_ordering(cls):\n    \"\"\"Class decorator that fills in missing ordering methods\"\"\"\n    # Find user-defined comparisons (not those inherited from object).\n    roots = {op for op in _convert if getattr(cls, op, None) is not getattr(object, op, None)}\n    if not roots:\n        raise ValueError('must define at least one ordering operation: < > <= >=')\n    root = max(roots)       # prefer __lt__ to __le__ to __gt__ to __ge__\n    for opname, opfunc in _convert[root]:\n        if opname not in roots:\n            opfunc.__name__ = opname\n            setattr(cls, opname, opfunc)\n    return cls\n\n\n################################################################################\n### cmp_to_key() function converter\n################################################################################\n\ndef cmp_to_key(mycmp):\n    \"\"\"Convert a cmp= function into a key= function\"\"\"\n    class K(object):\n        __slots__ = ['obj']\n        def __init__(self, obj):\n            self.obj = obj\n        def __lt__(self, other):\n            return mycmp(self.obj, other.obj) < 0\n        def __gt__(self, other):\n            return mycmp(self.obj, other.obj) > 0\n        def __eq__(self, other):\n            return mycmp(self.obj, other.obj) == 0\n        def __le__(self, other):\n            return mycmp(self.obj, other.obj) <= 0\n        def __ge__(self, other):\n            return mycmp(self.obj, other.obj) >= 0\n        __hash__ = None\n    return K\n\ntry:\n    from _functools import cmp_to_key\nexcept ImportError:\n    pass\n\n\n################################################################################\n### reduce() sequence to a single item\n################################################################################\n\n_initial_missing = object()\n\ndef reduce(function, sequence, initial=_initial_missing):\n    \"\"\"\n    reduce(function, sequence[, initial]) -> value\n\n    Apply a function of two arguments cumulatively to the items of a sequence,\n    from left to right, so as to reduce the sequence to a single value.\n    For example, reduce(lambda x, y: x+y, [1, 2, 3, 4, 5]) calculates\n    ((((1+2)+3)+4)+5).  If initial is present, it is placed before the items\n    of the sequence in the calculation, and serves as a default when the\n    sequence is empty.\n    \"\"\"\n\n    it = iter(sequence)\n\n    if initial is _initial_missing:\n        try:\n            value = next(it)\n        except StopIteration:\n            raise TypeError(\"reduce() of empty sequence with no initial value\") from None\n    else:\n        value = initial\n\n    for element in it:\n        value = function(value, element)\n\n    return value\n\ntry:\n    from _functools import reduce\nexcept ImportError:\n    pass\n\n\n################################################################################\n### partial() argument application\n################################################################################\n\n# Purely functional, no descriptor behaviour\nclass partial:\n    \"\"\"New function with partial application of the given arguments\n    and keywords.\n    \"\"\"\n\n    __slots__ = \"func\", \"args\", \"keywords\", \"__dict__\", \"__weakref__\"\n\n    def __new__(cls, func, /, *args, **keywords):\n        if not callable(func):\n            raise TypeError(\"the first argument must be callable\")\n\n        if hasattr(func, \"func\"):\n            args = func.args + args\n            keywords = {**func.keywords, **keywords}\n            func = func.func\n\n        self = super(partial, cls).__new__(cls)\n\n        self.func = func\n        self.args = args\n        self.keywords = keywords\n        return self\n\n    def __call__(self, /, *args, **keywords):\n        keywords = {**self.keywords, **keywords}\n        return self.func(*self.args, *args, **keywords)\n\n    @recursive_repr()\n    def __repr__(self):\n        qualname = type(self).__qualname__\n        args = [repr(self.func)]\n        args.extend(repr(x) for x in self.args)\n        args.extend(f\"{k}={v!r}\" for (k, v) in self.keywords.items())\n        if type(self).__module__ == \"functools\":\n            return f\"functools.{qualname}({', '.join(args)})\"\n        return f\"{qualname}({', '.join(args)})\"\n\n    def __reduce__(self):\n        return type(self), (self.func,), (self.func, self.args,\n               self.keywords or None, self.__dict__ or None)\n\n    def __setstate__(self, state):\n        if not isinstance(state, tuple):\n            raise TypeError(\"argument to __setstate__ must be a tuple\")\n        if len(state) != 4:\n            raise TypeError(f\"expected 4 items in state, got {len(state)}\")\n        func, args, kwds, namespace = state\n        if (not callable(func) or not isinstance(args, tuple) or\n           (kwds is not None and not isinstance(kwds, dict)) or\n           (namespace is not None and not isinstance(namespace, dict))):\n            raise TypeError(\"invalid partial state\")\n\n        args = tuple(args) # just in case it's a subclass\n        if kwds is None:\n            kwds = {}\n        elif type(kwds) is not dict: # XXX does it need to be *exactly* dict?\n            kwds = dict(kwds)\n        if namespace is None:\n            namespace = {}\n\n        self.__dict__ = namespace\n        self.func = func\n        self.args = args\n        self.keywords = kwds\n\ntry:\n    from _functools import partial\nexcept ImportError:\n    pass\n\n# Descriptor version\nclass partialmethod(object):\n    \"\"\"Method descriptor with partial application of the given arguments\n    and keywords.\n\n    Supports wrapping existing descriptors and handles non-descriptor\n    callables as instance methods.\n    \"\"\"\n\n    def __init__(self, func, /, *args, **keywords):\n        if not callable(func) and not hasattr(func, \"__get__\"):\n            raise TypeError(\"{!r} is not callable or a descriptor\"\n                                 .format(func))\n\n        # func could be a descriptor like classmethod which isn't callable,\n        # so we can't inherit from partial (it verifies func is callable)\n        if isinstance(func, partialmethod):\n            # flattening is mandatory in order to place cls/self before all\n            # other arguments\n            # it's also more efficient since only one function will be called\n            self.func = func.func\n            self.args = func.args + args\n            self.keywords = {**func.keywords, **keywords}\n        else:\n            self.func = func\n            self.args = args\n            self.keywords = keywords\n\n    def __repr__(self):\n        args = \", \".join(map(repr, self.args))\n        keywords = \", \".join(\"{}={!r}\".format(k, v)\n                                 for k, v in self.keywords.items())\n        format_string = \"{module}.{cls}({func}, {args}, {keywords})\"\n        return format_string.format(module=self.__class__.__module__,\n                                    cls=self.__class__.__qualname__,\n                                    func=self.func,\n                                    args=args,\n                                    keywords=keywords)\n\n    def _make_unbound_method(self):\n        def _method(cls_or_self, /, *args, **keywords):\n            keywords = {**self.keywords, **keywords}\n            return self.func(cls_or_self, *self.args, *args, **keywords)\n        _method.__isabstractmethod__ = self.__isabstractmethod__\n        _method._partialmethod = self\n        return _method\n\n    def __get__(self, obj, cls=None):\n        get = getattr(self.func, \"__get__\", None)\n        result = None\n        if get is not None:\n            new_func = get(obj, cls)\n            if new_func is not self.func:\n                # Assume __get__ returning something new indicates the\n                # creation of an appropriate callable\n                result = partial(new_func, *self.args, **self.keywords)\n                try:\n                    result.__self__ = new_func.__self__\n                except AttributeError:\n                    pass\n        if result is None:\n            # If the underlying descriptor didn't do anything, treat this\n            # like an instance method\n            result = self._make_unbound_method().__get__(obj, cls)\n        return result\n\n    @property\n    def __isabstractmethod__(self):\n        return getattr(self.func, \"__isabstractmethod__\", False)\n\n    __class_getitem__ = classmethod(GenericAlias)\n\n\n# Helper functions\n\ndef _unwrap_partial(func):\n    while isinstance(func, partial):\n        func = func.func\n    return func\n\n################################################################################\n### LRU Cache function decorator\n################################################################################\n\n_CacheInfo = namedtuple(\"CacheInfo\", [\"hits\", \"misses\", \"maxsize\", \"currsize\"])\n\nclass _HashedSeq(list):\n    \"\"\" This class guarantees that hash() will be called no more than once\n        per element.  This is important because the lru_cache() will hash\n        the key multiple times on a cache miss.\n\n    \"\"\"\n\n    __slots__ = 'hashvalue'\n\n    def __init__(self, tup, hash=hash):\n        self[:] = tup\n        self.hashvalue = hash(tup)\n\n    def __hash__(self):\n        return self.hashvalue\n\ndef _make_key(args, kwds, typed,\n             kwd_mark = (object(),),\n             fasttypes = {int, str},\n             tuple=tuple, type=type, len=len):\n    \"\"\"Make a cache key from optionally typed positional and keyword arguments\n\n    The key is constructed in a way that is flat as possible rather than\n    as a nested structure that would take more memory.\n\n    If there is only a single argument and its data type is known to cache\n    its hash value, then that argument is returned without a wrapper.  This\n    saves space and improves lookup speed.\n\n    \"\"\"\n    # All of code below relies on kwds preserving the order input by the user.\n    # Formerly, we sorted() the kwds before looping.  The new way is *much*\n    # faster; however, it means that f(x=1, y=2) will now be treated as a\n    # distinct call from f(y=2, x=1) which will be cached separately.\n    key = args\n    if kwds:\n        key += kwd_mark\n        for item in kwds.items():\n            key += item\n    if typed:\n        key += tuple(type(v) for v in args)\n        if kwds:\n            key += tuple(type(v) for v in kwds.values())\n    elif len(key) == 1 and type(key[0]) in fasttypes:\n        return key[0]\n    return _HashedSeq(key)\n\ndef lru_cache(maxsize=128, typed=False):\n    \"\"\"Least-recently-used cache decorator.\n\n    If *maxsize* is set to None, the LRU features are disabled and the cache\n    can grow without bound.\n\n    If *typed* is True, arguments of different types will be cached separately.\n    For example, f(3.0) and f(3) will be treated as distinct calls with\n    distinct results.\n\n    Arguments to the cached function must be hashable.\n\n    View the cache statistics named tuple (hits, misses, maxsize, currsize)\n    with f.cache_info().  Clear the cache and statistics with f.cache_clear().\n    Access the underlying function with f.__wrapped__.\n\n    See:  https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)\n\n    \"\"\"\n\n    # Users should only access the lru_cache through its public API:\n    #       cache_info, cache_clear, and f.__wrapped__\n    # The internals of the lru_cache are encapsulated for thread safety and\n    # to allow the implementation to change (including a possible C version).\n\n    if isinstance(maxsize, int):\n        # Negative maxsize is treated as 0\n        if maxsize < 0:\n            maxsize = 0\n    elif callable(maxsize) and isinstance(typed, bool):\n        # The user_function was passed in directly via the maxsize argument\n        user_function, maxsize = maxsize, 128\n        wrapper = _lru_cache_wrapper(user_function, maxsize, typed, _CacheInfo)\n        wrapper.cache_parameters = lambda : {'maxsize': maxsize, 'typed': typed}\n        return update_wrapper(wrapper, user_function)\n    elif maxsize is not None:\n        raise TypeError(\n            'Expected first argument to be an integer, a callable, or None')\n\n    def decorating_function(user_function):\n        wrapper = _lru_cache_wrapper(user_function, maxsize, typed, _CacheInfo)\n        wrapper.cache_parameters = lambda : {'maxsize': maxsize, 'typed': typed}\n        return update_wrapper(wrapper, user_function)\n\n    return decorating_function\n\ndef _lru_cache_wrapper(user_function, maxsize, typed, _CacheInfo):\n    # Constants shared by all lru cache instances:\n    sentinel = object()          # unique object used to signal cache misses\n    make_key = _make_key         # build a key from the function arguments\n    PREV, NEXT, KEY, RESULT = 0, 1, 2, 3   # names for the link fields\n\n    cache = {}\n    hits = misses = 0\n    full = False\n    cache_get = cache.get    # bound method to lookup a key or return None\n    cache_len = cache.__len__  # get cache size without calling len()\n    lock = RLock()           # because linkedlist updates aren't threadsafe\n    root = []                # root of the circular doubly linked list\n    root[:] = [root, root, None, None]     # initialize by pointing to self\n\n    if maxsize == 0:\n\n        def wrapper(*args, **kwds):\n            # No caching -- just a statistics update\n            nonlocal misses\n            misses += 1\n            result = user_function(*args, **kwds)\n            return result\n\n    elif maxsize is None:\n\n        def wrapper(*args, **kwds):\n            # Simple caching without ordering or size limit\n            nonlocal hits, misses\n            key = make_key(args, kwds, typed)\n            result = cache_get(key, sentinel)\n            if result is not sentinel:\n                hits += 1\n                return result\n            misses += 1\n            result = user_function(*args, **kwds)\n            cache[key] = result\n            return result\n\n    else:\n\n        def wrapper(*args, **kwds):\n            # Size limited caching that tracks accesses by recency\n            nonlocal root, hits, misses, full\n            key = make_key(args, kwds, typed)\n            with lock:\n                link = cache_get(key)\n                if link is not None:\n                    # Move the link to the front of the circular queue\n                    link_prev, link_next, _key, result = link\n                    link_prev[NEXT] = link_next\n                    link_next[PREV] = link_prev\n                    last = root[PREV]\n                    last[NEXT] = root[PREV] = link\n                    link[PREV] = last\n                    link[NEXT] = root\n                    hits += 1\n                    return result\n                misses += 1\n            result = user_function(*args, **kwds)\n            with lock:\n                if key in cache:\n                    # Getting here means that this same key was added to the\n                    # cache while the lock was released.  Since the link\n                    # update is already done, we need only return the\n                    # computed result and update the count of misses.\n                    pass\n                elif full:\n                    # Use the old root to store the new key and result.\n                    oldroot = root\n                    oldroot[KEY] = key\n                    oldroot[RESULT] = result\n                    # Empty the oldest link and make it the new root.\n                    # Keep a reference to the old key and old result to\n                    # prevent their ref counts from going to zero during the\n                    # update. That will prevent potentially arbitrary object\n                    # clean-up code (i.e. __del__) from running while we're\n                    # still adjusting the links.\n                    root = oldroot[NEXT]\n                    oldkey = root[KEY]\n                    oldresult = root[RESULT]\n                    root[KEY] = root[RESULT] = None\n                    # Now update the cache dictionary.\n                    del cache[oldkey]\n                    # Save the potentially reentrant cache[key] assignment\n                    # for last, after the root and links have been put in\n                    # a consistent state.\n                    cache[key] = oldroot\n                else:\n                    # Put result in a new link at the front of the queue.\n                    last = root[PREV]\n                    link = [last, root, key, result]\n                    last[NEXT] = root[PREV] = cache[key] = link\n                    # Use the cache_len bound method instead of the len() function\n                    # which could potentially be wrapped in an lru_cache itself.\n                    full = (cache_len() >= maxsize)\n            return result\n\n    def cache_info():\n        \"\"\"Report cache statistics\"\"\"\n        with lock:\n            return _CacheInfo(hits, misses, maxsize, cache_len())\n\n    def cache_clear():\n        \"\"\"Clear the cache and cache statistics\"\"\"\n        nonlocal hits, misses, full\n        with lock:\n            cache.clear()\n            root[:] = [root, root, None, None]\n            hits = misses = 0\n            full = False\n\n    wrapper.cache_info = cache_info\n    wrapper.cache_clear = cache_clear\n    return wrapper\n\ntry:\n    from _functools import _lru_cache_wrapper\nexcept ImportError:\n    pass\n\n\n################################################################################\n### cache -- simplified access to the infinity cache\n################################################################################\n\ndef cache(user_function, /):\n    'Simple lightweight unbounded cache.  Sometimes called \"memoize\".'\n    return lru_cache(maxsize=None)(user_function)\n\n\n################################################################################\n### singledispatch() - single-dispatch generic function decorator\n################################################################################\n\ndef _c3_merge(sequences):\n    \"\"\"Merges MROs in *sequences* to a single MRO using the C3 algorithm.\n\n    Adapted from https://www.python.org/download/releases/2.3/mro/.\n\n    \"\"\"\n    result = []\n    while True:\n        sequences = [s for s in sequences if s]   # purge empty sequences\n        if not sequences:\n            return result\n        for s1 in sequences:   # find merge candidates among seq heads\n            candidate = s1[0]\n            for s2 in sequences:\n                if candidate in s2[1:]:\n                    candidate = None\n                    break      # reject the current head, it appears later\n            else:\n                break\n        if candidate is None:\n            raise RuntimeError(\"Inconsistent hierarchy\")\n        result.append(candidate)\n        # remove the chosen candidate\n        for seq in sequences:\n            if seq[0] == candidate:\n                del seq[0]\n\ndef _c3_mro(cls, abcs=None):\n    \"\"\"Computes the method resolution order using extended C3 linearization.\n\n    If no *abcs* are given, the algorithm works exactly like the built-in C3\n    linearization used for method resolution.\n\n    If given, *abcs* is a list of abstract base classes that should be inserted\n    into the resulting MRO. Unrelated ABCs are ignored and don't end up in the\n    result. The algorithm inserts ABCs where their functionality is introduced,\n    i.e. issubclass(cls, abc) returns True for the class itself but returns\n    False for all its direct base classes. Implicit ABCs for a given class\n    (either registered or inferred from the presence of a special method like\n    __len__) are inserted directly after the last ABC explicitly listed in the\n    MRO of said class. If two implicit ABCs end up next to each other in the\n    resulting MRO, their ordering depends on the order of types in *abcs*.\n\n    \"\"\"\n    for i, base in enumerate(reversed(cls.__bases__)):\n        if hasattr(base, '__abstractmethods__'):\n            boundary = len(cls.__bases__) - i\n            break   # Bases up to the last explicit ABC are considered first.\n    else:\n        boundary = 0\n    abcs = list(abcs) if abcs else []\n    explicit_bases = list(cls.__bases__[:boundary])\n    abstract_bases = []\n    other_bases = list(cls.__bases__[boundary:])\n    for base in abcs:\n        if issubclass(cls, base) and not any(\n                issubclass(b, base) for b in cls.__bases__\n            ):\n            # If *cls* is the class that introduces behaviour described by\n            # an ABC *base*, insert said ABC to its MRO.\n            abstract_bases.append(base)\n    for base in abstract_bases:\n        abcs.remove(base)\n    explicit_c3_mros = [_c3_mro(base, abcs=abcs) for base in explicit_bases]\n    abstract_c3_mros = [_c3_mro(base, abcs=abcs) for base in abstract_bases]\n    other_c3_mros = [_c3_mro(base, abcs=abcs) for base in other_bases]\n    return _c3_merge(\n        [[cls]] +\n        explicit_c3_mros + abstract_c3_mros + other_c3_mros +\n        [explicit_bases] + [abstract_bases] + [other_bases]\n    )\n\ndef _compose_mro(cls, types):\n    \"\"\"Calculates the method resolution order for a given class *cls*.\n\n    Includes relevant abstract base classes (with their respective bases) from\n    the *types* iterable. Uses a modified C3 linearization algorithm.\n\n    \"\"\"\n    bases = set(cls.__mro__)\n    # Remove entries which are already present in the __mro__ or unrelated.\n    def is_related(typ):\n        return (typ not in bases and hasattr(typ, '__mro__')\n                                 and issubclass(cls, typ))\n    types = [n for n in types if is_related(n)]\n    # Remove entries which are strict bases of other entries (they will end up\n    # in the MRO anyway.\n    def is_strict_base(typ):\n        for other in types:\n            if typ != other and typ in other.__mro__:\n                return True\n        return False\n    types = [n for n in types if not is_strict_base(n)]\n    # Subclasses of the ABCs in *types* which are also implemented by\n    # *cls* can be used to stabilize ABC ordering.\n    type_set = set(types)\n    mro = []\n    for typ in types:\n        found = []\n        for sub in typ.__subclasses__():\n            if sub not in bases and issubclass(cls, sub):\n                found.append([s for s in sub.__mro__ if s in type_set])\n        if not found:\n            mro.append(typ)\n            continue\n        # Favor subclasses with the biggest number of useful bases\n        found.sort(key=len, reverse=True)\n        for sub in found:\n            for subcls in sub:\n                if subcls not in mro:\n                    mro.append(subcls)\n    return _c3_mro(cls, abcs=mro)\n\ndef _find_impl(cls, registry):\n    \"\"\"Returns the best matching implementation from *registry* for type *cls*.\n\n    Where there is no registered implementation for a specific type, its method\n    resolution order is used to find a more generic implementation.\n\n    Note: if *registry* does not contain an implementation for the base\n    *object* type, this function may return None.\n\n    \"\"\"\n    mro = _compose_mro(cls, registry.keys())\n    match = None\n    for t in mro:\n        if match is not None:\n            # If *match* is an implicit ABC but there is another unrelated,\n            # equally matching implicit ABC, refuse the temptation to guess.\n            if (t in registry and t not in cls.__mro__\n                              and match not in cls.__mro__\n                              and not issubclass(match, t)):\n                raise RuntimeError(\"Ambiguous dispatch: {} or {}\".format(\n                    match, t))\n            break\n        if t in registry:\n            match = t\n    return registry.get(match)\n\ndef singledispatch(func):\n    \"\"\"Single-dispatch generic function decorator.\n\n    Transforms a function into a generic function, which can have different\n    behaviours depending upon the type of its first argument. The decorated\n    function acts as the default implementation, and additional\n    implementations can be registered using the register() attribute of the\n    generic function.\n    \"\"\"\n    # There are many programs that use functools without singledispatch, so we\n    # trade-off making singledispatch marginally slower for the benefit of\n    # making start-up of such applications slightly faster.\n    import types, weakref\n\n    registry = {}\n    dispatch_cache = weakref.WeakKeyDictionary()\n    cache_token = None\n\n    def dispatch(cls):\n        \"\"\"generic_func.dispatch(cls) -> <function implementation>\n\n        Runs the dispatch algorithm to return the best available implementation\n        for the given *cls* registered on *generic_func*.\n\n        \"\"\"\n        nonlocal cache_token\n        if cache_token is not None:\n            current_token = get_cache_token()\n            if cache_token != current_token:\n                dispatch_cache.clear()\n                cache_token = current_token\n        try:\n            impl = dispatch_cache[cls]\n        except KeyError:\n            try:\n                impl = registry[cls]\n            except KeyError:\n                impl = _find_impl(cls, registry)\n            dispatch_cache[cls] = impl\n        return impl\n\n    def register(cls, func=None):\n        \"\"\"generic_func.register(cls, func) -> func\n\n        Registers a new implementation for the given *cls* on a *generic_func*.\n\n        \"\"\"\n        nonlocal cache_token\n        if func is None:\n            if isinstance(cls, type):\n                return lambda f: register(cls, f)\n            ann = getattr(cls, '__annotations__', {})\n            if not ann:\n                raise TypeError(\n                    f\"Invalid first argument to `register()`: {cls!r}. \"\n                    f\"Use either `@register(some_class)` or plain `@register` \"\n                    f\"on an annotated function.\"\n                )\n            func = cls\n\n            # only import typing if annotation parsing is necessary\n            from typing import get_type_hints\n            argname, cls = next(iter(get_type_hints(func).items()))\n            if not isinstance(cls, type):\n                raise TypeError(\n                    f\"Invalid annotation for {argname!r}. \"\n                    f\"{cls!r} is not a class.\"\n                )\n        registry[cls] = func\n        if cache_token is None and hasattr(cls, '__abstractmethods__'):\n            cache_token = get_cache_token()\n        dispatch_cache.clear()\n        return func\n\n    def wrapper(*args, **kw):\n        if not args:\n            raise TypeError(f'{funcname} requires at least '\n                            '1 positional argument')\n\n        return dispatch(args[0].__class__)(*args, **kw)\n\n    funcname = getattr(func, '__name__', 'singledispatch function')\n    registry[object] = func\n    wrapper.register = register\n    wrapper.dispatch = dispatch\n    wrapper.registry = types.MappingProxyType(registry)\n    wrapper._clear_cache = dispatch_cache.clear\n    update_wrapper(wrapper, func)\n    return wrapper\n\n\n# Descriptor version\nclass singledispatchmethod:\n    \"\"\"Single-dispatch generic method descriptor.\n\n    Supports wrapping existing descriptors and handles non-descriptor\n    callables as instance methods.\n    \"\"\"\n\n    def __init__(self, func):\n        if not callable(func) and not hasattr(func, \"__get__\"):\n            raise TypeError(f\"{func!r} is not callable or a descriptor\")\n\n        self.dispatcher = singledispatch(func)\n        self.func = func\n\n        # bpo-45678: special-casing for classmethod/staticmethod in Python <=3.9,\n        # as functools.update_wrapper doesn't work properly in singledispatchmethod.__get__\n        # if it is applied to an unbound classmethod/staticmethod\n        if isinstance(func, (staticmethod, classmethod)):\n            self._wrapped_func = func.__func__\n        else:\n            self._wrapped_func = func\n    def register(self, cls, method=None):\n        \"\"\"generic_method.register(cls, func) -> func\n\n        Registers a new implementation for the given *cls* on a *generic_method*.\n        \"\"\"\n        # bpo-39679: in Python <= 3.9, classmethods and staticmethods don't\n        # inherit __annotations__ of the wrapped function (fixed in 3.10+ as\n        # a side-effect of bpo-43682) but we need that for annotation-derived\n        # singledispatches. So we add that just-in-time here.\n        if isinstance(cls, (staticmethod, classmethod)):\n            cls.__annotations__ = getattr(cls.__func__, '__annotations__', {})\n        return self.dispatcher.register(cls, func=method)\n\n    def __get__(self, obj, cls=None):\n        def _method(*args, **kwargs):\n            method = self.dispatcher.dispatch(args[0].__class__)\n            return method.__get__(obj, cls)(*args, **kwargs)\n\n        _method.__isabstractmethod__ = self.__isabstractmethod__\n        _method.register = self.register\n        update_wrapper(_method, self._wrapped_func)\n        return _method\n\n    @property\n    def __isabstractmethod__(self):\n        return getattr(self.func, '__isabstractmethod__', False)\n\n\n################################################################################\n### cached_property() - computed once per instance, cached as attribute\n################################################################################\n\n_NOT_FOUND = object()\n\n\nclass cached_property:\n    def __init__(self, func):\n        self.func = func\n        self.attrname = None\n        self.__doc__ = func.__doc__\n        self.lock = RLock()\n\n    def __set_name__(self, owner, name):\n        if self.attrname is None:\n            self.attrname = name\n        elif name != self.attrname:\n            raise TypeError(\n                \"Cannot assign the same cached_property to two different names \"\n                f\"({self.attrname!r} and {name!r}).\"\n            )\n\n    def __get__(self, instance, owner=None):\n        if instance is None:\n            return self\n        if self.attrname is None:\n            raise TypeError(\n                \"Cannot use cached_property instance without calling __set_name__ on it.\")\n        try:\n            cache = instance.__dict__\n        except AttributeError:  # not all objects have __dict__ (e.g. class defines slots)\n            msg = (\n                f\"No '__dict__' attribute on {type(instance).__name__!r} \"\n                f\"instance to cache {self.attrname!r} property.\"\n            )\n            raise TypeError(msg) from None\n        val = cache.get(self.attrname, _NOT_FOUND)\n        if val is _NOT_FOUND:\n            with self.lock:\n                # check if another thread filled cache while we awaited lock\n                val = cache.get(self.attrname, _NOT_FOUND)\n                if val is _NOT_FOUND:\n                    val = self.func(instance)\n                    try:\n                        cache[self.attrname] = val\n                    except TypeError:\n                        msg = (\n                            f\"The '__dict__' attribute on {type(instance).__name__!r} instance \"\n                            f\"does not support item assignment for caching {self.attrname!r} property.\"\n                        )\n                        raise TypeError(msg) from None\n        return val\n\n    __class_getitem__ = classmethod(GenericAlias)\n", 993], "/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/tokenize.py": ["\"\"\"Tokenization help for Python programs.\n\ntokenize(readline) is a generator that breaks a stream of bytes into\nPython tokens.  It decodes the bytes according to PEP-0263 for\ndetermining source file encoding.\n\nIt accepts a readline-like method which is called repeatedly to get the\nnext line of input (or b\"\" for EOF).  It generates 5-tuples with these\nmembers:\n\n    the token type (see token.py)\n    the token (a string)\n    the starting (row, column) indices of the token (a 2-tuple of ints)\n    the ending (row, column) indices of the token (a 2-tuple of ints)\n    the original line (string)\n\nIt is designed to match the working of the Python tokenizer exactly, except\nthat it produces COMMENT tokens for comments and gives type OP for all\noperators.  Additionally, all token lists start with an ENCODING token\nwhich tells you which encoding was used to decode the bytes stream.\n\"\"\"\n\n__author__ = 'Ka-Ping Yee <ping@lfw.org>'\n__credits__ = ('GvR, ESR, Tim Peters, Thomas Wouters, Fred Drake, '\n               'Skip Montanaro, Raymond Hettinger, Trent Nelson, '\n               'Michael Foord')\nfrom builtins import open as _builtin_open\nfrom codecs import lookup, BOM_UTF8\nimport collections\nfrom io import TextIOWrapper\nimport itertools as _itertools\nimport re\nimport sys\nfrom token import *\nfrom token import EXACT_TOKEN_TYPES\n\ncookie_re = re.compile(r'^[ \\t\\f]*#.*?coding[:=][ \\t]*([-\\w.]+)', re.ASCII)\nblank_re = re.compile(br'^[ \\t\\f]*(?:[#\\r\\n]|$)', re.ASCII)\n\nimport token\n__all__ = token.__all__ + [\"tokenize\", \"generate_tokens\", \"detect_encoding\",\n                           \"untokenize\", \"TokenInfo\"]\ndel token\n\nclass TokenInfo(collections.namedtuple('TokenInfo', 'type string start end line')):\n    def __repr__(self):\n        annotated_type = '%d (%s)' % (self.type, tok_name[self.type])\n        return ('TokenInfo(type=%s, string=%r, start=%r, end=%r, line=%r)' %\n                self._replace(type=annotated_type))\n\n    @property\n    def exact_type(self):\n        if self.type == OP and self.string in EXACT_TOKEN_TYPES:\n            return EXACT_TOKEN_TYPES[self.string]\n        else:\n            return self.type\n\ndef group(*choices): return '(' + '|'.join(choices) + ')'\ndef any(*choices): return group(*choices) + '*'\ndef maybe(*choices): return group(*choices) + '?'\n\n# Note: we use unicode matching for names (\"\\w\") but ascii matching for\n# number literals.\nWhitespace = r'[ \\f\\t]*'\nComment = r'#[^\\r\\n]*'\nIgnore = Whitespace + any(r'\\\\\\r?\\n' + Whitespace) + maybe(Comment)\nName = r'\\w+'\n\nHexnumber = r'0[xX](?:_?[0-9a-fA-F])+'\nBinnumber = r'0[bB](?:_?[01])+'\nOctnumber = r'0[oO](?:_?[0-7])+'\nDecnumber = r'(?:0(?:_?0)*|[1-9](?:_?[0-9])*)'\nIntnumber = group(Hexnumber, Binnumber, Octnumber, Decnumber)\nExponent = r'[eE][-+]?[0-9](?:_?[0-9])*'\nPointfloat = group(r'[0-9](?:_?[0-9])*\\.(?:[0-9](?:_?[0-9])*)?',\n                   r'\\.[0-9](?:_?[0-9])*') + maybe(Exponent)\nExpfloat = r'[0-9](?:_?[0-9])*' + Exponent\nFloatnumber = group(Pointfloat, Expfloat)\nImagnumber = group(r'[0-9](?:_?[0-9])*[jJ]', Floatnumber + r'[jJ]')\nNumber = group(Imagnumber, Floatnumber, Intnumber)\n\n# Return the empty string, plus all of the valid string prefixes.\ndef _all_string_prefixes():\n    # The valid string prefixes. Only contain the lower case versions,\n    #  and don't contain any permutations (include 'fr', but not\n    #  'rf'). The various permutations will be generated.\n    _valid_string_prefixes = ['b', 'r', 'u', 'f', 'br', 'fr']\n    # if we add binary f-strings, add: ['fb', 'fbr']\n    result = {''}\n    for prefix in _valid_string_prefixes:\n        for t in _itertools.permutations(prefix):\n            # create a list with upper and lower versions of each\n            #  character\n            for u in _itertools.product(*[(c, c.upper()) for c in t]):\n                result.add(''.join(u))\n    return result\n\ndef _compile(expr):\n    return re.compile(expr, re.UNICODE)\n\n# Note that since _all_string_prefixes includes the empty string,\n#  StringPrefix can be the empty string (making it optional).\nStringPrefix = group(*_all_string_prefixes())\n\n# Tail end of ' string.\nSingle = r\"[^'\\\\]*(?:\\\\.[^'\\\\]*)*'\"\n# Tail end of \" string.\nDouble = r'[^\"\\\\]*(?:\\\\.[^\"\\\\]*)*\"'\n# Tail end of ''' string.\nSingle3 = r\"[^'\\\\]*(?:(?:\\\\.|'(?!''))[^'\\\\]*)*'''\"\n# Tail end of \"\"\" string.\nDouble3 = r'[^\"\\\\]*(?:(?:\\\\.|\"(?!\"\"))[^\"\\\\]*)*\"\"\"'\nTriple = group(StringPrefix + \"'''\", StringPrefix + '\"\"\"')\n# Single-line ' or \" string.\nString = group(StringPrefix + r\"'[^\\n'\\\\]*(?:\\\\.[^\\n'\\\\]*)*'\",\n               StringPrefix + r'\"[^\\n\"\\\\]*(?:\\\\.[^\\n\"\\\\]*)*\"')\n\n# Sorting in reverse order puts the long operators before their prefixes.\n# Otherwise if = came before ==, == would get recognized as two instances\n# of =.\nSpecial = group(*map(re.escape, sorted(EXACT_TOKEN_TYPES, reverse=True)))\nFunny = group(r'\\r?\\n', Special)\n\nPlainToken = group(Number, Funny, String, Name)\nToken = Ignore + PlainToken\n\n# First (or only) line of ' or \" string.\nContStr = group(StringPrefix + r\"'[^\\n'\\\\]*(?:\\\\.[^\\n'\\\\]*)*\" +\n                group(\"'\", r'\\\\\\r?\\n'),\n                StringPrefix + r'\"[^\\n\"\\\\]*(?:\\\\.[^\\n\"\\\\]*)*' +\n                group('\"', r'\\\\\\r?\\n'))\nPseudoExtras = group(r'\\\\\\r?\\n|\\Z', Comment, Triple)\nPseudoToken = Whitespace + group(PseudoExtras, Number, Funny, ContStr, Name)\n\n# For a given string prefix plus quotes, endpats maps it to a regex\n#  to match the remainder of that string. _prefix can be empty, for\n#  a normal single or triple quoted string (with no prefix).\nendpats = {}\nfor _prefix in _all_string_prefixes():\n    endpats[_prefix + \"'\"] = Single\n    endpats[_prefix + '\"'] = Double\n    endpats[_prefix + \"'''\"] = Single3\n    endpats[_prefix + '\"\"\"'] = Double3\n\n# A set of all of the single and triple quoted string prefixes,\n#  including the opening quotes.\nsingle_quoted = set()\ntriple_quoted = set()\nfor t in _all_string_prefixes():\n    for u in (t + '\"', t + \"'\"):\n        single_quoted.add(u)\n    for u in (t + '\"\"\"', t + \"'''\"):\n        triple_quoted.add(u)\n\ntabsize = 8\n\nclass TokenError(Exception): pass\n\nclass StopTokenizing(Exception): pass\n\n\nclass Untokenizer:\n\n    def __init__(self):\n        self.tokens = []\n        self.prev_row = 1\n        self.prev_col = 0\n        self.encoding = None\n\n    def add_whitespace(self, start):\n        row, col = start\n        if row < self.prev_row or row == self.prev_row and col < self.prev_col:\n            raise ValueError(\"start ({},{}) precedes previous end ({},{})\"\n                             .format(row, col, self.prev_row, self.prev_col))\n        row_offset = row - self.prev_row\n        if row_offset:\n            self.tokens.append(\"\\\\\\n\" * row_offset)\n            self.prev_col = 0\n        col_offset = col - self.prev_col\n        if col_offset:\n            self.tokens.append(\" \" * col_offset)\n\n    def untokenize(self, iterable):\n        it = iter(iterable)\n        indents = []\n        startline = False\n        for t in it:\n            if len(t) == 2:\n                self.compat(t, it)\n                break\n            tok_type, token, start, end, line = t\n            if tok_type == ENCODING:\n                self.encoding = token\n                continue\n            if tok_type == ENDMARKER:\n                break\n            if tok_type == INDENT:\n                indents.append(token)\n                continue\n            elif tok_type == DEDENT:\n                indents.pop()\n                self.prev_row, self.prev_col = end\n                continue\n            elif tok_type in (NEWLINE, NL):\n                startline = True\n            elif startline and indents:\n                indent = indents[-1]\n                if start[1] >= len(indent):\n                    self.tokens.append(indent)\n                    self.prev_col = len(indent)\n                startline = False\n            self.add_whitespace(start)\n            self.tokens.append(token)\n            self.prev_row, self.prev_col = end\n            if tok_type in (NEWLINE, NL):\n                self.prev_row += 1\n                self.prev_col = 0\n        return \"\".join(self.tokens)\n\n    def compat(self, token, iterable):\n        indents = []\n        toks_append = self.tokens.append\n        startline = token[0] in (NEWLINE, NL)\n        prevstring = False\n\n        for tok in _itertools.chain([token], iterable):\n            toknum, tokval = tok[:2]\n            if toknum == ENCODING:\n                self.encoding = tokval\n                continue\n\n            if toknum in (NAME, NUMBER):\n                tokval += ' '\n\n            # Insert a space between two consecutive strings\n            if toknum == STRING:\n                if prevstring:\n                    tokval = ' ' + tokval\n                prevstring = True\n            else:\n                prevstring = False\n\n            if toknum == INDENT:\n                indents.append(tokval)\n                continue\n            elif toknum == DEDENT:\n                indents.pop()\n                continue\n            elif toknum in (NEWLINE, NL):\n                startline = True\n            elif startline and indents:\n                toks_append(indents[-1])\n                startline = False\n            toks_append(tokval)\n\n\ndef untokenize(iterable):\n    \"\"\"Transform tokens back into Python source code.\n    It returns a bytes object, encoded using the ENCODING\n    token, which is the first token sequence output by tokenize.\n\n    Each element returned by the iterable must be a token sequence\n    with at least two elements, a token number and token value.  If\n    only two tokens are passed, the resulting output is poor.\n\n    Round-trip invariant for full input:\n        Untokenized source will match input source exactly\n\n    Round-trip invariant for limited input:\n        # Output bytes will tokenize back to the input\n        t1 = [tok[:2] for tok in tokenize(f.readline)]\n        newcode = untokenize(t1)\n        readline = BytesIO(newcode).readline\n        t2 = [tok[:2] for tok in tokenize(readline)]\n        assert t1 == t2\n    \"\"\"\n    ut = Untokenizer()\n    out = ut.untokenize(iterable)\n    if ut.encoding is not None:\n        out = out.encode(ut.encoding)\n    return out\n\n\ndef _get_normal_name(orig_enc):\n    \"\"\"Imitates get_normal_name in tokenizer.c.\"\"\"\n    # Only care about the first 12 characters.\n    enc = orig_enc[:12].lower().replace(\"_\", \"-\")\n    if enc == \"utf-8\" or enc.startswith(\"utf-8-\"):\n        return \"utf-8\"\n    if enc in (\"latin-1\", \"iso-8859-1\", \"iso-latin-1\") or \\\n       enc.startswith((\"latin-1-\", \"iso-8859-1-\", \"iso-latin-1-\")):\n        return \"iso-8859-1\"\n    return orig_enc\n\ndef detect_encoding(readline):\n    \"\"\"\n    The detect_encoding() function is used to detect the encoding that should\n    be used to decode a Python source file.  It requires one argument, readline,\n    in the same way as the tokenize() generator.\n\n    It will call readline a maximum of twice, and return the encoding used\n    (as a string) and a list of any lines (left as bytes) it has read in.\n\n    It detects the encoding from the presence of a utf-8 bom or an encoding\n    cookie as specified in pep-0263.  If both a bom and a cookie are present,\n    but disagree, a SyntaxError will be raised.  If the encoding cookie is an\n    invalid charset, raise a SyntaxError.  Note that if a utf-8 bom is found,\n    'utf-8-sig' is returned.\n\n    If no encoding is specified, then the default of 'utf-8' will be returned.\n    \"\"\"\n    try:\n        filename = readline.__self__.name\n    except AttributeError:\n        filename = None\n    bom_found = False\n    encoding = None\n    default = 'utf-8'\n    def read_or_stop():\n        try:\n            return readline()\n        except StopIteration:\n            return b''\n\n    def find_cookie(line):\n        try:\n            # Decode as UTF-8. Either the line is an encoding declaration,\n            # in which case it should be pure ASCII, or it must be UTF-8\n            # per default encoding.\n            line_string = line.decode('utf-8')\n        except UnicodeDecodeError:\n            msg = \"invalid or missing encoding declaration\"\n            if filename is not None:\n                msg = '{} for {!r}'.format(msg, filename)\n            raise SyntaxError(msg)\n\n        match = cookie_re.match(line_string)\n        if not match:\n            return None\n        encoding = _get_normal_name(match.group(1))\n        try:\n            codec = lookup(encoding)\n        except LookupError:\n            # This behaviour mimics the Python interpreter\n            if filename is None:\n                msg = \"unknown encoding: \" + encoding\n            else:\n                msg = \"unknown encoding for {!r}: {}\".format(filename,\n                        encoding)\n            raise SyntaxError(msg)\n\n        if bom_found:\n            if encoding != 'utf-8':\n                # This behaviour mimics the Python interpreter\n                if filename is None:\n                    msg = 'encoding problem: utf-8'\n                else:\n                    msg = 'encoding problem for {!r}: utf-8'.format(filename)\n                raise SyntaxError(msg)\n            encoding += '-sig'\n        return encoding\n\n    first = read_or_stop()\n    if first.startswith(BOM_UTF8):\n        bom_found = True\n        first = first[3:]\n        default = 'utf-8-sig'\n    if not first:\n        return default, []\n\n    encoding = find_cookie(first)\n    if encoding:\n        return encoding, [first]\n    if not blank_re.match(first):\n        return default, [first]\n\n    second = read_or_stop()\n    if not second:\n        return default, [first]\n\n    encoding = find_cookie(second)\n    if encoding:\n        return encoding, [first, second]\n\n    return default, [first, second]\n\n\ndef open(filename):\n    \"\"\"Open a file in read only mode using the encoding detected by\n    detect_encoding().\n    \"\"\"\n    buffer = _builtin_open(filename, 'rb')\n    try:\n        encoding, lines = detect_encoding(buffer.readline)\n        buffer.seek(0)\n        text = TextIOWrapper(buffer, encoding, line_buffering=True)\n        text.mode = 'r'\n        return text\n    except:\n        buffer.close()\n        raise\n\n\ndef tokenize(readline):\n    \"\"\"\n    The tokenize() generator requires one argument, readline, which\n    must be a callable object which provides the same interface as the\n    readline() method of built-in file objects.  Each call to the function\n    should return one line of input as bytes.  Alternatively, readline\n    can be a callable function terminating with StopIteration:\n        readline = open(myfile, 'rb').__next__  # Example of alternate readline\n\n    The generator produces 5-tuples with these members: the token type; the\n    token string; a 2-tuple (srow, scol) of ints specifying the row and\n    column where the token begins in the source; a 2-tuple (erow, ecol) of\n    ints specifying the row and column where the token ends in the source;\n    and the line on which the token was found.  The line passed is the\n    physical line.\n\n    The first token sequence will always be an ENCODING token\n    which tells you which encoding was used to decode the bytes stream.\n    \"\"\"\n    encoding, consumed = detect_encoding(readline)\n    empty = _itertools.repeat(b\"\")\n    rl_gen = _itertools.chain(consumed, iter(readline, b\"\"), empty)\n    return _tokenize(rl_gen.__next__, encoding)\n\n\ndef _tokenize(readline, encoding):\n    lnum = parenlev = continued = 0\n    numchars = '0123456789'\n    contstr, needcont = '', 0\n    contline = None\n    indents = [0]\n\n    if encoding is not None:\n        if encoding == \"utf-8-sig\":\n            # BOM will already have been stripped.\n            encoding = \"utf-8\"\n        yield TokenInfo(ENCODING, encoding, (0, 0), (0, 0), '')\n    last_line = b''\n    line = b''\n    while True:                                # loop over lines in stream\n        try:\n            # We capture the value of the line variable here because\n            # readline uses the empty string '' to signal end of input,\n            # hence `line` itself will always be overwritten at the end\n            # of this loop.\n            last_line = line\n            line = readline()\n        except StopIteration:\n            line = b''\n\n        if encoding is not None:\n            line = line.decode(encoding)\n        lnum += 1\n        pos, max = 0, len(line)\n\n        if contstr:                            # continued string\n            if not line:\n                raise TokenError(\"EOF in multi-line string\", strstart)\n            endmatch = endprog.match(line)\n            if endmatch:\n                pos = end = endmatch.end(0)\n                yield TokenInfo(STRING, contstr + line[:end],\n                       strstart, (lnum, end), contline + line)\n                contstr, needcont = '', 0\n                contline = None\n            elif needcont and line[-2:] != '\\\\\\n' and line[-3:] != '\\\\\\r\\n':\n                yield TokenInfo(ERRORTOKEN, contstr + line,\n                           strstart, (lnum, len(line)), contline)\n                contstr = ''\n                contline = None\n                continue\n            else:\n                contstr = contstr + line\n                contline = contline + line\n                continue\n\n        elif parenlev == 0 and not continued:  # new statement\n            if not line: break\n            column = 0\n            while pos < max:                   # measure leading whitespace\n                if line[pos] == ' ':\n                    column += 1\n                elif line[pos] == '\\t':\n                    column = (column//tabsize + 1)*tabsize\n                elif line[pos] == '\\f':\n                    column = 0\n                else:\n                    break\n                pos += 1\n            if pos == max:\n                break\n\n            if line[pos] in '#\\r\\n':           # skip comments or blank lines\n                if line[pos] == '#':\n                    comment_token = line[pos:].rstrip('\\r\\n')\n                    yield TokenInfo(COMMENT, comment_token,\n                           (lnum, pos), (lnum, pos + len(comment_token)), line)\n                    pos += len(comment_token)\n\n                yield TokenInfo(NL, line[pos:],\n                           (lnum, pos), (lnum, len(line)), line)\n                continue\n\n            if column > indents[-1]:           # count indents or dedents\n                indents.append(column)\n                yield TokenInfo(INDENT, line[:pos], (lnum, 0), (lnum, pos), line)\n            while column < indents[-1]:\n                if column not in indents:\n                    raise IndentationError(\n                        \"unindent does not match any outer indentation level\",\n                        (\"<tokenize>\", lnum, pos, line))\n                indents = indents[:-1]\n\n                yield TokenInfo(DEDENT, '', (lnum, pos), (lnum, pos), line)\n\n        else:                                  # continued statement\n            if not line:\n                raise TokenError(\"EOF in multi-line statement\", (lnum, 0))\n            continued = 0\n\n        while pos < max:\n            pseudomatch = _compile(PseudoToken).match(line, pos)\n            if pseudomatch:                                # scan for tokens\n                start, end = pseudomatch.span(1)\n                spos, epos, pos = (lnum, start), (lnum, end), end\n                if start == end:\n                    continue\n                token, initial = line[start:end], line[start]\n\n                if (initial in numchars or                 # ordinary number\n                    (initial == '.' and token != '.' and token != '...')):\n                    yield TokenInfo(NUMBER, token, spos, epos, line)\n                elif initial in '\\r\\n':\n                    if parenlev > 0:\n                        yield TokenInfo(NL, token, spos, epos, line)\n                    else:\n                        yield TokenInfo(NEWLINE, token, spos, epos, line)\n\n                elif initial == '#':\n                    assert not token.endswith(\"\\n\")\n                    yield TokenInfo(COMMENT, token, spos, epos, line)\n\n                elif token in triple_quoted:\n                    endprog = _compile(endpats[token])\n                    endmatch = endprog.match(line, pos)\n                    if endmatch:                           # all on one line\n                        pos = endmatch.end(0)\n                        token = line[start:pos]\n                        yield TokenInfo(STRING, token, spos, (lnum, pos), line)\n                    else:\n                        strstart = (lnum, start)           # multiple lines\n                        contstr = line[start:]\n                        contline = line\n                        break\n\n                # Check up to the first 3 chars of the token to see if\n                #  they're in the single_quoted set. If so, they start\n                #  a string.\n                # We're using the first 3, because we're looking for\n                #  \"rb'\" (for example) at the start of the token. If\n                #  we switch to longer prefixes, this needs to be\n                #  adjusted.\n                # Note that initial == token[:1].\n                # Also note that single quote checking must come after\n                #  triple quote checking (above).\n                elif (initial in single_quoted or\n                      token[:2] in single_quoted or\n                      token[:3] in single_quoted):\n                    if token[-1] == '\\n':                  # continued string\n                        strstart = (lnum, start)\n                        # Again, using the first 3 chars of the\n                        #  token. This is looking for the matching end\n                        #  regex for the correct type of quote\n                        #  character. So it's really looking for\n                        #  endpats[\"'\"] or endpats['\"'], by trying to\n                        #  skip string prefix characters, if any.\n                        endprog = _compile(endpats.get(initial) or\n                                           endpats.get(token[1]) or\n                                           endpats.get(token[2]))\n                        contstr, needcont = line[start:], 1\n                        contline = line\n                        break\n                    else:                                  # ordinary string\n                        yield TokenInfo(STRING, token, spos, epos, line)\n\n                elif initial.isidentifier():               # ordinary name\n                    yield TokenInfo(NAME, token, spos, epos, line)\n                elif initial == '\\\\':                      # continued stmt\n                    continued = 1\n                else:\n                    if initial in '([{':\n                        parenlev += 1\n                    elif initial in ')]}':\n                        parenlev -= 1\n                    yield TokenInfo(OP, token, spos, epos, line)\n            else:\n                yield TokenInfo(ERRORTOKEN, line[pos],\n                           (lnum, pos), (lnum, pos+1), line)\n                pos += 1\n\n    # Add an implicit NEWLINE if the input doesn't end in one\n    if last_line and last_line[-1] not in '\\r\\n' and not last_line.strip().startswith(\"#\"):\n        yield TokenInfo(NEWLINE, '', (lnum - 1, len(last_line)), (lnum - 1, len(last_line) + 1), '')\n    for indent in indents[1:]:                 # pop remaining indent levels\n        yield TokenInfo(DEDENT, '', (lnum, 0), (lnum, 0), '')\n    yield TokenInfo(ENDMARKER, '', (lnum, 0), (lnum, 0), '')\n\n\ndef generate_tokens(readline):\n    \"\"\"Tokenize a source reading Python code as unicode strings.\n\n    This has the same API as tokenize(), except that it expects the *readline*\n    callable to return str objects instead of bytes.\n    \"\"\"\n    return _tokenize(readline, None)\n\ndef main():\n    import argparse\n\n    # Helper error handling routines\n    def perror(message):\n        sys.stderr.write(message)\n        sys.stderr.write('\\n')\n\n    def error(message, filename=None, location=None):\n        if location:\n            args = (filename,) + location + (message,)\n            perror(\"%s:%d:%d: error: %s\" % args)\n        elif filename:\n            perror(\"%s: error: %s\" % (filename, message))\n        else:\n            perror(\"error: %s\" % message)\n        sys.exit(1)\n\n    # Parse the arguments and options\n    parser = argparse.ArgumentParser(prog='python -m tokenize')\n    parser.add_argument(dest='filename', nargs='?',\n                        metavar='filename.py',\n                        help='the file to tokenize; defaults to stdin')\n    parser.add_argument('-e', '--exact', dest='exact', action='store_true',\n                        help='display token names using the exact type')\n    args = parser.parse_args()\n\n    try:\n        # Tokenize the input\n        if args.filename:\n            filename = args.filename\n            with _builtin_open(filename, 'rb') as f:\n                tokens = list(tokenize(f.readline))\n        else:\n            filename = \"<stdin>\"\n            tokens = _tokenize(sys.stdin.readline, None)\n\n        # Output the tokenization\n        for token in tokens:\n            token_type = token.type\n            if args.exact:\n                token_type = token.exact_type\n            token_range = \"%d,%d-%d,%d:\" % (token.start + token.end)\n            print(\"%-20s%-15s%-15r\" %\n                  (token_range, tok_name[token_type], token.string))\n    except IndentationError as err:\n        line, column = err.args[1][1:3]\n        error(err.args[0], filename, (line, column))\n    except TokenError as err:\n        line, column = err.args[1]\n        error(err.args[0], filename, (line, column))\n    except SyntaxError as err:\n        error(err, filename)\n    except OSError as err:\n        error(err)\n    except KeyboardInterrupt:\n        print(\"interrupted\\n\")\n    except Exception as err:\n        perror(\"unexpected error: %s\" % err)\n        raise\n\nif __name__ == \"__main__\":\n    main()\n", 682], "/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/json/decoder.py": ["\"\"\"Implementation of JSONDecoder\n\"\"\"\nimport re\n\nfrom json import scanner\ntry:\n    from _json import scanstring as c_scanstring\nexcept ImportError:\n    c_scanstring = None\n\n__all__ = ['JSONDecoder', 'JSONDecodeError']\n\nFLAGS = re.VERBOSE | re.MULTILINE | re.DOTALL\n\nNaN = float('nan')\nPosInf = float('inf')\nNegInf = float('-inf')\n\n\nclass JSONDecodeError(ValueError):\n    \"\"\"Subclass of ValueError with the following additional properties:\n\n    msg: The unformatted error message\n    doc: The JSON document being parsed\n    pos: The start index of doc where parsing failed\n    lineno: The line corresponding to pos\n    colno: The column corresponding to pos\n\n    \"\"\"\n    # Note that this exception is used from _json\n    def __init__(self, msg, doc, pos):\n        lineno = doc.count('\\n', 0, pos) + 1\n        colno = pos - doc.rfind('\\n', 0, pos)\n        errmsg = '%s: line %d column %d (char %d)' % (msg, lineno, colno, pos)\n        ValueError.__init__(self, errmsg)\n        self.msg = msg\n        self.doc = doc\n        self.pos = pos\n        self.lineno = lineno\n        self.colno = colno\n\n    def __reduce__(self):\n        return self.__class__, (self.msg, self.doc, self.pos)\n\n\n_CONSTANTS = {\n    '-Infinity': NegInf,\n    'Infinity': PosInf,\n    'NaN': NaN,\n}\n\n\nSTRINGCHUNK = re.compile(r'(.*?)([\"\\\\\\x00-\\x1f])', FLAGS)\nBACKSLASH = {\n    '\"': '\"', '\\\\': '\\\\', '/': '/',\n    'b': '\\b', 'f': '\\f', 'n': '\\n', 'r': '\\r', 't': '\\t',\n}\n\ndef _decode_uXXXX(s, pos):\n    esc = s[pos + 1:pos + 5]\n    if len(esc) == 4 and esc[1] not in 'xX':\n        try:\n            return int(esc, 16)\n        except ValueError:\n            pass\n    msg = \"Invalid \\\\uXXXX escape\"\n    raise JSONDecodeError(msg, s, pos)\n\ndef py_scanstring(s, end, strict=True,\n        _b=BACKSLASH, _m=STRINGCHUNK.match):\n    \"\"\"Scan the string s for a JSON string. End is the index of the\n    character in s after the quote that started the JSON string.\n    Unescapes all valid JSON string escape sequences and raises ValueError\n    on attempt to decode an invalid string. If strict is False then literal\n    control characters are allowed in the string.\n\n    Returns a tuple of the decoded string and the index of the character in s\n    after the end quote.\"\"\"\n    chunks = []\n    _append = chunks.append\n    begin = end - 1\n    while 1:\n        chunk = _m(s, end)\n        if chunk is None:\n            raise JSONDecodeError(\"Unterminated string starting at\", s, begin)\n        end = chunk.end()\n        content, terminator = chunk.groups()\n        # Content is contains zero or more unescaped string characters\n        if content:\n            _append(content)\n        # Terminator is the end of string, a literal control character,\n        # or a backslash denoting that an escape sequence follows\n        if terminator == '\"':\n            break\n        elif terminator != '\\\\':\n            if strict:\n                #msg = \"Invalid control character %r at\" % (terminator,)\n                msg = \"Invalid control character {0!r} at\".format(terminator)\n                raise JSONDecodeError(msg, s, end)\n            else:\n                _append(terminator)\n                continue\n        try:\n            esc = s[end]\n        except IndexError:\n            raise JSONDecodeError(\"Unterminated string starting at\",\n                                  s, begin) from None\n        # If not a unicode escape sequence, must be in the lookup table\n        if esc != 'u':\n            try:\n                char = _b[esc]\n            except KeyError:\n                msg = \"Invalid \\\\escape: {0!r}\".format(esc)\n                raise JSONDecodeError(msg, s, end)\n            end += 1\n        else:\n            uni = _decode_uXXXX(s, end)\n            end += 5\n            if 0xd800 <= uni <= 0xdbff and s[end:end + 2] == '\\\\u':\n                uni2 = _decode_uXXXX(s, end + 1)\n                if 0xdc00 <= uni2 <= 0xdfff:\n                    uni = 0x10000 + (((uni - 0xd800) << 10) | (uni2 - 0xdc00))\n                    end += 6\n            char = chr(uni)\n        _append(char)\n    return ''.join(chunks), end\n\n\n# Use speedup if available\nscanstring = c_scanstring or py_scanstring\n\nWHITESPACE = re.compile(r'[ \\t\\n\\r]*', FLAGS)\nWHITESPACE_STR = ' \\t\\n\\r'\n\n\ndef JSONObject(s_and_end, strict, scan_once, object_hook, object_pairs_hook,\n               memo=None, _w=WHITESPACE.match, _ws=WHITESPACE_STR):\n    s, end = s_and_end\n    pairs = []\n    pairs_append = pairs.append\n    # Backwards compatibility\n    if memo is None:\n        memo = {}\n    memo_get = memo.setdefault\n    # Use a slice to prevent IndexError from being raised, the following\n    # check will raise a more specific ValueError if the string is empty\n    nextchar = s[end:end + 1]\n    # Normally we expect nextchar == '\"'\n    if nextchar != '\"':\n        if nextchar in _ws:\n            end = _w(s, end).end()\n            nextchar = s[end:end + 1]\n        # Trivial empty object\n        if nextchar == '}':\n            if object_pairs_hook is not None:\n                result = object_pairs_hook(pairs)\n                return result, end + 1\n            pairs = {}\n            if object_hook is not None:\n                pairs = object_hook(pairs)\n            return pairs, end + 1\n        elif nextchar != '\"':\n            raise JSONDecodeError(\n                \"Expecting property name enclosed in double quotes\", s, end)\n    end += 1\n    while True:\n        key, end = scanstring(s, end, strict)\n        key = memo_get(key, key)\n        # To skip some function call overhead we optimize the fast paths where\n        # the JSON key separator is \": \" or just \":\".\n        if s[end:end + 1] != ':':\n            end = _w(s, end).end()\n            if s[end:end + 1] != ':':\n                raise JSONDecodeError(\"Expecting ':' delimiter\", s, end)\n        end += 1\n\n        try:\n            if s[end] in _ws:\n                end += 1\n                if s[end] in _ws:\n                    end = _w(s, end + 1).end()\n        except IndexError:\n            pass\n\n        try:\n            value, end = scan_once(s, end)\n        except StopIteration as err:\n            raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n        pairs_append((key, value))\n        try:\n            nextchar = s[end]\n            if nextchar in _ws:\n                end = _w(s, end + 1).end()\n                nextchar = s[end]\n        except IndexError:\n            nextchar = ''\n        end += 1\n\n        if nextchar == '}':\n            break\n        elif nextchar != ',':\n            raise JSONDecodeError(\"Expecting ',' delimiter\", s, end - 1)\n        end = _w(s, end).end()\n        nextchar = s[end:end + 1]\n        end += 1\n        if nextchar != '\"':\n            raise JSONDecodeError(\n                \"Expecting property name enclosed in double quotes\", s, end - 1)\n    if object_pairs_hook is not None:\n        result = object_pairs_hook(pairs)\n        return result, end\n    pairs = dict(pairs)\n    if object_hook is not None:\n        pairs = object_hook(pairs)\n    return pairs, end\n\ndef JSONArray(s_and_end, scan_once, _w=WHITESPACE.match, _ws=WHITESPACE_STR):\n    s, end = s_and_end\n    values = []\n    nextchar = s[end:end + 1]\n    if nextchar in _ws:\n        end = _w(s, end + 1).end()\n        nextchar = s[end:end + 1]\n    # Look-ahead for trivial empty array\n    if nextchar == ']':\n        return values, end + 1\n    _append = values.append\n    while True:\n        try:\n            value, end = scan_once(s, end)\n        except StopIteration as err:\n            raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n        _append(value)\n        nextchar = s[end:end + 1]\n        if nextchar in _ws:\n            end = _w(s, end + 1).end()\n            nextchar = s[end:end + 1]\n        end += 1\n        if nextchar == ']':\n            break\n        elif nextchar != ',':\n            raise JSONDecodeError(\"Expecting ',' delimiter\", s, end - 1)\n        try:\n            if s[end] in _ws:\n                end += 1\n                if s[end] in _ws:\n                    end = _w(s, end + 1).end()\n        except IndexError:\n            pass\n\n    return values, end\n\n\nclass JSONDecoder(object):\n    \"\"\"Simple JSON <http://json.org> decoder\n\n    Performs the following translations in decoding by default:\n\n    +---------------+-------------------+\n    | JSON          | Python            |\n    +===============+===================+\n    | object        | dict              |\n    +---------------+-------------------+\n    | array         | list              |\n    +---------------+-------------------+\n    | string        | str               |\n    +---------------+-------------------+\n    | number (int)  | int               |\n    +---------------+-------------------+\n    | number (real) | float             |\n    +---------------+-------------------+\n    | true          | True              |\n    +---------------+-------------------+\n    | false         | False             |\n    +---------------+-------------------+\n    | null          | None              |\n    +---------------+-------------------+\n\n    It also understands ``NaN``, ``Infinity``, and ``-Infinity`` as\n    their corresponding ``float`` values, which is outside the JSON spec.\n\n    \"\"\"\n\n    def __init__(self, *, object_hook=None, parse_float=None,\n            parse_int=None, parse_constant=None, strict=True,\n            object_pairs_hook=None):\n        \"\"\"``object_hook``, if specified, will be called with the result\n        of every JSON object decoded and its return value will be used in\n        place of the given ``dict``.  This can be used to provide custom\n        deserializations (e.g. to support JSON-RPC class hinting).\n\n        ``object_pairs_hook``, if specified will be called with the result of\n        every JSON object decoded with an ordered list of pairs.  The return\n        value of ``object_pairs_hook`` will be used instead of the ``dict``.\n        This feature can be used to implement custom decoders.\n        If ``object_hook`` is also defined, the ``object_pairs_hook`` takes\n        priority.\n\n        ``parse_float``, if specified, will be called with the string\n        of every JSON float to be decoded. By default this is equivalent to\n        float(num_str). This can be used to use another datatype or parser\n        for JSON floats (e.g. decimal.Decimal).\n\n        ``parse_int``, if specified, will be called with the string\n        of every JSON int to be decoded. By default this is equivalent to\n        int(num_str). This can be used to use another datatype or parser\n        for JSON integers (e.g. float).\n\n        ``parse_constant``, if specified, will be called with one of the\n        following strings: -Infinity, Infinity, NaN.\n        This can be used to raise an exception if invalid JSON numbers\n        are encountered.\n\n        If ``strict`` is false (true is the default), then control\n        characters will be allowed inside strings.  Control characters in\n        this context are those with character codes in the 0-31 range,\n        including ``'\\\\t'`` (tab), ``'\\\\n'``, ``'\\\\r'`` and ``'\\\\0'``.\n        \"\"\"\n        self.object_hook = object_hook\n        self.parse_float = parse_float or float\n        self.parse_int = parse_int or int\n        self.parse_constant = parse_constant or _CONSTANTS.__getitem__\n        self.strict = strict\n        self.object_pairs_hook = object_pairs_hook\n        self.parse_object = JSONObject\n        self.parse_array = JSONArray\n        self.parse_string = scanstring\n        self.memo = {}\n        self.scan_once = scanner.make_scanner(self)\n\n\n    def decode(self, s, _w=WHITESPACE.match):\n        \"\"\"Return the Python representation of ``s`` (a ``str`` instance\n        containing a JSON document).\n\n        \"\"\"\n        obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n        end = _w(s, end).end()\n        if end != len(s):\n            raise JSONDecodeError(\"Extra data\", s, end)\n        return obj\n\n    def raw_decode(self, s, idx=0):\n        \"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\n        a JSON document) and return a 2-tuple of the Python\n        representation and the index in ``s`` where the document ended.\n\n        This can be used to decode a JSON document from a string that may\n        have extraneous data at the end.\n\n        \"\"\"\n        try:\n            obj, end = self.scan_once(s, idx)\n        except StopIteration as err:\n            raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n        return obj, end\n", 356], "/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/json/__init__.py": ["r\"\"\"JSON (JavaScript Object Notation) <http://json.org> is a subset of\nJavaScript syntax (ECMA-262 3rd edition) used as a lightweight data\ninterchange format.\n\n:mod:`json` exposes an API familiar to users of the standard library\n:mod:`marshal` and :mod:`pickle` modules.  It is derived from a\nversion of the externally maintained simplejson library.\n\nEncoding basic Python object hierarchies::\n\n    >>> import json\n    >>> json.dumps(['foo', {'bar': ('baz', None, 1.0, 2)}])\n    '[\"foo\", {\"bar\": [\"baz\", null, 1.0, 2]}]'\n    >>> print(json.dumps(\"\\\"foo\\bar\"))\n    \"\\\"foo\\bar\"\n    >>> print(json.dumps('\\u1234'))\n    \"\\u1234\"\n    >>> print(json.dumps('\\\\'))\n    \"\\\\\"\n    >>> print(json.dumps({\"c\": 0, \"b\": 0, \"a\": 0}, sort_keys=True))\n    {\"a\": 0, \"b\": 0, \"c\": 0}\n    >>> from io import StringIO\n    >>> io = StringIO()\n    >>> json.dump(['streaming API'], io)\n    >>> io.getvalue()\n    '[\"streaming API\"]'\n\nCompact encoding::\n\n    >>> import json\n    >>> mydict = {'4': 5, '6': 7}\n    >>> json.dumps([1,2,3,mydict], separators=(',', ':'))\n    '[1,2,3,{\"4\":5,\"6\":7}]'\n\nPretty printing::\n\n    >>> import json\n    >>> print(json.dumps({'4': 5, '6': 7}, sort_keys=True, indent=4))\n    {\n        \"4\": 5,\n        \"6\": 7\n    }\n\nDecoding JSON::\n\n    >>> import json\n    >>> obj = ['foo', {'bar': ['baz', None, 1.0, 2]}]\n    >>> json.loads('[\"foo\", {\"bar\":[\"baz\", null, 1.0, 2]}]') == obj\n    True\n    >>> json.loads('\"\\\\\"foo\\\\bar\"') == '\"foo\\x08ar'\n    True\n    >>> from io import StringIO\n    >>> io = StringIO('[\"streaming API\"]')\n    >>> json.load(io)[0] == 'streaming API'\n    True\n\nSpecializing JSON object decoding::\n\n    >>> import json\n    >>> def as_complex(dct):\n    ...     if '__complex__' in dct:\n    ...         return complex(dct['real'], dct['imag'])\n    ...     return dct\n    ...\n    >>> json.loads('{\"__complex__\": true, \"real\": 1, \"imag\": 2}',\n    ...     object_hook=as_complex)\n    (1+2j)\n    >>> from decimal import Decimal\n    >>> json.loads('1.1', parse_float=Decimal) == Decimal('1.1')\n    True\n\nSpecializing JSON object encoding::\n\n    >>> import json\n    >>> def encode_complex(obj):\n    ...     if isinstance(obj, complex):\n    ...         return [obj.real, obj.imag]\n    ...     raise TypeError(f'Object of type {obj.__class__.__name__} '\n    ...                     f'is not JSON serializable')\n    ...\n    >>> json.dumps(2 + 1j, default=encode_complex)\n    '[2.0, 1.0]'\n    >>> json.JSONEncoder(default=encode_complex).encode(2 + 1j)\n    '[2.0, 1.0]'\n    >>> ''.join(json.JSONEncoder(default=encode_complex).iterencode(2 + 1j))\n    '[2.0, 1.0]'\n\n\nUsing json.tool from the shell to validate and pretty-print::\n\n    $ echo '{\"json\":\"obj\"}' | python -m json.tool\n    {\n        \"json\": \"obj\"\n    }\n    $ echo '{ 1.2:3.4}' | python -m json.tool\n    Expecting property name enclosed in double quotes: line 1 column 3 (char 2)\n\"\"\"\n__version__ = '2.0.9'\n__all__ = [\n    'dump', 'dumps', 'load', 'loads',\n    'JSONDecoder', 'JSONDecodeError', 'JSONEncoder',\n]\n\n__author__ = 'Bob Ippolito <bob@redivi.com>'\n\nfrom .decoder import JSONDecoder, JSONDecodeError\nfrom .encoder import JSONEncoder\nimport codecs\n\n_default_encoder = JSONEncoder(\n    skipkeys=False,\n    ensure_ascii=True,\n    check_circular=True,\n    allow_nan=True,\n    indent=None,\n    separators=None,\n    default=None,\n)\n\ndef dump(obj, fp, *, skipkeys=False, ensure_ascii=True, check_circular=True,\n        allow_nan=True, cls=None, indent=None, separators=None,\n        default=None, sort_keys=False, **kw):\n    \"\"\"Serialize ``obj`` as a JSON formatted stream to ``fp`` (a\n    ``.write()``-supporting file-like object).\n\n    If ``skipkeys`` is true then ``dict`` keys that are not basic types\n    (``str``, ``int``, ``float``, ``bool``, ``None``) will be skipped\n    instead of raising a ``TypeError``.\n\n    If ``ensure_ascii`` is false, then the strings written to ``fp`` can\n    contain non-ASCII characters if they appear in strings contained in\n    ``obj``. Otherwise, all such characters are escaped in JSON strings.\n\n    If ``check_circular`` is false, then the circular reference check\n    for container types will be skipped and a circular reference will\n    result in an ``OverflowError`` (or worse).\n\n    If ``allow_nan`` is false, then it will be a ``ValueError`` to\n    serialize out of range ``float`` values (``nan``, ``inf``, ``-inf``)\n    in strict compliance of the JSON specification, instead of using the\n    JavaScript equivalents (``NaN``, ``Infinity``, ``-Infinity``).\n\n    If ``indent`` is a non-negative integer, then JSON array elements and\n    object members will be pretty-printed with that indent level. An indent\n    level of 0 will only insert newlines. ``None`` is the most compact\n    representation.\n\n    If specified, ``separators`` should be an ``(item_separator, key_separator)``\n    tuple.  The default is ``(', ', ': ')`` if *indent* is ``None`` and\n    ``(',', ': ')`` otherwise.  To get the most compact JSON representation,\n    you should specify ``(',', ':')`` to eliminate whitespace.\n\n    ``default(obj)`` is a function that should return a serializable version\n    of obj or raise TypeError. The default simply raises TypeError.\n\n    If *sort_keys* is true (default: ``False``), then the output of\n    dictionaries will be sorted by key.\n\n    To use a custom ``JSONEncoder`` subclass (e.g. one that overrides the\n    ``.default()`` method to serialize additional types), specify it with\n    the ``cls`` kwarg; otherwise ``JSONEncoder`` is used.\n\n    \"\"\"\n    # cached encoder\n    if (not skipkeys and ensure_ascii and\n        check_circular and allow_nan and\n        cls is None and indent is None and separators is None and\n        default is None and not sort_keys and not kw):\n        iterable = _default_encoder.iterencode(obj)\n    else:\n        if cls is None:\n            cls = JSONEncoder\n        iterable = cls(skipkeys=skipkeys, ensure_ascii=ensure_ascii,\n            check_circular=check_circular, allow_nan=allow_nan, indent=indent,\n            separators=separators,\n            default=default, sort_keys=sort_keys, **kw).iterencode(obj)\n    # could accelerate with writelines in some versions of Python, at\n    # a debuggability cost\n    for chunk in iterable:\n        fp.write(chunk)\n\n\ndef dumps(obj, *, skipkeys=False, ensure_ascii=True, check_circular=True,\n        allow_nan=True, cls=None, indent=None, separators=None,\n        default=None, sort_keys=False, **kw):\n    \"\"\"Serialize ``obj`` to a JSON formatted ``str``.\n\n    If ``skipkeys`` is true then ``dict`` keys that are not basic types\n    (``str``, ``int``, ``float``, ``bool``, ``None``) will be skipped\n    instead of raising a ``TypeError``.\n\n    If ``ensure_ascii`` is false, then the return value can contain non-ASCII\n    characters if they appear in strings contained in ``obj``. Otherwise, all\n    such characters are escaped in JSON strings.\n\n    If ``check_circular`` is false, then the circular reference check\n    for container types will be skipped and a circular reference will\n    result in an ``OverflowError`` (or worse).\n\n    If ``allow_nan`` is false, then it will be a ``ValueError`` to\n    serialize out of range ``float`` values (``nan``, ``inf``, ``-inf``) in\n    strict compliance of the JSON specification, instead of using the\n    JavaScript equivalents (``NaN``, ``Infinity``, ``-Infinity``).\n\n    If ``indent`` is a non-negative integer, then JSON array elements and\n    object members will be pretty-printed with that indent level. An indent\n    level of 0 will only insert newlines. ``None`` is the most compact\n    representation.\n\n    If specified, ``separators`` should be an ``(item_separator, key_separator)``\n    tuple.  The default is ``(', ', ': ')`` if *indent* is ``None`` and\n    ``(',', ': ')`` otherwise.  To get the most compact JSON representation,\n    you should specify ``(',', ':')`` to eliminate whitespace.\n\n    ``default(obj)`` is a function that should return a serializable version\n    of obj or raise TypeError. The default simply raises TypeError.\n\n    If *sort_keys* is true (default: ``False``), then the output of\n    dictionaries will be sorted by key.\n\n    To use a custom ``JSONEncoder`` subclass (e.g. one that overrides the\n    ``.default()`` method to serialize additional types), specify it with\n    the ``cls`` kwarg; otherwise ``JSONEncoder`` is used.\n\n    \"\"\"\n    # cached encoder\n    if (not skipkeys and ensure_ascii and\n        check_circular and allow_nan and\n        cls is None and indent is None and separators is None and\n        default is None and not sort_keys and not kw):\n        return _default_encoder.encode(obj)\n    if cls is None:\n        cls = JSONEncoder\n    return cls(\n        skipkeys=skipkeys, ensure_ascii=ensure_ascii,\n        check_circular=check_circular, allow_nan=allow_nan, indent=indent,\n        separators=separators, default=default, sort_keys=sort_keys,\n        **kw).encode(obj)\n\n\n_default_decoder = JSONDecoder(object_hook=None, object_pairs_hook=None)\n\n\ndef detect_encoding(b):\n    bstartswith = b.startswith\n    if bstartswith((codecs.BOM_UTF32_BE, codecs.BOM_UTF32_LE)):\n        return 'utf-32'\n    if bstartswith((codecs.BOM_UTF16_BE, codecs.BOM_UTF16_LE)):\n        return 'utf-16'\n    if bstartswith(codecs.BOM_UTF8):\n        return 'utf-8-sig'\n\n    if len(b) >= 4:\n        if not b[0]:\n            # 00 00 -- -- - utf-32-be\n            # 00 XX -- -- - utf-16-be\n            return 'utf-16-be' if b[1] else 'utf-32-be'\n        if not b[1]:\n            # XX 00 00 00 - utf-32-le\n            # XX 00 00 XX - utf-16-le\n            # XX 00 XX -- - utf-16-le\n            return 'utf-16-le' if b[2] or b[3] else 'utf-32-le'\n    elif len(b) == 2:\n        if not b[0]:\n            # 00 XX - utf-16-be\n            return 'utf-16-be'\n        if not b[1]:\n            # XX 00 - utf-16-le\n            return 'utf-16-le'\n    # default\n    return 'utf-8'\n\n\ndef load(fp, *, cls=None, object_hook=None, parse_float=None,\n        parse_int=None, parse_constant=None, object_pairs_hook=None, **kw):\n    \"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\n    a JSON document) to a Python object.\n\n    ``object_hook`` is an optional function that will be called with the\n    result of any object literal decode (a ``dict``). The return value of\n    ``object_hook`` will be used instead of the ``dict``. This feature\n    can be used to implement custom decoders (e.g. JSON-RPC class hinting).\n\n    ``object_pairs_hook`` is an optional function that will be called with the\n    result of any object literal decoded with an ordered list of pairs.  The\n    return value of ``object_pairs_hook`` will be used instead of the ``dict``.\n    This feature can be used to implement custom decoders.  If ``object_hook``\n    is also defined, the ``object_pairs_hook`` takes priority.\n\n    To use a custom ``JSONDecoder`` subclass, specify it with the ``cls``\n    kwarg; otherwise ``JSONDecoder`` is used.\n    \"\"\"\n    return loads(fp.read(),\n        cls=cls, object_hook=object_hook,\n        parse_float=parse_float, parse_int=parse_int,\n        parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n\n\ndef loads(s, *, cls=None, object_hook=None, parse_float=None,\n        parse_int=None, parse_constant=None, object_pairs_hook=None, **kw):\n    \"\"\"Deserialize ``s`` (a ``str``, ``bytes`` or ``bytearray`` instance\n    containing a JSON document) to a Python object.\n\n    ``object_hook`` is an optional function that will be called with the\n    result of any object literal decode (a ``dict``). The return value of\n    ``object_hook`` will be used instead of the ``dict``. This feature\n    can be used to implement custom decoders (e.g. JSON-RPC class hinting).\n\n    ``object_pairs_hook`` is an optional function that will be called with the\n    result of any object literal decoded with an ordered list of pairs.  The\n    return value of ``object_pairs_hook`` will be used instead of the ``dict``.\n    This feature can be used to implement custom decoders.  If ``object_hook``\n    is also defined, the ``object_pairs_hook`` takes priority.\n\n    ``parse_float``, if specified, will be called with the string\n    of every JSON float to be decoded. By default this is equivalent to\n    float(num_str). This can be used to use another datatype or parser\n    for JSON floats (e.g. decimal.Decimal).\n\n    ``parse_int``, if specified, will be called with the string\n    of every JSON int to be decoded. By default this is equivalent to\n    int(num_str). This can be used to use another datatype or parser\n    for JSON integers (e.g. float).\n\n    ``parse_constant``, if specified, will be called with one of the\n    following strings: -Infinity, Infinity, NaN.\n    This can be used to raise an exception if invalid JSON numbers\n    are encountered.\n\n    To use a custom ``JSONDecoder`` subclass, specify it with the ``cls``\n    kwarg; otherwise ``JSONDecoder`` is used.\n    \"\"\"\n    if isinstance(s, str):\n        if s.startswith('\\ufeff'):\n            raise JSONDecodeError(\"Unexpected UTF-8 BOM (decode using utf-8-sig)\",\n                                  s, 0)\n    else:\n        if not isinstance(s, (bytes, bytearray)):\n            raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n                            f'not {s.__class__.__name__}')\n        s = s.decode(detect_encoding(s), 'surrogatepass')\n\n    if (cls is None and object_hook is None and\n            parse_int is None and parse_float is None and\n            parse_constant is None and object_pairs_hook is None and not kw):\n        return _default_decoder.decode(s)\n    if cls is None:\n        cls = JSONDecoder\n    if object_hook is not None:\n        kw['object_hook'] = object_hook\n    if object_pairs_hook is not None:\n        kw['object_pairs_hook'] = object_pairs_hook\n    if parse_float is not None:\n        kw['parse_float'] = parse_float\n    if parse_int is not None:\n        kw['parse_int'] = parse_int\n    if parse_constant is not None:\n        kw['parse_constant'] = parse_constant\n    return cls(**kw).decode(s)\n", 359], "/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/cuda/__init__.py": ["r\"\"\"\nThis package adds support for CUDA tensor types, that implement the same\nfunction as CPU tensors, but they utilize GPUs for computation.\n\nIt is lazily initialized, so you can always import it, and use\n:func:`is_available()` to determine if your system supports CUDA.\n\n:ref:`cuda-semantics` has more details about working with CUDA.\n\"\"\"\n\nimport contextlib\nimport os\nimport torch\nimport traceback\nimport warnings\nimport threading\nfrom typing import List, Optional, Tuple, Union, Any\nfrom ._utils import _get_device_index, _dummy_type\nfrom .graphs import CUDAGraph, graph_pool_handle, graph, make_graphed_callables\nfrom .streams import Stream, Event\nfrom .. import device as _device\nimport torch._C\n\ntry:\n    from torch._C import _cudart  # type: ignore[attr-defined]\nexcept ImportError:\n    _cudart = None\n\n_initialized = False\n_tls = threading.local()\n_initialization_lock = threading.Lock()\n_queued_calls = []  # don't invoke these until initialization occurs\n_is_in_bad_fork = getattr(torch._C, \"_cuda_isInBadFork\", lambda: False)\n_device_t = Union[_device, str, int, None]\n\n\nclass _LazySeedTracker:\n    # Since seeding is memory-less, only track the latest seed.\n    # Note: `manual_seed_all` followed by `manual_seed` overwrites\n    # the seed on current device. We track the order of **latest**\n    # calls between these two API.\n    def __init__(self):\n        self.manual_seed_all_cb = None\n        self.manual_seed_cb = None\n        self.call_order = []\n\n    def queue_seed_all(self, cb, traceback):\n        self.manual_seed_all_cb = (cb, traceback)\n        # update seed_all to be latest\n        self.call_order = [self.manual_seed_cb, self.manual_seed_all_cb]\n\n    def queue_seed(self, cb, traceback):\n        self.manual_seed_cb = (cb, traceback)\n        # update seed to be latest\n        self.call_order = [self.manual_seed_all_cb, self.manual_seed_cb]\n\n    def get_calls(self) -> List:\n        return self.call_order\n\n\n_lazy_seed_tracker = _LazySeedTracker()\n\n# Define dummy _CudaDeviceProperties type if PyTorch was compiled without CUDA\nif hasattr(torch._C, '_CudaDeviceProperties'):\n    _CudaDeviceProperties = torch._C._CudaDeviceProperties\nelse:\n    _CudaDeviceProperties = _dummy_type('_CudaDeviceProperties')  # type: ignore[assignment, misc]\n\n# Global variables dynamically populated by native code\nhas_magma: bool = False\nhas_half: bool = False\ndefault_generators: Tuple[torch._C.Generator] = ()  # type: ignore[assignment]\n\ndef is_available() -> bool:\n    r\"\"\"Returns a bool indicating if CUDA is currently available.\"\"\"\n    if not hasattr(torch._C, '_cuda_getDeviceCount'):\n        return False\n    # This function never throws and returns 0 if driver is missing or can't\n    # be initialized\n    return torch._C._cuda_getDeviceCount() > 0\n\ndef is_bf16_supported():\n    r\"\"\"Returns a bool indicating if the current CUDA device supports dtype bfloat16\"\"\"\n    cu_vers = torch.version.cuda\n    if cu_vers is not None:\n        cuda_maj_decide = int(cu_vers.split('.')[0]) >= 11\n\n    else:\n        cuda_maj_decide = False\n    return torch.cuda.get_device_properties(torch.cuda.current_device()).major >= 8 and cuda_maj_decide\n\ndef _sleep(cycles):\n    torch._C._cuda_sleep(cycles)\n\n\ndef _check_capability():\n    incorrect_binary_warn = \"\"\"\n    Found GPU%d %s which requires CUDA_VERSION >= %d to\n     work properly, but your PyTorch was compiled\n     with CUDA_VERSION %d. Please install the correct PyTorch binary\n     using instructions from https://pytorch.org\n    \"\"\"\n\n    old_gpu_warn = \"\"\"\n    Found GPU%d %s which is of cuda capability %d.%d.\n    PyTorch no longer supports this GPU because it is too old.\n    The minimum cuda capability supported by this library is %d.%d.\n    \"\"\"\n\n    if torch.version.cuda is not None:  # on ROCm we don't want this check\n        CUDA_VERSION = torch._C._cuda_getCompiledVersion()\n        for d in range(device_count()):\n            capability = get_device_capability(d)\n            major = capability[0]\n            minor = capability[1]\n            name = get_device_name(d)\n            current_arch = major * 10 + minor\n            min_arch = min((int(arch.split(\"_\")[1]) for arch in torch.cuda.get_arch_list()), default=35)\n            if current_arch < min_arch:\n                warnings.warn(old_gpu_warn.format(d, name, major, minor, min_arch // 10, min_arch % 10))\n            elif CUDA_VERSION <= 9000 and major >= 7 and minor >= 5:\n                warnings.warn(incorrect_binary_warn % (d, name, 10000, CUDA_VERSION))\n\ndef _check_cubins():\n    incompatible_device_warn = \"\"\"\n{} with CUDA capability sm_{} is not compatible with the current PyTorch installation.\nThe current PyTorch install supports CUDA capabilities {}.\nIf you want to use the {} GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n\"\"\"\n    if torch.version.cuda is None:  # on ROCm we don't want this check\n        return\n    arch_list = get_arch_list()\n    if len(arch_list) == 0:\n        return\n    supported_sm = [int(arch.split('_')[1]) for arch in arch_list if 'sm_' in arch]\n    for idx in range(device_count()):\n        cap_major, cap_minor = get_device_capability(idx)\n        # NVIDIA GPU compute architectures are backward compatible within major version\n        supported = any([sm // 10 == cap_major for sm in supported_sm])\n        if not supported:\n            device_name = get_device_name(idx)\n            capability = cap_major * 10 + cap_minor\n            warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n\n\ndef is_initialized():\n    r\"\"\"Returns whether PyTorch's CUDA state has been initialized.\"\"\"\n    return _initialized and not _is_in_bad_fork()\n\n\ndef _lazy_call(callable, **kwargs):\n    if is_initialized():\n        callable()\n    else:\n        # TODO(torch_deploy): this accesses linecache, which attempts to read the\n        # file system to get traceback info. Patch linecache or do something\n        # else here if this ends up being important.\n        global _lazy_seed_tracker\n        if kwargs.get(\"seed_all\", False):\n            _lazy_seed_tracker.queue_seed_all(callable, traceback.format_stack())\n        elif kwargs.get(\"seed\", False):\n            _lazy_seed_tracker.queue_seed(callable, traceback.format_stack())\n        else:\n            # Don't store the actual traceback to avoid memory cycle\n            _queued_calls.append((callable, traceback.format_stack()))\n\n_lazy_call(_check_capability)\n_lazy_call(_check_cubins)\n\n\nclass DeferredCudaCallError(Exception):\n    pass\n\n\ndef init():\n    r\"\"\"Initialize PyTorch's CUDA state.  You may need to call\n    this explicitly if you are interacting with PyTorch via\n    its C API, as Python bindings for CUDA functionality will not\n    be available until this initialization takes place.  Ordinary users\n    should not need this, as all of PyTorch's CUDA methods\n    automatically initialize CUDA state on-demand.\n\n    Does nothing if the CUDA state is already initialized.\n    \"\"\"\n    _lazy_init()\n\n\ndef _lazy_init():\n    global _initialized, _queued_calls\n    if is_initialized() or hasattr(_tls, 'is_initializing'):\n        return\n    with _initialization_lock:\n        # We be double-checked locking, boys!  This is OK because\n        # the above test was GIL protected anyway.  The inner test\n        # is for when a thread blocked on some other thread which was\n        # doing the initialization; when they get the lock, they will\n        # find there is nothing left to do.\n        if is_initialized():\n            return\n        # It is important to prevent other threads from entering _lazy_init\n        # immediately, while we are still guaranteed to have the GIL, because some\n        # of the C calls we make below will release the GIL\n        if _is_in_bad_fork():\n            raise RuntimeError(\n                \"Cannot re-initialize CUDA in forked subprocess. To use CUDA with \"\n                \"multiprocessing, you must use the 'spawn' start method\")\n        if not hasattr(torch._C, '_cuda_getDeviceCount'):\n            raise AssertionError(\"Torch not compiled with CUDA enabled\")\n        if _cudart is None:\n            raise AssertionError(\n                \"libcudart functions unavailable. It looks like you have a broken build?\")\n        # This function throws if there's a driver initialization error, no GPUs\n        # are found or any other error occurs\n        torch._C._cuda_init()\n        # Some of the queued calls may reentrantly call _lazy_init();\n        # we need to just return without initializing in that case.\n        # However, we must not let any *other* threads in!\n        _tls.is_initializing = True\n\n        for calls in _lazy_seed_tracker.get_calls():\n            if calls:\n                _queued_calls.append(calls)\n\n        try:\n            for queued_call, orig_traceback in _queued_calls:\n                try:\n                    queued_call()\n                except Exception as e:\n                    msg = (f\"CUDA call failed lazily at initialization with error: {str(e)}\\n\\n\"\n                           f\"CUDA call was originally invoked at:\\n\\n{orig_traceback}\")\n                    raise DeferredCudaCallError(msg) from e\n        finally:\n            delattr(_tls, 'is_initializing')\n        _initialized = True\n\n\ndef cudart():\n    _lazy_init()\n    return _cudart\n\n\nclass cudaStatus(object):\n    SUCCESS: int = 0\n    ERROR_NOT_READY: int = 34\n\nclass CudaError(RuntimeError):\n    def __init__(self, code: int) -> None:\n        msg = _cudart.cudaGetErrorString(_cudart.cudaError(code))\n        super(CudaError, self).__init__('{0} ({1})'.format(msg, code))\n\n\ndef check_error(res: int) -> None:\n    if res != _cudart.cudaError.success:\n        raise CudaError(res)\n\n\nclass device(object):\n    r\"\"\"Context-manager that changes the selected device.\n\n    Args:\n        device (torch.device or int): device index to select. It's a no-op if\n            this argument is a negative integer or ``None``.\n    \"\"\"\n\n    def __init__(self, device: Any):\n        self.idx = _get_device_index(device, optional=True)\n        self.prev_idx = -1\n\n    def __enter__(self):\n        if self.idx == -1:\n            return\n        self.prev_idx = torch.cuda.current_device()\n        if self.prev_idx != self.idx:\n            torch.cuda.set_device(self.idx)\n        if not torch.jit.is_scripting():\n            _lazy_init()\n\n    def __exit__(self, type: Any, value: Any, traceback: Any):\n        if self.prev_idx != self.idx:\n            torch.cuda.set_device(self.prev_idx)\n        return False\n\n\nclass device_of(device):\n    r\"\"\"Context-manager that changes the current device to that of given object.\n\n    You can use both tensors and storages as arguments. If a given object is\n    not allocated on a GPU, this is a no-op.\n\n    Args:\n        obj (Tensor or Storage): object allocated on the selected device.\n    \"\"\"\n\n    def __init__(self, obj):\n        idx = obj.get_device() if obj.is_cuda else -1\n        super(device_of, self).__init__(idx)\n\n\ndef set_device(device: _device_t) -> None:\n    r\"\"\"Sets the current device.\n\n    Usage of this function is discouraged in favor of :any:`device`. In most\n    cases it's better to use ``CUDA_VISIBLE_DEVICES`` environmental variable.\n\n    Args:\n        device (torch.device or int): selected device. This function is a no-op\n            if this argument is negative.\n    \"\"\"\n    device = _get_device_index(device)\n    if device >= 0:\n        torch._C._cuda_setDevice(device)\n\n\ndef get_device_name(device: Optional[_device_t] = None) -> str:\n    r\"\"\"Gets the name of a device.\n\n    Args:\n        device (torch.device or int, optional): device for which to return the\n            name. This function is a no-op if this argument is a negative\n            integer. It uses the current device, given by :func:`~torch.cuda.current_device`,\n            if :attr:`device` is ``None`` (default).\n\n    Returns:\n        str: the name of the device\n    \"\"\"\n    return get_device_properties(device).name\n\n\ndef get_device_capability(device: Optional[_device_t] = None) -> Tuple[int, int]:\n    r\"\"\"Gets the cuda capability of a device.\n\n    Args:\n        device (torch.device or int, optional): device for which to return the\n            device capability. This function is a no-op if this argument is\n            a negative integer. It uses the current device, given by\n            :func:`~torch.cuda.current_device`, if :attr:`device` is ``None``\n            (default).\n\n    Returns:\n        tuple(int, int): the major and minor cuda capability of the device\n    \"\"\"\n    prop = get_device_properties(device)\n    return prop.major, prop.minor\n\n\ndef get_device_properties(device: _device_t) -> _CudaDeviceProperties:\n    r\"\"\"Gets the properties of a device.\n\n    Args:\n        device (torch.device or int or str): device for which to return the\n            properties of the device.\n\n    Returns:\n        _CudaDeviceProperties: the properties of the device\n    \"\"\"\n    _lazy_init()  # will define _get_device_properties\n    device = _get_device_index(device, optional=True)\n    if device < 0 or device >= device_count():\n        raise AssertionError(\"Invalid device id\")\n    return _get_device_properties(device)  # type: ignore[name-defined]\n\ndef can_device_access_peer(device: _device_t, peer_device: _device_t) -> bool:\n    r\"\"\"Checks if peer access between two devices is possible.\n    \"\"\"\n    _lazy_init()\n    device = _get_device_index(device, optional=True)\n    peer_device = _get_device_index(peer_device)\n    if device < 0 or device >= device_count():\n        raise AssertionError(\"Invalid device id\")\n    if peer_device < 0 or peer_device >= device_count():\n        raise AssertionError(\"Invalid peer device id\")\n    return torch._C._cuda_canDeviceAccessPeer(device, peer_device)\n\n\nclass StreamContext(object):\n    r\"\"\"Context-manager that selects a given stream.\n\n    All CUDA kernels queued within its context will be enqueued on a selected\n    stream.\n\n    Args:\n        Stream (Stream): selected stream. This manager is a no-op if it's\n            ``None``.\n    .. note:: Streams are per-device.\n    \"\"\"\n    cur_stream : Optional['torch.cuda.Stream']\n\n    def __init__(self, stream: Optional['torch.cuda.Stream']):\n        self.stream = stream\n        self.idx = _get_device_index(None, True)\n        if not torch.jit.is_scripting():\n            if self.idx is None:\n                self.idx = -1\n\n        self.src_prev_stream = None if not torch.jit.is_scripting() else torch.cuda.default_stream(None)\n        self.dst_prev_stream = None if not torch.jit.is_scripting() else torch.cuda.default_stream(None)\n\n    def __enter__(self):\n        # Local cur_stream variable for type refinement\n        cur_stream = self.stream\n        # Return if stream is None or CUDA device not available\n        if cur_stream is None or self.idx == -1:\n            return\n        self.src_prev_stream = torch.cuda.current_stream(None)\n\n        # If the stream is not on the current device, then\n        # set the current stream on the device\n        if self.src_prev_stream.device != cur_stream.device:\n            with device(cur_stream.device):\n                self.dst_prev_stream = torch.cuda.current_stream(cur_stream.device)\n        torch.cuda.set_stream(cur_stream)\n\n    def __exit__(self, type: Any, value: Any, traceback: Any):\n        # Local cur_stream variable for type refinement\n        cur_stream = self.stream\n        # If stream is None or no CUDA device available, return\n        if cur_stream is None or self.idx == -1:\n            return\n\n        # Reset the stream on the original device\n        # and destination device\n        if self.src_prev_stream.device != cur_stream.device:  # type: ignore[union-attr]\n            torch.cuda.set_stream(self.dst_prev_stream)  # type: ignore[arg-type]\n        torch.cuda.set_stream(self.src_prev_stream)  # type: ignore[arg-type]\n\ndef stream(stream: Optional['torch.cuda.Stream']) -> StreamContext:\n    r\"\"\"Wrapper around the Context-manager StreamContext that\n    selects a given stream.\n\n    Arguments:\n        stream (Stream): selected stream. This manager is a no-op if it's\n            ``None``.\n    ..Note:: In eager mode stream is of type Stream class while in JIT it is\n    an object of the custom class ``torch.classes.cuda.Stream``.\n    \"\"\"\n    return StreamContext(stream)\n\ndef set_stream(stream: Stream):\n    r\"\"\"Sets the current stream.This is a wrapper API to set the stream.\n        Usage of this function is discouraged in favor of the ``stream``\n        context manager.\n\n    Args:\n        stream (Stream): selected stream. This function is a no-op\n            if this argument is ``None``.\n    \"\"\"\n    if stream is None:\n        return\n    torch._C._cuda_setStream(stream._cdata)\n\ndef device_count() -> int:\n    r\"\"\"Returns the number of GPUs available.\"\"\"\n    if is_available():\n        return torch._C._cuda_getDeviceCount()\n    else:\n        return 0\n\ndef get_arch_list() -> List[str]:\n    r\"\"\"Returns list CUDA architectures this library was compiled for.\"\"\"\n    if not is_available():\n        return []\n    arch_flags = torch._C._cuda_getArchFlags()\n    if arch_flags is None:\n        return []\n    return arch_flags.split()\n\ndef get_gencode_flags() -> str:\n    r\"\"\"Returns NVCC gencode flags this library was compiled with.\"\"\"\n    arch_list = get_arch_list()\n    if len(arch_list) == 0:\n        return \"\"\n    arch_list_ = [arch.split(\"_\") for arch in arch_list]\n    return \" \".join([f\"-gencode compute=compute_{arch},code={kind}_{arch}\" for (kind, arch) in arch_list_])\n\n\n\ndef current_device() -> int:\n    r\"\"\"Returns the index of a currently selected device.\"\"\"\n    _lazy_init()\n    return torch._C._cuda_getDevice()\n\n\ndef synchronize(device: _device_t = None) -> None:\n    r\"\"\"Waits for all kernels in all streams on a CUDA device to complete.\n\n    Args:\n        device (torch.device or int, optional): device for which to synchronize.\n            It uses the current device, given by :func:`~torch.cuda.current_device`,\n            if :attr:`device` is ``None`` (default).\n    \"\"\"\n    _lazy_init()\n    with torch.cuda.device(device):\n        return torch._C._cuda_synchronize()\n\n\ndef ipc_collect():\n    r\"\"\"Force collects GPU memory after it has been released by CUDA IPC.\n\n    .. note::\n        Checks if any sent CUDA tensors could be cleaned from the memory. Force\n        closes shared memory file used for reference counting if there is no\n        active counters. Useful when the producer process stopped actively sending\n        tensors and want to release unused memory.\n    \"\"\"\n    _lazy_init()\n    return torch._C._cuda_ipc_collect()\n\n\ndef current_stream(device: Optional[_device_t] = None) -> Stream:\n    r\"\"\"Returns the currently selected :class:`Stream` for a given device.\n\n    Args:\n        device (torch.device or int, optional): selected device. Returns\n            the currently selected :class:`Stream` for the current device, given\n            by :func:`~torch.cuda.current_device`, if :attr:`device` is ``None``\n            (default).\n    \"\"\"\n    _lazy_init()\n    return Stream(_cdata=torch._C._cuda_getCurrentStream(\n        _get_device_index(device, optional=True)))\n\n\ndef default_stream(device: Optional[_device_t] = None) -> Stream:\n    r\"\"\"Returns the default :class:`Stream` for a given device.\n\n    Args:\n        device (torch.device or int, optional): selected device. Returns\n            the default :class:`Stream` for the current device, given by\n            :func:`~torch.cuda.current_device`, if :attr:`device` is ``None``\n            (default).\n    \"\"\"\n    _lazy_init()\n    return Stream(_cdata=torch._C._cuda_getDefaultStream(\n        _get_device_index(device, optional=True)))\n\n\ndef current_blas_handle():\n    r\"\"\"Returns cublasHandle_t pointer to current cuBLAS handle\"\"\"\n    _lazy_init()\n    return torch._C._cuda_getCurrentBlasHandle()\n\ndef set_sync_debug_mode(debug_mode: Union[int, str]) -> None:\n    r\"\"\"Sets the debug mode for cuda synchronizing operations.\n\n    Args:\n        debug_mode(str or int): if \"default\" or 0, don't error or warn on synchronizing operations,\n            if \"warn\" or 1, warn on synchronizing operations, if \"error\" or 2, error out synchronizing operations.\n\n    Warning:\n        This is an experimental feature, and not all synchronizing operations will trigger warning or error. In\n        particular, operations in torch.distributed and torch.sparse namespaces are not covered yet.\n    \"\"\"\n\n    _lazy_init()\n    if isinstance(debug_mode, str):\n        if debug_mode == \"default\":\n            debug_mode = 0\n        elif debug_mode == \"warn\":\n            debug_mode = 1\n        elif debug_mode == \"error\":\n            debug_mode = 2\n        else:\n            raise RuntimeError(\"invalid value of debug_mode, expected one of `default`, `warn`, `error`\")\n\n    torch._C._cuda_set_sync_debug_mode(debug_mode)\n\ndef get_sync_debug_mode() -> int:\n    r\"\"\"Returns current value of debug mode for cuda synchronizing operations.\"\"\"\n\n    _lazy_init()\n    return torch._C._cuda_get_sync_debug_mode()\n\n\nfrom .memory import *  # noqa: F403\n\n\nfrom .random import *  # noqa: F403\n\n################################################################################\n# Define Storage and Tensor classes\n################################################################################\n\n\nfrom ..storage import _StorageBase\n\n\nif not hasattr(torch._C, 'CudaDoubleStorageBase'):\n    # Define dummy base classes\n    for t in ['Double', 'Float', 'Long', 'Int', 'Short', 'Char', 'Byte', 'Half', 'Bool', 'BFloat16',\n              'ComplexDouble', 'ComplexFloat']:\n        storage_name = 'Cuda{0}StorageBase'.format(t)\n        tensor_name = 'Cuda{0}TensorBase'.format(t)\n\n        torch._C.__dict__[storage_name] = _dummy_type(storage_name)\n        torch._C.__dict__[tensor_name] = _dummy_type(tensor_name)\n\n    torch._C.__dict__['_CudaStreamBase'] = _dummy_type('CudaStreamBase')\n    torch._C.__dict__['_CudaEventBase'] = _dummy_type('CudaEventBase')\n\n\n@staticmethod  # type: ignore[misc]\ndef _lazy_new(cls, *args, **kwargs):\n    _lazy_init()\n    # We may need to call lazy init again if we are a forked child\n    # del _CudaBase.__new__\n    return super(_CudaBase, cls).__new__(cls, *args, **kwargs)\n\n\nclass _CudaBase(object):\n    is_cuda = True\n    is_sparse = False\n\n    def type(self, *args, **kwargs):\n        # We could use a Protocol here to tell mypy that self has `get_device` method\n        # but it is only available in the typing module on Python >= 3.8\n        # or on typing_extensions module on Python >= 3.6\n        with device(self.get_device()):  # type: ignore[attr-defined]\n            return super(_CudaBase, self).type(*args, **kwargs)  # type: ignore[misc]\n\n    __new__ = _lazy_new\n\n\nclass DoubleStorage(_CudaBase, torch._C.CudaDoubleStorageBase, _StorageBase):\n    pass\n\n\nclass FloatStorage(_CudaBase, torch._C.CudaFloatStorageBase, _StorageBase):\n    pass\n\n\nclass LongStorage(_CudaBase, torch._C.CudaLongStorageBase, _StorageBase):\n    pass\n\n\nclass IntStorage(_CudaBase, torch._C.CudaIntStorageBase, _StorageBase):\n    pass\n\n\nclass ShortStorage(_CudaBase, torch._C.CudaShortStorageBase, _StorageBase):\n    pass\n\n\nclass CharStorage(_CudaBase, torch._C.CudaCharStorageBase, _StorageBase):\n    pass\n\n\nclass ByteStorage(_CudaBase, torch._C.CudaByteStorageBase, _StorageBase):\n    pass\n\n\nclass HalfStorage(_CudaBase, torch._C.CudaHalfStorageBase, _StorageBase):\n    pass\n\n\nclass BoolStorage(_CudaBase, torch._C.CudaBoolStorageBase, _StorageBase):\n    pass\n\n\nclass BFloat16Storage(_CudaBase, torch._C.CudaBFloat16StorageBase, _StorageBase):\n    pass\n\nclass ComplexDoubleStorage(_CudaBase, torch._C.CudaComplexDoubleStorageBase, _StorageBase):\n    pass\n\n\nclass ComplexFloatStorage(_CudaBase, torch._C.CudaComplexFloatStorageBase, _StorageBase):\n    pass\n\ntorch._storage_classes.add(DoubleStorage)\ntorch._storage_classes.add(FloatStorage)\ntorch._storage_classes.add(LongStorage)\ntorch._storage_classes.add(IntStorage)\ntorch._storage_classes.add(ShortStorage)\ntorch._storage_classes.add(CharStorage)\ntorch._storage_classes.add(ByteStorage)\ntorch._storage_classes.add(HalfStorage)\ntorch._storage_classes.add(BoolStorage)\ntorch._storage_classes.add(BFloat16Storage)\ntorch._storage_classes.add(ComplexDoubleStorage)\ntorch._storage_classes.add(ComplexFloatStorage)\n\nfrom . import sparse\nfrom . import profiler\nfrom . import nvtx\nfrom . import amp\n", 685], "/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py": ["\"\"\"Generic (shallow and deep) copying operations.\n\nInterface summary:\n\n        import copy\n\n        x = copy.copy(y)        # make a shallow copy of y\n        x = copy.deepcopy(y)    # make a deep copy of y\n\nFor module specific errors, copy.Error is raised.\n\nThe difference between shallow and deep copying is only relevant for\ncompound objects (objects that contain other objects, like lists or\nclass instances).\n\n- A shallow copy constructs a new compound object and then (to the\n  extent possible) inserts *the same objects* into it that the\n  original contains.\n\n- A deep copy constructs a new compound object and then, recursively,\n  inserts *copies* into it of the objects found in the original.\n\nTwo problems often exist with deep copy operations that don't exist\nwith shallow copy operations:\n\n a) recursive objects (compound objects that, directly or indirectly,\n    contain a reference to themselves) may cause a recursive loop\n\n b) because deep copy copies *everything* it may copy too much, e.g.\n    administrative data structures that should be shared even between\n    copies\n\nPython's deep copy operation avoids these problems by:\n\n a) keeping a table of objects already copied during the current\n    copying pass\n\n b) letting user-defined classes override the copying operation or the\n    set of components copied\n\nThis version does not copy types like module, class, function, method,\nnor stack trace, stack frame, nor file, socket, window, nor any\nsimilar types.\n\nClasses can use the same interfaces to control copying that they use\nto control pickling: they can define methods called __getinitargs__(),\n__getstate__() and __setstate__().  See the documentation for module\n\"pickle\" for information on these methods.\n\"\"\"\n\nimport types\nimport weakref\nfrom copyreg import dispatch_table\n\nclass Error(Exception):\n    pass\nerror = Error   # backward compatibility\n\ntry:\n    from org.python.core import PyStringMap\nexcept ImportError:\n    PyStringMap = None\n\n__all__ = [\"Error\", \"copy\", \"deepcopy\"]\n\ndef copy(x):\n    \"\"\"Shallow copy operation on arbitrary Python objects.\n\n    See the module's __doc__ string for more info.\n    \"\"\"\n\n    cls = type(x)\n\n    copier = _copy_dispatch.get(cls)\n    if copier:\n        return copier(x)\n\n    if issubclass(cls, type):\n        # treat it as a regular class:\n        return _copy_immutable(x)\n\n    copier = getattr(cls, \"__copy__\", None)\n    if copier is not None:\n        return copier(x)\n\n    reductor = dispatch_table.get(cls)\n    if reductor is not None:\n        rv = reductor(x)\n    else:\n        reductor = getattr(x, \"__reduce_ex__\", None)\n        if reductor is not None:\n            rv = reductor(4)\n        else:\n            reductor = getattr(x, \"__reduce__\", None)\n            if reductor:\n                rv = reductor()\n            else:\n                raise Error(\"un(shallow)copyable object of type %s\" % cls)\n\n    if isinstance(rv, str):\n        return x\n    return _reconstruct(x, None, *rv)\n\n\n_copy_dispatch = d = {}\n\ndef _copy_immutable(x):\n    return x\nfor t in (type(None), int, float, bool, complex, str, tuple,\n          bytes, frozenset, type, range, slice, property,\n          types.BuiltinFunctionType, type(Ellipsis), type(NotImplemented),\n          types.FunctionType, weakref.ref):\n    d[t] = _copy_immutable\nt = getattr(types, \"CodeType\", None)\nif t is not None:\n    d[t] = _copy_immutable\n\nd[list] = list.copy\nd[dict] = dict.copy\nd[set] = set.copy\nd[bytearray] = bytearray.copy\n\nif PyStringMap is not None:\n    d[PyStringMap] = PyStringMap.copy\n\ndel d, t\n\ndef deepcopy(x, memo=None, _nil=[]):\n    \"\"\"Deep copy operation on arbitrary Python objects.\n\n    See the module's __doc__ string for more info.\n    \"\"\"\n\n    if memo is None:\n        memo = {}\n\n    d = id(x)\n    y = memo.get(d, _nil)\n    if y is not _nil:\n        return y\n\n    cls = type(x)\n\n    copier = _deepcopy_dispatch.get(cls)\n    if copier is not None:\n        y = copier(x, memo)\n    else:\n        if issubclass(cls, type):\n            y = _deepcopy_atomic(x, memo)\n        else:\n            copier = getattr(x, \"__deepcopy__\", None)\n            if copier is not None:\n                y = copier(memo)\n            else:\n                reductor = dispatch_table.get(cls)\n                if reductor:\n                    rv = reductor(x)\n                else:\n                    reductor = getattr(x, \"__reduce_ex__\", None)\n                    if reductor is not None:\n                        rv = reductor(4)\n                    else:\n                        reductor = getattr(x, \"__reduce__\", None)\n                        if reductor:\n                            rv = reductor()\n                        else:\n                            raise Error(\n                                \"un(deep)copyable object of type %s\" % cls)\n                if isinstance(rv, str):\n                    y = x\n                else:\n                    y = _reconstruct(x, memo, *rv)\n\n    # If is its own copy, don't memoize.\n    if y is not x:\n        memo[d] = y\n        _keep_alive(x, memo) # Make sure x lives at least as long as d\n    return y\n\n_deepcopy_dispatch = d = {}\n\ndef _deepcopy_atomic(x, memo):\n    return x\nd[type(None)] = _deepcopy_atomic\nd[type(Ellipsis)] = _deepcopy_atomic\nd[type(NotImplemented)] = _deepcopy_atomic\nd[int] = _deepcopy_atomic\nd[float] = _deepcopy_atomic\nd[bool] = _deepcopy_atomic\nd[complex] = _deepcopy_atomic\nd[bytes] = _deepcopy_atomic\nd[str] = _deepcopy_atomic\nd[types.CodeType] = _deepcopy_atomic\nd[type] = _deepcopy_atomic\nd[types.BuiltinFunctionType] = _deepcopy_atomic\nd[types.FunctionType] = _deepcopy_atomic\nd[weakref.ref] = _deepcopy_atomic\nd[property] = _deepcopy_atomic\n\ndef _deepcopy_list(x, memo, deepcopy=deepcopy):\n    y = []\n    memo[id(x)] = y\n    append = y.append\n    for a in x:\n        append(deepcopy(a, memo))\n    return y\nd[list] = _deepcopy_list\n\ndef _deepcopy_tuple(x, memo, deepcopy=deepcopy):\n    y = [deepcopy(a, memo) for a in x]\n    # We're not going to put the tuple in the memo, but it's still important we\n    # check for it, in case the tuple contains recursive mutable structures.\n    try:\n        return memo[id(x)]\n    except KeyError:\n        pass\n    for k, j in zip(x, y):\n        if k is not j:\n            y = tuple(y)\n            break\n    else:\n        y = x\n    return y\nd[tuple] = _deepcopy_tuple\n\ndef _deepcopy_dict(x, memo, deepcopy=deepcopy):\n    y = {}\n    memo[id(x)] = y\n    for key, value in x.items():\n        y[deepcopy(key, memo)] = deepcopy(value, memo)\n    return y\nd[dict] = _deepcopy_dict\nif PyStringMap is not None:\n    d[PyStringMap] = _deepcopy_dict\n\ndef _deepcopy_method(x, memo): # Copy instance methods\n    return type(x)(x.__func__, deepcopy(x.__self__, memo))\nd[types.MethodType] = _deepcopy_method\n\ndel d\n\ndef _keep_alive(x, memo):\n    \"\"\"Keeps a reference to the object x in the memo.\n\n    Because we remember objects by their id, we have\n    to assure that possibly temporary objects are kept\n    alive by referencing them.\n    We store a reference at the id of the memo, which should\n    normally not be used unless someone tries to deepcopy\n    the memo itself...\n    \"\"\"\n    try:\n        memo[id(memo)].append(x)\n    except KeyError:\n        # aha, this is the first one :-)\n        memo[id(memo)]=[x]\n\ndef _reconstruct(x, memo, func, args,\n                 state=None, listiter=None, dictiter=None,\n                 deepcopy=deepcopy):\n    deep = memo is not None\n    if deep and args:\n        args = (deepcopy(arg, memo) for arg in args)\n    y = func(*args)\n    if deep:\n        memo[id(x)] = y\n\n    if state is not None:\n        if deep:\n            state = deepcopy(state, memo)\n        if hasattr(y, '__setstate__'):\n            y.__setstate__(state)\n        else:\n            if isinstance(state, tuple) and len(state) == 2:\n                state, slotstate = state\n            else:\n                slotstate = None\n            if state is not None:\n                y.__dict__.update(state)\n            if slotstate is not None:\n                for key, value in slotstate.items():\n                    setattr(y, key, value)\n\n    if listiter is not None:\n        if deep:\n            for item in listiter:\n                item = deepcopy(item, memo)\n                y.append(item)\n        else:\n            for item in listiter:\n                y.append(item)\n    if dictiter is not None:\n        if deep:\n            for key, value in dictiter:\n                key = deepcopy(key, memo)\n                value = deepcopy(value, memo)\n                y[key] = value\n        else:\n            for key, value in dictiter:\n                y[key] = value\n    return y\n\ndel types, weakref, PyStringMap\n", 303], "/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_tensor.py": ["from collections import OrderedDict\nimport enum\nimport functools\nfrom numbers import Number\nfrom typing import Any, Dict, Optional, Tuple, Union\nimport warnings\nimport copyreg\n\nimport torch\nimport torch._C as _C\nfrom torch._namedtensor_internals import (\n    update_names, check_serializing_named_tensor, resolve_ellipsis,\n    unzip_namedshape, single_ellipsis_index, is_ellipsis)\nfrom torch.overrides import (\n    has_torch_function, has_torch_function_unary, has_torch_function_variadic,\n    handle_torch_function, get_default_nowrap_functions)\nimport torch.utils.hooks as hooks\n\n\ndef _wrap_type_error_to_not_implemented(f):\n    # functools.wraps doesn't work well with methods in python 2\n    method_assignments = ('__name__', '__doc__')\n    assigned = functools.WRAPPER_ASSIGNMENTS\n\n    @functools.wraps(f, assigned=assigned)\n    def wrapped(*args, **kwargs):\n        if has_torch_function(args):\n            return handle_torch_function(wrapped, args, *args, **kwargs)\n        try:\n            return f(*args, **kwargs)\n        except TypeError:\n            return NotImplemented\n    return wrapped\n\n# Should not be used, this is kept only for BC of loading old serialized Tensor subclasses\ndef _rebuild_from_type(func, type, args, dict):\n    if type is Tensor:\n        return func(*args)\n\n    ret = func(*args).as_subclass(type)\n    ret.__dict__ = dict\n    return ret\n\ndef _rebuild_from_type_v2(func, new_type, args, state):\n    if new_type is Tensor:\n        return func(*args)\n\n    ret = func(*args).as_subclass(new_type)\n    # Tensor does define __setstate__ even though it doesn't define\n    # __getstate__. So only use __setstate__ if it is NOT the one defined\n    # on Tensor\n    if getattr(ret.__class__, \"__setstate__\", Tensor.__setstate__) is not Tensor.__setstate__:\n        ret.__setstate__(state)\n    else:\n        if isinstance(state, tuple):\n            if not len(state) == 2:\n                raise RuntimeError(f\"Invalid serialized state: {state}\")\n            dict_state = state[0]\n            slots_state = state[1]\n        else:\n            dict_state = state\n            slots_state = None\n\n        for k, v in dict_state.items():\n            setattr(ret, k, v)\n\n        if slots_state:\n            for k, v in slots_state.items():\n                setattr(ret, k, v)\n    return ret\n\n\n# NB: If you subclass Tensor, and want to share the subclassed class\n# across processes, you must also update torch/multiprocessing/reductions.py\n# to define a ForkingPickler serialization mode for the class.\n#\n# NB: If you add a new method to Tensor, you must update\n# torch/__init__.py.in to add a type annotation for your method;\n# otherwise, it will not show up in autocomplete.\nclass Tensor(torch._C._TensorBase):\n    def __deepcopy__(self, memo):\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__deepcopy__, (self,), self, memo)\n        if not self.is_leaf:\n            raise RuntimeError(\"Only Tensors created explicitly by the user \"\n                               \"(graph leaves) support the deepcopy protocol at the moment\")\n        if id(self) in memo:\n            return memo[id(self)]\n        with torch.no_grad():\n            # TODO: skipping storage copy is wrong for meta, as meta\n            # does accurate alias tracking; however, the code below\n            # doesn't work because of\n            # https://github.com/pytorch/pytorch/issues/47442\n            if self.is_sparse or self.device.type in ['xla', 'mlc', 'ort', 'meta']:\n                new_tensor = self.clone()\n            else:\n                new_storage = self.storage().__deepcopy__(memo)\n                if self.is_quantized:\n                    # quantizer_params can be different type based on torch attribute\n                    quantizer_params: Union[Tuple[torch.qscheme, float, int], Tuple[torch.qscheme, Tensor, Tensor, int]]\n                    if self.qscheme() == torch.per_tensor_affine:\n                        quantizer_params = self.qscheme(), self.q_scale(), self.q_zero_point()\n                    elif self.qscheme() in (torch.per_channel_affine, torch.per_channel_affine_float_qparams):\n                        quantizer_params = self.qscheme(), \\\n                            self.q_per_channel_scales(), \\\n                            self.q_per_channel_zero_points(), \\\n                            self.q_per_channel_axis()\n                    else:\n                        raise RuntimeError(f\"Unsupported qscheme {self.qscheme()} in deepcopy\")\n                    new_tensor = torch._utils._rebuild_qtensor(\n                        new_storage,\n                        self.storage_offset(),\n                        self.size(),\n                        self.stride(),\n                        quantizer_params,\n                        self.requires_grad,\n                        self._backward_hooks)\n                else:\n                    new_tensor = self.new_empty([])\n                    new_tensor.set_(new_storage, self.storage_offset(), self.size(), self.stride())\n                    if self.is_conj():\n                        new_tensor = new_tensor.conj_physical()\n                    if self.is_neg():\n                        new_tensor = new_tensor.neg()\n                    new_tensor.requires_grad = self.requires_grad\n            if self.grad is not None:\n                new_tensor.grad = self.grad.__deepcopy__(memo)\n            memo[id(self)] = new_tensor\n            return new_tensor\n\n    def __reduce_ex__(self, proto):\n        if type(self) is Tensor:\n            return self._reduce_ex_internal(proto)\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__reduce_ex__, (self,), self, proto)\n        func, args = self._reduce_ex_internal(proto)\n        # Get the state of the python subclass\n        # This loosely mimicks the function on the object class but since Tensor do not inherit\n        # from it, we cannot call that function directly\n        # https://github.com/python/cpython/blob/c83919bd635f4433f1c6ae8504996a9fe3c215e5/Objects/typeobject.c#L4891\n        getstate_fn = getattr(self, \"__getstate__\", None)\n        if getstate_fn:\n            state = getstate_fn()\n        else:\n            slots_to_save = copyreg._slotnames(self.__class__)  # type: ignore[attr-defined]\n            if slots_to_save:\n                state = (self.__dict__, {name: getattr(self, name) for name in slots_to_save if hasattr(self, name)})\n            else:\n                state = self.__dict__\n        return (_rebuild_from_type_v2, (func, type(self), args, state))\n\n    def _reduce_ex_internal(self, proto):\n        check_serializing_named_tensor(self)\n        # See Note [Don't serialize hooks]\n        torch.utils.hooks.warn_if_has_hooks(self)\n        backward_hooks: Dict[Any, Any] = OrderedDict()\n        # Note: Numpy array is chosen to be the rebuild component for XLA, ORT, MLC Tensors.\n        # We considered a few options:\n        # 1. CPU tensor can't be used here.\n        #    Otherwise in torch.load CPU storage is reconstructed with randomly\n        #    initialized data, moved onto backend device, and then storage is updated\n        #    to the serialized content. This works perfectly for CPU/CUDA but not these backends;\n        #    their tensors are disconnected with storage so they don't get the update.\n        # 2. Python list is not a good fit due to performance reason.\n        #    `tolist()` converts every single element in the tensor into python objects\n        #    and serialize them one by one.\n        if self.device.type in ['xla', 'ort', 'mlc']:\n            return (torch._utils._rebuild_device_tensor_from_numpy, (self.cpu().numpy(),\n                                                                     self.dtype,\n                                                                     str(self.device),\n                                                                     self.requires_grad))\n        if self.device.type == 'meta':\n            # NB: This implementation BREAKS storage sharing.  Current\n            # hypothesis is that no one cares for meta tensors.\n            arg_meta = (\n                self.dtype,\n                tuple(self.size()),\n                self.stride(),\n                self.requires_grad,\n            )\n            return (torch._utils._rebuild_meta_tensor_no_storage, arg_meta)\n        if self.is_quantized:\n            # quantizer_params can be different type based on torch attribute\n            quantizer_params: Union[Tuple[torch.qscheme, float, int], Tuple[Any, Tensor, Tensor, int]]\n            if self.qscheme() == torch.per_tensor_affine:\n                quantizer_params = (torch.per_tensor_affine,\n                                    self.q_scale(),\n                                    self.q_zero_point())\n            elif self.qscheme() in (torch.per_channel_affine, torch.per_channel_affine_float_qparams):\n                # convert scales and zero points to tuple to avoid recursive calls\n                # when/if we get multi-axis quantized tensors in the future, the shape\n                # is recoverable from the main tensor shape\n                quantizer_params = (torch.per_channel_affine,\n                                    self.q_per_channel_scales(),\n                                    self.q_per_channel_zero_points(),\n                                    self.q_per_channel_axis())\n            else:\n                raise RuntimeError(f\"Serialization is not supported for tensors of type {self.qscheme()}\")\n            args_qtensor = (self.storage(),\n                            self.storage_offset(),\n                            tuple(self.size()),\n                            self.stride(),\n                            quantizer_params,\n                            self.requires_grad,\n                            backward_hooks)\n            return (torch._utils._rebuild_qtensor, args_qtensor)\n        elif self.is_sparse:\n            if self.layout == torch.sparse_coo:\n                args_sparse = (self.layout,\n                               (self._indices(),\n                                self._values(),\n                                self.size()))\n            else:\n                raise NotImplementedError(\n                    'sparse tensor __reduce_ex__ for layout `%s`' % (self.layout))\n            return (torch._utils._rebuild_sparse_tensor, args_sparse)\n        else:\n            args = (self.storage(),\n                    self.storage_offset(),\n                    tuple(self.size()),\n                    self.stride(),\n                    self.requires_grad,\n                    backward_hooks)  # previously was self._backward_hooks\n            return (torch._utils._rebuild_tensor_v2, args)\n\n    def __setstate__(self, state):\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__setstate__, (self,), self, state)\n        # Warning: this method is NOT called when you torch.load() a tensor;\n        # that is managed by _rebuild_tensor_v2\n        if not self.is_leaf:\n            raise RuntimeError('__setstate__ can be only called on leaf Tensors')\n        if len(state) == 4:\n            # legacy serialization of Tensor\n            self.set_(*state)\n            return\n        elif len(state) == 5:\n            # legacy serialization of Variable\n            self.data = state[0]\n            state = (state[3], state[4], state[2])\n        # The setting of _backward_hooks is expected to be a no-op.\n        # See Note [Don't serialize hooks]\n        self.requires_grad, _, self._backward_hooks = state\n\n    def __repr__(self):\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__repr__, (self,), self)\n        # All strings are unicode in Python 3.\n        return torch._tensor_str._str(self)\n\n    def backward(self, gradient=None, retain_graph=None, create_graph=False, inputs=None):\n        r\"\"\"Computes the gradient of current tensor w.r.t. graph leaves.\n\n        The graph is differentiated using the chain rule. If the tensor is\n        non-scalar (i.e. its data has more than one element) and requires\n        gradient, the function additionally requires specifying ``gradient``.\n        It should be a tensor of matching type and location, that contains\n        the gradient of the differentiated function w.r.t. ``self``.\n\n        This function accumulates gradients in the leaves - you might need to zero\n        ``.grad`` attributes or set them to ``None`` before calling it.\n        See :ref:`Default gradient layouts<default-grad-layouts>`\n        for details on the memory layout of accumulated gradients.\n\n        .. note::\n\n            If you run any forward ops, create ``gradient``, and/or call ``backward``\n            in a user-specified CUDA stream context, see\n            :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.\n\n        .. note::\n\n            When ``inputs`` are provided and a given input is not a leaf,\n            the current implementation will call its grad_fn (though it is not strictly needed to get this gradients).\n            It is an implementation detail on which the user should not rely.\n            See https://github.com/pytorch/pytorch/pull/60521#issuecomment-867061780 for more details.\n\n        Args:\n            gradient (Tensor or None): Gradient w.r.t. the\n                tensor. If it is a tensor, it will be automatically converted\n                to a Tensor that does not require grad unless ``create_graph`` is True.\n                None values can be specified for scalar Tensors or ones that\n                don't require grad. If a None value would be acceptable then\n                this argument is optional.\n            retain_graph (bool, optional): If ``False``, the graph used to compute\n                the grads will be freed. Note that in nearly all cases setting\n                this option to True is not needed and often can be worked around\n                in a much more efficient way. Defaults to the value of\n                ``create_graph``.\n            create_graph (bool, optional): If ``True``, graph of the derivative will\n                be constructed, allowing to compute higher order derivative\n                products. Defaults to ``False``.\n            inputs (sequence of Tensor): Inputs w.r.t. which the gradient will be\n                accumulated into ``.grad``. All other Tensors will be ignored. If not\n                provided, the gradient is accumulated into all the leaf Tensors that were\n                used to compute the attr::tensors.\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(\n                Tensor.backward,\n                (self,),\n                self,\n                gradient=gradient,\n                retain_graph=retain_graph,\n                create_graph=create_graph,\n                inputs=inputs)\n        torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n\n    def register_hook(self, hook):\n        r\"\"\"Registers a backward hook.\n\n        The hook will be called every time a gradient with respect to the\n        Tensor is computed. The hook should have the following signature::\n\n            hook(grad) -> Tensor or None\n\n\n        The hook should not modify its argument, but it can optionally return\n        a new gradient which will be used in place of :attr:`grad`.\n\n        This function returns a handle with a method ``handle.remove()``\n        that removes the hook from the module.\n\n        Example::\n\n            >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n            >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n            >>> v.backward(torch.tensor([1., 2., 3.]))\n            >>> v.grad\n\n             2\n             4\n             6\n            [torch.FloatTensor of size (3,)]\n\n            >>> h.remove()  # removes the hook\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.register_hook, (self,), self, hook)\n        if not self.requires_grad:\n            raise RuntimeError(\"cannot register a hook on a tensor that \"\n                               \"doesn't require gradient\")\n        if self._backward_hooks is None:\n            self._backward_hooks = OrderedDict()\n            if self.grad_fn is not None:\n                self.grad_fn._register_hook_dict(self)\n        handle = hooks.RemovableHandle(self._backward_hooks)\n        self._backward_hooks[handle.id] = hook\n        return handle\n\n    def reinforce(self, reward):\n        def trim(str):\n            return '\\n'.join([line.strip() for line in str.split('\\n')])\n\n        raise RuntimeError(trim(r\"\"\"reinforce() was removed.\n            Use torch.distributions instead.\n            See https://pytorch.org/docs/master/distributions.html\n\n            Instead of:\n\n            probs = policy_network(state)\n            action = probs.multinomial()\n            next_state, reward = env.step(action)\n            action.reinforce(reward)\n            action.backward()\n\n            Use:\n\n            probs = policy_network(state)\n            # NOTE: categorical is equivalent to what used to be called multinomial\n            m = torch.distributions.Categorical(probs)\n            action = m.sample()\n            next_state, reward = env.step(action)\n            loss = -m.log_prob(action) * reward\n            loss.backward()\n        \"\"\"))\n\n    detach = _C._add_docstr(_C._TensorBase.detach, r\"\"\"\n    Returns a new Tensor, detached from the current graph.\n\n    The result will never require gradient.\n\n    This method also affects forward mode AD gradients and the result will never\n    have forward mode AD gradients.\n\n    .. note::\n\n      Returned Tensor shares the same storage with the original one.\n      In-place modifications on either of them will be seen, and may trigger\n      errors in correctness checks.\n      IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n      (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n      also update the original tensor. Now, these in-place changes will not update the\n      original tensor anymore, and will instead trigger an error.\n      For sparse tensors:\n      In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n      returned tensor will not update the original tensor anymore, and will instead\n      trigger an error.\n    \"\"\")\n\n    detach_ = _C._add_docstr(_C._TensorBase.detach_, r\"\"\"\n    Detaches the Tensor from the graph that created it, making it a leaf.\n    Views cannot be detached in-place.\n\n    This method also affects forward mode AD gradients and the result will never\n    have forward mode AD gradients.\n    \"\"\")\n\n    def is_shared(self):\n        r\"\"\"Checks if tensor is in shared memory.\n\n        This is always ``True`` for CUDA tensors.\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.is_shared, (self,), self)\n        return self.storage().is_shared()\n\n    def share_memory_(self):\n        r\"\"\"Moves the underlying storage to shared memory.\n\n        This is a no-op if the underlying storage is already in shared memory\n        and for CUDA tensors. Tensors in shared memory cannot be resized.\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.share_memory_, (self,), self)\n        self.storage().share_memory_()\n        return self\n\n    def __reversed__(self):\n        r\"\"\"Reverses the tensor along dimension 0.\"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__reversed__, (self,), self)\n        if self.dim() == 0:\n            return self\n        else:\n            return self.flip(0)\n\n    def norm(self, p=\"fro\", dim=None, keepdim=False, dtype=None):\n        r\"\"\"See :func:`torch.norm`\"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.norm, (self,), self, p=p, dim=dim, keepdim=keepdim, dtype=dtype)\n        return torch.norm(self, p, dim, keepdim, dtype=dtype)\n\n    def lu(self, pivot=True, get_infos=False):\n        r\"\"\"See :func:`torch.lu`\"\"\"\n        # If get_infos is True, then we don't need to check for errors and vice versa\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.lu, (self,), self, pivot=pivot, get_infos=get_infos)\n\n        LU, pivots, infos = torch._lu_with_info(self, pivot=pivot, check_errors=(not get_infos))\n        if get_infos:\n            return LU, pivots, infos\n        else:\n            return LU, pivots\n\n    def stft(self, n_fft: int, hop_length: Optional[int] = None,\n             win_length: Optional[int] = None, window: 'Optional[Tensor]' = None,\n             center: bool = True, pad_mode: str = 'reflect', normalized: bool = False,\n             onesided: Optional[bool] = None, return_complex: Optional[bool] = None):\n        r\"\"\"See :func:`torch.stft`\n\n        .. warning::\n          This function changed signature at version 0.4.1. Calling with\n          the previous signature may cause error or return incorrect result.\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(\n                Tensor.stft, (self,), self, n_fft, hop_length=hop_length,\n                win_length=win_length, window=window, center=center, pad_mode=pad_mode, normalized=normalized,\n                onesided=onesided, return_complex=return_complex\n            )\n        return torch.stft(self, n_fft, hop_length, win_length, window, center,\n                          pad_mode, normalized, onesided, return_complex=return_complex)\n\n    def istft(self, n_fft: int, hop_length: Optional[int] = None,\n              win_length: Optional[int] = None, window: 'Optional[Tensor]' = None,\n              center: bool = True, normalized: bool = False,\n              onesided: Optional[bool] = None, length: Optional[int] = None,\n              return_complex: bool = False):\n        r\"\"\"See :func:`torch.istft`\"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(\n                Tensor.istft, (self,), self, n_fft, hop_length=hop_length, win_length=win_length,\n                window=window, center=center, normalized=normalized, onesided=onesided, length=length,\n                return_complex=return_complex\n            )\n        return torch.istft(self, n_fft, hop_length, win_length, window, center,\n                           normalized, onesided, length, return_complex=return_complex)\n\n    def resize(self, *sizes):\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.resize, (self,), self, *sizes)\n        warnings.warn(\"non-inplace resize is deprecated\")\n        from torch.autograd._functions import Resize\n        return Resize.apply(self, sizes)\n\n    def resize_as(self, tensor):\n        if has_torch_function_variadic(self, tensor):\n            return handle_torch_function(Tensor.resize_as, (self, tensor), self, tensor)\n        warnings.warn(\"non-inplace resize_as is deprecated\")\n        from torch.autograd._functions import Resize\n        return Resize.apply(self, tensor.size())\n\n    def split(self, split_size, dim=0):\n        r\"\"\"See :func:`torch.split`\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.split, (self,), self, split_size, dim=dim)\n        if isinstance(split_size, int):\n            return super(Tensor, self).split(split_size, dim)\n        elif isinstance(split_size, Tensor):\n            try:\n                split_size = int(split_size)\n                return super(Tensor, self).split(split_size, dim)\n            except ValueError:\n                return super(Tensor, self).split_with_sizes(split_size, dim)\n        else:\n            return super(Tensor, self).split_with_sizes(split_size, dim)\n\n    def unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None):\n        r\"\"\"Returns the unique elements of the input tensor.\n\n        See :func:`torch.unique`\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(\n                Tensor.unique, (self,), self, sorted=sorted, return_inverse=return_inverse,\n                return_counts=return_counts, dim=dim\n            )\n        return torch.unique(self, sorted=sorted, return_inverse=return_inverse, return_counts=return_counts, dim=dim)\n\n    def unique_consecutive(self, return_inverse=False, return_counts=False, dim=None):\n        r\"\"\"Eliminates all but the first element from every consecutive group of equivalent elements.\n\n        See :func:`torch.unique_consecutive`\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(\n                Tensor.unique_consecutive, (self,), self, return_inverse=return_inverse,\n                return_counts=return_counts, dim=dim\n            )\n        return torch.unique_consecutive(self, return_inverse=return_inverse, return_counts=return_counts, dim=dim)\n\n    @_wrap_type_error_to_not_implemented\n    def __rsub__(self, other):\n        if has_torch_function_variadic(self, other):\n            return handle_torch_function(Tensor.__rsub__, (self, other), self, other)\n        return _C._VariableFunctions.rsub(self, other)\n\n    @_wrap_type_error_to_not_implemented\n    def __rdiv__(self, other):\n        if has_torch_function_variadic(self, other):\n            return handle_torch_function(Tensor.__rdiv__, (self, other), self, other)\n        return self.reciprocal() * other\n\n    __rtruediv__ = __rdiv__\n    __itruediv__ = _C._TensorBase.__idiv__\n\n    __pow__ = _wrap_type_error_to_not_implemented(_C._TensorBase.pow)\n\n    @_wrap_type_error_to_not_implemented\n    def __rmod__(self, other):\n        if has_torch_function_variadic(self, other):\n            return handle_torch_function(Tensor.__rmod__, (self, other), self, other)\n        return torch.remainder(other, self)\n\n    def __format__(self, format_spec):\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__format__, (self,), self, format_spec)\n        if self.dim() == 0:\n            return self.item().__format__(format_spec)\n        return object.__format__(self, format_spec)\n\n    def __ipow__(self, other):  # type: ignore[misc]\n        if has_torch_function_variadic(self, other):\n            return handle_torch_function(Tensor.__ipow__, (self, other), self, other)\n        return NotImplemented\n\n    @_wrap_type_error_to_not_implemented\n    def __rpow__(self, other):\n        dtype = torch.result_type(other, self)\n        return torch.tensor(other, dtype=dtype, device=self.device) ** self\n\n    @_wrap_type_error_to_not_implemented\n    def __floordiv__(self, other):\n        warnings.warn(\"__floordiv__ is deprecated, and its behavior will change in a future version of pytorch. \"\n                      \"It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). \"\n                      \"This results in incorrect rounding for negative values. \"\n                      \"To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), \"\n                      \"or for actual floor division, use torch.div(a, b, rounding_mode='floor').\", stacklevel=3)\n        return torch.div(self, other, rounding_mode='trunc')\n\n    @_wrap_type_error_to_not_implemented\n    def __rfloordiv__(self, other):\n        warnings.warn(\"__rfloordiv__ is deprecated, and its behavior will change in a future version of pytorch. \"\n                      \"It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). \"\n                      \"This results in incorrect rounding for negative values. \"\n                      \"To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), \"\n                      \"or for actual floor division, use torch.div(a, b, rounding_mode='floor').\", stacklevel=3)\n        return torch.div(other, self, rounding_mode='trunc')\n\n    @_wrap_type_error_to_not_implemented\n    def __rlshift__(self, other):\n        return torch.bitwise_left_shift(other, self)\n\n    @_wrap_type_error_to_not_implemented\n    def __rrshift__(self, other):\n        return torch.bitwise_right_shift(other, self)\n\n    @_wrap_type_error_to_not_implemented\n    def __rmatmul__(self, other):\n        if has_torch_function_variadic(self, other):\n            return handle_torch_function(Tensor.__rmatmul__, (self, other), self, other)\n        return torch.matmul(other, self)\n\n    __pos__ = _C._TensorBase.positive\n    __neg__ = _C._TensorBase.neg\n    __abs__ = _C._TensorBase.abs\n\n    def __len__(self):\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__len__, (self,), self)\n        if self.dim() == 0:\n            raise TypeError(\"len() of a 0-d tensor\")\n        if torch._C._get_tracing_state():\n            warnings.warn('Using len to get tensor shape might cause the trace to be incorrect. '\n                          'Recommended usage would be tensor.shape[0]. '\n                          'Passing a tensor of different shape might lead to errors or silently give '\n                          'incorrect results.', category=torch.jit.TracerWarning, stacklevel=2)\n        return self.shape[0]\n\n    def __iter__(self):\n        # NB: we use 'imap' and not 'map' here, so that in Python 2 we get a\n        # generator and don't eagerly perform all the indexes.  This could\n        # save us work, and also helps keep trace ordering deterministic\n        # (e.g., if you zip(*hiddens), the eager map will force all the\n        # indexes of hiddens[0] before hiddens[1], while the generator\n        # map will interleave them.)\n        # NB: We have intentionally skipped __torch_function__ dispatch here.\n        # See gh-54457\n        if self.dim() == 0:\n            raise TypeError('iteration over a 0-d tensor')\n        if torch._C._get_tracing_state():\n            warnings.warn('Iterating over a tensor might cause the trace to be incorrect. '\n                          'Passing a tensor of different shape won\\'t change the number of '\n                          'iterations executed (and might lead to errors or silently give '\n                          'incorrect results).', category=torch.jit.TracerWarning, stacklevel=2)\n        return iter(self.unbind(0))\n\n    def __hash__(self):\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__hash__, (self,), self)\n        return id(self)\n\n    def __dir__(self):\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__dir__, (self,), self)\n        if self.is_quantized:\n            warnings.warn('Only a small subset of methods are supported for quantized tensors.')\n        tensor_methods = dir(self.__class__)\n        tensor_methods.remove('volatile')  # deprecated\n        attrs = list(self.__dict__.keys())\n        keys = tensor_methods + attrs\n\n        # property only available dense, cuda tensors\n        if (not self.is_cuda) or self.is_sparse:\n            keys.remove(\"__cuda_array_interface__\")\n\n        return sorted(keys)\n\n    # Numpy array interface, to support `numpy.asarray(tensor) -> ndarray`\n    __array_priority__ = 1000    # prefer Tensor ops over numpy ones\n\n    def __array__(self, dtype=None):\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__array__, (self,), self, dtype=dtype)\n        if dtype is None:\n            return self.numpy()\n        else:\n            return self.numpy().astype(dtype, copy=False)\n\n    # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n    # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n    def __array_wrap__(self, array):\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__array_wrap__, (self,), self, array=array)\n        if array.dtype == bool:\n            # Workaround, torch has no built-in bool tensor\n            array = array.astype('uint8')\n        return torch.from_numpy(array)\n\n    def __contains__(self, element):\n        r\"\"\"Check if `element` is present in tensor\n\n        Args:\n            element (Tensor or scalar): element to be checked\n                for presence in current tensor\"\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__contains__, (self,), self, element)\n        if isinstance(element, (torch.Tensor, Number)):\n            # type hint doesn't understand the __contains__ result array\n            return (element == self).any().item()  # type: ignore[union-attr]\n\n        raise RuntimeError(\n            \"Tensor.__contains__ only supports Tensor or scalar, but you passed in a %s.\" %\n            type(element)\n        )\n\n    @property\n    def __cuda_array_interface__(self):\n        \"\"\"Array view description for cuda tensors.\n\n        See:\n        https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n        \"\"\"\n        if has_torch_function_unary(self):\n            # TODO mypy doesn't support @property, see: https://github.com/python/mypy/issues/6185\n            return handle_torch_function(Tensor.__cuda_array_interface__.__get__, (self,), self)  # type: ignore[attr-defined]\n\n        # raise AttributeError for unsupported tensors, so that\n        # hasattr(cpu_tensor, \"__cuda_array_interface__\") is False.\n        if not self.is_cuda:\n            raise AttributeError(\n                \"Can't get __cuda_array_interface__ on non-CUDA tensor type: %s \"\n                \"If CUDA data is required use tensor.cuda() to copy tensor to device memory.\" %\n                self.type()\n            )\n\n        if self.is_sparse:\n            raise AttributeError(\n                \"Can't get __cuda_array_interface__ on sparse type: %s \"\n                \"Use Tensor.to_dense() to convert to a dense tensor first.\" %\n                self.type()\n            )\n\n        # RuntimeError, matching tensor.__array__() behavior.\n        if self.requires_grad:\n            raise RuntimeError(\n                \"Can't get __cuda_array_interface__ on Variable that requires grad. \"\n                \"If gradients aren't required, use var.detach() to get Variable that doesn't require grad.\"\n            )\n\n        # CUDA devices are little-endian and tensors are stored in native byte\n        # order. 1-byte entries are endian-agnostic.\n        typestr = {\n            torch.complex64: \"<c8\",\n            torch.complex128: \"<c16\",\n            torch.float16: \"<f2\",\n            torch.float32: \"<f4\",\n            torch.float64: \"<f8\",\n            torch.uint8: \"|u1\",\n            torch.int8: \"|i1\",\n            torch.int16: \"<i2\",\n            torch.int32: \"<i4\",\n            torch.int64: \"<i8\",\n        }[self.dtype]\n\n        itemsize = self.storage().element_size()\n\n        shape = tuple(self.shape)\n        if self.is_contiguous():\n            # __cuda_array_interface__ v2 requires the strides to be omitted\n            # (either not set or set to None) for C-contiguous arrays.\n            strides = None\n        else:\n            strides = tuple(s * itemsize for s in self.stride())\n        data_ptr = self.data_ptr() if self.numel() > 0 else 0\n        data = (data_ptr, False)  # read-only is false\n\n        return dict(typestr=typestr, shape=shape, strides=strides, data=data, version=2)\n\n    def refine_names(self, *names):\n        r\"\"\"Refines the dimension names of :attr:`self` according to :attr:`names`.\n\n        Refining is a special case of renaming that \"lifts\" unnamed dimensions.\n        A ``None`` dim can be refined to have any name; a named dim can only be\n        refined to have the same name.\n\n        Because named tensors can coexist with unnamed tensors, refining names\n        gives a nice way to write named-tensor-aware code that works with both\n        named and unnamed tensors.\n\n        :attr:`names` may contain up to one Ellipsis (``...``).\n        The Ellipsis is expanded greedily; it is expanded in-place to fill\n        :attr:`names` to the same length as ``self.dim()`` using names from the\n        corresponding indices of ``self.names``.\n\n        Python 2 does not support Ellipsis but one may use a string literal\n        instead (``'...'``).\n\n        Args:\n            names (iterable of str): The desired names of the output tensor. May\n                contain up to one Ellipsis.\n\n        Examples::\n\n            >>> imgs = torch.randn(32, 3, 128, 128)\n            >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')\n            >>> named_imgs.names\n            ('N', 'C', 'H', 'W')\n\n            >>> tensor = torch.randn(2, 3, 5, 7, 11)\n            >>> tensor = tensor.refine_names('A', ..., 'B', 'C')\n            >>> tensor.names\n            ('A', None, None, 'B', 'C')\n\n        .. warning::\n            The named tensor API is experimental and subject to change.\n\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.refine_names, (self,), self, *names)\n        names = resolve_ellipsis(names, self.names, 'refine_names')\n        return super(Tensor, self).refine_names(names)\n\n    def align_to(self, *names):\n        r\"\"\"Permutes the dimensions of the :attr:`self` tensor to match the order\n        specified in :attr:`names`, adding size-one dims for any new names.\n\n        All of the dims of :attr:`self` must be named in order to use this method.\n        The resulting tensor is a view on the original tensor.\n\n        All dimension names of :attr:`self` must be present in :attr:`names`.\n        :attr:`names` may contain additional names that are not in ``self.names``;\n        the output tensor has a size-one dimension for each of those new names.\n\n        :attr:`names` may contain up to one Ellipsis (``...``).\n        The Ellipsis is expanded to be equal to all dimension names of :attr:`self`\n        that are not mentioned in :attr:`names`, in the order that they appear\n        in :attr:`self`.\n\n        Python 2 does not support Ellipsis but one may use a string literal\n        instead (``'...'``).\n\n        Args:\n            names (iterable of str): The desired dimension ordering of the\n                output tensor. May contain up to one Ellipsis that is expanded\n                to all unmentioned dim names of :attr:`self`.\n\n        Examples::\n\n            >>> tensor = torch.randn(2, 2, 2, 2, 2, 2)\n            >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')\n\n            # Move the F and E dims to the front while keeping the rest in order\n            >>> named_tensor.align_to('F', 'E', ...)\n\n        .. warning::\n            The named tensor API is experimental and subject to change.\n\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.align_to, (self,), self, *names)\n        ellipsis_idx = single_ellipsis_index(names, 'align_to')\n        if ellipsis_idx is None:\n            return super(Tensor, self).align_to(names)\n        return super(Tensor, self).align_to(\n            [name for name in names if not is_ellipsis(name)],\n            ellipsis_idx)\n\n    def unflatten(self, dim, sizes):\n        r\"\"\"Expands the dimension :attr:`dim` of the :attr:`self` tensor over multiple dimensions\n        of sizes given by :attr:`sizes`.\n\n        * :attr:`sizes` is the new shape of the unflattened dimension and it can be a `Tuple[int]` as well\n          as `torch.Size` if :attr:`self` is a `Tensor`, or `namedshape` (Tuple[(name: str, size: int)])\n          if :attr:`self` is a `NamedTensor`. The total number of elements in sizes must match the number\n          of elements in the original dim being unflattened.\n\n        Args:\n            dim (Union[int, str]): Dimension to unflatten\n            sizes (Union[Tuple[int] or torch.Size, Tuple[Tuple[str, int]]]): New shape of the unflattened dimension\n\n        Examples:\n            >>> torch.randn(3, 4, 1).unflatten(1, (2, 2)).shape\n            torch.Size([3, 2, 2, 1])\n            >>> torch.randn(3, 4, 1).unflatten(1, (-1, 2)).shape # the size -1 is inferred from the size of dimension 1\n            torch.Size([3, 2, 2, 1])\n            >>> torch.randn(2, 4, names=('A', 'B')).unflatten('B', (('B1', 2), ('B2', 2)))\n            tensor([[[-1.1772,  0.0180],\n                    [ 0.2412,  0.1431]],\n                    [[-1.1819, -0.8899],\n                    [ 1.5813,  0.2274]]], names=('A', 'B1', 'B2'))\n            >>> torch.randn(2, names=('A',)).unflatten('A', (('B1', -1), ('B2', 1)))\n            tensor([[-0.8591],\n                    [ 0.3100]], names=('B1', 'B2'))\n\n        .. warning::\n            The named tensor API is experimental and subject to change.\n\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.unflatten, (self,), self, dim, sizes)\n\n        if not sizes:\n            raise RuntimeError(\"unflatten: sizes must be non-empty\")\n\n        names = None\n        if isinstance(sizes, OrderedDict) or (isinstance(sizes, (tuple, list)) and isinstance(sizes[0], (tuple, list))):\n            names, sizes = unzip_namedshape(sizes)\n        return super(Tensor, self).unflatten(dim, sizes, names)\n\n\n    def rename_(self, *names, **rename_map):\n        \"\"\"In-place version of :meth:`~Tensor.rename`.\"\"\"\n\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.rename_, (self,), self, *names, **rename_map)\n\n        # Note [rename_ / rename API]\n        # The Python API for these is different from the C++ API. In Python:\n        # 1) tensor.rename(*names) takes a vararglist of names\n        # 2) tensor.rename(**rename_map) takes a map of names to rename.\n        # C++ is static, making it difficult to implement similar behavior.\n        return update_names(self, names, rename_map, inplace=True)\n\n    def rename(self, *names, **rename_map):\n        \"\"\"Renames dimension names of :attr:`self`.\n\n        There are two main usages:\n\n        ``self.rename(**rename_map)`` returns a view on tensor that has dims\n        renamed as specified in the mapping :attr:`rename_map`.\n\n        ``self.rename(*names)`` returns a view on tensor, renaming all\n        dimensions positionally using :attr:`names`.\n        Use ``self.rename(None)`` to drop names on a tensor.\n\n        One cannot specify both positional args :attr:`names` and keyword args\n        :attr:`rename_map`.\n\n        Examples::\n\n            >>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))\n            >>> renamed_imgs = imgs.rename(N='batch', C='channels')\n            >>> renamed_imgs.names\n            ('batch', 'channels', 'H', 'W')\n\n            >>> renamed_imgs = imgs.rename(None)\n            >>> renamed_imgs.names\n            (None,)\n\n            >>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')\n            >>> renamed_imgs.names\n            ('batch', 'channel', 'height', 'width')\n\n        .. warning::\n            The named tensor API is experimental and subject to change.\n\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.rename, (self,), self, *names, **rename_map)\n\n        # See Note [rename_ / rename API]\n        return update_names(self, names, rename_map, inplace=False)\n\n    def to_sparse_csr(self):\n        \"\"\" Convert a tensor to compressed row storage format. Only works with 2D tensors.\n\n        Examples::\n\n            >>> dense = torch.randn(5, 5)\n            >>> sparse = dense.to_sparse_csr()\n            >>> sparse._nnz()\n            25\n\n        \"\"\"\n        shape = self.size()\n        fill_value = 0\n        if len(shape) != 2:\n            raise RuntimeError(\"Only 2D tensors can be converted to the CSR format but got shape: \", shape)\n\n        if self.is_sparse:\n            coalesced_self = self.coalesce()\n            row_indices = coalesced_self.indices()[0]\n            device = coalesced_self.values().device\n            crow_indices = torch._convert_indices_from_coo_to_csr(\n                row_indices, self.shape[0], out_int32=row_indices.dtype == torch.int32)\n            return torch.sparse_csr_tensor(crow_indices,\n                                           coalesced_self.indices()[1].contiguous(),\n                                           coalesced_self.values(),\n                                           size=coalesced_self.shape,\n                                           dtype=coalesced_self.dtype,\n                                           device=device)\n        elif self.is_sparse_csr:\n            return self\n        else:\n            return self.to_sparse().to_sparse_csr()\n\n    def _update_names(self, names, inplace):\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor._update_names, (self,), self, names, inplace)\n\n        # See Note [rename_ / rename API]\n        if inplace:\n            return super(Tensor, self).rename_(names)\n        else:\n            return super(Tensor, self).rename(names)\n\n    @property\n    def grad(self):\n        \"\"\"\n        This attribute is ``None`` by default and becomes a Tensor the first time a call to\n        :func:`backward` computes gradients for ``self``.\n        The attribute will then contain the gradients computed and future calls to\n        :func:`backward` will accumulate (add) gradients into it.\n        \"\"\"\n        if has_torch_function_unary(self):\n            # TODO mypy doesn't support @property, see: https://github.com/python/mypy/issues/6185\n            return handle_torch_function(Tensor.grad.__get__, (self,), self)  # type: ignore[attr-defined]\n\n        return self._grad\n\n    @grad.setter\n    def grad(self, new_grad):\n        if has_torch_function_unary(self):\n            # TODO mypy doesn't support @property, see: https://github.com/python/mypy/issues/6185\n            return handle_torch_function(Tensor.grad.__set__, (self,), self, new_grad)  # type: ignore[attr-defined]\n        self._grad = new_grad\n\n    @grad.deleter\n    def grad(self):\n        if has_torch_function_unary(self):\n            # TODO mypy doesn't support @property, see: https://github.com/python/mypy/issues/6185\n            return handle_torch_function(Tensor.grad.__delete__, (self,), self)  # type: ignore[attr-defined]\n        del self._grad\n\n    @classmethod\n    def __torch_function__(cls, func, types, args=(), kwargs=None):\n        \"\"\"\n        This __torch_function__ implementation wraps subclasses such that\n        methods called on subclasses return a subclass instance instead of\n        a ``torch.Tensor`` instance.\n\n        One corollary to this is that you need coverage for torch.Tensor\n        methods if implementing __torch_function__ for subclasses.\n\n        We recommend always calling ``super().__torch_function__`` as the base\n        case when doing the above.\n\n        While not mandatory, we recommend making `__torch_function__` a classmethod.\n        \"\"\"\n        if kwargs is None:\n            kwargs = {}\n\n        if not all(issubclass(cls, t) for t in types):\n            return NotImplemented\n\n        with _C.DisableTorchFunction():\n            ret = func(*args, **kwargs)\n            if func in get_default_nowrap_functions():\n                return ret\n            else:\n                return _convert(ret, cls)\n\n    def __dlpack__(self, stream=None):\n        \"\"\"\n        Creates a DLpack `capsule https://data-apis.org/array-api/latest/design_topics/data_interchange.html#data-interchange`_\n        of the current tensor to be exported to other libraries.\n\n        This function will be called from the `from_dlpack` method\n        of the library that will consume the capsule. `from_dlpack` passes the current\n        stream to this method as part of the specification.\n\n        Args:\n            stream (integer or None): An optional Python integer representing a\n            pointer to a CUDA stream. The current stream is synchronized with\n            this stream before the capsule is created, and since the capsule\n            shares its storage with the tensor this make it safe to access from\n            both streams.  If None or -1 is passed then no synchronization is performed.\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__dlpack__, (self,), self, stream)\n\n        # DLPack capsules can't capture all of PyTorch's semantics,\n        # so we prohibit exporting tensors that would lose their properties like\n        # requires_grad and having the conjugate bit set.\n        if self.requires_grad:\n            raise RuntimeError('Can\\'t export tensors that require gradient, use tensor.detach()')\n        if self.is_conj():\n            raise RuntimeError('Can\\'t export tensors with the conjugate bit set')\n        if self.layout != torch.strided:\n            raise RuntimeError('Can\\'t export tensors with layout other than torch.strided')\n\n        if stream is not None and type(stream) is not int:\n            # Stream pointers in CUDA/ROCm are uniquely numbered and can\n            # be retrieved from their integer value.\n            raise TypeError('stream must be ``int`` or ``none``')\n        elif stream is not None and stream != -1:\n            if self.device.type == 'cuda':\n                stream = torch.cuda.streams.ExternalStream(stream)\n                # Only synchronize on different streams\n                if stream != torch.cuda.current_stream:\n                    event = torch.cuda.Event()\n                    event.record(torch.cuda.current_stream())\n                    stream.wait_event(event)\n        return torch.to_dlpack(self)\n\n    def __dlpack_device__(self) -> Tuple[enum.IntEnum, int]:\n        # Avoid circular import\n        from torch.utils.dlpack import DLDeviceType\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__dlpack_device__, (self,), self)\n        idx = self.device.index if self.device.index is not None else 0\n        if self.device.type == 'cuda' and torch.version.hip is not None:\n            device_type = DLDeviceType.kDLROCM\n        elif self.device.type == 'cpu' and self.is_pinned():\n            device_type = DLDeviceType.kDLCPUPinned\n        elif self.device.type == 'cuda':\n            device_type = DLDeviceType.kDLGPU\n        elif self.device.type == 'cpu':\n            device_type = DLDeviceType.kDLCPU\n        else:\n            raise ValueError('Unknown device type {} for Dlpack'.format(self.device.type))\n        return (device_type, idx)\n\n    __module__ = 'torch'\n\ndef _convert(ret, cls):\n    if cls is Tensor:\n        return ret\n\n    if isinstance(ret, Tensor) and not isinstance(ret, cls):\n        ret = ret.as_subclass(cls)\n\n    if isinstance(ret, (tuple, list)):\n        # Also handles things like namedtuples\n        ret = type(ret)(_convert(r, cls) for r in ret)\n\n    return ret\n", 1131], "/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/minimize.py": ["\"\"\" The strategy that uses a minimizer method for searching through the parameter space \"\"\"\nfrom __future__ import print_function\n\nfrom collections import OrderedDict\nimport logging\n\nimport numpy\nimport scipy.optimize\nfrom kernel_tuner import util\n\nsupported_methods = [\"Nelder-Mead\", \"Powell\", \"CG\", \"BFGS\", \"L-BFGS-B\", \"TNC\", \"COBYLA\", \"SLSQP\"]\n\n\ndef tune(runner, kernel_options, device_options, tuning_options):\n    \"\"\" Find the best performing kernel configuration in the parameter space\n\n    :params runner: A runner from kernel_tuner.runners\n    :type runner: kernel_tuner.runner\n\n    :param kernel_options: A dictionary with all options for the kernel.\n    :type kernel_options: kernel_tuner.interface.Options\n\n    :param device_options: A dictionary with all options for the device\n        on which the kernel should be tuned.\n    :type device_options: kernel_tuner.interface.Options\n\n    :param tuning_options: A dictionary with all options regarding the tuning\n        process.\n    :type tuning_options: kernel_tuner.interface.Options\n\n    :returns: A list of dictionaries for executed kernel configurations and their\n        execution times. And a dictionary that contains a information\n        about the hardware/software environment on which the tuning took place.\n    :rtype: list(dict()), dict()\n\n    \"\"\"\n\n    results = []\n\n    method = tuning_options.strategy_options.get(\"method\", \"L-BFGS-B\")\n\n    # scale variables in x to make 'eps' relevant for multiple variables\n    tuning_options[\"scaling\"] = True\n\n    bounds, x0, _ = get_bounds_x0_eps(tuning_options)\n    kwargs = setup_method_arguments(method, bounds)\n    options = setup_method_options(method, tuning_options)\n\n    args = (kernel_options, tuning_options, runner, results)\n\n    opt_result = scipy.optimize.minimize(_cost_func, x0, args=args, method=method, options=options, **kwargs)\n\n    if tuning_options.verbose:\n        print(opt_result.message)\n\n    return results, runner.dev.get_environment()\n\n\ndef _cost_func(x, kernel_options, tuning_options, runner, results, check_restrictions=True):\n    \"\"\" Cost function used by minimize \"\"\"\n\n    error_time = 1e20\n    logging.debug('_cost_func called')\n    logging.debug('x: ' + str(x))\n\n    # snap values in x to nearest actual value for each parameter unscale x if needed\n    if tuning_options.snap:\n        if tuning_options.scaling:\n            params = unscale_and_snap_to_nearest(x, tuning_options.tune_params, tuning_options.eps)\n        else:\n            params = snap_to_nearest_config(x, tuning_options.tune_params)\n    else:\n        params = x\n    logging.debug('params ' + str(params))\n\n    # we cache snapped values, since those correspond to results for an actual instance of the kernel\n    x_int = \",\".join([str(i) for i in params])\n    if x_int in tuning_options.cache:\n        results.append(tuning_options.cache[x_int])\n        return tuning_options.cache[x_int][\"time\"]\n\n    # check if this is a legal (non-restricted) parameter instance\n    if check_restrictions and tuning_options.restrictions:\n        legal = util.check_restrictions(tuning_options.restrictions, params, tuning_options.tune_params.keys(), tuning_options.verbose)\n        if not legal:\n            error_result = OrderedDict(zip(tuning_options.tune_params.keys(), params))\n            error_result[\"time\"] = error_time\n            tuning_options.cache[x_int] = error_result\n            return error_time\n\n    # compile and benchmark this instance\n    res, _ = runner.run([params], kernel_options, tuning_options)\n\n    # append to tuning results\n    if res:\n        results.append(res[0])\n        return res[0]['time']\n\n    return error_time\n\n\ndef get_bounds_x0_eps(tuning_options):\n    \"\"\"compute bounds, x0 (the initial guess), and eps\"\"\"\n    values = list(tuning_options.tune_params.values())\n\n    if \"x0\" in tuning_options.strategy_options:\n        x0 = tuning_options.strategy_options.x0\n    else:\n        x0 = None\n\n    if tuning_options.scaling:\n        eps = numpy.amin([1.0 / len(v) for v in values])\n\n        # reducing interval from [0, 1] to [0, eps*len(v)]\n        bounds = [(0, eps * len(v)) for v in values]\n        if x0:\n            # x0 has been supplied by the user, map x0 into [0, eps*len(v)]\n            for i, e in enumerate(values):\n                x0[i] = eps * values[i].index(x0[i])\n        else:\n            x0 = [0.5 * eps * len(v) for v in values]\n    else:\n        bounds = get_bounds(tuning_options.tune_params)\n        if not x0:\n            x0 = [(min_v + max_v) / 2.0 for (min_v, max_v) in bounds]\n        eps = 1e9\n        for v_list in values:\n            vals = numpy.sort(v_list)\n            eps = min(eps, numpy.amin(numpy.gradient(vals)))\n\n    tuning_options[\"eps\"] = eps\n    logging.debug('get_bounds_x0_eps called')\n    logging.debug('bounds ' + str(bounds))\n    logging.debug('x0 ' + str(x0))\n    logging.debug('eps ' + str(eps))\n\n    return bounds, x0, eps\n\n\ndef get_bounds(tune_params):\n    \"\"\" create a bounds array from the tunable parameters \"\"\"\n    bounds = []\n    for values in tune_params.values():\n        sorted_values = numpy.sort(values)\n        bounds.append((sorted_values[0], sorted_values[-1]))\n    return bounds\n\n\ndef setup_method_arguments(method, bounds):\n    \"\"\" prepare method specific arguments \"\"\"\n    kwargs = {}\n    # pass bounds to methods that support it\n    if method in [\"L-BFGS-B\", \"TNC\", \"SLSQP\"]:\n        kwargs['bounds'] = bounds\n    return kwargs\n\n\ndef setup_method_options(method, tuning_options):\n    \"\"\" prepare method specific options \"\"\"\n    kwargs = {}\n\n    # Note that not all methods iterpret maxiter in the same manner\n    if \"maxiter\" in tuning_options.strategy_options:\n        maxiter = tuning_options.strategy_options.maxiter\n    else:\n        maxiter = 100\n    kwargs['maxiter'] = maxiter\n    if method in [\"Nelder-Mead\", \"Powell\"]:\n        kwargs['maxfev'] = maxiter\n    elif method == \"L-BFGS-B\":\n        kwargs['maxfun'] = maxiter\n\n    # pass eps to methods that support it\n    if method in [\"CG\", \"BFGS\", \"L-BFGS-B\", \"TNC\", \"SLSQP\"]:\n        kwargs['eps'] = tuning_options.eps\n    elif method == \"COBYLA\":\n        kwargs['rhobeg'] = tuning_options.eps\n\n    # not all methods support 'disp' option\n    if not method in ['TNC']:\n        kwargs['disp'] = tuning_options.verbose\n\n    return kwargs\n\n\ndef snap_to_nearest_config(x, tune_params, resolution=1):\n    \"\"\"helper func that for each param selects the closest actual value\"\"\"\n    params = []\n    for i, k in enumerate(tune_params.keys()):\n        values = numpy.array(tune_params[k])\n        idx = numpy.abs(values - x[i]).argmin()\n        params.append(values[idx])\n    return params\n\n\ndef unscale_and_snap_to_nearest(x, tune_params, eps):\n    \"\"\"helper func that snaps a scaled variable to the nearest config\"\"\"\n    x_u = [i for i in x]\n    for i, v in enumerate(tune_params.values()):\n        # create an evenly spaced linear space to map [0,1]-interval\n        # to actual values, giving each value an equal chance\n        # pad = 0.5/len(v)  #use when interval is [0,1]\n        pad = 0.5 * eps    # use when interval is [0, eps*len(v)]\n        linspace = numpy.linspace(pad, (eps * len(v)) - pad, len(v))\n\n        # snap value to nearest point in space, store index\n        idx = numpy.abs(linspace - x[i]).argmin()\n\n        # safeguard that should not be needed\n        idx = min(max(idx, 0), len(v) - 1)\n\n        # use index into array of actual values\n        x_u[i] = v[idx]\n    return x_u\n", 214], "/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/_methods.py": ["\"\"\"\nArray methods which are called by both the C-code for the method\nand the Python code for the NumPy-namespace function\n\n\"\"\"\nimport warnings\nfrom contextlib import nullcontext\n\nfrom numpy.core import multiarray as mu\nfrom numpy.core import umath as um\nfrom numpy.core.multiarray import asanyarray\nfrom numpy.core import numerictypes as nt\nfrom numpy.core import _exceptions\nfrom numpy._globals import _NoValue\nfrom numpy.compat import pickle, os_fspath\n\n# save those O(100) nanoseconds!\numr_maximum = um.maximum.reduce\numr_minimum = um.minimum.reduce\numr_sum = um.add.reduce\numr_prod = um.multiply.reduce\numr_any = um.logical_or.reduce\numr_all = um.logical_and.reduce\n\n# Complex types to -> (2,)float view for fast-path computation in _var()\n_complex_to_float = {\n    nt.dtype(nt.csingle) : nt.dtype(nt.single),\n    nt.dtype(nt.cdouble) : nt.dtype(nt.double),\n}\n# Special case for windows: ensure double takes precedence\nif nt.dtype(nt.longdouble) != nt.dtype(nt.double):\n    _complex_to_float.update({\n        nt.dtype(nt.clongdouble) : nt.dtype(nt.longdouble),\n    })\n\n# avoid keyword arguments to speed up parsing, saves about 15%-20% for very\n# small reductions\ndef _amax(a, axis=None, out=None, keepdims=False,\n          initial=_NoValue, where=True):\n    return umr_maximum(a, axis, None, out, keepdims, initial, where)\n\ndef _amin(a, axis=None, out=None, keepdims=False,\n          initial=_NoValue, where=True):\n    return umr_minimum(a, axis, None, out, keepdims, initial, where)\n\ndef _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n         initial=_NoValue, where=True):\n    return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n\ndef _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n          initial=_NoValue, where=True):\n    return umr_prod(a, axis, dtype, out, keepdims, initial, where)\n\ndef _any(a, axis=None, dtype=None, out=None, keepdims=False, *, where=True):\n    # Parsing keyword arguments is currently fairly slow, so avoid it for now\n    if where is True:\n        return umr_any(a, axis, dtype, out, keepdims)\n    return umr_any(a, axis, dtype, out, keepdims, where=where)\n\ndef _all(a, axis=None, dtype=None, out=None, keepdims=False, *, where=True):\n    # Parsing keyword arguments is currently fairly slow, so avoid it for now\n    if where is True:\n        return umr_all(a, axis, dtype, out, keepdims)\n    return umr_all(a, axis, dtype, out, keepdims, where=where)\n\ndef _count_reduce_items(arr, axis, keepdims=False, where=True):\n    # fast-path for the default case\n    if where is True:\n        # no boolean mask given, calculate items according to axis\n        if axis is None:\n            axis = tuple(range(arr.ndim))\n        elif not isinstance(axis, tuple):\n            axis = (axis,)\n        items = nt.intp(1)\n        for ax in axis:\n            items *= arr.shape[mu.normalize_axis_index(ax, arr.ndim)]\n    else:\n        # TODO: Optimize case when `where` is broadcast along a non-reduction\n        # axis and full sum is more excessive than needed.\n\n        # guarded to protect circular imports\n        from numpy.lib.stride_tricks import broadcast_to\n        # count True values in (potentially broadcasted) boolean mask\n        items = umr_sum(broadcast_to(where, arr.shape), axis, nt.intp, None,\n                        keepdims)\n    return items\n\n# Numpy 1.17.0, 2019-02-24\n# Various clip behavior deprecations, marked with _clip_dep as a prefix.\n\ndef _clip_dep_is_scalar_nan(a):\n    # guarded to protect circular imports\n    from numpy.core.fromnumeric import ndim\n    if ndim(a) != 0:\n        return False\n    try:\n        return um.isnan(a)\n    except TypeError:\n        return False\n\ndef _clip_dep_is_byte_swapped(a):\n    if isinstance(a, mu.ndarray):\n        return not a.dtype.isnative\n    return False\n\ndef _clip_dep_invoke_with_casting(ufunc, *args, out=None, casting=None, **kwargs):\n    # normal path\n    if casting is not None:\n        return ufunc(*args, out=out, casting=casting, **kwargs)\n\n    # try to deal with broken casting rules\n    try:\n        return ufunc(*args, out=out, **kwargs)\n    except _exceptions._UFuncOutputCastingError as e:\n        # Numpy 1.17.0, 2019-02-24\n        warnings.warn(\n            \"Converting the output of clip from {!r} to {!r} is deprecated. \"\n            \"Pass `casting=\\\"unsafe\\\"` explicitly to silence this warning, or \"\n            \"correct the type of the variables.\".format(e.from_, e.to),\n            DeprecationWarning,\n            stacklevel=2\n        )\n        return ufunc(*args, out=out, casting=\"unsafe\", **kwargs)\n\ndef _clip(a, min=None, max=None, out=None, *, casting=None, **kwargs):\n    if min is None and max is None:\n        raise ValueError(\"One of max or min must be given\")\n\n    # Numpy 1.17.0, 2019-02-24\n    # This deprecation probably incurs a substantial slowdown for small arrays,\n    # it will be good to get rid of it.\n    if not _clip_dep_is_byte_swapped(a) and not _clip_dep_is_byte_swapped(out):\n        using_deprecated_nan = False\n        if _clip_dep_is_scalar_nan(min):\n            min = -float('inf')\n            using_deprecated_nan = True\n        if _clip_dep_is_scalar_nan(max):\n            max = float('inf')\n            using_deprecated_nan = True\n        if using_deprecated_nan:\n            warnings.warn(\n                \"Passing `np.nan` to mean no clipping in np.clip has always \"\n                \"been unreliable, and is now deprecated. \"\n                \"In future, this will always return nan, like it already does \"\n                \"when min or max are arrays that contain nan. \"\n                \"To skip a bound, pass either None or an np.inf of an \"\n                \"appropriate sign.\",\n                DeprecationWarning,\n                stacklevel=2\n            )\n\n    if min is None:\n        return _clip_dep_invoke_with_casting(\n            um.minimum, a, max, out=out, casting=casting, **kwargs)\n    elif max is None:\n        return _clip_dep_invoke_with_casting(\n            um.maximum, a, min, out=out, casting=casting, **kwargs)\n    else:\n        return _clip_dep_invoke_with_casting(\n            um.clip, a, min, max, out=out, casting=casting, **kwargs)\n\ndef _mean(a, axis=None, dtype=None, out=None, keepdims=False, *, where=True):\n    arr = asanyarray(a)\n\n    is_float16_result = False\n\n    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)\n    if rcount == 0 if where is True else umr_any(rcount == 0, axis=None):\n        warnings.warn(\"Mean of empty slice.\", RuntimeWarning, stacklevel=2)\n\n    # Cast bool, unsigned int, and int to float64 by default\n    if dtype is None:\n        if issubclass(arr.dtype.type, (nt.integer, nt.bool_)):\n            dtype = mu.dtype('f8')\n        elif issubclass(arr.dtype.type, nt.float16):\n            dtype = mu.dtype('f4')\n            is_float16_result = True\n\n    ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n    if isinstance(ret, mu.ndarray):\n        ret = um.true_divide(\n                ret, rcount, out=ret, casting='unsafe', subok=False)\n        if is_float16_result and out is None:\n            ret = arr.dtype.type(ret)\n    elif hasattr(ret, 'dtype'):\n        if is_float16_result:\n            ret = arr.dtype.type(ret / rcount)\n        else:\n            ret = ret.dtype.type(ret / rcount)\n    else:\n        ret = ret / rcount\n\n    return ret\n\ndef _var(a, axis=None, dtype=None, out=None, ddof=0, keepdims=False, *,\n         where=True):\n    arr = asanyarray(a)\n\n    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)\n    # Make this warning show up on top.\n    if ddof >= rcount if where is True else umr_any(ddof >= rcount, axis=None):\n        warnings.warn(\"Degrees of freedom <= 0 for slice\", RuntimeWarning,\n                      stacklevel=2)\n\n    # Cast bool, unsigned int, and int to float64 by default\n    if dtype is None and issubclass(arr.dtype.type, (nt.integer, nt.bool_)):\n        dtype = mu.dtype('f8')\n\n    # Compute the mean.\n    # Note that if dtype is not of inexact type then arraymean will\n    # not be either.\n    arrmean = umr_sum(arr, axis, dtype, keepdims=True, where=where)\n    # The shape of rcount has to match arrmean to not change the shape of out\n    # in broadcasting. Otherwise, it cannot be stored back to arrmean.\n    if rcount.ndim == 0:\n        # fast-path for default case when where is True\n        div = rcount\n    else:\n        # matching rcount to arrmean when where is specified as array\n        div = rcount.reshape(arrmean.shape)\n    if isinstance(arrmean, mu.ndarray):\n        arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n                                 subok=False)\n    else:\n        arrmean = arrmean.dtype.type(arrmean / rcount)\n\n    # Compute sum of squared deviations from mean\n    # Note that x may not be inexact and that we need it to be an array,\n    # not a scalar.\n    x = asanyarray(arr - arrmean)\n\n    if issubclass(arr.dtype.type, (nt.floating, nt.integer)):\n        x = um.multiply(x, x, out=x)\n    # Fast-paths for built-in complex types\n    elif x.dtype in _complex_to_float:\n        xv = x.view(dtype=(_complex_to_float[x.dtype], (2,)))\n        um.multiply(xv, xv, out=xv)\n        x = um.add(xv[..., 0], xv[..., 1], out=x.real).real\n    # Most general case; includes handling object arrays containing imaginary\n    # numbers and complex types with non-native byteorder\n    else:\n        x = um.multiply(x, um.conjugate(x), out=x).real\n\n    ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n\n    # Compute degrees of freedom and make sure it is not negative.\n    rcount = um.maximum(rcount - ddof, 0)\n\n    # divide by degrees of freedom\n    if isinstance(ret, mu.ndarray):\n        ret = um.true_divide(\n                ret, rcount, out=ret, casting='unsafe', subok=False)\n    elif hasattr(ret, 'dtype'):\n        ret = ret.dtype.type(ret / rcount)\n    else:\n        ret = ret / rcount\n\n    return ret\n\ndef _std(a, axis=None, dtype=None, out=None, ddof=0, keepdims=False, *,\n         where=True):\n    ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n               keepdims=keepdims, where=where)\n\n    if isinstance(ret, mu.ndarray):\n        ret = um.sqrt(ret, out=ret)\n    elif hasattr(ret, 'dtype'):\n        ret = ret.dtype.type(um.sqrt(ret))\n    else:\n        ret = um.sqrt(ret)\n\n    return ret\n\ndef _ptp(a, axis=None, out=None, keepdims=False):\n    return um.subtract(\n        umr_maximum(a, axis, None, out, keepdims),\n        umr_minimum(a, axis, None, None, keepdims),\n        out\n    )\n\ndef _dump(self, file, protocol=2):\n    if hasattr(file, 'write'):\n        ctx = nullcontext(file)\n    else:\n        ctx = open(os_fspath(file), \"wb\")\n    with ctx as f:\n        pickle.dump(self, f, protocol=protocol)\n\ndef _dumps(self, protocol=2):\n    return pickle.dumps(self, protocol=protocol)\n", 290], "/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/random.py": ["\"\"\"Random variable generators.\n\n    bytes\n    -----\n           uniform bytes (values between 0 and 255)\n\n    integers\n    --------\n           uniform within range\n\n    sequences\n    ---------\n           pick random element\n           pick random sample\n           pick weighted random sample\n           generate random permutation\n\n    distributions on the real line:\n    ------------------------------\n           uniform\n           triangular\n           normal (Gaussian)\n           lognormal\n           negative exponential\n           gamma\n           beta\n           pareto\n           Weibull\n\n    distributions on the circle (angles 0 to 2pi)\n    ---------------------------------------------\n           circular uniform\n           von Mises\n\nGeneral notes on the underlying Mersenne Twister core generator:\n\n* The period is 2**19937-1.\n* It is one of the most extensively tested generators in existence.\n* The random() method is implemented in C, executes in a single Python step,\n  and is, therefore, threadsafe.\n\n\"\"\"\n\n# Translated by Guido van Rossum from C source provided by\n# Adrian Baddeley.  Adapted by Raymond Hettinger for use with\n# the Mersenne Twister  and os.urandom() core generators.\n\nfrom warnings import warn as _warn\nfrom math import log as _log, exp as _exp, pi as _pi, e as _e, ceil as _ceil\nfrom math import sqrt as _sqrt, acos as _acos, cos as _cos, sin as _sin\nfrom math import tau as TWOPI, floor as _floor\nfrom os import urandom as _urandom\nfrom _collections_abc import Set as _Set, Sequence as _Sequence\nfrom itertools import accumulate as _accumulate, repeat as _repeat\nfrom bisect import bisect as _bisect\nimport os as _os\nimport _random\n\ntry:\n    # hashlib is pretty heavy to load, try lean internal module first\n    from _sha512 import sha512 as _sha512\nexcept ImportError:\n    # fallback to official implementation\n    from hashlib import sha512 as _sha512\n\n__all__ = [\n    \"Random\",\n    \"SystemRandom\",\n    \"betavariate\",\n    \"choice\",\n    \"choices\",\n    \"expovariate\",\n    \"gammavariate\",\n    \"gauss\",\n    \"getrandbits\",\n    \"getstate\",\n    \"lognormvariate\",\n    \"normalvariate\",\n    \"paretovariate\",\n    \"randbytes\",\n    \"randint\",\n    \"random\",\n    \"randrange\",\n    \"sample\",\n    \"seed\",\n    \"setstate\",\n    \"shuffle\",\n    \"triangular\",\n    \"uniform\",\n    \"vonmisesvariate\",\n    \"weibullvariate\",\n]\n\nNV_MAGICCONST = 4 * _exp(-0.5) / _sqrt(2.0)\nLOG4 = _log(4.0)\nSG_MAGICCONST = 1.0 + _log(4.5)\nBPF = 53        # Number of bits in a float\nRECIP_BPF = 2 ** -BPF\n\n\nclass Random(_random.Random):\n    \"\"\"Random number generator base class used by bound module functions.\n\n    Used to instantiate instances of Random to get generators that don't\n    share state.\n\n    Class Random can also be subclassed if you want to use a different basic\n    generator of your own devising: in that case, override the following\n    methods:  random(), seed(), getstate(), and setstate().\n    Optionally, implement a getrandbits() method so that randrange()\n    can cover arbitrarily large ranges.\n\n    \"\"\"\n\n    VERSION = 3     # used by getstate/setstate\n\n    def __init__(self, x=None):\n        \"\"\"Initialize an instance.\n\n        Optional argument x controls seeding, as for Random.seed().\n        \"\"\"\n\n        self.seed(x)\n        self.gauss_next = None\n\n    def seed(self, a=None, version=2):\n        \"\"\"Initialize internal state from a seed.\n\n        The only supported seed types are None, int, float,\n        str, bytes, and bytearray.\n\n        None or no argument seeds from current time or from an operating\n        system specific randomness source if available.\n\n        If *a* is an int, all bits are used.\n\n        For version 2 (the default), all of the bits are used if *a* is a str,\n        bytes, or bytearray.  For version 1 (provided for reproducing random\n        sequences from older versions of Python), the algorithm for str and\n        bytes generates a narrower range of seeds.\n\n        \"\"\"\n\n        if version == 1 and isinstance(a, (str, bytes)):\n            a = a.decode('latin-1') if isinstance(a, bytes) else a\n            x = ord(a[0]) << 7 if a else 0\n            for c in map(ord, a):\n                x = ((1000003 * x) ^ c) & 0xFFFFFFFFFFFFFFFF\n            x ^= len(a)\n            a = -2 if x == -1 else x\n\n        elif version == 2 and isinstance(a, (str, bytes, bytearray)):\n            if isinstance(a, str):\n                a = a.encode()\n            a = int.from_bytes(a + _sha512(a).digest(), 'big')\n\n        elif not isinstance(a, (type(None), int, float, str, bytes, bytearray)):\n            _warn('Seeding based on hashing is deprecated\\n'\n                  'since Python 3.9 and will be removed in a subsequent '\n                  'version. The only \\n'\n                  'supported seed types are: None, '\n                  'int, float, str, bytes, and bytearray.',\n                  DeprecationWarning, 2)\n\n        super().seed(a)\n        self.gauss_next = None\n\n    def getstate(self):\n        \"\"\"Return internal state; can be passed to setstate() later.\"\"\"\n        return self.VERSION, super().getstate(), self.gauss_next\n\n    def setstate(self, state):\n        \"\"\"Restore internal state from object returned by getstate().\"\"\"\n        version = state[0]\n        if version == 3:\n            version, internalstate, self.gauss_next = state\n            super().setstate(internalstate)\n        elif version == 2:\n            version, internalstate, self.gauss_next = state\n            # In version 2, the state was saved as signed ints, which causes\n            #   inconsistencies between 32/64-bit systems. The state is\n            #   really unsigned 32-bit ints, so we convert negative ints from\n            #   version 2 to positive longs for version 3.\n            try:\n                internalstate = tuple(x % (2 ** 32) for x in internalstate)\n            except ValueError as e:\n                raise TypeError from e\n            super().setstate(internalstate)\n        else:\n            raise ValueError(\"state with version %s passed to \"\n                             \"Random.setstate() of version %s\" %\n                             (version, self.VERSION))\n\n\n    ## -------------------------------------------------------\n    ## ---- Methods below this point do not need to be overridden or extended\n    ## ---- when subclassing for the purpose of using a different core generator.\n\n\n    ## -------------------- pickle support  -------------------\n\n    # Issue 17489: Since __reduce__ was defined to fix #759889 this is no\n    # longer called; we leave it here because it has been here since random was\n    # rewritten back in 2001 and why risk breaking something.\n    def __getstate__(self):  # for pickle\n        return self.getstate()\n\n    def __setstate__(self, state):  # for pickle\n        self.setstate(state)\n\n    def __reduce__(self):\n        return self.__class__, (), self.getstate()\n\n\n    ## ---- internal support method for evenly distributed integers ----\n\n    def __init_subclass__(cls, /, **kwargs):\n        \"\"\"Control how subclasses generate random integers.\n\n        The algorithm a subclass can use depends on the random() and/or\n        getrandbits() implementation available to it and determines\n        whether it can generate random integers from arbitrarily large\n        ranges.\n        \"\"\"\n\n        for c in cls.__mro__:\n            if '_randbelow' in c.__dict__:\n                # just inherit it\n                break\n            if 'getrandbits' in c.__dict__:\n                cls._randbelow = cls._randbelow_with_getrandbits\n                break\n            if 'random' in c.__dict__:\n                cls._randbelow = cls._randbelow_without_getrandbits\n                break\n\n    def _randbelow_with_getrandbits(self, n):\n        \"Return a random int in the range [0,n).  Returns 0 if n==0.\"\n\n        if not n:\n            return 0\n        getrandbits = self.getrandbits\n        k = n.bit_length()  # don't use (n-1) here because n can be 1\n        r = getrandbits(k)  # 0 <= r < 2**k\n        while r >= n:\n            r = getrandbits(k)\n        return r\n\n    def _randbelow_without_getrandbits(self, n, maxsize=1<<BPF):\n        \"\"\"Return a random int in the range [0,n).  Returns 0 if n==0.\n\n        The implementation does not use getrandbits, but only random.\n        \"\"\"\n\n        random = self.random\n        if n >= maxsize:\n            _warn(\"Underlying random() generator does not supply \\n\"\n                \"enough bits to choose from a population range this large.\\n\"\n                \"To remove the range limitation, add a getrandbits() method.\")\n            return _floor(random() * n)\n        if n == 0:\n            return 0\n        rem = maxsize % n\n        limit = (maxsize - rem) / maxsize   # int(limit * maxsize) % n == 0\n        r = random()\n        while r >= limit:\n            r = random()\n        return _floor(r * maxsize) % n\n\n    _randbelow = _randbelow_with_getrandbits\n\n\n    ## --------------------------------------------------------\n    ## ---- Methods below this point generate custom distributions\n    ## ---- based on the methods defined above.  They do not\n    ## ---- directly touch the underlying generator and only\n    ## ---- access randomness through the methods:  random(),\n    ## ---- getrandbits(), or _randbelow().\n\n\n    ## -------------------- bytes methods ---------------------\n\n    def randbytes(self, n):\n        \"\"\"Generate n random bytes.\"\"\"\n        return self.getrandbits(n * 8).to_bytes(n, 'little')\n\n\n    ## -------------------- integer methods  -------------------\n\n    def randrange(self, start, stop=None, step=1):\n        \"\"\"Choose a random item from range(start, stop[, step]).\n\n        This fixes the problem with randint() which includes the\n        endpoint; in Python this is usually not what you want.\n\n        \"\"\"\n\n        # This code is a bit messy to make it fast for the\n        # common case while still doing adequate error checking.\n        istart = int(start)\n        if istart != start:\n            raise ValueError(\"non-integer arg 1 for randrange()\")\n        if stop is None:\n            if istart > 0:\n                return self._randbelow(istart)\n            raise ValueError(\"empty range for randrange()\")\n\n        # stop argument supplied.\n        istop = int(stop)\n        if istop != stop:\n            raise ValueError(\"non-integer stop for randrange()\")\n        width = istop - istart\n        if step == 1 and width > 0:\n            return istart + self._randbelow(width)\n        if step == 1:\n            raise ValueError(\"empty range for randrange() (%d, %d, %d)\" % (istart, istop, width))\n\n        # Non-unit step argument supplied.\n        istep = int(step)\n        if istep != step:\n            raise ValueError(\"non-integer step for randrange()\")\n        if istep > 0:\n            n = (width + istep - 1) // istep\n        elif istep < 0:\n            n = (width + istep + 1) // istep\n        else:\n            raise ValueError(\"zero step for randrange()\")\n\n        if n <= 0:\n            raise ValueError(\"empty range for randrange()\")\n\n        return istart + istep * self._randbelow(n)\n\n    def randint(self, a, b):\n        \"\"\"Return random integer in range [a, b], including both end points.\n        \"\"\"\n\n        return self.randrange(a, b+1)\n\n\n    ## -------------------- sequence methods  -------------------\n\n    def choice(self, seq):\n        \"\"\"Choose a random element from a non-empty sequence.\"\"\"\n        # raises IndexError if seq is empty\n        return seq[self._randbelow(len(seq))]\n\n    def shuffle(self, x, random=None):\n        \"\"\"Shuffle list x in place, and return None.\n\n        Optional argument random is a 0-argument function returning a\n        random float in [0.0, 1.0); if it is the default None, the\n        standard random.random will be used.\n\n        \"\"\"\n\n        if random is None:\n            randbelow = self._randbelow\n            for i in reversed(range(1, len(x))):\n                # pick an element in x[:i+1] with which to exchange x[i]\n                j = randbelow(i + 1)\n                x[i], x[j] = x[j], x[i]\n        else:\n            _warn('The *random* parameter to shuffle() has been deprecated\\n'\n                  'since Python 3.9 and will be removed in a subsequent '\n                  'version.',\n                  DeprecationWarning, 2)\n            floor = _floor\n            for i in reversed(range(1, len(x))):\n                # pick an element in x[:i+1] with which to exchange x[i]\n                j = floor(random() * (i + 1))\n                x[i], x[j] = x[j], x[i]\n\n    def sample(self, population, k, *, counts=None):\n        \"\"\"Chooses k unique random elements from a population sequence or set.\n\n        Returns a new list containing elements from the population while\n        leaving the original population unchanged.  The resulting list is\n        in selection order so that all sub-slices will also be valid random\n        samples.  This allows raffle winners (the sample) to be partitioned\n        into grand prize and second place winners (the subslices).\n\n        Members of the population need not be hashable or unique.  If the\n        population contains repeats, then each occurrence is a possible\n        selection in the sample.\n\n        Repeated elements can be specified one at a time or with the optional\n        counts parameter.  For example:\n\n            sample(['red', 'blue'], counts=[4, 2], k=5)\n\n        is equivalent to:\n\n            sample(['red', 'red', 'red', 'red', 'blue', 'blue'], k=5)\n\n        To choose a sample from a range of integers, use range() for the\n        population argument.  This is especially fast and space efficient\n        for sampling from a large population:\n\n            sample(range(10000000), 60)\n\n        \"\"\"\n\n        # Sampling without replacement entails tracking either potential\n        # selections (the pool) in a list or previous selections in a set.\n\n        # When the number of selections is small compared to the\n        # population, then tracking selections is efficient, requiring\n        # only a small set and an occasional reselection.  For\n        # a larger number of selections, the pool tracking method is\n        # preferred since the list takes less space than the\n        # set and it doesn't suffer from frequent reselections.\n\n        # The number of calls to _randbelow() is kept at or near k, the\n        # theoretical minimum.  This is important because running time\n        # is dominated by _randbelow() and because it extracts the\n        # least entropy from the underlying random number generators.\n\n        # Memory requirements are kept to the smaller of a k-length\n        # set or an n-length list.\n\n        # There are other sampling algorithms that do not require\n        # auxiliary memory, but they were rejected because they made\n        # too many calls to _randbelow(), making them slower and\n        # causing them to eat more entropy than necessary.\n\n        if isinstance(population, _Set):\n            _warn('Sampling from a set deprecated\\n'\n                  'since Python 3.9 and will be removed in a subsequent version.',\n                  DeprecationWarning, 2)\n            population = tuple(population)\n        if not isinstance(population, _Sequence):\n            raise TypeError(\"Population must be a sequence.  For dicts or sets, use sorted(d).\")\n        n = len(population)\n        if counts is not None:\n            cum_counts = list(_accumulate(counts))\n            if len(cum_counts) != n:\n                raise ValueError('The number of counts does not match the population')\n            total = cum_counts.pop()\n            if not isinstance(total, int):\n                raise TypeError('Counts must be integers')\n            if total <= 0:\n                raise ValueError('Total of counts must be greater than zero')\n            selections = self.sample(range(total), k=k)\n            bisect = _bisect\n            return [population[bisect(cum_counts, s)] for s in selections]\n        randbelow = self._randbelow\n        if not 0 <= k <= n:\n            raise ValueError(\"Sample larger than population or is negative\")\n        result = [None] * k\n        setsize = 21        # size of a small set minus size of an empty list\n        if k > 5:\n            setsize += 4 ** _ceil(_log(k * 3, 4))  # table size for big sets\n        if n <= setsize:\n            # An n-length list is smaller than a k-length set.\n            # Invariant:  non-selected at pool[0 : n-i]\n            pool = list(population)\n            for i in range(k):\n                j = randbelow(n - i)\n                result[i] = pool[j]\n                pool[j] = pool[n - i - 1]  # move non-selected item into vacancy\n        else:\n            selected = set()\n            selected_add = selected.add\n            for i in range(k):\n                j = randbelow(n)\n                while j in selected:\n                    j = randbelow(n)\n                selected_add(j)\n                result[i] = population[j]\n        return result\n\n    def choices(self, population, weights=None, *, cum_weights=None, k=1):\n        \"\"\"Return a k sized list of population elements chosen with replacement.\n\n        If the relative weights or cumulative weights are not specified,\n        the selections are made with equal probability.\n\n        \"\"\"\n        random = self.random\n        n = len(population)\n        if cum_weights is None:\n            if weights is None:\n                floor = _floor\n                n += 0.0    # convert to float for a small speed improvement\n                return [population[floor(random() * n)] for i in _repeat(None, k)]\n            try:\n                cum_weights = list(_accumulate(weights))\n            except TypeError:\n                if not isinstance(weights, int):\n                    raise\n                k = weights\n                raise TypeError(\n                    f'The number of choices must be a keyword argument: {k=}'\n                ) from None\n        elif weights is not None:\n            raise TypeError('Cannot specify both weights and cumulative weights')\n        if len(cum_weights) != n:\n            raise ValueError('The number of weights does not match the population')\n        total = cum_weights[-1] + 0.0   # convert to float\n        if total <= 0.0:\n            raise ValueError('Total of weights must be greater than zero')\n        bisect = _bisect\n        hi = n - 1\n        return [population[bisect(cum_weights, random() * total, 0, hi)]\n                for i in _repeat(None, k)]\n\n\n    ## -------------------- real-valued distributions  -------------------\n\n    def uniform(self, a, b):\n        \"Get a random number in the range [a, b) or [a, b] depending on rounding.\"\n        return a + (b - a) * self.random()\n\n    def triangular(self, low=0.0, high=1.0, mode=None):\n        \"\"\"Triangular distribution.\n\n        Continuous distribution bounded by given lower and upper limits,\n        and having a given mode value in-between.\n\n        http://en.wikipedia.org/wiki/Triangular_distribution\n\n        \"\"\"\n        u = self.random()\n        try:\n            c = 0.5 if mode is None else (mode - low) / (high - low)\n        except ZeroDivisionError:\n            return low\n        if u > c:\n            u = 1.0 - u\n            c = 1.0 - c\n            low, high = high, low\n        return low + (high - low) * _sqrt(u * c)\n\n    def normalvariate(self, mu, sigma):\n        \"\"\"Normal distribution.\n\n        mu is the mean, and sigma is the standard deviation.\n\n        \"\"\"\n        # Uses Kinderman and Monahan method. Reference: Kinderman,\n        # A.J. and Monahan, J.F., \"Computer generation of random\n        # variables using the ratio of uniform deviates\", ACM Trans\n        # Math Software, 3, (1977), pp257-260.\n\n        random = self.random\n        while True:\n            u1 = random()\n            u2 = 1.0 - random()\n            z = NV_MAGICCONST * (u1 - 0.5) / u2\n            zz = z * z / 4.0\n            if zz <= -_log(u2):\n                break\n        return mu + z * sigma\n\n    def gauss(self, mu, sigma):\n        \"\"\"Gaussian distribution.\n\n        mu is the mean, and sigma is the standard deviation.  This is\n        slightly faster than the normalvariate() function.\n\n        Not thread-safe without a lock around calls.\n\n        \"\"\"\n        # When x and y are two variables from [0, 1), uniformly\n        # distributed, then\n        #\n        #    cos(2*pi*x)*sqrt(-2*log(1-y))\n        #    sin(2*pi*x)*sqrt(-2*log(1-y))\n        #\n        # are two *independent* variables with normal distribution\n        # (mu = 0, sigma = 1).\n        # (Lambert Meertens)\n        # (corrected version; bug discovered by Mike Miller, fixed by LM)\n\n        # Multithreading note: When two threads call this function\n        # simultaneously, it is possible that they will receive the\n        # same return value.  The window is very small though.  To\n        # avoid this, you have to use a lock around all calls.  (I\n        # didn't want to slow this down in the serial case by using a\n        # lock here.)\n\n        random = self.random\n        z = self.gauss_next\n        self.gauss_next = None\n        if z is None:\n            x2pi = random() * TWOPI\n            g2rad = _sqrt(-2.0 * _log(1.0 - random()))\n            z = _cos(x2pi) * g2rad\n            self.gauss_next = _sin(x2pi) * g2rad\n\n        return mu + z * sigma\n\n    def lognormvariate(self, mu, sigma):\n        \"\"\"Log normal distribution.\n\n        If you take the natural logarithm of this distribution, you'll get a\n        normal distribution with mean mu and standard deviation sigma.\n        mu can have any value, and sigma must be greater than zero.\n\n        \"\"\"\n        return _exp(self.normalvariate(mu, sigma))\n\n    def expovariate(self, lambd):\n        \"\"\"Exponential distribution.\n\n        lambd is 1.0 divided by the desired mean.  It should be\n        nonzero.  (The parameter would be called \"lambda\", but that is\n        a reserved word in Python.)  Returned values range from 0 to\n        positive infinity if lambd is positive, and from negative\n        infinity to 0 if lambd is negative.\n\n        \"\"\"\n        # lambd: rate lambd = 1/mean\n        # ('lambda' is a Python reserved word)\n\n        # we use 1-random() instead of random() to preclude the\n        # possibility of taking the log of zero.\n        return -_log(1.0 - self.random()) / lambd\n\n    def vonmisesvariate(self, mu, kappa):\n        \"\"\"Circular data distribution.\n\n        mu is the mean angle, expressed in radians between 0 and 2*pi, and\n        kappa is the concentration parameter, which must be greater than or\n        equal to zero.  If kappa is equal to zero, this distribution reduces\n        to a uniform random angle over the range 0 to 2*pi.\n\n        \"\"\"\n        # Based upon an algorithm published in: Fisher, N.I.,\n        # \"Statistical Analysis of Circular Data\", Cambridge\n        # University Press, 1993.\n\n        # Thanks to Magnus Kessler for a correction to the\n        # implementation of step 4.\n\n        random = self.random\n        if kappa <= 1e-6:\n            return TWOPI * random()\n\n        s = 0.5 / kappa\n        r = s + _sqrt(1.0 + s * s)\n\n        while True:\n            u1 = random()\n            z = _cos(_pi * u1)\n\n            d = z / (r + z)\n            u2 = random()\n            if u2 < 1.0 - d * d or u2 <= (1.0 - d) * _exp(d):\n                break\n\n        q = 1.0 / r\n        f = (q + z) / (1.0 + q * z)\n        u3 = random()\n        if u3 > 0.5:\n            theta = (mu + _acos(f)) % TWOPI\n        else:\n            theta = (mu - _acos(f)) % TWOPI\n\n        return theta\n\n    def gammavariate(self, alpha, beta):\n        \"\"\"Gamma distribution.  Not the gamma function!\n\n        Conditions on the parameters are alpha > 0 and beta > 0.\n\n        The probability distribution function is:\n\n                    x ** (alpha - 1) * math.exp(-x / beta)\n          pdf(x) =  --------------------------------------\n                      math.gamma(alpha) * beta ** alpha\n\n        \"\"\"\n        # alpha > 0, beta > 0, mean is alpha*beta, variance is alpha*beta**2\n\n        # Warning: a few older sources define the gamma distribution in terms\n        # of alpha > -1.0\n        if alpha <= 0.0 or beta <= 0.0:\n            raise ValueError('gammavariate: alpha and beta must be > 0.0')\n\n        random = self.random\n        if alpha > 1.0:\n\n            # Uses R.C.H. Cheng, \"The generation of Gamma\n            # variables with non-integral shape parameters\",\n            # Applied Statistics, (1977), 26, No. 1, p71-74\n\n            ainv = _sqrt(2.0 * alpha - 1.0)\n            bbb = alpha - LOG4\n            ccc = alpha + ainv\n\n            while 1:\n                u1 = random()\n                if not 1e-7 < u1 < 0.9999999:\n                    continue\n                u2 = 1.0 - random()\n                v = _log(u1 / (1.0 - u1)) / ainv\n                x = alpha * _exp(v)\n                z = u1 * u1 * u2\n                r = bbb + ccc * v - x\n                if r + SG_MAGICCONST - 4.5 * z >= 0.0 or r >= _log(z):\n                    return x * beta\n\n        elif alpha == 1.0:\n            # expovariate(1/beta)\n            return -_log(1.0 - random()) * beta\n\n        else:\n            # alpha is between 0 and 1 (exclusive)\n            # Uses ALGORITHM GS of Statistical Computing - Kennedy & Gentle\n            while True:\n                u = random()\n                b = (_e + alpha) / _e\n                p = b * u\n                if p <= 1.0:\n                    x = p ** (1.0 / alpha)\n                else:\n                    x = -_log((b - p) / alpha)\n                u1 = random()\n                if p > 1.0:\n                    if u1 <= x ** (alpha - 1.0):\n                        break\n                elif u1 <= _exp(-x):\n                    break\n            return x * beta\n\n    def betavariate(self, alpha, beta):\n        \"\"\"Beta distribution.\n\n        Conditions on the parameters are alpha > 0 and beta > 0.\n        Returned values range between 0 and 1.\n\n        \"\"\"\n        ## See\n        ## http://mail.python.org/pipermail/python-bugs-list/2001-January/003752.html\n        ## for Ivan Frohne's insightful analysis of why the original implementation:\n        ##\n        ##    def betavariate(self, alpha, beta):\n        ##        # Discrete Event Simulation in C, pp 87-88.\n        ##\n        ##        y = self.expovariate(alpha)\n        ##        z = self.expovariate(1.0/beta)\n        ##        return z/(y+z)\n        ##\n        ## was dead wrong, and how it probably got that way.\n\n        # This version due to Janne Sinkkonen, and matches all the std\n        # texts (e.g., Knuth Vol 2 Ed 3 pg 134 \"the beta distribution\").\n        y = self.gammavariate(alpha, 1.0)\n        if y:\n            return y / (y + self.gammavariate(beta, 1.0))\n        return 0.0\n\n    def paretovariate(self, alpha):\n        \"\"\"Pareto distribution.  alpha is the shape parameter.\"\"\"\n        # Jain, pg. 495\n\n        u = 1.0 - self.random()\n        return 1.0 / u ** (1.0 / alpha)\n\n    def weibullvariate(self, alpha, beta):\n        \"\"\"Weibull distribution.\n\n        alpha is the scale parameter and beta is the shape parameter.\n\n        \"\"\"\n        # Jain, pg. 499; bug fix courtesy Bill Arms\n\n        u = 1.0 - self.random()\n        return alpha * (-_log(u)) ** (1.0 / beta)\n\n\n## ------------------------------------------------------------------\n## --------------- Operating System Random Source  ------------------\n\n\nclass SystemRandom(Random):\n    \"\"\"Alternate random number generator using sources provided\n    by the operating system (such as /dev/urandom on Unix or\n    CryptGenRandom on Windows).\n\n     Not available on all systems (see os.urandom() for details).\n\n    \"\"\"\n\n    def random(self):\n        \"\"\"Get the next random number in the range [0.0, 1.0).\"\"\"\n        return (int.from_bytes(_urandom(7), 'big') >> 3) * RECIP_BPF\n\n    def getrandbits(self, k):\n        \"\"\"getrandbits(k) -> x.  Generates an int with k random bits.\"\"\"\n        if k < 0:\n            raise ValueError('number of bits must be non-negative')\n        numbytes = (k + 7) // 8                       # bits / 8 and rounded up\n        x = int.from_bytes(_urandom(numbytes), 'big')\n        return x >> (numbytes * 8 - k)                # trim excess bits\n\n    def randbytes(self, n):\n        \"\"\"Generate n random bytes.\"\"\"\n        # os.urandom(n) fails with ValueError for n < 0\n        # and returns an empty bytes string for n == 0.\n        return _urandom(n)\n\n    def seed(self, *args, **kwds):\n        \"Stub method.  Not used for a system random number generator.\"\n        return None\n\n    def _notimplemented(self, *args, **kwds):\n        \"Method should not be called for a system random number generator.\"\n        raise NotImplementedError('System entropy source does not have state.')\n    getstate = setstate = _notimplemented\n\n\n# ----------------------------------------------------------------------\n# Create one instance, seeded from current time, and export its methods\n# as module-level functions.  The functions share state across all uses\n# (both in the user's code and in the Python libraries), but that's fine\n# for most programs and is easier for the casual user than making them\n# instantiate their own Random() instance.\n\n_inst = Random()\nseed = _inst.seed\nrandom = _inst.random\nuniform = _inst.uniform\ntriangular = _inst.triangular\nrandint = _inst.randint\nchoice = _inst.choice\nrandrange = _inst.randrange\nsample = _inst.sample\nshuffle = _inst.shuffle\nchoices = _inst.choices\nnormalvariate = _inst.normalvariate\nlognormvariate = _inst.lognormvariate\nexpovariate = _inst.expovariate\nvonmisesvariate = _inst.vonmisesvariate\ngammavariate = _inst.gammavariate\ngauss = _inst.gauss\nbetavariate = _inst.betavariate\nparetovariate = _inst.paretovariate\nweibullvariate = _inst.weibullvariate\ngetstate = _inst.getstate\nsetstate = _inst.setstate\ngetrandbits = _inst.getrandbits\nrandbytes = _inst.randbytes\n\n\n## ------------------------------------------------------\n## ----------------- test program -----------------------\n\ndef _test_generator(n, func, args):\n    from statistics import stdev, fmean as mean\n    from time import perf_counter\n\n    t0 = perf_counter()\n    data = [func(*args) for i in range(n)]\n    t1 = perf_counter()\n\n    xbar = mean(data)\n    sigma = stdev(data, xbar)\n    low = min(data)\n    high = max(data)\n\n    print(f'{t1 - t0:.3f} sec, {n} times {func.__name__}')\n    print('avg %g, stddev %g, min %g, max %g\\n' % (xbar, sigma, low, high))\n\n\ndef _test(N=2000):\n    _test_generator(N, random, ())\n    _test_generator(N, normalvariate, (0.0, 1.0))\n    _test_generator(N, lognormvariate, (0.0, 1.0))\n    _test_generator(N, vonmisesvariate, (0.0, 1.0))\n    _test_generator(N, gammavariate, (0.01, 1.0))\n    _test_generator(N, gammavariate, (0.1, 1.0))\n    _test_generator(N, gammavariate, (0.1, 2.0))\n    _test_generator(N, gammavariate, (0.5, 1.0))\n    _test_generator(N, gammavariate, (0.9, 1.0))\n    _test_generator(N, gammavariate, (1.0, 1.0))\n    _test_generator(N, gammavariate, (2.0, 1.0))\n    _test_generator(N, gammavariate, (20.0, 1.0))\n    _test_generator(N, gammavariate, (200.0, 1.0))\n    _test_generator(N, gauss, (0.0, 1.0))\n    _test_generator(N, betavariate, (3.0, 3.0))\n    _test_generator(N, triangular, (0.0, 1.0, 1.0 / 3.0))\n\n\n## ------------------------------------------------------\n## ------------------ fork support  ---------------------\n\nif hasattr(_os, \"fork\"):\n    _os.register_at_fork(after_in_child=_inst.seed)\n\n\nif __name__ == '__main__':\n    _test()\n", 895], "/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/multiarray.py": ["\"\"\"\nCreate the numpy.core.multiarray namespace for backward compatibility. In v1.16\nthe multiarray and umath c-extension modules were merged into a single\n_multiarray_umath extension module. So we replicate the old namespace\nby importing from the extension module.\n\n\"\"\"\n\nimport functools\nimport warnings\n\nfrom . import overrides\nfrom . import _multiarray_umath\nfrom ._multiarray_umath import *  # noqa: F403\n# These imports are needed for backward compatibility,\n# do not change them. issue gh-15518\n# _get_ndarray_c_version is semi-public, on purpose not added to __all__\nfrom ._multiarray_umath import (\n    _fastCopyAndTranspose, _flagdict, _insert, _reconstruct, _vec_string,\n    _ARRAY_API, _monotonicity, _get_ndarray_c_version, _set_madvise_hugepage,\n    )\n\n__all__ = [\n    '_ARRAY_API', 'ALLOW_THREADS', 'BUFSIZE', 'CLIP', 'DATETIMEUNITS',\n    'ITEM_HASOBJECT', 'ITEM_IS_POINTER', 'LIST_PICKLE', 'MAXDIMS',\n    'MAY_SHARE_BOUNDS', 'MAY_SHARE_EXACT', 'NEEDS_INIT', 'NEEDS_PYAPI',\n    'RAISE', 'USE_GETITEM', 'USE_SETITEM', 'WRAP', '_fastCopyAndTranspose',\n    '_flagdict', '_insert', '_reconstruct', '_vec_string', '_monotonicity',\n    'add_docstring', 'arange', 'array', 'asarray', 'asanyarray',\n    'ascontiguousarray', 'asfortranarray', 'bincount', 'broadcast',\n    'busday_count', 'busday_offset', 'busdaycalendar', 'can_cast',\n    'compare_chararrays', 'concatenate', 'copyto', 'correlate', 'correlate2',\n    'count_nonzero', 'c_einsum', 'datetime_as_string', 'datetime_data',\n    'digitize', 'dot', 'dragon4_positional', 'dragon4_scientific', 'dtype',\n    'empty', 'empty_like', 'error', 'flagsobj', 'flatiter', 'format_longfloat',\n    'frombuffer', 'fromfile', 'fromiter', 'fromstring', 'inner',\n    'interp', 'interp_complex', 'is_busday', 'lexsort',\n    'matmul', 'may_share_memory', 'min_scalar_type', 'ndarray', 'nditer',\n    'nested_iters', 'normalize_axis_index', 'packbits',\n    'promote_types', 'putmask', 'ravel_multi_index', 'result_type', 'scalar',\n    'set_datetimeparse_function', 'set_legacy_print_mode', 'set_numeric_ops',\n    'set_string_function', 'set_typeDict', 'shares_memory',\n    'tracemalloc_domain', 'typeinfo', 'unpackbits', 'unravel_index', 'vdot',\n    'where', 'zeros']\n\n# For backward compatibility, make sure pickle imports these functions from here\n_reconstruct.__module__ = 'numpy.core.multiarray'\nscalar.__module__ = 'numpy.core.multiarray'\n\n\narange.__module__ = 'numpy'\narray.__module__ = 'numpy'\nasarray.__module__ = 'numpy'\nasanyarray.__module__ = 'numpy'\nascontiguousarray.__module__ = 'numpy'\nasfortranarray.__module__ = 'numpy'\ndatetime_data.__module__ = 'numpy'\nempty.__module__ = 'numpy'\nfrombuffer.__module__ = 'numpy'\nfromfile.__module__ = 'numpy'\nfromiter.__module__ = 'numpy'\nfrompyfunc.__module__ = 'numpy'\nfromstring.__module__ = 'numpy'\ngeterrobj.__module__ = 'numpy'\nmay_share_memory.__module__ = 'numpy'\nnested_iters.__module__ = 'numpy'\npromote_types.__module__ = 'numpy'\nset_numeric_ops.__module__ = 'numpy'\nseterrobj.__module__ = 'numpy'\nzeros.__module__ = 'numpy'\n\n\n# We can't verify dispatcher signatures because NumPy's C functions don't\n# support introspection.\narray_function_from_c_func_and_dispatcher = functools.partial(\n    overrides.array_function_from_dispatcher,\n    module='numpy', docs_from_dispatcher=True, verify=False)\n\n\n@array_function_from_c_func_and_dispatcher(_multiarray_umath.empty_like)\ndef empty_like(prototype, dtype=None, order=None, subok=None, shape=None):\n    \"\"\"\n    empty_like(prototype, dtype=None, order='K', subok=True, shape=None)\n\n    Return a new array with the same shape and type as a given array.\n\n    Parameters\n    ----------\n    prototype : array_like\n        The shape and data-type of `prototype` define these same attributes\n        of the returned array.\n    dtype : data-type, optional\n        Overrides the data type of the result.\n\n        .. versionadded:: 1.6.0\n    order : {'C', 'F', 'A', or 'K'}, optional\n        Overrides the memory layout of the result. 'C' means C-order,\n        'F' means F-order, 'A' means 'F' if `prototype` is Fortran\n        contiguous, 'C' otherwise. 'K' means match the layout of `prototype`\n        as closely as possible.\n\n        .. versionadded:: 1.6.0\n    subok : bool, optional.\n        If True, then the newly created array will use the sub-class\n        type of `prototype`, otherwise it will be a base-class array. Defaults\n        to True.\n    shape : int or sequence of ints, optional.\n        Overrides the shape of the result. If order='K' and the number of\n        dimensions is unchanged, will try to keep order, otherwise,\n        order='C' is implied.\n\n        .. versionadded:: 1.17.0\n\n    Returns\n    -------\n    out : ndarray\n        Array of uninitialized (arbitrary) data with the same\n        shape and type as `prototype`.\n\n    See Also\n    --------\n    ones_like : Return an array of ones with shape and type of input.\n    zeros_like : Return an array of zeros with shape and type of input.\n    full_like : Return a new array with shape of input filled with value.\n    empty : Return a new uninitialized array.\n\n    Notes\n    -----\n    This function does *not* initialize the returned array; to do that use\n    `zeros_like` or `ones_like` instead.  It may be marginally faster than\n    the functions that do set the array values.\n\n    Examples\n    --------\n    >>> a = ([1,2,3], [4,5,6])                         # a is array-like\n    >>> np.empty_like(a)\n    array([[-1073741821, -1073741821,           3],    # uninitialized\n           [          0,           0, -1073741821]])\n    >>> a = np.array([[1., 2., 3.],[4.,5.,6.]])\n    >>> np.empty_like(a)\n    array([[ -2.00000715e+000,   1.48219694e-323,  -2.00000572e+000], # uninitialized\n           [  4.38791518e-305,  -2.00000715e+000,   4.17269252e-309]])\n\n    \"\"\"\n    return (prototype,)\n\n\n@array_function_from_c_func_and_dispatcher(_multiarray_umath.concatenate)\ndef concatenate(arrays, axis=None, out=None, *, dtype=None, casting=None):\n    \"\"\"\n    concatenate((a1, a2, ...), axis=0, out=None, dtype=None, casting=\"same_kind\")\n\n    Join a sequence of arrays along an existing axis.\n\n    Parameters\n    ----------\n    a1, a2, ... : sequence of array_like\n        The arrays must have the same shape, except in the dimension\n        corresponding to `axis` (the first, by default).\n    axis : int, optional\n        The axis along which the arrays will be joined.  If axis is None,\n        arrays are flattened before use.  Default is 0.\n    out : ndarray, optional\n        If provided, the destination to place the result. The shape must be\n        correct, matching that of what concatenate would have returned if no\n        out argument were specified.\n    dtype : str or dtype\n        If provided, the destination array will have this dtype. Cannot be\n        provided together with `out`.\n\n        .. versionadded:: 1.20.0\n\n    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n        Controls what kind of data casting may occur. Defaults to 'same_kind'.\n\n        .. versionadded:: 1.20.0\n\n    Returns\n    -------\n    res : ndarray\n        The concatenated array.\n\n    See Also\n    --------\n    ma.concatenate : Concatenate function that preserves input masks.\n    array_split : Split an array into multiple sub-arrays of equal or\n                  near-equal size.\n    split : Split array into a list of multiple sub-arrays of equal size.\n    hsplit : Split array into multiple sub-arrays horizontally (column wise).\n    vsplit : Split array into multiple sub-arrays vertically (row wise).\n    dsplit : Split array into multiple sub-arrays along the 3rd axis (depth).\n    stack : Stack a sequence of arrays along a new axis.\n    block : Assemble arrays from blocks.\n    hstack : Stack arrays in sequence horizontally (column wise).\n    vstack : Stack arrays in sequence vertically (row wise).\n    dstack : Stack arrays in sequence depth wise (along third dimension).\n    column_stack : Stack 1-D arrays as columns into a 2-D array.\n\n    Notes\n    -----\n    When one or more of the arrays to be concatenated is a MaskedArray,\n    this function will return a MaskedArray object instead of an ndarray,\n    but the input masks are *not* preserved. In cases where a MaskedArray\n    is expected as input, use the ma.concatenate function from the masked\n    array module instead.\n\n    Examples\n    --------\n    >>> a = np.array([[1, 2], [3, 4]])\n    >>> b = np.array([[5, 6]])\n    >>> np.concatenate((a, b), axis=0)\n    array([[1, 2],\n           [3, 4],\n           [5, 6]])\n    >>> np.concatenate((a, b.T), axis=1)\n    array([[1, 2, 5],\n           [3, 4, 6]])\n    >>> np.concatenate((a, b), axis=None)\n    array([1, 2, 3, 4, 5, 6])\n\n    This function will not preserve masking of MaskedArray inputs.\n\n    >>> a = np.ma.arange(3)\n    >>> a[1] = np.ma.masked\n    >>> b = np.arange(2, 5)\n    >>> a\n    masked_array(data=[0, --, 2],\n                 mask=[False,  True, False],\n           fill_value=999999)\n    >>> b\n    array([2, 3, 4])\n    >>> np.concatenate([a, b])\n    masked_array(data=[0, 1, 2, 2, 3, 4],\n                 mask=False,\n           fill_value=999999)\n    >>> np.ma.concatenate([a, b])\n    masked_array(data=[0, --, 2, 2, 3, 4],\n                 mask=[False,  True, False, False, False, False],\n           fill_value=999999)\n\n    \"\"\"\n    if out is not None:\n        # optimize for the typical case where only arrays is provided\n        arrays = list(arrays)\n        arrays.append(out)\n    return arrays\n\n\n@array_function_from_c_func_and_dispatcher(_multiarray_umath.inner)\ndef inner(a, b):\n    \"\"\"\n    inner(a, b)\n\n    Inner product of two arrays.\n\n    Ordinary inner product of vectors for 1-D arrays (without complex\n    conjugation), in higher dimensions a sum product over the last axes.\n\n    Parameters\n    ----------\n    a, b : array_like\n        If `a` and `b` are nonscalar, their last dimensions must match.\n\n    Returns\n    -------\n    out : ndarray\n        If `a` and `b` are both\n        scalars or both 1-D arrays then a scalar is returned; otherwise\n        an array is returned.\n        ``out.shape = (*a.shape[:-1], *b.shape[:-1])``\n\n    Raises\n    ------\n    ValueError\n        If both `a` and `b` are nonscalar and their last dimensions have\n        different sizes.\n\n    See Also\n    --------\n    tensordot : Sum products over arbitrary axes.\n    dot : Generalised matrix product, using second last dimension of `b`.\n    einsum : Einstein summation convention.\n\n    Notes\n    -----\n    For vectors (1-D arrays) it computes the ordinary inner-product::\n\n        np.inner(a, b) = sum(a[:]*b[:])\n\n    More generally, if `ndim(a) = r > 0` and `ndim(b) = s > 0`::\n\n        np.inner(a, b) = np.tensordot(a, b, axes=(-1,-1))\n\n    or explicitly::\n\n        np.inner(a, b)[i0,...,ir-2,j0,...,js-2]\n             = sum(a[i0,...,ir-2,:]*b[j0,...,js-2,:])\n\n    In addition `a` or `b` may be scalars, in which case::\n\n       np.inner(a,b) = a*b\n\n    Examples\n    --------\n    Ordinary inner product for vectors:\n\n    >>> a = np.array([1,2,3])\n    >>> b = np.array([0,1,0])\n    >>> np.inner(a, b)\n    2\n\n    Some multidimensional examples:\n\n    >>> a = np.arange(24).reshape((2,3,4))\n    >>> b = np.arange(4)\n    >>> c = np.inner(a, b)\n    >>> c.shape\n    (2, 3)\n    >>> c\n    array([[ 14,  38,  62],\n           [ 86, 110, 134]])\n\n    >>> a = np.arange(2).reshape((1,1,2))\n    >>> b = np.arange(6).reshape((3,2))\n    >>> c = np.inner(a, b)\n    >>> c.shape\n    (1, 1, 3)\n    >>> c\n    array([[[1, 3, 5]]])\n\n    An example where `b` is a scalar:\n\n    >>> np.inner(np.eye(2), 7)\n    array([[7., 0.],\n           [0., 7.]])\n\n    \"\"\"\n    return (a, b)\n\n\n@array_function_from_c_func_and_dispatcher(_multiarray_umath.where)\ndef where(condition, x=None, y=None):\n    \"\"\"\n    where(condition, [x, y])\n\n    Return elements chosen from `x` or `y` depending on `condition`.\n\n    .. note::\n        When only `condition` is provided, this function is a shorthand for\n        ``np.asarray(condition).nonzero()``. Using `nonzero` directly should be\n        preferred, as it behaves correctly for subclasses. The rest of this\n        documentation covers only the case where all three arguments are\n        provided.\n\n    Parameters\n    ----------\n    condition : array_like, bool\n        Where True, yield `x`, otherwise yield `y`.\n    x, y : array_like\n        Values from which to choose. `x`, `y` and `condition` need to be\n        broadcastable to some shape.\n\n    Returns\n    -------\n    out : ndarray\n        An array with elements from `x` where `condition` is True, and elements\n        from `y` elsewhere.\n\n    See Also\n    --------\n    choose\n    nonzero : The function that is called when x and y are omitted\n\n    Notes\n    -----\n    If all the arrays are 1-D, `where` is equivalent to::\n\n        [xv if c else yv\n         for c, xv, yv in zip(condition, x, y)]\n\n    Examples\n    --------\n    >>> a = np.arange(10)\n    >>> a\n    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n    >>> np.where(a < 5, a, 10*a)\n    array([ 0,  1,  2,  3,  4, 50, 60, 70, 80, 90])\n\n    This can be used on multidimensional arrays too:\n\n    >>> np.where([[True, False], [True, True]],\n    ...          [[1, 2], [3, 4]],\n    ...          [[9, 8], [7, 6]])\n    array([[1, 8],\n           [3, 4]])\n\n    The shapes of x, y, and the condition are broadcast together:\n\n    >>> x, y = np.ogrid[:3, :4]\n    >>> np.where(x < y, x, 10 + y)  # both x and 10+y are broadcast\n    array([[10,  0,  0,  0],\n           [10, 11,  1,  1],\n           [10, 11, 12,  2]])\n\n    >>> a = np.array([[0, 1, 2],\n    ...               [0, 2, 4],\n    ...               [0, 3, 6]])\n    >>> np.where(a < 4, a, -1)  # -1 is broadcast\n    array([[ 0,  1,  2],\n           [ 0,  2, -1],\n           [ 0,  3, -1]])\n    \"\"\"\n    return (condition, x, y)\n\n\n@array_function_from_c_func_and_dispatcher(_multiarray_umath.lexsort)\ndef lexsort(keys, axis=None):\n    \"\"\"\n    lexsort(keys, axis=-1)\n\n    Perform an indirect stable sort using a sequence of keys.\n\n    Given multiple sorting keys, which can be interpreted as columns in a\n    spreadsheet, lexsort returns an array of integer indices that describes\n    the sort order by multiple columns. The last key in the sequence is used\n    for the primary sort order, the second-to-last key for the secondary sort\n    order, and so on. The keys argument must be a sequence of objects that\n    can be converted to arrays of the same shape. If a 2D array is provided\n    for the keys argument, its rows are interpreted as the sorting keys and\n    sorting is according to the last row, second last row etc.\n\n    Parameters\n    ----------\n    keys : (k, N) array or tuple containing k (N,)-shaped sequences\n        The `k` different \"columns\" to be sorted.  The last column (or row if\n        `keys` is a 2D array) is the primary sort key.\n    axis : int, optional\n        Axis to be indirectly sorted.  By default, sort over the last axis.\n\n    Returns\n    -------\n    indices : (N,) ndarray of ints\n        Array of indices that sort the keys along the specified axis.\n\n    See Also\n    --------\n    argsort : Indirect sort.\n    ndarray.sort : In-place sort.\n    sort : Return a sorted copy of an array.\n\n    Examples\n    --------\n    Sort names: first by surname, then by name.\n\n    >>> surnames =    ('Hertz',    'Galilei', 'Hertz')\n    >>> first_names = ('Heinrich', 'Galileo', 'Gustav')\n    >>> ind = np.lexsort((first_names, surnames))\n    >>> ind\n    array([1, 2, 0])\n\n    >>> [surnames[i] + \", \" + first_names[i] for i in ind]\n    ['Galilei, Galileo', 'Hertz, Gustav', 'Hertz, Heinrich']\n\n    Sort two columns of numbers:\n\n    >>> a = [1,5,1,4,3,4,4] # First column\n    >>> b = [9,4,0,4,0,2,1] # Second column\n    >>> ind = np.lexsort((b,a)) # Sort by a, then by b\n    >>> ind\n    array([2, 0, 4, 6, 5, 3, 1])\n\n    >>> [(a[i],b[i]) for i in ind]\n    [(1, 0), (1, 9), (3, 0), (4, 1), (4, 2), (4, 4), (5, 4)]\n\n    Note that sorting is first according to the elements of ``a``.\n    Secondary sorting is according to the elements of ``b``.\n\n    A normal ``argsort`` would have yielded:\n\n    >>> [(a[i],b[i]) for i in np.argsort(a)]\n    [(1, 9), (1, 0), (3, 0), (4, 4), (4, 2), (4, 1), (5, 4)]\n\n    Structured arrays are sorted lexically by ``argsort``:\n\n    >>> x = np.array([(1,9), (5,4), (1,0), (4,4), (3,0), (4,2), (4,1)],\n    ...              dtype=np.dtype([('x', int), ('y', int)]))\n\n    >>> np.argsort(x) # or np.argsort(x, order=('x', 'y'))\n    array([2, 0, 4, 6, 5, 3, 1])\n\n    \"\"\"\n    if isinstance(keys, tuple):\n        return keys\n    else:\n        return (keys,)\n\n\n@array_function_from_c_func_and_dispatcher(_multiarray_umath.can_cast)\ndef can_cast(from_, to, casting=None):\n    \"\"\"\n    can_cast(from_, to, casting='safe')\n\n    Returns True if cast between data types can occur according to the\n    casting rule.  If from is a scalar or array scalar, also returns\n    True if the scalar value can be cast without overflow or truncation\n    to an integer.\n\n    Parameters\n    ----------\n    from_ : dtype, dtype specifier, scalar, or array\n        Data type, scalar, or array to cast from.\n    to : dtype or dtype specifier\n        Data type to cast to.\n    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n        Controls what kind of data casting may occur.\n\n          * 'no' means the data types should not be cast at all.\n          * 'equiv' means only byte-order changes are allowed.\n          * 'safe' means only casts which can preserve values are allowed.\n          * 'same_kind' means only safe casts or casts within a kind,\n            like float64 to float32, are allowed.\n          * 'unsafe' means any data conversions may be done.\n\n    Returns\n    -------\n    out : bool\n        True if cast can occur according to the casting rule.\n\n    Notes\n    -----\n    .. versionchanged:: 1.17.0\n       Casting between a simple data type and a structured one is possible only\n       for \"unsafe\" casting.  Casting to multiple fields is allowed, but\n       casting from multiple fields is not.\n\n    .. versionchanged:: 1.9.0\n       Casting from numeric to string types in 'safe' casting mode requires\n       that the string dtype length is long enough to store the maximum\n       integer/float value converted.\n\n    See also\n    --------\n    dtype, result_type\n\n    Examples\n    --------\n    Basic examples\n\n    >>> np.can_cast(np.int32, np.int64)\n    True\n    >>> np.can_cast(np.float64, complex)\n    True\n    >>> np.can_cast(complex, float)\n    False\n\n    >>> np.can_cast('i8', 'f8')\n    True\n    >>> np.can_cast('i8', 'f4')\n    False\n    >>> np.can_cast('i4', 'S4')\n    False\n\n    Casting scalars\n\n    >>> np.can_cast(100, 'i1')\n    True\n    >>> np.can_cast(150, 'i1')\n    False\n    >>> np.can_cast(150, 'u1')\n    True\n\n    >>> np.can_cast(3.5e100, np.float32)\n    False\n    >>> np.can_cast(1000.0, np.float32)\n    True\n\n    Array scalar checks the value, array does not\n\n    >>> np.can_cast(np.array(1000.0), np.float32)\n    True\n    >>> np.can_cast(np.array([1000.0]), np.float32)\n    False\n\n    Using the casting rules\n\n    >>> np.can_cast('i8', 'i8', 'no')\n    True\n    >>> np.can_cast('<i8', '>i8', 'no')\n    False\n\n    >>> np.can_cast('<i8', '>i8', 'equiv')\n    True\n    >>> np.can_cast('<i4', '>i8', 'equiv')\n    False\n\n    >>> np.can_cast('<i4', '>i8', 'safe')\n    True\n    >>> np.can_cast('<i8', '>i4', 'safe')\n    False\n\n    >>> np.can_cast('<i8', '>i4', 'same_kind')\n    True\n    >>> np.can_cast('<i8', '>u4', 'same_kind')\n    False\n\n    >>> np.can_cast('<i8', '>u4', 'unsafe')\n    True\n\n    \"\"\"\n    return (from_,)\n\n\n@array_function_from_c_func_and_dispatcher(_multiarray_umath.min_scalar_type)\ndef min_scalar_type(a):\n    \"\"\"\n    min_scalar_type(a)\n\n    For scalar ``a``, returns the data type with the smallest size\n    and smallest scalar kind which can hold its value.  For non-scalar\n    array ``a``, returns the vector's dtype unmodified.\n\n    Floating point values are not demoted to integers,\n    and complex values are not demoted to floats.\n\n    Parameters\n    ----------\n    a : scalar or array_like\n        The value whose minimal data type is to be found.\n\n    Returns\n    -------\n    out : dtype\n        The minimal data type.\n\n    Notes\n    -----\n    .. versionadded:: 1.6.0\n\n    See Also\n    --------\n    result_type, promote_types, dtype, can_cast\n\n    Examples\n    --------\n    >>> np.min_scalar_type(10)\n    dtype('uint8')\n\n    >>> np.min_scalar_type(-260)\n    dtype('int16')\n\n    >>> np.min_scalar_type(3.1)\n    dtype('float16')\n\n    >>> np.min_scalar_type(1e50)\n    dtype('float64')\n\n    >>> np.min_scalar_type(np.arange(4,dtype='f8'))\n    dtype('float64')\n\n    \"\"\"\n    return (a,)\n\n\n@array_function_from_c_func_and_dispatcher(_multiarray_umath.result_type)\ndef result_type(*arrays_and_dtypes):\n    \"\"\"\n    result_type(*arrays_and_dtypes)\n\n    Returns the type that results from applying the NumPy\n    type promotion rules to the arguments.\n\n    Type promotion in NumPy works similarly to the rules in languages\n    like C++, with some slight differences.  When both scalars and\n    arrays are used, the array's type takes precedence and the actual value\n    of the scalar is taken into account.\n\n    For example, calculating 3*a, where a is an array of 32-bit floats,\n    intuitively should result in a 32-bit float output.  If the 3 is a\n    32-bit integer, the NumPy rules indicate it can't convert losslessly\n    into a 32-bit float, so a 64-bit float should be the result type.\n    By examining the value of the constant, '3', we see that it fits in\n    an 8-bit integer, which can be cast losslessly into the 32-bit float.\n\n    Parameters\n    ----------\n    arrays_and_dtypes : list of arrays and dtypes\n        The operands of some operation whose result type is needed.\n\n    Returns\n    -------\n    out : dtype\n        The result type.\n\n    See also\n    --------\n    dtype, promote_types, min_scalar_type, can_cast\n\n    Notes\n    -----\n    .. versionadded:: 1.6.0\n\n    The specific algorithm used is as follows.\n\n    Categories are determined by first checking which of boolean,\n    integer (int/uint), or floating point (float/complex) the maximum\n    kind of all the arrays and the scalars are.\n\n    If there are only scalars or the maximum category of the scalars\n    is higher than the maximum category of the arrays,\n    the data types are combined with :func:`promote_types`\n    to produce the return value.\n\n    Otherwise, `min_scalar_type` is called on each array, and\n    the resulting data types are all combined with :func:`promote_types`\n    to produce the return value.\n\n    The set of int values is not a subset of the uint values for types\n    with the same number of bits, something not reflected in\n    :func:`min_scalar_type`, but handled as a special case in `result_type`.\n\n    Examples\n    --------\n    >>> np.result_type(3, np.arange(7, dtype='i1'))\n    dtype('int8')\n\n    >>> np.result_type('i4', 'c8')\n    dtype('complex128')\n\n    >>> np.result_type(3.0, -2)\n    dtype('float64')\n\n    \"\"\"\n    return arrays_and_dtypes\n\n\n@array_function_from_c_func_and_dispatcher(_multiarray_umath.dot)\ndef dot(a, b, out=None):\n    \"\"\"\n    dot(a, b, out=None)\n\n    Dot product of two arrays. Specifically,\n\n    - If both `a` and `b` are 1-D arrays, it is inner product of vectors\n      (without complex conjugation).\n\n    - If both `a` and `b` are 2-D arrays, it is matrix multiplication,\n      but using :func:`matmul` or ``a @ b`` is preferred.\n\n    - If either `a` or `b` is 0-D (scalar), it is equivalent to :func:`multiply`\n      and using ``numpy.multiply(a, b)`` or ``a * b`` is preferred.\n\n    - If `a` is an N-D array and `b` is a 1-D array, it is a sum product over\n      the last axis of `a` and `b`.\n\n    - If `a` is an N-D array and `b` is an M-D array (where ``M>=2``), it is a\n      sum product over the last axis of `a` and the second-to-last axis of `b`::\n\n        dot(a, b)[i,j,k,m] = sum(a[i,j,:] * b[k,:,m])\n\n    Parameters\n    ----------\n    a : array_like\n        First argument.\n    b : array_like\n        Second argument.\n    out : ndarray, optional\n        Output argument. This must have the exact kind that would be returned\n        if it was not used. In particular, it must have the right type, must be\n        C-contiguous, and its dtype must be the dtype that would be returned\n        for `dot(a,b)`. This is a performance feature. Therefore, if these\n        conditions are not met, an exception is raised, instead of attempting\n        to be flexible.\n\n    Returns\n    -------\n    output : ndarray\n        Returns the dot product of `a` and `b`.  If `a` and `b` are both\n        scalars or both 1-D arrays then a scalar is returned; otherwise\n        an array is returned.\n        If `out` is given, then it is returned.\n\n    Raises\n    ------\n    ValueError\n        If the last dimension of `a` is not the same size as\n        the second-to-last dimension of `b`.\n\n    See Also\n    --------\n    vdot : Complex-conjugating dot product.\n    tensordot : Sum products over arbitrary axes.\n    einsum : Einstein summation convention.\n    matmul : '@' operator as method with out parameter.\n    linalg.multi_dot : Chained dot product.\n\n    Examples\n    --------\n    >>> np.dot(3, 4)\n    12\n\n    Neither argument is complex-conjugated:\n\n    >>> np.dot([2j, 3j], [2j, 3j])\n    (-13+0j)\n\n    For 2-D arrays it is the matrix product:\n\n    >>> a = [[1, 0], [0, 1]]\n    >>> b = [[4, 1], [2, 2]]\n    >>> np.dot(a, b)\n    array([[4, 1],\n           [2, 2]])\n\n    >>> a = np.arange(3*4*5*6).reshape((3,4,5,6))\n    >>> b = np.arange(3*4*5*6)[::-1].reshape((5,4,6,3))\n    >>> np.dot(a, b)[2,3,2,1,2,2]\n    499128\n    >>> sum(a[2,3,2,:] * b[1,2,:,2])\n    499128\n\n    \"\"\"\n    return (a, b, out)\n\n\n@array_function_from_c_func_and_dispatcher(_multiarray_umath.vdot)\ndef vdot(a, b):\n    \"\"\"\n    vdot(a, b)\n\n    Return the dot product of two vectors.\n\n    The vdot(`a`, `b`) function handles complex numbers differently than\n    dot(`a`, `b`).  If the first argument is complex the complex conjugate\n    of the first argument is used for the calculation of the dot product.\n\n    Note that `vdot` handles multidimensional arrays differently than `dot`:\n    it does *not* perform a matrix product, but flattens input arguments\n    to 1-D vectors first. Consequently, it should only be used for vectors.\n\n    Parameters\n    ----------\n    a : array_like\n        If `a` is complex the complex conjugate is taken before calculation\n        of the dot product.\n    b : array_like\n        Second argument to the dot product.\n\n    Returns\n    -------\n    output : ndarray\n        Dot product of `a` and `b`.  Can be an int, float, or\n        complex depending on the types of `a` and `b`.\n\n    See Also\n    --------\n    dot : Return the dot product without using the complex conjugate of the\n          first argument.\n\n    Examples\n    --------\n    >>> a = np.array([1+2j,3+4j])\n    >>> b = np.array([5+6j,7+8j])\n    >>> np.vdot(a, b)\n    (70-8j)\n    >>> np.vdot(b, a)\n    (70+8j)\n\n    Note that higher-dimensional arrays are flattened!\n\n    >>> a = np.array([[1, 4], [5, 6]])\n    >>> b = np.array([[4, 1], [2, 2]])\n    >>> np.vdot(a, b)\n    30\n    >>> np.vdot(b, a)\n    30\n    >>> 1*4 + 4*1 + 5*2 + 6*2\n    30\n\n    \"\"\"\n    return (a, b)\n\n\n@array_function_from_c_func_and_dispatcher(_multiarray_umath.bincount)\ndef bincount(x, weights=None, minlength=None):\n    \"\"\"\n    bincount(x, weights=None, minlength=0)\n\n    Count number of occurrences of each value in array of non-negative ints.\n\n    The number of bins (of size 1) is one larger than the largest value in\n    `x`. If `minlength` is specified, there will be at least this number\n    of bins in the output array (though it will be longer if necessary,\n    depending on the contents of `x`).\n    Each bin gives the number of occurrences of its index value in `x`.\n    If `weights` is specified the input array is weighted by it, i.e. if a\n    value ``n`` is found at position ``i``, ``out[n] += weight[i]`` instead\n    of ``out[n] += 1``.\n\n    Parameters\n    ----------\n    x : array_like, 1 dimension, nonnegative ints\n        Input array.\n    weights : array_like, optional\n        Weights, array of the same shape as `x`.\n    minlength : int, optional\n        A minimum number of bins for the output array.\n\n        .. versionadded:: 1.6.0\n\n    Returns\n    -------\n    out : ndarray of ints\n        The result of binning the input array.\n        The length of `out` is equal to ``np.amax(x)+1``.\n\n    Raises\n    ------\n    ValueError\n        If the input is not 1-dimensional, or contains elements with negative\n        values, or if `minlength` is negative.\n    TypeError\n        If the type of the input is float or complex.\n\n    See Also\n    --------\n    histogram, digitize, unique\n\n    Examples\n    --------\n    >>> np.bincount(np.arange(5))\n    array([1, 1, 1, 1, 1])\n    >>> np.bincount(np.array([0, 1, 1, 3, 2, 1, 7]))\n    array([1, 3, 1, 1, 0, 0, 0, 1])\n\n    >>> x = np.array([0, 1, 1, 3, 2, 1, 7, 23])\n    >>> np.bincount(x).size == np.amax(x)+1\n    True\n\n    The input array needs to be of integer dtype, otherwise a\n    TypeError is raised:\n\n    >>> np.bincount(np.arange(5, dtype=float))\n    Traceback (most recent call last):\n      ...\n    TypeError: Cannot cast array data from dtype('float64') to dtype('int64')\n    according to the rule 'safe'\n\n    A possible use of ``bincount`` is to perform sums over\n    variable-size chunks of an array, using the ``weights`` keyword.\n\n    >>> w = np.array([0.3, 0.5, 0.2, 0.7, 1., -0.6]) # weights\n    >>> x = np.array([0, 1, 1, 2, 2, 2])\n    >>> np.bincount(x,  weights=w)\n    array([ 0.3,  0.7,  1.1])\n\n    \"\"\"\n    return (x, weights)\n\n\n@array_function_from_c_func_and_dispatcher(_multiarray_umath.ravel_multi_index)\ndef ravel_multi_index(multi_index, dims, mode=None, order=None):\n    \"\"\"\n    ravel_multi_index(multi_index, dims, mode='raise', order='C')\n\n    Converts a tuple of index arrays into an array of flat\n    indices, applying boundary modes to the multi-index.\n\n    Parameters\n    ----------\n    multi_index : tuple of array_like\n        A tuple of integer arrays, one array for each dimension.\n    dims : tuple of ints\n        The shape of array into which the indices from ``multi_index`` apply.\n    mode : {'raise', 'wrap', 'clip'}, optional\n        Specifies how out-of-bounds indices are handled.  Can specify\n        either one mode or a tuple of modes, one mode per index.\n\n        * 'raise' -- raise an error (default)\n        * 'wrap' -- wrap around\n        * 'clip' -- clip to the range\n\n        In 'clip' mode, a negative index which would normally\n        wrap will clip to 0 instead.\n    order : {'C', 'F'}, optional\n        Determines whether the multi-index should be viewed as\n        indexing in row-major (C-style) or column-major\n        (Fortran-style) order.\n\n    Returns\n    -------\n    raveled_indices : ndarray\n        An array of indices into the flattened version of an array\n        of dimensions ``dims``.\n\n    See Also\n    --------\n    unravel_index\n\n    Notes\n    -----\n    .. versionadded:: 1.6.0\n\n    Examples\n    --------\n    >>> arr = np.array([[3,6,6],[4,5,1]])\n    >>> np.ravel_multi_index(arr, (7,6))\n    array([22, 41, 37])\n    >>> np.ravel_multi_index(arr, (7,6), order='F')\n    array([31, 41, 13])\n    >>> np.ravel_multi_index(arr, (4,6), mode='clip')\n    array([22, 23, 19])\n    >>> np.ravel_multi_index(arr, (4,4), mode=('clip','wrap'))\n    array([12, 13, 13])\n\n    >>> np.ravel_multi_index((3,1,4,1), (6,7,8,9))\n    1621\n    \"\"\"\n    return multi_index\n\n\n@array_function_from_c_func_and_dispatcher(_multiarray_umath.unravel_index)\ndef unravel_index(indices, shape=None, order=None):\n    \"\"\"\n    unravel_index(indices, shape, order='C')\n\n    Converts a flat index or array of flat indices into a tuple\n    of coordinate arrays.\n\n    Parameters\n    ----------\n    indices : array_like\n        An integer array whose elements are indices into the flattened\n        version of an array of dimensions ``shape``. Before version 1.6.0,\n        this function accepted just one index value.\n    shape : tuple of ints\n        The shape of the array to use for unraveling ``indices``.\n\n        .. versionchanged:: 1.16.0\n            Renamed from ``dims`` to ``shape``.\n\n    order : {'C', 'F'}, optional\n        Determines whether the indices should be viewed as indexing in\n        row-major (C-style) or column-major (Fortran-style) order.\n\n        .. versionadded:: 1.6.0\n\n    Returns\n    -------\n    unraveled_coords : tuple of ndarray\n        Each array in the tuple has the same shape as the ``indices``\n        array.\n\n    See Also\n    --------\n    ravel_multi_index\n\n    Examples\n    --------\n    >>> np.unravel_index([22, 41, 37], (7,6))\n    (array([3, 6, 6]), array([4, 5, 1]))\n    >>> np.unravel_index([31, 41, 13], (7,6), order='F')\n    (array([3, 6, 6]), array([4, 5, 1]))\n\n    >>> np.unravel_index(1621, (6,7,8,9))\n    (3, 1, 4, 1)\n\n    \"\"\"\n    return (indices,)\n\n\n@array_function_from_c_func_and_dispatcher(_multiarray_umath.copyto)\ndef copyto(dst, src, casting=None, where=None):\n    \"\"\"\n    copyto(dst, src, casting='same_kind', where=True)\n\n    Copies values from one array to another, broadcasting as necessary.\n\n    Raises a TypeError if the `casting` rule is violated, and if\n    `where` is provided, it selects which elements to copy.\n\n    .. versionadded:: 1.7.0\n\n    Parameters\n    ----------\n    dst : ndarray\n        The array into which values are copied.\n    src : array_like\n        The array from which values are copied.\n    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n        Controls what kind of data casting may occur when copying.\n\n          * 'no' means the data types should not be cast at all.\n          * 'equiv' means only byte-order changes are allowed.\n          * 'safe' means only casts which can preserve values are allowed.\n          * 'same_kind' means only safe casts or casts within a kind,\n            like float64 to float32, are allowed.\n          * 'unsafe' means any data conversions may be done.\n    where : array_like of bool, optional\n        A boolean array which is broadcasted to match the dimensions\n        of `dst`, and selects elements to copy from `src` to `dst`\n        wherever it contains the value True.\n    \"\"\"\n    return (dst, src, where)\n\n\n@array_function_from_c_func_and_dispatcher(_multiarray_umath.putmask)\ndef putmask(a, mask, values):\n    \"\"\"\n    putmask(a, mask, values)\n\n    Changes elements of an array based on conditional and input values.\n\n    Sets ``a.flat[n] = values[n]`` for each n where ``mask.flat[n]==True``.\n\n    If `values` is not the same size as `a` and `mask` then it will repeat.\n    This gives behavior different from ``a[mask] = values``.\n\n    Parameters\n    ----------\n    a : ndarray\n        Target array.\n    mask : array_like\n        Boolean mask array. It has to be the same shape as `a`.\n    values : array_like\n        Values to put into `a` where `mask` is True. If `values` is smaller\n        than `a` it will be repeated.\n\n    See Also\n    --------\n    place, put, take, copyto\n\n    Examples\n    --------\n    >>> x = np.arange(6).reshape(2, 3)\n    >>> np.putmask(x, x>2, x**2)\n    >>> x\n    array([[ 0,  1,  2],\n           [ 9, 16, 25]])\n\n    If `values` is smaller than `a` it is repeated:\n\n    >>> x = np.arange(5)\n    >>> np.putmask(x, x>1, [-33, -44])\n    >>> x\n    array([  0,   1, -33, -44, -33])\n\n    \"\"\"\n    return (a, mask, values)\n\n\n@array_function_from_c_func_and_dispatcher(_multiarray_umath.packbits)\ndef packbits(a, axis=None, bitorder='big'):\n    \"\"\"\n    packbits(a, axis=None, bitorder='big')\n\n    Packs the elements of a binary-valued array into bits in a uint8 array.\n\n    The result is padded to full bytes by inserting zero bits at the end.\n\n    Parameters\n    ----------\n    a : array_like\n        An array of integers or booleans whose elements should be packed to\n        bits.\n    axis : int, optional\n        The dimension over which bit-packing is done.\n        ``None`` implies packing the flattened array.\n    bitorder : {'big', 'little'}, optional\n        The order of the input bits. 'big' will mimic bin(val),\n        ``[0, 0, 0, 0, 0, 0, 1, 1] => 3 = 0b00000011``, 'little' will\n        reverse the order so ``[1, 1, 0, 0, 0, 0, 0, 0] => 3``.\n        Defaults to 'big'.\n\n        .. versionadded:: 1.17.0\n\n    Returns\n    -------\n    packed : ndarray\n        Array of type uint8 whose elements represent bits corresponding to the\n        logical (0 or nonzero) value of the input elements. The shape of\n        `packed` has the same number of dimensions as the input (unless `axis`\n        is None, in which case the output is 1-D).\n\n    See Also\n    --------\n    unpackbits: Unpacks elements of a uint8 array into a binary-valued output\n                array.\n\n    Examples\n    --------\n    >>> a = np.array([[[1,0,1],\n    ...                [0,1,0]],\n    ...               [[1,1,0],\n    ...                [0,0,1]]])\n    >>> b = np.packbits(a, axis=-1)\n    >>> b\n    array([[[160],\n            [ 64]],\n           [[192],\n            [ 32]]], dtype=uint8)\n\n    Note that in binary 160 = 1010 0000, 64 = 0100 0000, 192 = 1100 0000,\n    and 32 = 0010 0000.\n\n    \"\"\"\n    return (a,)\n\n\n@array_function_from_c_func_and_dispatcher(_multiarray_umath.unpackbits)\ndef unpackbits(a, axis=None, count=None, bitorder='big'):\n    \"\"\"\n    unpackbits(a, axis=None, count=None, bitorder='big')\n\n    Unpacks elements of a uint8 array into a binary-valued output array.\n\n    Each element of `a` represents a bit-field that should be unpacked\n    into a binary-valued output array. The shape of the output array is\n    either 1-D (if `axis` is ``None``) or the same shape as the input\n    array with unpacking done along the axis specified.\n\n    Parameters\n    ----------\n    a : ndarray, uint8 type\n       Input array.\n    axis : int, optional\n        The dimension over which bit-unpacking is done.\n        ``None`` implies unpacking the flattened array.\n    count : int or None, optional\n        The number of elements to unpack along `axis`, provided as a way\n        of undoing the effect of packing a size that is not a multiple\n        of eight. A non-negative number means to only unpack `count`\n        bits. A negative number means to trim off that many bits from\n        the end. ``None`` means to unpack the entire array (the\n        default). Counts larger than the available number of bits will\n        add zero padding to the output. Negative counts must not\n        exceed the available number of bits.\n\n        .. versionadded:: 1.17.0\n\n    bitorder : {'big', 'little'}, optional\n        The order of the returned bits. 'big' will mimic bin(val),\n        ``3 = 0b00000011 => [0, 0, 0, 0, 0, 0, 1, 1]``, 'little' will reverse\n        the order to ``[1, 1, 0, 0, 0, 0, 0, 0]``.\n        Defaults to 'big'.\n\n        .. versionadded:: 1.17.0\n\n    Returns\n    -------\n    unpacked : ndarray, uint8 type\n       The elements are binary-valued (0 or 1).\n\n    See Also\n    --------\n    packbits : Packs the elements of a binary-valued array into bits in\n               a uint8 array.\n\n    Examples\n    --------\n    >>> a = np.array([[2], [7], [23]], dtype=np.uint8)\n    >>> a\n    array([[ 2],\n           [ 7],\n           [23]], dtype=uint8)\n    >>> b = np.unpackbits(a, axis=1)\n    >>> b\n    array([[0, 0, 0, 0, 0, 0, 1, 0],\n           [0, 0, 0, 0, 0, 1, 1, 1],\n           [0, 0, 0, 1, 0, 1, 1, 1]], dtype=uint8)\n    >>> c = np.unpackbits(a, axis=1, count=-3)\n    >>> c\n    array([[0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 0],\n           [0, 0, 0, 1, 0]], dtype=uint8)\n\n    >>> p = np.packbits(b, axis=0)\n    >>> np.unpackbits(p, axis=0)\n    array([[0, 0, 0, 0, 0, 0, 1, 0],\n           [0, 0, 0, 0, 0, 1, 1, 1],\n           [0, 0, 0, 1, 0, 1, 1, 1],\n           [0, 0, 0, 0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 0, 0, 0, 0]], dtype=uint8)\n    >>> np.array_equal(b, np.unpackbits(p, axis=0, count=b.shape[0]))\n    True\n\n    \"\"\"\n    return (a,)\n\n\n@array_function_from_c_func_and_dispatcher(_multiarray_umath.shares_memory)\ndef shares_memory(a, b, max_work=None):\n    \"\"\"\n    shares_memory(a, b, max_work=None)\n\n    Determine if two arrays share memory.\n\n    .. warning::\n\n       This function can be exponentially slow for some inputs, unless\n       `max_work` is set to a finite number or ``MAY_SHARE_BOUNDS``.\n       If in doubt, use `numpy.may_share_memory` instead.\n\n    Parameters\n    ----------\n    a, b : ndarray\n        Input arrays\n    max_work : int, optional\n        Effort to spend on solving the overlap problem (maximum number\n        of candidate solutions to consider). The following special\n        values are recognized:\n\n        max_work=MAY_SHARE_EXACT  (default)\n            The problem is solved exactly. In this case, the function returns\n            True only if there is an element shared between the arrays. Finding\n            the exact solution may take extremely long in some cases.\n        max_work=MAY_SHARE_BOUNDS\n            Only the memory bounds of a and b are checked.\n\n    Raises\n    ------\n    numpy.TooHardError\n        Exceeded max_work.\n\n    Returns\n    -------\n    out : bool\n\n    See Also\n    --------\n    may_share_memory\n\n    Examples\n    --------\n    >>> x = np.array([1, 2, 3, 4])\n    >>> np.shares_memory(x, np.array([5, 6, 7]))\n    False\n    >>> np.shares_memory(x[::2], x)\n    True\n    >>> np.shares_memory(x[::2], x[1::2])\n    False\n\n    Checking whether two arrays share memory is NP-complete, and\n    runtime may increase exponentially in the number of\n    dimensions. Hence, `max_work` should generally be set to a finite\n    number, as it is possible to construct examples that take\n    extremely long to run:\n\n    >>> from numpy.lib.stride_tricks import as_strided\n    >>> x = np.zeros([192163377], dtype=np.int8)\n    >>> x1 = as_strided(x, strides=(36674, 61119, 85569), shape=(1049, 1049, 1049))\n    >>> x2 = as_strided(x[64023025:], strides=(12223, 12224, 1), shape=(1049, 1049, 1))\n    >>> np.shares_memory(x1, x2, max_work=1000)\n    Traceback (most recent call last):\n    ...\n    numpy.TooHardError: Exceeded max_work\n\n    Running ``np.shares_memory(x1, x2)`` without `max_work` set takes\n    around 1 minute for this case. It is possible to find problems\n    that take still significantly longer.\n\n    \"\"\"\n    return (a, b)\n\n\n@array_function_from_c_func_and_dispatcher(_multiarray_umath.may_share_memory)\ndef may_share_memory(a, b, max_work=None):\n    \"\"\"\n    may_share_memory(a, b, max_work=None)\n\n    Determine if two arrays might share memory\n\n    A return of True does not necessarily mean that the two arrays\n    share any element.  It just means that they *might*.\n\n    Only the memory bounds of a and b are checked by default.\n\n    Parameters\n    ----------\n    a, b : ndarray\n        Input arrays\n    max_work : int, optional\n        Effort to spend on solving the overlap problem.  See\n        `shares_memory` for details.  Default for ``may_share_memory``\n        is to do a bounds check.\n\n    Returns\n    -------\n    out : bool\n\n    See Also\n    --------\n    shares_memory\n\n    Examples\n    --------\n    >>> np.may_share_memory(np.array([1,2]), np.array([5,8,9]))\n    False\n    >>> x = np.zeros([3, 4])\n    >>> np.may_share_memory(x[:,0], x[:,1])\n    True\n\n    \"\"\"\n    return (a, b)\n\n\n@array_function_from_c_func_and_dispatcher(_multiarray_umath.is_busday)\ndef is_busday(dates, weekmask=None, holidays=None, busdaycal=None, out=None):\n    \"\"\"\n    is_busday(dates, weekmask='1111100', holidays=None, busdaycal=None, out=None)\n\n    Calculates which of the given dates are valid days, and which are not.\n\n    .. versionadded:: 1.7.0\n\n    Parameters\n    ----------\n    dates : array_like of datetime64[D]\n        The array of dates to process.\n    weekmask : str or array_like of bool, optional\n        A seven-element array indicating which of Monday through Sunday are\n        valid days. May be specified as a length-seven list or array, like\n        [1,1,1,1,1,0,0]; a length-seven string, like '1111100'; or a string\n        like \"Mon Tue Wed Thu Fri\", made up of 3-character abbreviations for\n        weekdays, optionally separated by white space. Valid abbreviations\n        are: Mon Tue Wed Thu Fri Sat Sun\n    holidays : array_like of datetime64[D], optional\n        An array of dates to consider as invalid dates.  They may be\n        specified in any order, and NaT (not-a-time) dates are ignored.\n        This list is saved in a normalized form that is suited for\n        fast calculations of valid days.\n    busdaycal : busdaycalendar, optional\n        A `busdaycalendar` object which specifies the valid days. If this\n        parameter is provided, neither weekmask nor holidays may be\n        provided.\n    out : array of bool, optional\n        If provided, this array is filled with the result.\n\n    Returns\n    -------\n    out : array of bool\n        An array with the same shape as ``dates``, containing True for\n        each valid day, and False for each invalid day.\n\n    See Also\n    --------\n    busdaycalendar : An object that specifies a custom set of valid days.\n    busday_offset : Applies an offset counted in valid days.\n    busday_count : Counts how many valid days are in a half-open date range.\n\n    Examples\n    --------\n    >>> # The weekdays are Friday, Saturday, and Monday\n    ... np.is_busday(['2011-07-01', '2011-07-02', '2011-07-18'],\n    ...                 holidays=['2011-07-01', '2011-07-04', '2011-07-17'])\n    array([False, False,  True])\n    \"\"\"\n    return (dates, weekmask, holidays, out)\n\n\n@array_function_from_c_func_and_dispatcher(_multiarray_umath.busday_offset)\ndef busday_offset(dates, offsets, roll=None, weekmask=None, holidays=None,\n                  busdaycal=None, out=None):\n    \"\"\"\n    busday_offset(dates, offsets, roll='raise', weekmask='1111100', holidays=None, busdaycal=None, out=None)\n\n    First adjusts the date to fall on a valid day according to\n    the ``roll`` rule, then applies offsets to the given dates\n    counted in valid days.\n\n    .. versionadded:: 1.7.0\n\n    Parameters\n    ----------\n    dates : array_like of datetime64[D]\n        The array of dates to process.\n    offsets : array_like of int\n        The array of offsets, which is broadcast with ``dates``.\n    roll : {'raise', 'nat', 'forward', 'following', 'backward', 'preceding', 'modifiedfollowing', 'modifiedpreceding'}, optional\n        How to treat dates that do not fall on a valid day. The default\n        is 'raise'.\n\n          * 'raise' means to raise an exception for an invalid day.\n          * 'nat' means to return a NaT (not-a-time) for an invalid day.\n          * 'forward' and 'following' mean to take the first valid day\n            later in time.\n          * 'backward' and 'preceding' mean to take the first valid day\n            earlier in time.\n          * 'modifiedfollowing' means to take the first valid day\n            later in time unless it is across a Month boundary, in which\n            case to take the first valid day earlier in time.\n          * 'modifiedpreceding' means to take the first valid day\n            earlier in time unless it is across a Month boundary, in which\n            case to take the first valid day later in time.\n    weekmask : str or array_like of bool, optional\n        A seven-element array indicating which of Monday through Sunday are\n        valid days. May be specified as a length-seven list or array, like\n        [1,1,1,1,1,0,0]; a length-seven string, like '1111100'; or a string\n        like \"Mon Tue Wed Thu Fri\", made up of 3-character abbreviations for\n        weekdays, optionally separated by white space. Valid abbreviations\n        are: Mon Tue Wed Thu Fri Sat Sun\n    holidays : array_like of datetime64[D], optional\n        An array of dates to consider as invalid dates.  They may be\n        specified in any order, and NaT (not-a-time) dates are ignored.\n        This list is saved in a normalized form that is suited for\n        fast calculations of valid days.\n    busdaycal : busdaycalendar, optional\n        A `busdaycalendar` object which specifies the valid days. If this\n        parameter is provided, neither weekmask nor holidays may be\n        provided.\n    out : array of datetime64[D], optional\n        If provided, this array is filled with the result.\n\n    Returns\n    -------\n    out : array of datetime64[D]\n        An array with a shape from broadcasting ``dates`` and ``offsets``\n        together, containing the dates with offsets applied.\n\n    See Also\n    --------\n    busdaycalendar : An object that specifies a custom set of valid days.\n    is_busday : Returns a boolean array indicating valid days.\n    busday_count : Counts how many valid days are in a half-open date range.\n\n    Examples\n    --------\n    >>> # First business day in October 2011 (not accounting for holidays)\n    ... np.busday_offset('2011-10', 0, roll='forward')\n    numpy.datetime64('2011-10-03')\n    >>> # Last business day in February 2012 (not accounting for holidays)\n    ... np.busday_offset('2012-03', -1, roll='forward')\n    numpy.datetime64('2012-02-29')\n    >>> # Third Wednesday in January 2011\n    ... np.busday_offset('2011-01', 2, roll='forward', weekmask='Wed')\n    numpy.datetime64('2011-01-19')\n    >>> # 2012 Mother's Day in Canada and the U.S.\n    ... np.busday_offset('2012-05', 1, roll='forward', weekmask='Sun')\n    numpy.datetime64('2012-05-13')\n\n    >>> # First business day on or after a date\n    ... np.busday_offset('2011-03-20', 0, roll='forward')\n    numpy.datetime64('2011-03-21')\n    >>> np.busday_offset('2011-03-22', 0, roll='forward')\n    numpy.datetime64('2011-03-22')\n    >>> # First business day after a date\n    ... np.busday_offset('2011-03-20', 1, roll='backward')\n    numpy.datetime64('2011-03-21')\n    >>> np.busday_offset('2011-03-22', 1, roll='backward')\n    numpy.datetime64('2011-03-23')\n    \"\"\"\n    return (dates, offsets, weekmask, holidays, out)\n\n\n@array_function_from_c_func_and_dispatcher(_multiarray_umath.busday_count)\ndef busday_count(begindates, enddates, weekmask=None, holidays=None,\n                 busdaycal=None, out=None):\n    \"\"\"\n    busday_count(begindates, enddates, weekmask='1111100', holidays=[], busdaycal=None, out=None)\n\n    Counts the number of valid days between `begindates` and\n    `enddates`, not including the day of `enddates`.\n\n    If ``enddates`` specifies a date value that is earlier than the\n    corresponding ``begindates`` date value, the count will be negative.\n\n    .. versionadded:: 1.7.0\n\n    Parameters\n    ----------\n    begindates : array_like of datetime64[D]\n        The array of the first dates for counting.\n    enddates : array_like of datetime64[D]\n        The array of the end dates for counting, which are excluded\n        from the count themselves.\n    weekmask : str or array_like of bool, optional\n        A seven-element array indicating which of Monday through Sunday are\n        valid days. May be specified as a length-seven list or array, like\n        [1,1,1,1,1,0,0]; a length-seven string, like '1111100'; or a string\n        like \"Mon Tue Wed Thu Fri\", made up of 3-character abbreviations for\n        weekdays, optionally separated by white space. Valid abbreviations\n        are: Mon Tue Wed Thu Fri Sat Sun\n    holidays : array_like of datetime64[D], optional\n        An array of dates to consider as invalid dates.  They may be\n        specified in any order, and NaT (not-a-time) dates are ignored.\n        This list is saved in a normalized form that is suited for\n        fast calculations of valid days.\n    busdaycal : busdaycalendar, optional\n        A `busdaycalendar` object which specifies the valid days. If this\n        parameter is provided, neither weekmask nor holidays may be\n        provided.\n    out : array of int, optional\n        If provided, this array is filled with the result.\n\n    Returns\n    -------\n    out : array of int\n        An array with a shape from broadcasting ``begindates`` and ``enddates``\n        together, containing the number of valid days between\n        the begin and end dates.\n\n    See Also\n    --------\n    busdaycalendar : An object that specifies a custom set of valid days.\n    is_busday : Returns a boolean array indicating valid days.\n    busday_offset : Applies an offset counted in valid days.\n\n    Examples\n    --------\n    >>> # Number of weekdays in January 2011\n    ... np.busday_count('2011-01', '2011-02')\n    21\n    >>> # Number of weekdays in 2011\n    >>> np.busday_count('2011', '2012')\n    260\n    >>> # Number of Saturdays in 2011\n    ... np.busday_count('2011', '2012', weekmask='Sat')\n    53\n    \"\"\"\n    return (begindates, enddates, weekmask, holidays, out)\n\n\n@array_function_from_c_func_and_dispatcher(\n    _multiarray_umath.datetime_as_string)\ndef datetime_as_string(arr, unit=None, timezone=None, casting=None):\n    \"\"\"\n    datetime_as_string(arr, unit=None, timezone='naive', casting='same_kind')\n\n    Convert an array of datetimes into an array of strings.\n\n    Parameters\n    ----------\n    arr : array_like of datetime64\n        The array of UTC timestamps to format.\n    unit : str\n        One of None, 'auto', or a :ref:`datetime unit <arrays.dtypes.dateunits>`.\n    timezone : {'naive', 'UTC', 'local'} or tzinfo\n        Timezone information to use when displaying the datetime. If 'UTC', end\n        with a Z to indicate UTC time. If 'local', convert to the local timezone\n        first, and suffix with a +-#### timezone offset. If a tzinfo object,\n        then do as with 'local', but use the specified timezone.\n    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}\n        Casting to allow when changing between datetime units.\n\n    Returns\n    -------\n    str_arr : ndarray\n        An array of strings the same shape as `arr`.\n\n    Examples\n    --------\n    >>> import pytz\n    >>> d = np.arange('2002-10-27T04:30', 4*60, 60, dtype='M8[m]')\n    >>> d\n    array(['2002-10-27T04:30', '2002-10-27T05:30', '2002-10-27T06:30',\n           '2002-10-27T07:30'], dtype='datetime64[m]')\n\n    Setting the timezone to UTC shows the same information, but with a Z suffix\n\n    >>> np.datetime_as_string(d, timezone='UTC')\n    array(['2002-10-27T04:30Z', '2002-10-27T05:30Z', '2002-10-27T06:30Z',\n           '2002-10-27T07:30Z'], dtype='<U35')\n\n    Note that we picked datetimes that cross a DST boundary. Passing in a\n    ``pytz`` timezone object will print the appropriate offset\n\n    >>> np.datetime_as_string(d, timezone=pytz.timezone('US/Eastern'))\n    array(['2002-10-27T00:30-0400', '2002-10-27T01:30-0400',\n           '2002-10-27T01:30-0500', '2002-10-27T02:30-0500'], dtype='<U39')\n\n    Passing in a unit will change the precision\n\n    >>> np.datetime_as_string(d, unit='h')\n    array(['2002-10-27T04', '2002-10-27T05', '2002-10-27T06', '2002-10-27T07'],\n          dtype='<U32')\n    >>> np.datetime_as_string(d, unit='s')\n    array(['2002-10-27T04:30:00', '2002-10-27T05:30:00', '2002-10-27T06:30:00',\n           '2002-10-27T07:30:00'], dtype='<U38')\n\n    'casting' can be used to specify whether precision can be changed\n\n    >>> np.datetime_as_string(d, unit='h', casting='safe')\n    Traceback (most recent call last):\n        ...\n    TypeError: Cannot create a datetime string as units 'h' from a NumPy\n    datetime with units 'm' according to the rule 'safe'\n    \"\"\"\n    return (arr,)\n", 1690], "/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/contextlib.py": ["\"\"\"Utilities for with-statement contexts.  See PEP 343.\"\"\"\nimport abc\nimport sys\nimport _collections_abc\nfrom collections import deque\nfrom functools import wraps\nfrom types import MethodType, GenericAlias\n\n__all__ = [\"asynccontextmanager\", \"contextmanager\", \"closing\", \"nullcontext\",\n           \"AbstractContextManager\", \"AbstractAsyncContextManager\",\n           \"AsyncExitStack\", \"ContextDecorator\", \"ExitStack\",\n           \"redirect_stdout\", \"redirect_stderr\", \"suppress\"]\n\n\nclass AbstractContextManager(abc.ABC):\n\n    \"\"\"An abstract base class for context managers.\"\"\"\n\n    __class_getitem__ = classmethod(GenericAlias)\n\n    def __enter__(self):\n        \"\"\"Return `self` upon entering the runtime context.\"\"\"\n        return self\n\n    @abc.abstractmethod\n    def __exit__(self, exc_type, exc_value, traceback):\n        \"\"\"Raise any exception triggered within the runtime context.\"\"\"\n        return None\n\n    @classmethod\n    def __subclasshook__(cls, C):\n        if cls is AbstractContextManager:\n            return _collections_abc._check_methods(C, \"__enter__\", \"__exit__\")\n        return NotImplemented\n\n\nclass AbstractAsyncContextManager(abc.ABC):\n\n    \"\"\"An abstract base class for asynchronous context managers.\"\"\"\n\n    __class_getitem__ = classmethod(GenericAlias)\n\n    async def __aenter__(self):\n        \"\"\"Return `self` upon entering the runtime context.\"\"\"\n        return self\n\n    @abc.abstractmethod\n    async def __aexit__(self, exc_type, exc_value, traceback):\n        \"\"\"Raise any exception triggered within the runtime context.\"\"\"\n        return None\n\n    @classmethod\n    def __subclasshook__(cls, C):\n        if cls is AbstractAsyncContextManager:\n            return _collections_abc._check_methods(C, \"__aenter__\",\n                                                   \"__aexit__\")\n        return NotImplemented\n\n\nclass ContextDecorator(object):\n    \"A base class or mixin that enables context managers to work as decorators.\"\n\n    def _recreate_cm(self):\n        \"\"\"Return a recreated instance of self.\n\n        Allows an otherwise one-shot context manager like\n        _GeneratorContextManager to support use as\n        a decorator via implicit recreation.\n\n        This is a private interface just for _GeneratorContextManager.\n        See issue #11647 for details.\n        \"\"\"\n        return self\n\n    def __call__(self, func):\n        @wraps(func)\n        def inner(*args, **kwds):\n            with self._recreate_cm():\n                return func(*args, **kwds)\n        return inner\n\n\nclass _GeneratorContextManagerBase:\n    \"\"\"Shared functionality for @contextmanager and @asynccontextmanager.\"\"\"\n\n    def __init__(self, func, args, kwds):\n        self.gen = func(*args, **kwds)\n        self.func, self.args, self.kwds = func, args, kwds\n        # Issue 19330: ensure context manager instances have good docstrings\n        doc = getattr(func, \"__doc__\", None)\n        if doc is None:\n            doc = type(self).__doc__\n        self.__doc__ = doc\n        # Unfortunately, this still doesn't provide good help output when\n        # inspecting the created context manager instances, since pydoc\n        # currently bypasses the instance docstring and shows the docstring\n        # for the class instead.\n        # See http://bugs.python.org/issue19404 for more details.\n\n    def _recreate_cm(self):\n        # _GCMB instances are one-shot context managers, so the\n        # CM must be recreated each time a decorated function is\n        # called\n        return self.__class__(self.func, self.args, self.kwds)\n\n\nclass _GeneratorContextManager(\n    _GeneratorContextManagerBase,\n    AbstractContextManager,\n    ContextDecorator,\n):\n    \"\"\"Helper for @contextmanager decorator.\"\"\"\n\n    def __enter__(self):\n        # do not keep args and kwds alive unnecessarily\n        # they are only needed for recreation, which is not possible anymore\n        del self.args, self.kwds, self.func\n        try:\n            return next(self.gen)\n        except StopIteration:\n            raise RuntimeError(\"generator didn't yield\") from None\n\n    def __exit__(self, typ, value, traceback):\n        if typ is None:\n            try:\n                next(self.gen)\n            except StopIteration:\n                return False\n            else:\n                raise RuntimeError(\"generator didn't stop\")\n        else:\n            if value is None:\n                # Need to force instantiation so we can reliably\n                # tell if we get the same exception back\n                value = typ()\n            try:\n                self.gen.throw(typ, value, traceback)\n            except StopIteration as exc:\n                # Suppress StopIteration *unless* it's the same exception that\n                # was passed to throw().  This prevents a StopIteration\n                # raised inside the \"with\" statement from being suppressed.\n                return exc is not value\n            except RuntimeError as exc:\n                # Don't re-raise the passed in exception. (issue27122)\n                if exc is value:\n                    return False\n                # Avoid suppressing if a StopIteration exception\n                # was passed to throw() and later wrapped into a RuntimeError\n                # (see PEP 479 for sync generators; async generators also\n                # have this behavior). But do this only if the exception wrapped\n                # by the RuntimeError is actually Stop(Async)Iteration (see\n                # issue29692).\n                if (\n                    isinstance(value, StopIteration)\n                    and exc.__cause__ is value\n                ):\n                    return False\n                raise\n            except BaseException as exc:\n                # only re-raise if it's *not* the exception that was\n                # passed to throw(), because __exit__() must not raise\n                # an exception unless __exit__() itself failed.  But throw()\n                # has to raise the exception to signal propagation, so this\n                # fixes the impedance mismatch between the throw() protocol\n                # and the __exit__() protocol.\n                if exc is not value:\n                    raise\n                return False\n            raise RuntimeError(\"generator didn't stop after throw()\")\n\n\nclass _AsyncGeneratorContextManager(_GeneratorContextManagerBase,\n                                    AbstractAsyncContextManager):\n    \"\"\"Helper for @asynccontextmanager decorator.\"\"\"\n\n    async def __aenter__(self):\n        # do not keep args and kwds alive unnecessarily\n        # they are only needed for recreation, which is not possible anymore\n        del self.args, self.kwds, self.func\n        try:\n            return await self.gen.__anext__()\n        except StopAsyncIteration:\n            raise RuntimeError(\"generator didn't yield\") from None\n\n    async def __aexit__(self, typ, value, traceback):\n        if typ is None:\n            try:\n                await self.gen.__anext__()\n            except StopAsyncIteration:\n                return False\n            else:\n                raise RuntimeError(\"generator didn't stop\")\n        else:\n            if value is None:\n                # Need to force instantiation so we can reliably\n                # tell if we get the same exception back\n                value = typ()\n            try:\n                await self.gen.athrow(typ, value, traceback)\n            except StopAsyncIteration as exc:\n                # Suppress StopIteration *unless* it's the same exception that\n                # was passed to throw().  This prevents a StopIteration\n                # raised inside the \"with\" statement from being suppressed.\n                return exc is not value\n            except RuntimeError as exc:\n                # Don't re-raise the passed in exception. (issue27122)\n                if exc is value:\n                    return False\n                # Avoid suppressing if a Stop(Async)Iteration exception\n                # was passed to athrow() and later wrapped into a RuntimeError\n                # (see PEP 479 for sync generators; async generators also\n                # have this behavior). But do this only if the exception wrapped\n                # by the RuntimeError is actully Stop(Async)Iteration (see\n                # issue29692).\n                if (\n                    isinstance(value, (StopIteration, StopAsyncIteration))\n                    and exc.__cause__ is value\n                ):\n                    return False\n                raise\n            except BaseException as exc:\n                # only re-raise if it's *not* the exception that was\n                # passed to throw(), because __exit__() must not raise\n                # an exception unless __exit__() itself failed.  But throw()\n                # has to raise the exception to signal propagation, so this\n                # fixes the impedance mismatch between the throw() protocol\n                # and the __exit__() protocol.\n                if exc is not value:\n                    raise\n                return False\n            raise RuntimeError(\"generator didn't stop after athrow()\")\n\n\ndef contextmanager(func):\n    \"\"\"@contextmanager decorator.\n\n    Typical usage:\n\n        @contextmanager\n        def some_generator(<arguments>):\n            <setup>\n            try:\n                yield <value>\n            finally:\n                <cleanup>\n\n    This makes this:\n\n        with some_generator(<arguments>) as <variable>:\n            <body>\n\n    equivalent to this:\n\n        <setup>\n        try:\n            <variable> = <value>\n            <body>\n        finally:\n            <cleanup>\n    \"\"\"\n    @wraps(func)\n    def helper(*args, **kwds):\n        return _GeneratorContextManager(func, args, kwds)\n    return helper\n\n\ndef asynccontextmanager(func):\n    \"\"\"@asynccontextmanager decorator.\n\n    Typical usage:\n\n        @asynccontextmanager\n        async def some_async_generator(<arguments>):\n            <setup>\n            try:\n                yield <value>\n            finally:\n                <cleanup>\n\n    This makes this:\n\n        async with some_async_generator(<arguments>) as <variable>:\n            <body>\n\n    equivalent to this:\n\n        <setup>\n        try:\n            <variable> = <value>\n            <body>\n        finally:\n            <cleanup>\n    \"\"\"\n    @wraps(func)\n    def helper(*args, **kwds):\n        return _AsyncGeneratorContextManager(func, args, kwds)\n    return helper\n\n\nclass closing(AbstractContextManager):\n    \"\"\"Context to automatically close something at the end of a block.\n\n    Code like this:\n\n        with closing(<module>.open(<arguments>)) as f:\n            <block>\n\n    is equivalent to this:\n\n        f = <module>.open(<arguments>)\n        try:\n            <block>\n        finally:\n            f.close()\n\n    \"\"\"\n    def __init__(self, thing):\n        self.thing = thing\n    def __enter__(self):\n        return self.thing\n    def __exit__(self, *exc_info):\n        self.thing.close()\n\n\nclass _RedirectStream(AbstractContextManager):\n\n    _stream = None\n\n    def __init__(self, new_target):\n        self._new_target = new_target\n        # We use a list of old targets to make this CM re-entrant\n        self._old_targets = []\n\n    def __enter__(self):\n        self._old_targets.append(getattr(sys, self._stream))\n        setattr(sys, self._stream, self._new_target)\n        return self._new_target\n\n    def __exit__(self, exctype, excinst, exctb):\n        setattr(sys, self._stream, self._old_targets.pop())\n\n\nclass redirect_stdout(_RedirectStream):\n    \"\"\"Context manager for temporarily redirecting stdout to another file.\n\n        # How to send help() to stderr\n        with redirect_stdout(sys.stderr):\n            help(dir)\n\n        # How to write help() to a file\n        with open('help.txt', 'w') as f:\n            with redirect_stdout(f):\n                help(pow)\n    \"\"\"\n\n    _stream = \"stdout\"\n\n\nclass redirect_stderr(_RedirectStream):\n    \"\"\"Context manager for temporarily redirecting stderr to another file.\"\"\"\n\n    _stream = \"stderr\"\n\n\nclass suppress(AbstractContextManager):\n    \"\"\"Context manager to suppress specified exceptions\n\n    After the exception is suppressed, execution proceeds with the next\n    statement following the with statement.\n\n         with suppress(FileNotFoundError):\n             os.remove(somefile)\n         # Execution still resumes here if the file was already removed\n    \"\"\"\n\n    def __init__(self, *exceptions):\n        self._exceptions = exceptions\n\n    def __enter__(self):\n        pass\n\n    def __exit__(self, exctype, excinst, exctb):\n        # Unlike isinstance and issubclass, CPython exception handling\n        # currently only looks at the concrete type hierarchy (ignoring\n        # the instance and subclass checking hooks). While Guido considers\n        # that a bug rather than a feature, it's a fairly hard one to fix\n        # due to various internal implementation details. suppress provides\n        # the simpler issubclass based semantics, rather than trying to\n        # exactly reproduce the limitations of the CPython interpreter.\n        #\n        # See http://bugs.python.org/issue12029 for more details\n        return exctype is not None and issubclass(exctype, self._exceptions)\n\n\nclass _BaseExitStack:\n    \"\"\"A base class for ExitStack and AsyncExitStack.\"\"\"\n\n    @staticmethod\n    def _create_exit_wrapper(cm, cm_exit):\n        return MethodType(cm_exit, cm)\n\n    @staticmethod\n    def _create_cb_wrapper(callback, /, *args, **kwds):\n        def _exit_wrapper(exc_type, exc, tb):\n            callback(*args, **kwds)\n        return _exit_wrapper\n\n    def __init__(self):\n        self._exit_callbacks = deque()\n\n    def pop_all(self):\n        \"\"\"Preserve the context stack by transferring it to a new instance.\"\"\"\n        new_stack = type(self)()\n        new_stack._exit_callbacks = self._exit_callbacks\n        self._exit_callbacks = deque()\n        return new_stack\n\n    def push(self, exit):\n        \"\"\"Registers a callback with the standard __exit__ method signature.\n\n        Can suppress exceptions the same way __exit__ method can.\n        Also accepts any object with an __exit__ method (registering a call\n        to the method instead of the object itself).\n        \"\"\"\n        # We use an unbound method rather than a bound method to follow\n        # the standard lookup behaviour for special methods.\n        _cb_type = type(exit)\n\n        try:\n            exit_method = _cb_type.__exit__\n        except AttributeError:\n            # Not a context manager, so assume it's a callable.\n            self._push_exit_callback(exit)\n        else:\n            self._push_cm_exit(exit, exit_method)\n        return exit  # Allow use as a decorator.\n\n    def enter_context(self, cm):\n        \"\"\"Enters the supplied context manager.\n\n        If successful, also pushes its __exit__ method as a callback and\n        returns the result of the __enter__ method.\n        \"\"\"\n        # We look up the special methods on the type to match the with\n        # statement.\n        _cm_type = type(cm)\n        _exit = _cm_type.__exit__\n        result = _cm_type.__enter__(cm)\n        self._push_cm_exit(cm, _exit)\n        return result\n\n    def callback(self, callback, /, *args, **kwds):\n        \"\"\"Registers an arbitrary callback and arguments.\n\n        Cannot suppress exceptions.\n        \"\"\"\n        _exit_wrapper = self._create_cb_wrapper(callback, *args, **kwds)\n\n        # We changed the signature, so using @wraps is not appropriate, but\n        # setting __wrapped__ may still help with introspection.\n        _exit_wrapper.__wrapped__ = callback\n        self._push_exit_callback(_exit_wrapper)\n        return callback  # Allow use as a decorator\n\n    def _push_cm_exit(self, cm, cm_exit):\n        \"\"\"Helper to correctly register callbacks to __exit__ methods.\"\"\"\n        _exit_wrapper = self._create_exit_wrapper(cm, cm_exit)\n        self._push_exit_callback(_exit_wrapper, True)\n\n    def _push_exit_callback(self, callback, is_sync=True):\n        self._exit_callbacks.append((is_sync, callback))\n\n\n# Inspired by discussions on http://bugs.python.org/issue13585\nclass ExitStack(_BaseExitStack, AbstractContextManager):\n    \"\"\"Context manager for dynamic management of a stack of exit callbacks.\n\n    For example:\n        with ExitStack() as stack:\n            files = [stack.enter_context(open(fname)) for fname in filenames]\n            # All opened files will automatically be closed at the end of\n            # the with statement, even if attempts to open files later\n            # in the list raise an exception.\n    \"\"\"\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *exc_details):\n        received_exc = exc_details[0] is not None\n\n        # We manipulate the exception state so it behaves as though\n        # we were actually nesting multiple with statements\n        frame_exc = sys.exc_info()[1]\n        def _fix_exception_context(new_exc, old_exc):\n            # Context may not be correct, so find the end of the chain\n            while 1:\n                exc_context = new_exc.__context__\n                if exc_context is None or exc_context is old_exc:\n                    # Context is already set correctly (see issue 20317)\n                    return\n                if exc_context is frame_exc:\n                    break\n                new_exc = exc_context\n            # Change the end of the chain to point to the exception\n            # we expect it to reference\n            new_exc.__context__ = old_exc\n\n        # Callbacks are invoked in LIFO order to match the behaviour of\n        # nested context managers\n        suppressed_exc = False\n        pending_raise = False\n        while self._exit_callbacks:\n            is_sync, cb = self._exit_callbacks.pop()\n            assert is_sync\n            try:\n                if cb(*exc_details):\n                    suppressed_exc = True\n                    pending_raise = False\n                    exc_details = (None, None, None)\n            except:\n                new_exc_details = sys.exc_info()\n                # simulate the stack of exceptions by setting the context\n                _fix_exception_context(new_exc_details[1], exc_details[1])\n                pending_raise = True\n                exc_details = new_exc_details\n        if pending_raise:\n            try:\n                # bare \"raise exc_details[1]\" replaces our carefully\n                # set-up context\n                fixed_ctx = exc_details[1].__context__\n                raise exc_details[1]\n            except BaseException:\n                exc_details[1].__context__ = fixed_ctx\n                raise\n        return received_exc and suppressed_exc\n\n    def close(self):\n        \"\"\"Immediately unwind the context stack.\"\"\"\n        self.__exit__(None, None, None)\n\n\n# Inspired by discussions on https://bugs.python.org/issue29302\nclass AsyncExitStack(_BaseExitStack, AbstractAsyncContextManager):\n    \"\"\"Async context manager for dynamic management of a stack of exit\n    callbacks.\n\n    For example:\n        async with AsyncExitStack() as stack:\n            connections = [await stack.enter_async_context(get_connection())\n                for i in range(5)]\n            # All opened connections will automatically be released at the\n            # end of the async with statement, even if attempts to open a\n            # connection later in the list raise an exception.\n    \"\"\"\n\n    @staticmethod\n    def _create_async_exit_wrapper(cm, cm_exit):\n        return MethodType(cm_exit, cm)\n\n    @staticmethod\n    def _create_async_cb_wrapper(callback, /, *args, **kwds):\n        async def _exit_wrapper(exc_type, exc, tb):\n            await callback(*args, **kwds)\n        return _exit_wrapper\n\n    async def enter_async_context(self, cm):\n        \"\"\"Enters the supplied async context manager.\n\n        If successful, also pushes its __aexit__ method as a callback and\n        returns the result of the __aenter__ method.\n        \"\"\"\n        _cm_type = type(cm)\n        _exit = _cm_type.__aexit__\n        result = await _cm_type.__aenter__(cm)\n        self._push_async_cm_exit(cm, _exit)\n        return result\n\n    def push_async_exit(self, exit):\n        \"\"\"Registers a coroutine function with the standard __aexit__ method\n        signature.\n\n        Can suppress exceptions the same way __aexit__ method can.\n        Also accepts any object with an __aexit__ method (registering a call\n        to the method instead of the object itself).\n        \"\"\"\n        _cb_type = type(exit)\n        try:\n            exit_method = _cb_type.__aexit__\n        except AttributeError:\n            # Not an async context manager, so assume it's a coroutine function\n            self._push_exit_callback(exit, False)\n        else:\n            self._push_async_cm_exit(exit, exit_method)\n        return exit  # Allow use as a decorator\n\n    def push_async_callback(self, callback, /, *args, **kwds):\n        \"\"\"Registers an arbitrary coroutine function and arguments.\n\n        Cannot suppress exceptions.\n        \"\"\"\n        _exit_wrapper = self._create_async_cb_wrapper(callback, *args, **kwds)\n\n        # We changed the signature, so using @wraps is not appropriate, but\n        # setting __wrapped__ may still help with introspection.\n        _exit_wrapper.__wrapped__ = callback\n        self._push_exit_callback(_exit_wrapper, False)\n        return callback  # Allow use as a decorator\n\n    async def aclose(self):\n        \"\"\"Immediately unwind the context stack.\"\"\"\n        await self.__aexit__(None, None, None)\n\n    def _push_async_cm_exit(self, cm, cm_exit):\n        \"\"\"Helper to correctly register coroutine function to __aexit__\n        method.\"\"\"\n        _exit_wrapper = self._create_async_exit_wrapper(cm, cm_exit)\n        self._push_exit_callback(_exit_wrapper, False)\n\n    async def __aenter__(self):\n        return self\n\n    async def __aexit__(self, *exc_details):\n        received_exc = exc_details[0] is not None\n\n        # We manipulate the exception state so it behaves as though\n        # we were actually nesting multiple with statements\n        frame_exc = sys.exc_info()[1]\n        def _fix_exception_context(new_exc, old_exc):\n            # Context may not be correct, so find the end of the chain\n            while 1:\n                exc_context = new_exc.__context__\n                if exc_context is None or exc_context is old_exc:\n                    # Context is already set correctly (see issue 20317)\n                    return\n                if exc_context is frame_exc:\n                    break\n                new_exc = exc_context\n            # Change the end of the chain to point to the exception\n            # we expect it to reference\n            new_exc.__context__ = old_exc\n\n        # Callbacks are invoked in LIFO order to match the behaviour of\n        # nested context managers\n        suppressed_exc = False\n        pending_raise = False\n        while self._exit_callbacks:\n            is_sync, cb = self._exit_callbacks.pop()\n            try:\n                if is_sync:\n                    cb_suppress = cb(*exc_details)\n                else:\n                    cb_suppress = await cb(*exc_details)\n\n                if cb_suppress:\n                    suppressed_exc = True\n                    pending_raise = False\n                    exc_details = (None, None, None)\n            except:\n                new_exc_details = sys.exc_info()\n                # simulate the stack of exceptions by setting the context\n                _fix_exception_context(new_exc_details[1], exc_details[1])\n                pending_raise = True\n                exc_details = new_exc_details\n        if pending_raise:\n            try:\n                # bare \"raise exc_details[1]\" replaces our carefully\n                # set-up context\n                fixed_ctx = exc_details[1].__context__\n                raise exc_details[1]\n            except BaseException:\n                exc_details[1].__context__ = fixed_ctx\n                raise\n        return received_exc and suppressed_exc\n\n\nclass nullcontext(AbstractContextManager):\n    \"\"\"Context manager that does no additional processing.\n\n    Used as a stand-in for a normal context manager, when a particular\n    block of code is only sometimes used with a normal context manager:\n\n    cm = optional_cm if condition else nullcontext()\n    with cm:\n        # Perform operation, using optional_cm if condition is True\n    \"\"\"\n\n    def __init__(self, enter_result=None):\n        self.enter_result = enter_result\n\n    def __enter__(self):\n        return self.enter_result\n\n    def __exit__(self, *excinfo):\n        pass\n", 695], "/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/_ufunc_config.py": ["\"\"\"\nFunctions for changing global ufunc configuration\n\nThis provides helpers which wrap `umath.geterrobj` and `umath.seterrobj`\n\"\"\"\nimport collections.abc\nimport contextlib\n\nfrom .overrides import set_module\nfrom .umath import (\n    UFUNC_BUFSIZE_DEFAULT,\n    ERR_IGNORE, ERR_WARN, ERR_RAISE, ERR_CALL, ERR_PRINT, ERR_LOG, ERR_DEFAULT,\n    SHIFT_DIVIDEBYZERO, SHIFT_OVERFLOW, SHIFT_UNDERFLOW, SHIFT_INVALID,\n)\nfrom . import umath\n\n__all__ = [\n    \"seterr\", \"geterr\", \"setbufsize\", \"getbufsize\", \"seterrcall\", \"geterrcall\",\n    \"errstate\",\n]\n\n_errdict = {\"ignore\": ERR_IGNORE,\n            \"warn\": ERR_WARN,\n            \"raise\": ERR_RAISE,\n            \"call\": ERR_CALL,\n            \"print\": ERR_PRINT,\n            \"log\": ERR_LOG}\n\n_errdict_rev = {value: key for key, value in _errdict.items()}\n\n\n@set_module('numpy')\ndef seterr(all=None, divide=None, over=None, under=None, invalid=None):\n    \"\"\"\n    Set how floating-point errors are handled.\n\n    Note that operations on integer scalar types (such as `int16`) are\n    handled like floating point, and are affected by these settings.\n\n    Parameters\n    ----------\n    all : {'ignore', 'warn', 'raise', 'call', 'print', 'log'}, optional\n        Set treatment for all types of floating-point errors at once:\n\n        - ignore: Take no action when the exception occurs.\n        - warn: Print a `RuntimeWarning` (via the Python `warnings` module).\n        - raise: Raise a `FloatingPointError`.\n        - call: Call a function specified using the `seterrcall` function.\n        - print: Print a warning directly to ``stdout``.\n        - log: Record error in a Log object specified by `seterrcall`.\n\n        The default is not to change the current behavior.\n    divide : {'ignore', 'warn', 'raise', 'call', 'print', 'log'}, optional\n        Treatment for division by zero.\n    over : {'ignore', 'warn', 'raise', 'call', 'print', 'log'}, optional\n        Treatment for floating-point overflow.\n    under : {'ignore', 'warn', 'raise', 'call', 'print', 'log'}, optional\n        Treatment for floating-point underflow.\n    invalid : {'ignore', 'warn', 'raise', 'call', 'print', 'log'}, optional\n        Treatment for invalid floating-point operation.\n\n    Returns\n    -------\n    old_settings : dict\n        Dictionary containing the old settings.\n\n    See also\n    --------\n    seterrcall : Set a callback function for the 'call' mode.\n    geterr, geterrcall, errstate\n\n    Notes\n    -----\n    The floating-point exceptions are defined in the IEEE 754 standard [1]_:\n\n    - Division by zero: infinite result obtained from finite numbers.\n    - Overflow: result too large to be expressed.\n    - Underflow: result so close to zero that some precision\n      was lost.\n    - Invalid operation: result is not an expressible number, typically\n      indicates that a NaN was produced.\n\n    .. [1] https://en.wikipedia.org/wiki/IEEE_754\n\n    Examples\n    --------\n    >>> old_settings = np.seterr(all='ignore')  #seterr to known value\n    >>> np.seterr(over='raise')\n    {'divide': 'ignore', 'over': 'ignore', 'under': 'ignore', 'invalid': 'ignore'}\n    >>> np.seterr(**old_settings)  # reset to default\n    {'divide': 'ignore', 'over': 'raise', 'under': 'ignore', 'invalid': 'ignore'}\n\n    >>> np.int16(32000) * np.int16(3)\n    30464\n    >>> old_settings = np.seterr(all='warn', over='raise')\n    >>> np.int16(32000) * np.int16(3)\n    Traceback (most recent call last):\n      File \"<stdin>\", line 1, in <module>\n    FloatingPointError: overflow encountered in short_scalars\n\n    >>> old_settings = np.seterr(all='print')\n    >>> np.geterr()\n    {'divide': 'print', 'over': 'print', 'under': 'print', 'invalid': 'print'}\n    >>> np.int16(32000) * np.int16(3)\n    30464\n\n    \"\"\"\n\n    pyvals = umath.geterrobj()\n    old = geterr()\n\n    if divide is None:\n        divide = all or old['divide']\n    if over is None:\n        over = all or old['over']\n    if under is None:\n        under = all or old['under']\n    if invalid is None:\n        invalid = all or old['invalid']\n\n    maskvalue = ((_errdict[divide] << SHIFT_DIVIDEBYZERO) +\n                 (_errdict[over] << SHIFT_OVERFLOW) +\n                 (_errdict[under] << SHIFT_UNDERFLOW) +\n                 (_errdict[invalid] << SHIFT_INVALID))\n\n    pyvals[1] = maskvalue\n    umath.seterrobj(pyvals)\n    return old\n\n\n@set_module('numpy')\ndef geterr():\n    \"\"\"\n    Get the current way of handling floating-point errors.\n\n    Returns\n    -------\n    res : dict\n        A dictionary with keys \"divide\", \"over\", \"under\", and \"invalid\",\n        whose values are from the strings \"ignore\", \"print\", \"log\", \"warn\",\n        \"raise\", and \"call\". The keys represent possible floating-point\n        exceptions, and the values define how these exceptions are handled.\n\n    See Also\n    --------\n    geterrcall, seterr, seterrcall\n\n    Notes\n    -----\n    For complete documentation of the types of floating-point exceptions and\n    treatment options, see `seterr`.\n\n    Examples\n    --------\n    >>> np.geterr()\n    {'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}\n    >>> np.arange(3.) / np.arange(3.)\n    array([nan,  1.,  1.])\n\n    >>> oldsettings = np.seterr(all='warn', over='raise')\n    >>> np.geterr()\n    {'divide': 'warn', 'over': 'raise', 'under': 'warn', 'invalid': 'warn'}\n    >>> np.arange(3.) / np.arange(3.)\n    array([nan,  1.,  1.])\n\n    \"\"\"\n    maskvalue = umath.geterrobj()[1]\n    mask = 7\n    res = {}\n    val = (maskvalue >> SHIFT_DIVIDEBYZERO) & mask\n    res['divide'] = _errdict_rev[val]\n    val = (maskvalue >> SHIFT_OVERFLOW) & mask\n    res['over'] = _errdict_rev[val]\n    val = (maskvalue >> SHIFT_UNDERFLOW) & mask\n    res['under'] = _errdict_rev[val]\n    val = (maskvalue >> SHIFT_INVALID) & mask\n    res['invalid'] = _errdict_rev[val]\n    return res\n\n\n@set_module('numpy')\ndef setbufsize(size):\n    \"\"\"\n    Set the size of the buffer used in ufuncs.\n\n    Parameters\n    ----------\n    size : int\n        Size of buffer.\n\n    \"\"\"\n    if size > 10e6:\n        raise ValueError(\"Buffer size, %s, is too big.\" % size)\n    if size < 5:\n        raise ValueError(\"Buffer size, %s, is too small.\" % size)\n    if size % 16 != 0:\n        raise ValueError(\"Buffer size, %s, is not a multiple of 16.\" % size)\n\n    pyvals = umath.geterrobj()\n    old = getbufsize()\n    pyvals[0] = size\n    umath.seterrobj(pyvals)\n    return old\n\n\n@set_module('numpy')\ndef getbufsize():\n    \"\"\"\n    Return the size of the buffer used in ufuncs.\n\n    Returns\n    -------\n    getbufsize : int\n        Size of ufunc buffer in bytes.\n\n    \"\"\"\n    return umath.geterrobj()[0]\n\n\n@set_module('numpy')\ndef seterrcall(func):\n    \"\"\"\n    Set the floating-point error callback function or log object.\n\n    There are two ways to capture floating-point error messages.  The first\n    is to set the error-handler to 'call', using `seterr`.  Then, set\n    the function to call using this function.\n\n    The second is to set the error-handler to 'log', using `seterr`.\n    Floating-point errors then trigger a call to the 'write' method of\n    the provided object.\n\n    Parameters\n    ----------\n    func : callable f(err, flag) or object with write method\n        Function to call upon floating-point errors ('call'-mode) or\n        object whose 'write' method is used to log such message ('log'-mode).\n\n        The call function takes two arguments. The first is a string describing\n        the type of error (such as \"divide by zero\", \"overflow\", \"underflow\",\n        or \"invalid value\"), and the second is the status flag.  The flag is a\n        byte, whose four least-significant bits indicate the type of error, one\n        of \"divide\", \"over\", \"under\", \"invalid\"::\n\n          [0 0 0 0 divide over under invalid]\n\n        In other words, ``flags = divide + 2*over + 4*under + 8*invalid``.\n\n        If an object is provided, its write method should take one argument,\n        a string.\n\n    Returns\n    -------\n    h : callable, log instance or None\n        The old error handler.\n\n    See Also\n    --------\n    seterr, geterr, geterrcall\n\n    Examples\n    --------\n    Callback upon error:\n\n    >>> def err_handler(type, flag):\n    ...     print(\"Floating point error (%s), with flag %s\" % (type, flag))\n    ...\n\n    >>> saved_handler = np.seterrcall(err_handler)\n    >>> save_err = np.seterr(all='call')\n\n    >>> np.array([1, 2, 3]) / 0.0\n    Floating point error (divide by zero), with flag 1\n    array([inf, inf, inf])\n\n    >>> np.seterrcall(saved_handler)\n    <function err_handler at 0x...>\n    >>> np.seterr(**save_err)\n    {'divide': 'call', 'over': 'call', 'under': 'call', 'invalid': 'call'}\n\n    Log error message:\n\n    >>> class Log:\n    ...     def write(self, msg):\n    ...         print(\"LOG: %s\" % msg)\n    ...\n\n    >>> log = Log()\n    >>> saved_handler = np.seterrcall(log)\n    >>> save_err = np.seterr(all='log')\n\n    >>> np.array([1, 2, 3]) / 0.0\n    LOG: Warning: divide by zero encountered in true_divide\n    array([inf, inf, inf])\n\n    >>> np.seterrcall(saved_handler)\n    <numpy.core.numeric.Log object at 0x...>\n    >>> np.seterr(**save_err)\n    {'divide': 'log', 'over': 'log', 'under': 'log', 'invalid': 'log'}\n\n    \"\"\"\n    if func is not None and not isinstance(func, collections.abc.Callable):\n        if (not hasattr(func, 'write') or\n                not isinstance(func.write, collections.abc.Callable)):\n            raise ValueError(\"Only callable can be used as callback\")\n    pyvals = umath.geterrobj()\n    old = geterrcall()\n    pyvals[2] = func\n    umath.seterrobj(pyvals)\n    return old\n\n\n@set_module('numpy')\ndef geterrcall():\n    \"\"\"\n    Return the current callback function used on floating-point errors.\n\n    When the error handling for a floating-point error (one of \"divide\",\n    \"over\", \"under\", or \"invalid\") is set to 'call' or 'log', the function\n    that is called or the log instance that is written to is returned by\n    `geterrcall`. This function or log instance has been set with\n    `seterrcall`.\n\n    Returns\n    -------\n    errobj : callable, log instance or None\n        The current error handler. If no handler was set through `seterrcall`,\n        ``None`` is returned.\n\n    See Also\n    --------\n    seterrcall, seterr, geterr\n\n    Notes\n    -----\n    For complete documentation of the types of floating-point exceptions and\n    treatment options, see `seterr`.\n\n    Examples\n    --------\n    >>> np.geterrcall()  # we did not yet set a handler, returns None\n\n    >>> oldsettings = np.seterr(all='call')\n    >>> def err_handler(type, flag):\n    ...     print(\"Floating point error (%s), with flag %s\" % (type, flag))\n    >>> oldhandler = np.seterrcall(err_handler)\n    >>> np.array([1, 2, 3]) / 0.0\n    Floating point error (divide by zero), with flag 1\n    array([inf, inf, inf])\n\n    >>> cur_handler = np.geterrcall()\n    >>> cur_handler is err_handler\n    True\n\n    \"\"\"\n    return umath.geterrobj()[2]\n\n\nclass _unspecified:\n    pass\n\n\n_Unspecified = _unspecified()\n\n\n@set_module('numpy')\nclass errstate(contextlib.ContextDecorator):\n    \"\"\"\n    errstate(**kwargs)\n\n    Context manager for floating-point error handling.\n\n    Using an instance of `errstate` as a context manager allows statements in\n    that context to execute with a known error handling behavior. Upon entering\n    the context the error handling is set with `seterr` and `seterrcall`, and\n    upon exiting it is reset to what it was before.\n\n    ..  versionchanged:: 1.17.0\n        `errstate` is also usable as a function decorator, saving\n        a level of indentation if an entire function is wrapped.\n        See :py:class:`contextlib.ContextDecorator` for more information.\n\n    Parameters\n    ----------\n    kwargs : {divide, over, under, invalid}\n        Keyword arguments. The valid keywords are the possible floating-point\n        exceptions. Each keyword should have a string value that defines the\n        treatment for the particular error. Possible values are\n        {'ignore', 'warn', 'raise', 'call', 'print', 'log'}.\n\n    See Also\n    --------\n    seterr, geterr, seterrcall, geterrcall\n\n    Notes\n    -----\n    For complete documentation of the types of floating-point exceptions and\n    treatment options, see `seterr`.\n\n    Examples\n    --------\n    >>> olderr = np.seterr(all='ignore')  # Set error handling to known state.\n\n    >>> np.arange(3) / 0.\n    array([nan, inf, inf])\n    >>> with np.errstate(divide='warn'):\n    ...     np.arange(3) / 0.\n    array([nan, inf, inf])\n\n    >>> np.sqrt(-1)\n    nan\n    >>> with np.errstate(invalid='raise'):\n    ...     np.sqrt(-1)\n    Traceback (most recent call last):\n      File \"<stdin>\", line 2, in <module>\n    FloatingPointError: invalid value encountered in sqrt\n\n    Outside the context the error handling behavior has not changed:\n\n    >>> np.geterr()\n    {'divide': 'ignore', 'over': 'ignore', 'under': 'ignore', 'invalid': 'ignore'}\n\n    \"\"\"\n\n    def __init__(self, *, call=_Unspecified, **kwargs):\n        self.call = call\n        self.kwargs = kwargs\n\n    def __enter__(self):\n        self.oldstate = seterr(**self.kwargs)\n        if self.call is not _Unspecified:\n            self.oldcall = seterrcall(self.call)\n\n    def __exit__(self, *exc_info):\n        seterr(**self.oldstate)\n        if self.call is not _Unspecified:\n            seterrcall(self.oldcall)\n\n\ndef _setdef():\n    defval = [UFUNC_BUFSIZE_DEFAULT, ERR_DEFAULT, None]\n    umath.seterrobj(defval)\n\n\n# set the default values\n_setdef()\n", 446], "/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_VF.py": ["\"\"\"\nThis makes the functions in torch._C._VariableFunctions available as\n    torch._VF.<funcname>\nwithout mypy being able to find them.\n\nA subset of those functions are mapped to ATen functions in\ntorch/jit/_builtins.py\n\nSee https://github.com/pytorch/pytorch/issues/21478 for the reason for\nintroducing torch._VF\n\n\"\"\"\nimport torch\nimport sys\nimport types\n\n\nclass VFModule(types.ModuleType):\n    vf: types.ModuleType\n\n    def __init__(self, name):\n        super(VFModule, self).__init__(name)\n        self.vf = torch._C._VariableFunctions\n\n    def __getattr__(self, attr):\n        return getattr(self.vf, attr)\n\n\nsys.modules[__name__] = VFModule(__name__)\n", 29], "/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/functional.py": ["from typing import (\n    Tuple, Optional, Union, Any, Sequence, TYPE_CHECKING\n)\n\nimport torch\nimport torch.nn.functional as F\nfrom ._lowrank import svd_lowrank, pca_lowrank\nfrom .overrides import (\n    has_torch_function, has_torch_function_unary, has_torch_function_variadic,\n    handle_torch_function)\nfrom ._jit_internal import boolean_dispatch, List\nfrom ._jit_internal import _overload as overload\n\nTensor = torch.Tensor\nfrom torch import _VF\n\n__all__ = [\n    'atleast_1d',\n    'atleast_2d',\n    'atleast_3d',\n    'align_tensors',\n    'broadcast_shapes',\n    'broadcast_tensors',\n    'cartesian_prod',\n    'block_diag',\n    'cdist',\n    'chain_matmul',\n    'einsum',\n    'istft',\n    'lu',\n    'norm',\n    'meshgrid',\n    'pca_lowrank',\n    'split',\n    'stft',\n    'svd_lowrank',\n    'tensordot',\n    'unique',\n    'unique_consecutive',\n]\n\n\ndef broadcast_tensors(*tensors):\n    r\"\"\"broadcast_tensors(*tensors) -> List of Tensors\n\n    Broadcasts the given tensors according to :ref:`broadcasting-semantics`.\n\n    Args:\n        *tensors: any number of tensors of the same type\n\n    .. warning::\n\n        More than one element of a broadcasted tensor may refer to a single\n        memory location. As a result, in-place operations (especially ones that\n        are vectorized) may result in incorrect behavior. If you need to write\n        to the tensors, please clone them first.\n\n    Example::\n\n        >>> x = torch.arange(3).view(1, 3)\n        >>> y = torch.arange(2).view(2, 1)\n        >>> a, b = torch.broadcast_tensors(x, y)\n        >>> a.size()\n        torch.Size([2, 3])\n        >>> a\n        tensor([[0, 1, 2],\n                [0, 1, 2]])\n    \"\"\"\n    # This wrapper exists to support variadic args.\n    if has_torch_function(tensors):\n        return handle_torch_function(broadcast_tensors, tensors, *tensors)\n    return _VF.broadcast_tensors(tensors)  # type: ignore[attr-defined]\n\n\ndef broadcast_shapes(*shapes):\n    r\"\"\"broadcast_shapes(*shapes) -> Size\n\n    Similar to :func:`broadcast_tensors` but for shapes.\n\n    This is equivalent to\n    ``torch.broadcast_tensors(*map(torch.empty, shapes))[0].shape``\n    but avoids the need create to intermediate tensors. This is useful for\n    broadcasting tensors of common batch shape but different rightmost shape,\n    e.g. to broadcast mean vectors with covariance matrices.\n\n    Example::\n\n        >>> torch.broadcast_shapes((2,), (3, 1), (1, 1, 1))\n        torch.Size([1, 3, 2])\n\n    Args:\n        \\*shapes (torch.Size): Shapes of tensors.\n\n    Returns:\n        shape (torch.Size): A shape compatible with all input shapes.\n\n    Raises:\n        RuntimeError: If shapes are incompatible.\n    \"\"\"\n    # This wrapper exists to support variadic args.\n    # TODO Movie this to C++ once the jit has better support for torch.Size.\n    with torch.no_grad():\n        scalar = torch.zeros((), device=\"cpu\")\n        tensors = [scalar.expand(shape) for shape in shapes]\n        tensors = broadcast_tensors(*tensors)\n        return tensors[0].shape\n\n\ndef split(tensor, split_size_or_sections, dim=0):\n    r\"\"\"Splits the tensor into chunks. Each chunk is a view of the original tensor.\n\n    If :attr:`split_size_or_sections` is an integer type, then :attr:`tensor` will\n    be split into equally sized chunks (if possible). Last chunk will be smaller if\n    the tensor size along the given dimension :attr:`dim` is not divisible by\n    :attr:`split_size`.\n\n    If :attr:`split_size_or_sections` is a list, then :attr:`tensor` will be split\n    into ``len(split_size_or_sections)`` chunks with sizes in :attr:`dim` according\n    to :attr:`split_size_or_sections`.\n\n    Args:\n        tensor (Tensor): tensor to split.\n        split_size_or_sections (int) or (list(int)): size of a single chunk or\n            list of sizes for each chunk\n        dim (int): dimension along which to split the tensor.\n\n    Example::\n\n        >>> a = torch.arange(10).reshape(5,2)\n        >>> a\n        tensor([[0, 1],\n                [2, 3],\n                [4, 5],\n                [6, 7],\n                [8, 9]])\n        >>> torch.split(a, 2)\n        (tensor([[0, 1],\n                 [2, 3]]),\n         tensor([[4, 5],\n                 [6, 7]]),\n         tensor([[8, 9]]))\n        >>> torch.split(a, [1,4])\n        (tensor([[0, 1]]),\n         tensor([[2, 3],\n                 [4, 5],\n                 [6, 7],\n                 [8, 9]]))\n    \"\"\"\n    if has_torch_function_unary(tensor):\n        return handle_torch_function(\n            split, (tensor,), tensor, split_size_or_sections, dim=dim)\n    # Overwriting reason:\n    # This dispatches to two ATen functions depending on the type of\n    # split_size_or_sections. The branching code is in _tensor.py, which we\n    # call here.\n    return tensor.split(split_size_or_sections, dim)\n\n\ndef einsum(*args):\n    r\"\"\"einsum(equation, *operands) -> Tensor\n\n    Sums the product of the elements of the input :attr:`operands` along dimensions specified using a notation\n    based on the Einstein summation convention.\n\n    Einsum allows computing many common multi-dimensional linear algebraic array operations by representing them\n    in a short-hand format based on the Einstein summation convention, given by :attr:`equation`. The details of\n    this format are described below, but the general idea is to label every dimension of the input :attr:`operands`\n    with some subscript and define which subscripts are part of the output. The output is then computed by summing\n    the product of the elements of the :attr:`operands` along the dimensions whose subscripts are not part of the\n    output. For example, matrix multiplication can be computed using einsum as `torch.einsum(\"ij,jk->ik\", A, B)`.\n    Here, j is the summation subscript and i and k the output subscripts (see section below for more details on why).\n\n    Equation:\n\n        The :attr:`equation` string specifies the subscripts (letters in `[a-zA-Z]`) for each dimension of\n        the input :attr:`operands` in the same order as the dimensions, separating subcripts for each operand by a\n        comma (','), e.g. `'ij,jk'` specify subscripts for two 2D operands. The dimensions labeled with the same subscript\n        must be broadcastable, that is, their size must either match or be `1`. The exception is if a subscript is\n        repeated for the same input operand, in which case the dimensions labeled with this subscript for this operand\n        must match in size and the operand will be replaced by its diagonal along these dimensions. The subscripts that\n        appear exactly once in the :attr:`equation` will be part of the output, sorted in increasing alphabetical order.\n        The output is computed by multiplying the input :attr:`operands` element-wise, with their dimensions aligned based\n        on the subscripts, and then summing out the dimensions whose subscripts are not part of the output.\n\n        Optionally, the output subscripts can be explicitly defined by adding an arrow ('->') at the end of the equation\n        followed by the subscripts for the output. For instance, the following equation computes the transpose of a\n        matrix multiplication: 'ij,jk->ki'. The output subscripts must appear at least once for some input operand and\n        at most once for the output.\n\n        Ellipsis ('...') can be used in place of subscripts to broadcast the dimensions covered by the ellipsis.\n        Each input operand may contain at most one ellipsis which will cover the dimensions not covered by subscripts,\n        e.g. for an input operand with 5 dimensions, the ellipsis in the equation `'ab...c'` cover the third and fourth\n        dimensions. The ellipsis does not need to cover the same number of dimensions across the :attr:`operands` but the\n        'shape' of the ellipsis (the size of the dimensions covered by them) must broadcast together. If the output is not\n        explicitly defined with the arrow ('->') notation, the ellipsis will come first in the output (left-most dimensions),\n        before the subscript labels that appear exactly once for the input operands. e.g. the following equation implements\n        batch matrix multiplication `'...ij,...jk'`.\n\n        A few final notes: the equation may contain whitespaces between the different elements (subscripts, ellipsis,\n        arrow and comma) but something like `'. . .'` is not valid. An empty string `''` is valid for scalar operands.\n\n    .. note::\n\n        ``torch.einsum`` handles ellipsis ('...') differently from NumPy in that it allows dimensions\n        covered by the ellipsis to be summed over, that is, ellipsis are not required to be part of the output.\n\n    .. note::\n\n        This function does not optimize the given expression, so a different formula for the same computation may\n        run faster or consume less memory. Projects like opt_einsum (https://optimized-einsum.readthedocs.io/en/stable/)\n        can optimize the formula for you.\n\n    .. note::\n\n        As of PyTorch 1.10 :func:`torch.einsum` also supports the sublist format (see examples below). In this format,\n        subscripts for each operand are specified by sublists, list of integers in the range [0, 52). These sublists\n        follow their operands, and an extra sublist can appear at the end of the input to specify the output's\n        subscripts., e.g. `torch.einsum(op1, sublist1, op2, sublist2, ..., [subslist_out])`. Python's `Ellipsis` object\n        may be provided in a sublist to enable broadcasting as described in the Equation section above.\n\n    Args:\n        equation (string): The subscripts for the Einstein summation.\n        operands (List[Tensor]): The tensors to compute the Einstein summation of.\n\n    Examples::\n\n        # trace\n        >>> torch.einsum('ii', torch.randn(4, 4))\n        tensor(-1.2104)\n\n        # diagonal\n        >>> torch.einsum('ii->i', torch.randn(4, 4))\n        tensor([-0.1034,  0.7952, -0.2433,  0.4545])\n\n        # outer product\n        >>> x = torch.randn(5)\n        >>> y = torch.randn(4)\n        >>> torch.einsum('i,j->ij', x, y)\n        tensor([[ 0.1156, -0.2897, -0.3918,  0.4963],\n                [-0.3744,  0.9381,  1.2685, -1.6070],\n                [ 0.7208, -1.8058, -2.4419,  3.0936],\n                [ 0.1713, -0.4291, -0.5802,  0.7350],\n                [ 0.5704, -1.4290, -1.9323,  2.4480]])\n\n        # batch matrix multiplication\n        >>> As = torch.randn(3,2,5)\n        >>> Bs = torch.randn(3,5,4)\n        >>> torch.einsum('bij,bjk->bik', As, Bs)\n        tensor([[[-1.0564, -1.5904,  3.2023,  3.1271],\n                [-1.6706, -0.8097, -0.8025, -2.1183]],\n\n                [[ 4.2239,  0.3107, -0.5756, -0.2354],\n                [-1.4558, -0.3460,  1.5087, -0.8530]],\n\n                [[ 2.8153,  1.8787, -4.3839, -1.2112],\n                [ 0.3728, -2.1131,  0.0921,  0.8305]]])\n\n        # with sublist format and ellipsis\n        >>> torch.einsum(As, [..., 0, 1], Bs, [..., 1, 2], [..., 0, 2])\n        tensor([[[-1.0564, -1.5904,  3.2023,  3.1271],\n                [-1.6706, -0.8097, -0.8025, -2.1183]],\n\n                [[ 4.2239,  0.3107, -0.5756, -0.2354],\n                [-1.4558, -0.3460,  1.5087, -0.8530]],\n\n                [[ 2.8153,  1.8787, -4.3839, -1.2112],\n                [ 0.3728, -2.1131,  0.0921,  0.8305]]])\n\n        # batch permute\n        >>> A = torch.randn(2, 3, 4, 5)\n        >>> torch.einsum('...ij->...ji', A).shape\n        torch.Size([2, 3, 5, 4])\n\n        # equivalent to torch.nn.functional.bilinear\n        >>> A = torch.randn(3,5,4)\n        >>> l = torch.randn(2,5)\n        >>> r = torch.randn(2,4)\n        >>> torch.einsum('bn,anm,bm->ba', l, A, r)\n        tensor([[-0.3430, -5.2405,  0.4494],\n                [ 0.3311,  5.5201, -3.0356]])\n    \"\"\"\n    # This wrapper exists to support variadic args.\n    if len(args) < 2:\n        raise ValueError('einsum(): must specify the equation string and at least one operand, '\n                         'or at least one operand and its subscripts list')\n\n    equation = None\n    operands = None\n\n    if isinstance(args[0], torch.Tensor):\n        # Convert the subscript list format which is an interleaving of operand and its subscripts\n        # list with an optional output subscripts list at the end (see documentation for more details on this)\n        # to the equation string format by creating the equation string from the subscripts list and grouping the\n        # input operands into a tensorlist (List[Tensor]).\n        def parse_subscript(n: int) -> str:\n            if n == Ellipsis:\n                return '...'\n            if n >= 0 and n < 26:\n                return chr(ord('A') + n)\n            if n >= 26 and n < 52:\n                return chr(ord('a') + n - 26)\n            raise ValueError('einsum(): subscript in subscript list is not within the valid range [0, 52)')\n\n        # Parse subscripts for input operands\n        equation = ','.join(''.join(parse_subscript(s) for s in l) for l in args[1::2])\n\n        # Parse optional output subscripts (provided when the number of arguments is odd)\n        if len(args) % 2 == 1:\n            equation += '->' + ''.join(parse_subscript(s) for s in args[-1])\n            operands = args[:-1:2]\n        else:\n            operands = args[::2]\n    else:\n        equation = args[0]\n        operands = args[1:]\n\n    if has_torch_function(operands):\n        return handle_torch_function(einsum, operands, equation, *operands)\n\n    if len(operands) == 1 and isinstance(operands[0], (list, tuple)):\n        # the old interface of passing the operands as one list argument\n        _operands = operands[0]\n        # recurse incase operands contains value that has torch function\n        # in the original implementation this line is omitted\n        return einsum(equation, *_operands)\n\n    return _VF.einsum(equation, operands)  # type: ignore[attr-defined]\n\n\n# This wrapper exists to support variadic args.\nif TYPE_CHECKING:\n    # The JIT doesn't understand Union, so only add type annotation for mypy\n    def meshgrid(*tensors: Union[Tensor, List[Tensor]],\n                 indexing: Optional[str] = None) -> Tuple[Tensor, ...]:\n        return _meshgrid(*tensors, indexing=indexing)\nelse:\n    def meshgrid(*tensors, indexing: Optional[str] = None) -> Tuple[Tensor, ...]:\n        r\"\"\"Creates grids of coordinates specified by the 1D inputs in `attr`:tensors.\n\n        This is helpful when you want to visualize data over some\n        range of inputs. See below for a plotting example.\n\n        Given :math:`N` 1D tensors :math:`T_0 \\ldots T_{N-1}` as\n        inputs with corresponding sizes :math:`S_0 \\ldots S_{N-1}`,\n        this creates :math:`N` N-dimensional tensors :math:`G_0 \\ldots\n        G_{N-1}`, each with shape :math:`(S_0, ..., S_{N-1})` where\n        the output :math:`G_i` is constructed by expanding :math:`T_i`\n        to the result shape.\n\n        .. note::\n            0D inputs are treated equivalently to 1D inputs of a\n            single element.\n\n        .. warning::\n            `torch.meshgrid(*tensors)` currently has the same behavior\n            as calling `numpy.meshgrid(*arrays, indexing='ij')`.\n\n            In the future `torch.meshgrid` will transition to\n            `indexing='xy'` as the default.\n\n            https://github.com/pytorch/pytorch/issues/50276 tracks\n            this issue with the goal of migrating to NumPy's behavior.\n\n        .. seealso::\n\n            :func:`torch.cartesian_prod` has the same effect but it\n            collects the data in a tensor of vectors.\n\n        Args:\n            tensors (list of Tensor): list of scalars or 1 dimensional tensors. Scalars will be\n                treated as tensors of size :math:`(1,)` automatically\n\n            indexing: (str, optional): the indexing mode, either \"xy\"\n                or \"ij\", defaults to \"ij\". See warning for future changes.\n\n                If \"xy\" is selected, the first dimension corresponds\n                to the cardinality of the second input and the second\n                dimension corresponds to the cardinality of the first\n                input.\n\n                If \"ij\" is selected, the dimensions are in the same\n                order as the cardinality of the inputs.\n\n        Returns:\n            seq (sequence of Tensors): If the input has :math:`N`\n            tensors of size :math:`S_0 \\ldots S_{N-1}``, then the\n            output will also have :math:`N` tensors, where each tensor\n            is of shape :math:`(S_0, ..., S_{N-1})`.\n\n        Example::\n\n            >>> x = torch.tensor([1, 2, 3])\n            >>> y = torch.tensor([4, 5, 6])\n\n            Observe the element-wise pairings across the grid, (1, 4),\n            (1, 5), ..., (3, 6). This is the same thing as the\n            cartesian product.\n            >>> grid_x, grid_y = torch.meshgrid(x, y, indexing='ij')\n            >>> grid_x\n            tensor([[1, 1, 1],\n                    [2, 2, 2],\n                    [3, 3, 3]])\n            >>> grid_y\n            tensor([[4, 5, 6],\n                    [4, 5, 6],\n                    [4, 5, 6]])\n\n            This correspondence can be seen when these grids are\n            stacked properly.\n            >>> torch.equal(torch.cat(tuple(torch.dstack([grid_x, grid_y]))),\n            ...             torch.cartesian_prod(x, y))\n            True\n\n            `torch.meshgrid` is commonly used to produce a grid for\n            plotting.\n            >>> import matplotlib.pyplot as plt\n            >>> xs = torch.linspace(-5, 5, steps=100)\n            >>> ys = torch.linspace(-5, 5, steps=100)\n            >>> x, y = torch.meshgrid(xs, ys, indexing='xy')\n            >>> z = torch.sin(torch.sqrt(x * x + y * y))\n            >>> ax = plt.axes(projection='3d')\n            >>> ax.plot_surface(x.numpy(), y.numpy(), z.numpy())\n            <mpl_toolkits.mplot3d.art3d.Poly3DCollection object at 0x7f8f30d40100>\n            >>> plt.show()\n\n        .. image:: ../_static/img/meshgrid.png\n            :width: 512\n\n        \"\"\"\n        return _meshgrid(*tensors, indexing=indexing)\n\n\ndef _meshgrid(*tensors, indexing: Optional[str]):\n    if has_torch_function(tensors):\n        return handle_torch_function(meshgrid, tensors, *tensors, indexing=indexing)\n    if len(tensors) == 1 and isinstance(tensors[0], (list, tuple)):\n        # the old interface of passing the operands as one list argument\n        tensors = tensors[0]  # type: ignore[assignment]\n\n    # Continue allowing call of old method that takes no indexing\n    # kwarg for forward compatibility reasons.\n    #\n    # Remove this two weeks after landing.\n    kwargs = {} if indexing is None else {'indexing': indexing}\n    return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n\n\ndef stft(input: Tensor, n_fft: int, hop_length: Optional[int] = None,\n         win_length: Optional[int] = None, window: Optional[Tensor] = None,\n         center: bool = True, pad_mode: str = 'reflect', normalized: bool = False,\n         onesided: Optional[bool] = None,\n         return_complex: Optional[bool] = None) -> Tensor:\n    r\"\"\"Short-time Fourier transform (STFT).\n\n    .. warning::\n        From version 1.8.0, :attr:`return_complex` must always be given\n        explicitly for real inputs and `return_complex=False` has been\n        deprecated. Strongly prefer `return_complex=True` as in a future\n        pytorch release, this function will only return complex tensors.\n\n        Note that :func:`torch.view_as_real` can be used to recover a real\n        tensor with an extra last dimension for real and imaginary components.\n\n    The STFT computes the Fourier transform of short overlapping windows of the\n    input. This giving frequency components of the signal as they change over\n    time. The interface of this function is modeled after the librosa_ stft function.\n\n    .. _librosa: https://librosa.org/doc/latest/generated/librosa.stft.html\n\n    Ignoring the optional batch dimension, this method computes the following\n    expression:\n\n    .. math::\n        X[\\omega, m] = \\sum_{k = 0}^{\\text{win\\_length-1}}%\n                            \\text{window}[k]\\ \\text{input}[m \\times \\text{hop\\_length} + k]\\ %\n                            \\exp\\left(- j \\frac{2 \\pi \\cdot \\omega k}{\\text{win\\_length}}\\right),\n\n    where :math:`m` is the index of the sliding window, and :math:`\\omega` is\n    the frequency :math:`0 \\leq \\omega < \\text{n\\_fft}` for ``onesided=False``,\n    or :math:`0 \\leq \\omega < \\lfloor \\text{n\\_fft} / 2 \\rfloor + 1` for ``onesided=True``.\n\n    * :attr:`input` must be either a 1-D time sequence or a 2-D batch of time\n      sequences.\n\n    * If :attr:`hop_length` is ``None`` (default), it is treated as equal to\n      ``floor(n_fft / 4)``.\n\n    * If :attr:`win_length` is ``None`` (default), it is treated as equal to\n      :attr:`n_fft`.\n\n    * :attr:`window` can be a 1-D tensor of size :attr:`win_length`, e.g., from\n      :meth:`torch.hann_window`. If :attr:`window` is ``None`` (default), it is\n      treated as if having :math:`1` everywhere in the window. If\n      :math:`\\text{win\\_length} < \\text{n\\_fft}`, :attr:`window` will be padded on\n      both sides to length :attr:`n_fft` before being applied.\n\n    * If :attr:`center` is ``True`` (default), :attr:`input` will be padded on\n      both sides so that the :math:`t`-th frame is centered at time\n      :math:`t \\times \\text{hop\\_length}`. Otherwise, the :math:`t`-th frame\n      begins at time  :math:`t \\times \\text{hop\\_length}`.\n\n    * :attr:`pad_mode` determines the padding method used on :attr:`input` when\n      :attr:`center` is ``True``. See :meth:`torch.nn.functional.pad` for\n      all available options. Default is ``\"reflect\"``.\n\n    * If :attr:`onesided` is ``True`` (default for real input), only values for\n      :math:`\\omega` in :math:`\\left[0, 1, 2, \\dots, \\left\\lfloor\n      \\frac{\\text{n\\_fft}}{2} \\right\\rfloor + 1\\right]` are returned because\n      the real-to-complex Fourier transform satisfies the conjugate symmetry,\n      i.e., :math:`X[m, \\omega] = X[m, \\text{n\\_fft} - \\omega]^*`.\n      Note if the input or window tensors are complex, then :attr:`onesided`\n      output is not possible.\n\n    * If :attr:`normalized` is ``True`` (default is ``False``), the function\n      returns the normalized STFT results, i.e., multiplied by :math:`(\\text{frame\\_length})^{-0.5}`.\n\n    * If :attr:`return_complex` is ``True`` (default if input is complex), the\n      return is a ``input.dim() + 1`` dimensional complex tensor. If ``False``,\n      the output is a ``input.dim() + 2`` dimensional real tensor where the last\n      dimension represents the real and imaginary components.\n\n    Returns either a complex tensor of size :math:`(* \\times N \\times T)` if\n    :attr:`return_complex` is true, or a real tensor of size :math:`(* \\times N\n    \\times T \\times 2)`. Where :math:`*` is the optional batch size of\n    :attr:`input`, :math:`N` is the number of frequencies where STFT is applied\n    and :math:`T` is the total number of frames used.\n\n    .. warning::\n      This function changed signature at version 0.4.1. Calling with the\n      previous signature may cause error or return incorrect result.\n\n    Args:\n        input (Tensor): the input tensor\n        n_fft (int): size of Fourier transform\n        hop_length (int, optional): the distance between neighboring sliding window\n            frames. Default: ``None`` (treated as equal to ``floor(n_fft / 4)``)\n        win_length (int, optional): the size of window frame and STFT filter.\n            Default: ``None``  (treated as equal to :attr:`n_fft`)\n        window (Tensor, optional): the optional window function.\n            Default: ``None`` (treated as window of all :math:`1` s)\n        center (bool, optional): whether to pad :attr:`input` on both sides so\n            that the :math:`t`-th frame is centered at time :math:`t \\times \\text{hop\\_length}`.\n            Default: ``True``\n        pad_mode (string, optional): controls the padding method used when\n            :attr:`center` is ``True``. Default: ``\"reflect\"``\n        normalized (bool, optional): controls whether to return the normalized STFT results\n             Default: ``False``\n        onesided (bool, optional): controls whether to return half of results to\n            avoid redundancy for real inputs.\n            Default: ``True`` for real :attr:`input` and :attr:`window`, ``False`` otherwise.\n        return_complex (bool, optional): whether to return a complex tensor, or\n            a real tensor with an extra last dimension for the real and\n            imaginary components.\n\n    Returns:\n        Tensor: A tensor containing the STFT result with shape described above\n\n    \"\"\"\n    if has_torch_function_unary(input):\n        return handle_torch_function(\n            stft, (input,), input, n_fft, hop_length=hop_length, win_length=win_length,\n            window=window, center=center, pad_mode=pad_mode, normalized=normalized,\n            onesided=onesided, return_complex=return_complex)\n    # TODO: after having proper ways to map Python strings to ATen Enum, move\n    #       this and F.pad to ATen.\n    if center:\n        signal_dim = input.dim()\n        extended_shape = [1] * (3 - signal_dim) + list(input.size())\n        pad = int(n_fft // 2)\n        input = F.pad(input.view(extended_shape), [pad, pad], pad_mode)\n        input = input.view(input.shape[-signal_dim:])\n    return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n                    normalized, onesided, return_complex)\n\ndef istft(input: Tensor, n_fft: int, hop_length: Optional[int] = None,\n          win_length: Optional[int] = None, window: Optional[Tensor] = None,\n          center: bool = True, normalized: bool = False,\n          onesided: Optional[bool] = None, length: Optional[int] = None,\n          return_complex: bool = False) -> Tensor:\n    r\"\"\"Inverse short time Fourier Transform. This is expected to be the inverse of :func:`~torch.stft`.\n    It has the same parameters (+ additional optional parameter of :attr:`length`) and it should return the\n    least squares estimation of the original signal. The algorithm will check using the NOLA condition (\n    nonzero overlap).\n\n    Important consideration in the parameters :attr:`window` and :attr:`center` so that the envelop\n    created by the summation of all the windows is never zero at certain point in time. Specifically,\n    :math:`\\sum_{t=-\\infty}^{\\infty} |w|^2[n-t\\times hop\\_length] \\cancel{=} 0`.\n\n    Since :func:`~torch.stft` discards elements at the end of the signal if they do not fit in a frame,\n    ``istft`` may return a shorter signal than the original signal (can occur if :attr:`center` is False\n    since the signal isn't padded). If `length` is given in the arguments and is longer than expected,\n    ``istft`` will pad zeros to the end of the returned signal.\n\n    If :attr:`center` is ``True``, then there will be padding e.g. ``'constant'``, ``'reflect'``, etc.\n    Left padding can be trimmed off exactly because they can be calculated but right padding cannot be\n    calculated without additional information.\n\n    Example: Suppose the last window is:\n    ``[17, 18, 0, 0, 0]`` vs ``[18, 0, 0, 0, 0]``\n\n    The :attr:`n_fft`, :attr:`hop_length`, :attr:`win_length` are all the same which prevents the calculation\n    of right padding. These additional values could be zeros or a reflection of the signal so providing\n    :attr:`length` could be useful. If :attr:`length` is ``None`` then padding will be aggressively removed\n    (some loss of signal).\n\n    [1] D. W. Griffin and J. S. Lim, \"Signal estimation from modified short-time Fourier transform,\"\n    IEEE Trans. ASSP, vol.32, no.2, pp.236-243, Apr. 1984.\n\n    Args:\n        input (Tensor): The input tensor. Expected to be output of :func:`~torch.stft`,\n            can either be complex (``channel``, ``fft_size``, ``n_frame``), or real\n            (``channel``, ``fft_size``, ``n_frame``, 2) where the ``channel``\n            dimension is optional.\n\n            .. deprecated:: 1.8.0\n               Real input is deprecated, use complex inputs as returned by\n               ``stft(..., return_complex=True)`` instead.\n        n_fft (int): Size of Fourier transform\n        hop_length (Optional[int]): The distance between neighboring sliding window frames.\n            (Default: ``n_fft // 4``)\n        win_length (Optional[int]): The size of window frame and STFT filter. (Default: ``n_fft``)\n        window (Optional[torch.Tensor]): The optional window function.\n            (Default: ``torch.ones(win_length)``)\n        center (bool): Whether :attr:`input` was padded on both sides so that the :math:`t`-th frame is\n            centered at time :math:`t \\times \\text{hop\\_length}`.\n            (Default: ``True``)\n        normalized (bool): Whether the STFT was normalized. (Default: ``False``)\n        onesided (Optional[bool]): Whether the STFT was onesided.\n            (Default: ``True`` if ``n_fft != fft_size`` in the input size)\n        length (Optional[int]): The amount to trim the signal by (i.e. the\n            original signal length). (Default: whole signal)\n        return_complex (Optional[bool]):\n            Whether the output should be complex, or if the input should be\n            assumed to derive from a real signal and window.\n            Note that this is incompatible with ``onesided=True``.\n            (Default: ``False``)\n\n    Returns:\n        Tensor: Least squares estimation of the original signal of size (..., signal_length)\n    \"\"\"\n    if has_torch_function_unary(input):\n        return handle_torch_function(\n            istft, (input,), input, n_fft, hop_length=hop_length, win_length=win_length,\n            window=window, center=center, normalized=normalized, onesided=onesided,\n            length=length, return_complex=return_complex)\n\n    return _VF.istft(input, n_fft, hop_length, win_length, window, center,  # type: ignore[attr-defined]\n                     normalized, onesided, length, return_complex)\n\n\nif TYPE_CHECKING:\n    # These _impl functions return a variable number of tensors as output with\n    # __torch_function__; tuple unpacking is done already rather than being\n    # done by the caller of the _impl function\n    _unique_impl_out = Any\nelse:\n    _unique_impl_out = Tuple[Tensor, Tensor, Tensor]\n\n\ndef _unique_impl(input: Tensor, sorted: bool = True,\n                 return_inverse: bool = False, return_counts: bool = False,\n                 dim: Optional[int] = None) -> _unique_impl_out:\n    r\"\"\"Returns the unique elements of the input tensor.\n\n    .. note:: This function is different from :func:`torch.unique_consecutive` in the sense that\n        this function also eliminates non-consecutive duplicate values.\n\n    .. note:: Currently in the CUDA implementation and the CPU implementation when dim is specified,\n        `torch.unique` always sort the tensor at the beginning regardless of the `sort` argument.\n        Sorting could be slow, so if your input tensor is already sorted, it is recommended to use\n        :func:`torch.unique_consecutive` which avoids the sorting.\n\n    Args:\n        input (Tensor): the input tensor\n        sorted (bool): Whether to sort the unique elements in ascending order\n            before returning as output.\n        return_inverse (bool): Whether to also return the indices for where\n            elements in the original input ended up in the returned unique list.\n        return_counts (bool): Whether to also return the counts for each unique\n            element.\n        dim (int): the dimension to apply unique. If ``None``, the unique of the\n            flattened input is returned. default: ``None``\n\n    Returns:\n        (Tensor, Tensor (optional), Tensor (optional)): A tensor or a tuple of tensors containing\n\n            - **output** (*Tensor*): the output list of unique scalar elements.\n            - **inverse_indices** (*Tensor*): (optional) if\n              :attr:`return_inverse` is True, there will be an additional\n              returned tensor (same shape as input) representing the indices\n              for where elements in the original input map to in the output;\n              otherwise, this function will only return a single tensor.\n            - **counts** (*Tensor*): (optional) if\n              :attr:`return_counts` is True, there will be an additional\n              returned tensor (same shape as output or output.size(dim),\n              if dim was specified) representing the number of occurrences\n              for each unique value or tensor.\n\n    Example::\n\n        >>> output = torch.unique(torch.tensor([1, 3, 2, 3], dtype=torch.long))\n        >>> output\n        tensor([ 2,  3,  1])\n\n        >>> output, inverse_indices = torch.unique(\n        ...     torch.tensor([1, 3, 2, 3], dtype=torch.long), sorted=True, return_inverse=True)\n        >>> output\n        tensor([ 1,  2,  3])\n        >>> inverse_indices\n        tensor([ 0,  2,  1,  2])\n\n        >>> output, inverse_indices = torch.unique(\n        ...     torch.tensor([[1, 3], [2, 3]], dtype=torch.long), sorted=True, return_inverse=True)\n        >>> output\n        tensor([ 1,  2,  3])\n        >>> inverse_indices\n        tensor([[ 0,  2],\n                [ 1,  2]])\n\n    \"\"\"\n    if has_torch_function_unary(input):\n        return handle_torch_function(\n            unique, (input,), input, sorted=sorted, return_inverse=return_inverse,\n            return_counts=return_counts, dim=dim)\n\n    if dim is not None:\n        output, inverse_indices, counts = _VF.unique_dim(\n            input,\n            dim,\n            sorted=sorted,\n            return_inverse=return_inverse,\n            return_counts=return_counts,\n        )\n    else:\n        output, inverse_indices, counts = torch._unique2(\n            input,\n            sorted=sorted,\n            return_inverse=return_inverse,\n            return_counts=return_counts,\n        )\n    return output, inverse_indices, counts\n\n\ndef _unique_consecutive_impl(input: Tensor, return_inverse: bool = False,\n                             return_counts: bool = False,\n                             dim: Optional[int] = None) -> _unique_impl_out:\n    r\"\"\"Eliminates all but the first element from every consecutive group of equivalent elements.\n\n    .. note:: This function is different from :func:`torch.unique` in the sense that this function\n        only eliminates consecutive duplicate values. This semantics is similar to `std::unique`\n        in C++.\n\n    Args:\n        input (Tensor): the input tensor\n        return_inverse (bool): Whether to also return the indices for where\n            elements in the original input ended up in the returned unique list.\n        return_counts (bool): Whether to also return the counts for each unique\n            element.\n        dim (int): the dimension to apply unique. If ``None``, the unique of the\n            flattened input is returned. default: ``None``\n\n    Returns:\n        (Tensor, Tensor (optional), Tensor (optional)): A tensor or a tuple of tensors containing\n\n            - **output** (*Tensor*): the output list of unique scalar elements.\n            - **inverse_indices** (*Tensor*): (optional) if\n              :attr:`return_inverse` is True, there will be an additional\n              returned tensor (same shape as input) representing the indices\n              for where elements in the original input map to in the output;\n              otherwise, this function will only return a single tensor.\n            - **counts** (*Tensor*): (optional) if\n              :attr:`return_counts` is True, there will be an additional\n              returned tensor (same shape as output or output.size(dim),\n              if dim was specified) representing the number of occurrences\n              for each unique value or tensor.\n\n    Example::\n\n        >>> x = torch.tensor([1, 1, 2, 2, 3, 1, 1, 2])\n        >>> output = torch.unique_consecutive(x)\n        >>> output\n        tensor([1, 2, 3, 1, 2])\n\n        >>> output, inverse_indices = torch.unique_consecutive(x, return_inverse=True)\n        >>> output\n        tensor([1, 2, 3, 1, 2])\n        >>> inverse_indices\n        tensor([0, 0, 1, 1, 2, 3, 3, 4])\n\n        >>> output, counts = torch.unique_consecutive(x, return_counts=True)\n        >>> output\n        tensor([1, 2, 3, 1, 2])\n        >>> counts\n        tensor([2, 2, 1, 2, 1])\n    \"\"\"\n    if has_torch_function_unary(input):\n        return handle_torch_function(\n            unique_consecutive, (input,), input, return_inverse=return_inverse,\n            return_counts=return_counts, dim=dim)\n    output, inverse_indices, counts = _VF.unique_consecutive(  # type: ignore[attr-defined]\n        input, return_inverse=return_inverse, return_counts=return_counts, dim=dim)\n    return output, inverse_indices, counts\n\n\ndef _return_counts(input, sorted=True, return_inverse=False, return_counts=False, dim=None):\n    # type: (Tensor, bool, bool, bool, Optional[int]) -> Tuple[Tensor, Tensor]\n\n    if has_torch_function_unary(input):\n        return _unique_impl(input, sorted, return_inverse, return_counts, dim)\n\n    output, _, counts = _unique_impl(input, sorted, return_inverse, return_counts, dim)\n    return output, counts\n\n\ndef _return_output(input, sorted=True, return_inverse=False, return_counts=False, dim=None):\n    # type: (Tensor, bool, bool, bool, Optional[int]) -> Tensor\n\n    if has_torch_function_unary(input):\n        return _unique_impl(input, sorted, return_inverse, return_counts, dim)\n\n    output, _, _ = _unique_impl(input, sorted, return_inverse, return_counts, dim)\n    return output\n\n\ndef _return_inverse(input, sorted=True, return_inverse=False, return_counts=False, dim=None):\n    # type: (Tensor, bool, bool, bool, Optional[int]) -> Tuple[Tensor, Tensor]\n\n    if has_torch_function_unary(input):\n        return _unique_impl(input, sorted, return_inverse, return_counts, dim)\n\n    output, inverse_indices, _ = _unique_impl(input, sorted, return_inverse, return_counts, dim)\n    return output, inverse_indices\n\n\n_return_inverse_false = boolean_dispatch(\n    arg_name='return_counts',\n    arg_index=3,\n    default=False,\n    if_true=_return_counts,\n    if_false=_return_output,\n    module_name=__name__,\n    func_name='unique')\n\n_return_inverse_true = boolean_dispatch(\n    arg_name='return_counts',\n    arg_index=3,\n    default=False,\n    if_true=_unique_impl,\n    if_false=_return_inverse,\n    module_name=__name__,\n    func_name='unique')\n\n# The return type of unique depends on `return_inverse`, and `return_counts` so in order to\n# resolve the output type in TorchScript we need to statically know the value of both parameters\n\nunique = boolean_dispatch(\n    arg_name='return_inverse',\n    arg_index=2,\n    default=False,\n    if_true=_return_inverse_true,\n    if_false=_return_inverse_false,\n    module_name=__name__,\n    func_name='unique')\nunique.__doc__ = _unique_impl.__doc__\n\n\ndef _consecutive_return_counts(input, return_inverse=False, return_counts=False, dim=None):\n    # type: (Tensor, bool, bool, Optional[int]) -> Tuple[Tensor, Tensor]\n\n    if has_torch_function_unary(input):\n        return _unique_consecutive_impl(input, return_inverse, return_counts, dim)\n\n    output, _, counts = _unique_consecutive_impl(input, return_inverse, return_counts, dim)\n    return output, counts\n\n\ndef _consecutive_return_output(input, return_inverse=False, return_counts=False, dim=None):\n    # type: (Tensor, bool, bool, Optional[int]) -> Tensor\n\n    if has_torch_function_unary(input):\n        return _unique_consecutive_impl(input, return_inverse, return_counts, dim)\n\n    output, _, _ = _unique_consecutive_impl(input, return_inverse, return_counts, dim)\n    return output\n\n\ndef _consecutive_return_inverse(input, return_inverse=False, return_counts=False, dim=None):\n    # type: (Tensor, bool, bool, Optional[int]) -> Tuple[Tensor, Tensor]\n\n    if has_torch_function_unary(input):\n        return _unique_consecutive_impl(input, return_inverse, return_counts, dim)\n\n    output, inverse_indices, _ = _unique_consecutive_impl(input, return_inverse, return_counts, dim)\n    return output, inverse_indices\n\n\n_consecutive_return_inverse_false = boolean_dispatch(\n    arg_name='return_counts',\n    arg_index=1,\n    default=False,\n    if_true=_consecutive_return_counts,\n    if_false=_consecutive_return_output,\n    module_name=__name__,\n    func_name='unique_consecutive')\n\n_consecutive_return_inverse_true = boolean_dispatch(\n    arg_name='return_counts',\n    arg_index=1,\n    default=False,\n    if_true=_unique_consecutive_impl,\n    if_false=_consecutive_return_inverse,\n    module_name=__name__,\n    func_name='unique_consecutive')\n\n# The return type of unique depends on `return_inverse`, and `return_counts` so in order to\n# resolve the output type in TorchScript we need to statically know the value of both parameters\n\nunique_consecutive = boolean_dispatch(\n    arg_name='return_inverse',\n    arg_index=2,\n    default=False,\n    if_true=_consecutive_return_inverse_true,\n    if_false=_consecutive_return_inverse_false,\n    module_name=__name__,\n    func_name='unique_consecutive')\nunique_consecutive.__doc__ = _unique_consecutive_impl.__doc__\n\nif TYPE_CHECKING:\n    pass\n    # There's no good way to use this type annotation without breaking JIT\n    # overloads. So leave untyped for mypy for now.\nelse:\n    @overload\n    def tensordot(a, b, dims: int = 2, out: Optional[torch.Tensor] = None):\n        pass\n\n    @overload\n    def tensordot(a, b, dims: Tuple[List[int], List[int]], out: Optional[torch.Tensor] = None):  # noqa: F811\n        pass\n\n    @overload\n    def tensordot(a, b, dims: List[List[int]], out: Optional[torch.Tensor] = None):  # noqa: F811\n        pass\n\n    @overload\n    def tensordot(a, b, dims: torch.Tensor, out: Optional[torch.Tensor] = None):  # noqa: F811\n        pass\n\ndef tensordot(a, b, dims=2, out: Optional[torch.Tensor] = None):  # noqa: F811\n    r\"\"\"Returns a contraction of a and b over multiple dimensions.\n\n    :attr:`tensordot` implements a generalized matrix product.\n\n    Args:\n      a (Tensor): Left tensor to contract\n      b (Tensor): Right tensor to contract\n      dims (int or Tuple[List[int], List[int]] or List[List[int]] containing two lists or Tensor): number of dimensions to\n         contract or explicit lists of dimensions for :attr:`a` and\n         :attr:`b` respectively\n\n    When called with a non-negative integer argument :attr:`dims` = :math:`d`, and\n    the number of dimensions of :attr:`a` and :attr:`b` is :math:`m` and :math:`n`,\n    respectively, :func:`~torch.tensordot` computes\n\n    .. math::\n        r_{i_0,...,i_{m-d}, i_d,...,i_n}\n          = \\sum_{k_0,...,k_{d-1}} a_{i_0,...,i_{m-d},k_0,...,k_{d-1}} \\times b_{k_0,...,k_{d-1}, i_d,...,i_n}.\n\n    When called with :attr:`dims` of the list form, the given dimensions will be contracted\n    in place of the last :math:`d` of :attr:`a` and the first :math:`d` of :math:`b`. The sizes\n    in these dimensions must match, but :func:`~torch.tensordot` will deal with broadcasted\n    dimensions.\n\n    Examples::\n\n        >>> a = torch.arange(60.).reshape(3, 4, 5)\n        >>> b = torch.arange(24.).reshape(4, 3, 2)\n        >>> torch.tensordot(a, b, dims=([1, 0], [0, 1]))\n        tensor([[4400., 4730.],\n                [4532., 4874.],\n                [4664., 5018.],\n                [4796., 5162.],\n                [4928., 5306.]])\n\n        >>> a = torch.randn(3, 4, 5, device='cuda')\n        >>> b = torch.randn(4, 5, 6, device='cuda')\n        >>> c = torch.tensordot(a, b, dims=2).cpu()\n        tensor([[ 8.3504, -2.5436,  6.2922,  2.7556, -1.0732,  3.2741],\n                [ 3.3161,  0.0704,  5.0187, -0.4079, -4.3126,  4.8744],\n                [ 0.8223,  3.9445,  3.2168, -0.2400,  3.4117,  1.7780]])\n\n        >>> a = torch.randn(3, 5, 4, 6)\n        >>> b = torch.randn(6, 4, 5, 3)\n        >>> torch.tensordot(a, b, dims=([2, 1, 3], [1, 2, 0]))\n        tensor([[  7.7193,  -2.4867, -10.3204],\n                [  1.5513, -14.4737,  -6.5113],\n                [ -0.2850,   4.2573,  -3.5997]])\n    \"\"\"\n    if has_torch_function_variadic(a, b):\n        return handle_torch_function(tensordot, (a, b), a, b, dims=dims)\n\n    if not isinstance(dims, (tuple, list, torch.Tensor, int)):\n        raise RuntimeError(\"tensordot expects dims to be int or \"\n                           + \"Tuple[List[int], List[int]] or \"\n                           + \"List[List[int]] containing two lists, but got \"\n                           + f\"dims={dims}\")\n\n    dims_a: List[int] = []\n    dims_b: List[int] = []\n\n    if isinstance(dims, (tuple, list)):\n        dims_a, dims_b = dims\n\n    if isinstance(dims, torch.Tensor):\n        num_elements = dims.numel()\n        if num_elements > 1:\n            assert dims.size()[0] == 2\n            dims_a = torch.jit.annotate(List[int], dims[0].tolist())\n            dims_b = torch.jit.annotate(List[int], dims[1].tolist())\n        else:\n            dims_val = int(dims.item())\n            if dims_val < 0:\n                raise RuntimeError(f\"tensordot expects dims >= 0, but got dims={dims}\")\n            dims_a = list(range(-dims_val, 0))\n            dims_b = list(range(dims_val))\n\n    if isinstance(dims, int):\n        if dims < 0:\n            raise RuntimeError(f\"tensordot expects dims >= 0, but got dims={dims}\")\n        dims_a = list(range(-dims, 0))\n        dims_b = list(range(dims))\n\n    if out is None:\n        return _VF.tensordot(a, b, dims_a, dims_b)  # type: ignore[attr-defined]\n    else:\n        return _VF.tensordot(a, b, dims_a, dims_b, out=out)  # type: ignore[attr-defined]\n\ndef cartesian_prod(*tensors):\n    \"\"\"Do cartesian product of the given sequence of tensors. The behavior is similar to\n    python's `itertools.product`.\n\n    Args:\n        *tensors: any number of 1 dimensional tensors.\n\n    Returns:\n        Tensor: A tensor equivalent to converting all the input tensors into lists,\n        do `itertools.product` on these lists, and finally convert the resulting list\n        into tensor.\n\n    Example::\n\n        >>> a = [1, 2, 3]\n        >>> b = [4, 5]\n        >>> list(itertools.product(a, b))\n        [(1, 4), (1, 5), (2, 4), (2, 5), (3, 4), (3, 5)]\n        >>> tensor_a = torch.tensor(a)\n        >>> tensor_b = torch.tensor(b)\n        >>> torch.cartesian_prod(tensor_a, tensor_b)\n        tensor([[1, 4],\n                [1, 5],\n                [2, 4],\n                [2, 5],\n                [3, 4],\n                [3, 5]])\n    \"\"\"\n    # This wrapper exists to support variadic args.\n    if has_torch_function(tensors):\n        return handle_torch_function(cartesian_prod, tensors, *tensors)\n    return _VF.cartesian_prod(tensors)  # type: ignore[attr-defined]\n\ndef block_diag(*tensors):\n    \"\"\"Create a block diagonal matrix from provided tensors.\n\n    Args:\n        *tensors: One or more tensors with 0, 1, or 2 dimensions.\n\n    Returns:\n        Tensor: A 2 dimensional tensor with all the input tensors arranged in\n        order such that their upper left and lower right corners are\n        diagonally adjacent. All other elements are set to 0.\n\n    Example::\n\n        >>> import torch\n        >>> A = torch.tensor([[0, 1], [1, 0]])\n        >>> B = torch.tensor([[3, 4, 5], [6, 7, 8]])\n        >>> C = torch.tensor(7)\n        >>> D = torch.tensor([1, 2, 3])\n        >>> E = torch.tensor([[4], [5], [6]])\n        >>> torch.block_diag(A, B, C, D, E)\n        tensor([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n                [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n                [0, 0, 3, 4, 5, 0, 0, 0, 0, 0],\n                [0, 0, 6, 7, 8, 0, 0, 0, 0, 0],\n                [0, 0, 0, 0, 0, 7, 0, 0, 0, 0],\n                [0, 0, 0, 0, 0, 0, 1, 2, 3, 0],\n                [0, 0, 0, 0, 0, 0, 0, 0, 0, 4],\n                [0, 0, 0, 0, 0, 0, 0, 0, 0, 5],\n                [0, 0, 0, 0, 0, 0, 0, 0, 0, 6]])\n    \"\"\"\n    # This wrapper exists to support variadic args.\n    if has_torch_function(tensors):\n        return handle_torch_function(block_diag, tensors, *tensors)\n    return torch._C._VariableFunctions.block_diag(tensors)  # type: ignore[attr-defined]\n\n\ndef cdist(x1, x2, p=2., compute_mode='use_mm_for_euclid_dist_if_necessary'):\n    # type: (Tensor, Tensor, float, str) -> (Tensor)\n    r\"\"\"Computes batched the p-norm distance between each pair of the two collections of row vectors.\n\n    Args:\n        x1 (Tensor): input tensor of shape :math:`B \\times P \\times M`.\n        x2 (Tensor): input tensor of shape :math:`B \\times R \\times M`.\n        p: p value for the p-norm distance to calculate between each vector pair\n            :math:`\\in [0, \\infty]`.\n        compute_mode:\n            'use_mm_for_euclid_dist_if_necessary' - will use matrix multiplication approach to calculate\n            euclidean distance (p = 2) if P > 25 or R > 25\n            'use_mm_for_euclid_dist' - will always use matrix multiplication approach to calculate\n            euclidean distance (p = 2)\n            'donot_use_mm_for_euclid_dist' - will never use matrix multiplication approach to calculate\n            euclidean distance (p = 2)\n            Default: use_mm_for_euclid_dist_if_necessary.\n\n    If x1 has shape :math:`B \\times P \\times M` and x2 has shape :math:`B \\times R \\times M` then the\n    output will have shape :math:`B \\times P \\times R`.\n\n    This function is equivalent to `scipy.spatial.distance.cdist(input,'minkowski', p=p)`\n    if :math:`p \\in (0, \\infty)`. When :math:`p = 0` it is equivalent to\n    `scipy.spatial.distance.cdist(input, 'hamming') * M`. When :math:`p = \\infty`, the closest\n    scipy function is `scipy.spatial.distance.cdist(xn, lambda x, y: np.abs(x - y).max())`.\n\n    Example:\n\n        >>> a = torch.tensor([[0.9041,  0.0196], [-0.3108, -2.4423], [-0.4821,  1.059]])\n        >>> a\n        tensor([[ 0.9041,  0.0196],\n                [-0.3108, -2.4423],\n                [-0.4821,  1.0590]])\n        >>> b = torch.tensor([[-2.1763, -0.4713], [-0.6986,  1.3702]])\n        >>> b\n        tensor([[-2.1763, -0.4713],\n                [-0.6986,  1.3702]])\n        >>> torch.cdist(a, b, p=2)\n        tensor([[3.1193, 2.0959],\n                [2.7138, 3.8322],\n                [2.2830, 0.3791]])\n    \"\"\"\n    if has_torch_function_variadic(x1, x2):\n        return handle_torch_function(\n            cdist, (x1, x2), x1, x2, p=p, compute_mode=compute_mode)\n    if compute_mode == 'use_mm_for_euclid_dist_if_necessary':\n        return _VF.cdist(x1, x2, p, None)  # type: ignore[attr-defined]\n    elif compute_mode == 'use_mm_for_euclid_dist':\n        return _VF.cdist(x1, x2, p, 1)  # type: ignore[attr-defined]\n    elif compute_mode == 'donot_use_mm_for_euclid_dist':\n        return _VF.cdist(x1, x2, p, 2)  # type: ignore[attr-defined]\n    else:\n        raise ValueError(f\"{compute_mode} is not a valid value for compute_mode\")\n\ndef atleast_1d(*tensors):\n    r\"\"\"\n    Returns a 1-dimensional view of each input tensor with zero dimensions.\n    Input tensors with one or more dimensions are returned as-is.\n\n    Args:\n        input (Tensor or list of Tensors)\n\n    Returns:\n        output (Tensor or tuple of Tensors)\n\n    Example::\n\n        >>> x = torch.randn(2)\n        >>> x\n        tensor([1.4584, 0.7583])\n        >>> torch.atleast_1d(x)\n        tensor([1.4584, 0.7583])\n        >>> x = torch.tensor(1.)\n        >>> x\n        tensor(1.)\n        >>> torch.atleast_1d(x)\n        tensor([1.])\n        >>> x = torch.tensor(0.5)\n        >>> y = torch.tensor(1.)\n        >>> torch.atleast_1d((x,y))\n        (tensor([0.5000]), tensor([1.]))\n    \"\"\"\n    # This wrapper exists to support variadic args.\n    if has_torch_function(tensors):\n        return handle_torch_function(atleast_1d, tensors, *tensors)\n    if len(tensors) == 1:\n        tensors = tensors[0]\n    return _VF.atleast_1d(tensors)  # type: ignore[attr-defined]\n\ndef atleast_2d(*tensors):\n    r\"\"\"\n    Returns a 2-dimensional view of each input tensor with zero dimensions.\n    Input tensors with two or more dimensions are returned as-is.\n\n    Args:\n        input (Tensor or list of Tensors)\n\n    Returns:\n        output (Tensor or tuple of Tensors)\n\n    Example::\n\n        >>> x = torch.tensor(1.)\n        >>> x\n        tensor(1.)\n        >>> torch.atleast_2d(x)\n        tensor([[1.]])\n        >>> x = torch.randn(2,2)\n        >>> x\n        tensor([[2.2086, 2.5165],\n                [0.1757, 0.5194]])\n        >>> torch.atleast_2d(x)\n        tensor([[2.2086, 2.5165],\n                [0.1757, 0.5194]])\n        >>> x = torch.tensor(0.5)\n        >>> y = torch.tensor(1.)\n        >>> torch.atleast_2d((x,y))\n        (tensor([[0.5000]]), tensor([[1.]]))\n    \"\"\"\n    # This wrapper exists to support variadic args.\n    if has_torch_function(tensors):\n        return handle_torch_function(atleast_2d, tensors, *tensors)\n    if len(tensors) == 1:\n        tensors = tensors[0]\n    return _VF.atleast_2d(tensors)  # type: ignore[attr-defined]\n\ndef atleast_3d(*tensors):\n    r\"\"\"\n    Returns a 3-dimensional view of each input tensor with zero dimensions.\n    Input tensors with three or more dimensions are returned as-is.\n\n    Args:\n        input (Tensor or list of Tensors)\n\n    Returns:\n        output (Tensor or tuple of Tensors)\n\n    Example:\n\n        >>> x = torch.tensor(0.5)\n        >>> x\n        tensor(0.5000)\n        >>> torch.atleast_3d(x)\n        tensor([[[0.5000]]])\n        >>> y = torch.randn(2,2)\n        >>> y\n        tensor([[-0.8079,  0.7460],\n                [-1.1647,  1.4734]])\n        >>> torch.atleast_3d(y)\n        tensor([[[-0.8079],\n                [ 0.7460]],\n                <BLANKLINE>\n                [[-1.1647],\n                [ 1.4734]]])\n        >>> x = torch.randn(1,1,1)\n        >>> x\n        tensor([[[-1.5689]]])\n        >>> torch.atleast_3d(x)\n        tensor([[[-1.5689]]])\n        >>> x = torch.tensor(0.5)\n        >>> y = torch.tensor(1.)\n        >>> torch.atleast_3d((x,y))\n        (tensor([[[0.5000]]]), tensor([[[1.]]]))\n    \"\"\"\n    # This wrapper exists to support variadic args.\n    if has_torch_function(tensors):\n        return handle_torch_function(atleast_3d, tensors, *tensors)\n    if len(tensors) == 1:\n        tensors = tensors[0]\n    return _VF.atleast_3d(tensors)  # type: ignore[attr-defined]\n\n\nif TYPE_CHECKING:\n    pass\n    # There's no good way to use this type annotation; cannot rename norm() to\n    # _norm_impl() in a way that doesn't break JIT overloads. So leave untyped\n    # for mypy for now.\n    #    def norm(input: Tensor,\n    #             p: Optional[Union[str, Number]] = \"fro\",\n    #             dim: Optional[Union[int, List[int]]] = None,\n    #             keepdim: bool = False,\n    #             out: Optional[Tensor] = None,\n    #             dtype: _dtype = None) -> Tensor:\n    #        return _norm_impl(input, p, dim, keepdim, out, dtype)\nelse:\n    # TODO: type dim as BroadcastingList when\n    # https://github.com/pytorch/pytorch/issues/33782 is fixed\n    @overload\n    def norm(input, p=\"fro\", dim=None, keepdim=False, out=None, dtype=None):\n        # type: (Tensor, str, Optional[List[int]], bool, Optional[Tensor], Optional[int]) -> Tensor\n        pass\n\n    @overload\n    def norm(input, p=\"fro\", dim=None, keepdim=False, out=None, dtype=None):  # noqa: F811\n        # type: (Tensor, Optional[number], Optional[List[int]], bool, Optional[Tensor], Optional[int]) -> Tensor\n        pass\n\n    @overload\n    def norm(input, p=\"fro\", dim=None, keepdim=False, out=None, dtype=None):  # noqa: F811\n        # type: (Tensor, Optional[number], Optional[int], bool, Optional[Tensor], Optional[int]) -> Tensor\n        pass\n\n    @overload\n    def norm(input, p=\"fro\", dim=None, keepdim=False, out=None, dtype=None):  # noqa: F811\n        # type: (Tensor, str, Optional[int], bool, Optional[Tensor], Optional[int]) -> Tensor\n        pass\n\n\ndef norm(input, p=\"fro\", dim=None, keepdim=False, out=None, dtype=None):  # noqa: F811\n    r\"\"\"Returns the matrix norm or vector norm of a given tensor.\n\n    .. warning::\n\n        torch.norm is deprecated and may be removed in a future PyTorch release.\n        Its documentation and behavior may be incorrect, and it is no longer\n        actively maintained.\n\n        Use :func:`torch.linalg.norm`, instead, or :func:`torch.linalg.vector_norm`\n        when computing vector norms and :func:`torch.linalg.matrix_norm` when\n        computing matrix norms. Note, however, the signature for these functions\n        is slightly different than the signature for torch.norm.\n\n    Args:\n        input (Tensor): The input tensor. Its data type must be either a floating\n            point or complex type. For complex inputs, the norm is calculated using the\n            absolute value of each element. If the input is complex and neither\n            :attr:`dtype` nor :attr:`out` is specified, the result's data type will\n            be the corresponding floating point type (e.g. float if :attr:`input` is\n            complexfloat).\n\n        p (int, float, inf, -inf, 'fro', 'nuc', optional): the order of norm. Default: ``'fro'``\n            The following norms can be calculated:\n\n            ======  ==============  ==========================\n            ord     matrix norm     vector norm\n            ======  ==============  ==========================\n            'fro'   Frobenius norm  --\n            'nuc'   nuclear norm    --\n            Number  --              sum(abs(x)**ord)**(1./ord)\n            ======  ==============  ==========================\n\n            The vector norm can be calculated across any number of dimensions.\n            The corresponding dimensions of :attr:`input` are flattened into\n            one dimension, and the norm is calculated on the flattened\n            dimension.\n\n            Frobenius norm produces the same result as ``p=2`` in all cases\n            except when :attr:`dim` is a list of three or more dims, in which\n            case Frobenius norm throws an error.\n\n            Nuclear norm can only be calculated across exactly two dimensions.\n\n        dim (int, tuple of ints, list of ints, optional):\n            Specifies which dimension or dimensions of :attr:`input` to\n            calculate the norm across. If :attr:`dim` is ``None``, the norm will\n            be calculated across all dimensions of :attr:`input`. If the norm\n            type indicated by :attr:`p` does not support the specified number of\n            dimensions, an error will occur.\n        keepdim (bool, optional): whether the output tensors have :attr:`dim`\n            retained or not. Ignored if :attr:`dim` = ``None`` and\n            :attr:`out` = ``None``. Default: ``False``\n        out (Tensor, optional): the output tensor. Ignored if\n            :attr:`dim` = ``None`` and :attr:`out` = ``None``.\n        dtype (:class:`torch.dtype`, optional): the desired data type of\n            returned tensor. If specified, the input tensor is casted to\n            :attr:`dtype` while performing the operation. Default: None.\n\n    .. note::\n        Even though ``p='fro'`` supports any number of dimensions, the true\n        mathematical definition of Frobenius norm only applies to tensors with\n        exactly two dimensions. :func:`torch.linalg.norm` with ``ord='fro'`` aligns\n        with the mathematical definition, since it can only be applied across\n        exactly two dimensions.\n\n    Example::\n\n        >>> import torch\n        >>> a = torch.arange(9, dtype= torch.float) - 4\n        >>> b = a.reshape((3, 3))\n        >>> torch.norm(a)\n        tensor(7.7460)\n        >>> torch.norm(b)\n        tensor(7.7460)\n        >>> torch.norm(a, float('inf'))\n        tensor(4.)\n        >>> torch.norm(b, float('inf'))\n        tensor(4.)\n        >>> c = torch.tensor([[ 1, 2, 3],[-1, 1, 4]] , dtype= torch.float)\n        >>> torch.norm(c, dim=0)\n        tensor([1.4142, 2.2361, 5.0000])\n        >>> torch.norm(c, dim=1)\n        tensor([3.7417, 4.2426])\n        >>> torch.norm(c, p=1, dim=1)\n        tensor([6., 6.])\n        >>> d = torch.arange(8, dtype= torch.float).reshape(2,2,2)\n        >>> torch.norm(d, dim=(1,2))\n        tensor([ 3.7417, 11.2250])\n        >>> torch.norm(d[0, :, :]), torch.norm(d[1, :, :])\n        (tensor(3.7417), tensor(11.2250))\n    \"\"\"\n\n    if has_torch_function_unary(input):\n        return handle_torch_function(\n            norm, (input,), input, p=p, dim=dim, keepdim=keepdim, out=out, dtype=dtype)\n\n    ndim = input.dim()\n\n    # catch default case\n    if dim is None and out is None and dtype is None and p is not None:\n        if isinstance(p, str):\n            if p == \"fro\":\n                return _VF.frobenius_norm(input, dim=(), keepdim=keepdim)\n        if not isinstance(p, str):\n            _dim = [i for i in range(ndim)]  # noqa: C416 TODO: rewrite as list(range(m))\n            return _VF.norm(input, p, dim=_dim, keepdim=keepdim)  # type: ignore[attr-defined]\n\n    # TODO: when https://github.com/pytorch/pytorch/issues/33782 is fixed\n    # remove the overloads where dim is an int and replace with BraodcastingList1\n    # and remove next four lines, replace _dim with dim\n    if dim is not None:\n        if isinstance(dim, int):\n            _dim = [dim]\n        else:\n            _dim = dim\n    else:\n        _dim = None  # type: ignore[assignment]\n\n    if isinstance(p, str):\n        if p == \"fro\":\n            if dtype is not None:\n                raise ValueError(\"dtype argument is not supported in frobenius norm\")\n\n            if _dim is None:\n                _dim = list(range(ndim))\n            if out is None:\n                return _VF.frobenius_norm(input, _dim, keepdim=keepdim)\n            else:\n                return _VF.frobenius_norm(input, _dim, keepdim=keepdim, out=out)\n        elif p == \"nuc\":\n            if dtype is not None:\n                raise ValueError(\"dtype argument is not supported in nuclear norm\")\n            if _dim is None:\n                if out is None:\n                    return _VF.nuclear_norm(input, keepdim=keepdim)\n                else:\n                    return _VF.nuclear_norm(input, keepdim=keepdim, out=out)\n            else:\n                if out is None:\n                    return _VF.nuclear_norm(input, _dim, keepdim=keepdim)\n                else:\n                    return _VF.nuclear_norm(input, _dim, keepdim=keepdim, out=out)\n        raise RuntimeError(f\"only valid string values are 'fro' and 'nuc', found {p}\")\n    else:\n        if _dim is None:\n            _dim = list(range(ndim))\n\n        if out is None:\n            if dtype is None:\n                return _VF.norm(input, p, _dim, keepdim=keepdim)  # type: ignore[attr-defined]\n            else:\n                return _VF.norm(input, p, _dim, keepdim=keepdim, dtype=dtype)  # type: ignore[attr-defined]\n        else:\n            if dtype is None:\n                return _VF.norm(input, p, _dim, keepdim=keepdim, out=out)  # type: ignore[attr-defined]\n            else:\n                return _VF.norm(input, p, _dim, keepdim=keepdim, dtype=dtype, out=out)  # type: ignore[attr-defined]\n\ndef chain_matmul(*matrices, out=None):\n    r\"\"\"Returns the matrix product of the :math:`N` 2-D tensors. This product is efficiently computed\n    using the matrix chain order algorithm which selects the order in which incurs the lowest cost in terms\n    of arithmetic operations (`[CLRS]`_). Note that since this is a function to compute the product, :math:`N`\n    needs to be greater than or equal to 2; if equal to 2 then a trivial matrix-matrix product is returned.\n    If :math:`N` is 1, then this is a no-op - the original matrix is returned as is.\n\n    .. warning::\n\n        :func:`torch.chain_matmul` is deprecated and will be removed in a future PyTorch release.\n        Use :func:`torch.linalg.multi_dot` instead, which accepts a list of two or more tensors\n        rather than multiple arguments.\n\n    Args:\n        matrices (Tensors...): a sequence of 2 or more 2-D tensors whose product is to be determined.\n        out (Tensor, optional): the output tensor. Ignored if :attr:`out` = ``None``.\n\n    Returns:\n        Tensor: if the :math:`i^{th}` tensor was of dimensions :math:`p_{i} \\times p_{i + 1}`, then the product\n        would be of dimensions :math:`p_{1} \\times p_{N + 1}`.\n\n    Example::\n\n        >>> a = torch.randn(3, 4)\n        >>> b = torch.randn(4, 5)\n        >>> c = torch.randn(5, 6)\n        >>> d = torch.randn(6, 7)\n        >>> torch.chain_matmul(a, b, c, d)\n        tensor([[ -2.3375,  -3.9790,  -4.1119,  -6.6577,   9.5609, -11.5095,  -3.2614],\n                [ 21.4038,   3.3378,  -8.4982,  -5.2457, -10.2561,  -2.4684,   2.7163],\n                [ -0.9647,  -5.8917,  -2.3213,  -5.2284,  12.8615, -12.2816,  -2.5095]])\n\n    .. _`[CLRS]`: https://mitpress.mit.edu/books/introduction-algorithms-third-edition\n    \"\"\"\n    # This wrapper exists to support variadic args.\n    if has_torch_function(matrices):\n        return handle_torch_function(chain_matmul, matrices, *matrices)\n\n    if out is None:\n        return _VF.chain_matmul(matrices)  # type: ignore[attr-defined]\n    else:\n        return _VF.chain_matmul(matrices, out=out)  # type: ignore[attr-defined]\n\n\ndef _lu_impl(A, pivot=True, get_infos=False, out=None):\n    # type: (Tensor, bool, bool, Any) -> Tuple[Tensor, Tensor, Tensor]\n    r\"\"\"Computes the LU factorization of a matrix or batches of matrices\n    :attr:`A`. Returns a tuple containing the LU factorization and\n    pivots of :attr:`A`.  Pivoting is done if :attr:`pivot` is set to\n    ``True``.\n\n    .. note::\n        * The pivots returned by the function are 1-indexed. If :attr:`pivot`\n          is ``False``, then the returned pivots is a tensor filled with\n          zeros of the appropriate size.\n        * LU factorization with :attr:`pivot` = ``False`` is not available\n          for CPU, and attempting to do so will throw an error. However,\n          LU factorization with :attr:`pivot` = ``False`` is available for\n          CUDA.\n        * This function does not check if the factorization was successful\n          or not if :attr:`get_infos` is ``True`` since the status of the\n          factorization is present in the third element of the return tuple.\n        * In the case of batches of square matrices with size less or equal\n          to 32 on a CUDA device, the LU factorization is repeated for\n          singular matrices due to the bug in the MAGMA library\n          (see magma issue 13).\n        * ``L``, ``U``, and ``P`` can be derived using :func:`torch.lu_unpack`.\n\n    .. warning::\n        The gradients of this function will only be finite when :attr:`A` is full rank.\n        This is because the LU decomposition is just differentiable at full rank matrices.\n        Furthermore, if :attr:`A` is close to not being full rank,\n        the gradient will be numerically unstable as it depends on the computation of :math:`L^{-1}` and :math:`U^{-1}`.\n\n    Args:\n        A (Tensor): the tensor to factor of size :math:`(*, m, n)`\n        pivot (bool, optional): controls whether pivoting is done. Default: ``True``\n        get_infos (bool, optional): if set to ``True``, returns an info IntTensor.\n                                    Default: ``False``\n        out (tuple, optional): optional output tuple. If :attr:`get_infos` is ``True``,\n                               then the elements in the tuple are Tensor, IntTensor,\n                               and IntTensor. If :attr:`get_infos` is ``False``, then the\n                               elements in the tuple are Tensor, IntTensor. Default: ``None``\n\n    Returns:\n        (Tensor, IntTensor, IntTensor (optional)): A tuple of tensors containing\n\n            - **factorization** (*Tensor*): the factorization of size :math:`(*, m, n)`\n\n            - **pivots** (*IntTensor*): the pivots of size :math:`(*, \\text{min}(m, n))`.\n              ``pivots`` stores all the intermediate transpositions of rows.\n              The final permutation ``perm`` could be reconstructed by\n              applying ``swap(perm[i], perm[pivots[i] - 1])`` for ``i = 0, ..., pivots.size(-1) - 1``,\n              where ``perm`` is initially the identity permutation of :math:`m` elements\n              (essentially this is what :func:`torch.lu_unpack` is doing).\n\n            - **infos** (*IntTensor*, *optional*): if :attr:`get_infos` is ``True``, this is a tensor of\n              size :math:`(*)` where non-zero values indicate whether factorization for the matrix or\n              each minibatch has succeeded or failed\n\n    Example::\n\n        >>> A = torch.randn(2, 3, 3)\n        >>> A_LU, pivots = torch.lu(A)\n        >>> A_LU\n        tensor([[[ 1.3506,  2.5558, -0.0816],\n                 [ 0.1684,  1.1551,  0.1940],\n                 [ 0.1193,  0.6189, -0.5497]],\n\n                [[ 0.4526,  1.2526, -0.3285],\n                 [-0.7988,  0.7175, -0.9701],\n                 [ 0.2634, -0.9255, -0.3459]]])\n        >>> pivots\n        tensor([[ 3,  3,  3],\n                [ 3,  3,  3]], dtype=torch.int32)\n        >>> A_LU, pivots, info = torch.lu(A, get_infos=True)\n        >>> if info.nonzero().size(0) == 0:\n        ...   print('LU factorization succeeded for all samples!')\n        LU factorization succeeded for all samples!\n    \"\"\"\n    # If get_infos is True, then we don't need to check for errors and vice versa\n    return torch._lu_with_info(A, pivot=pivot, check_errors=(not get_infos))\n\nif TYPE_CHECKING:\n    _ListOrSeq = Sequence[Tensor]\nelse:\n    _ListOrSeq = List[Tensor]\n\ndef _check_list_size(out_len: int, get_infos: bool, out: _ListOrSeq) -> None:\n    get_infos_int = 1 if get_infos else 0\n    if out_len - get_infos_int != 2:\n        raise TypeError(f\"expected tuple of {2 + int(get_infos)} elements but got {out_len}\")\n    if not isinstance(out, (tuple, list)):\n        raise TypeError(f\"argument 'out' must be tuple of Tensors, not {type(out).__name__}\")\n\ndef _lu_with_infos(A, pivot=True, get_infos=False, out=None):\n    # type: (Tensor, bool, bool, Optional[Tuple[Tensor, Tensor, Tensor]]) -> Tuple[Tensor, Tensor, Tensor]\n    if has_torch_function_unary(A):\n        return handle_torch_function(\n            lu, (A,), A, pivot=pivot, get_infos=get_infos, out=out)\n    result = _lu_impl(A, pivot, get_infos, out)\n    if out is not None:\n        _check_list_size(len(out), get_infos, out)\n        for i in range(len(out)):\n            out[i].resize_as_(result[i]).copy_(result[i])\n        return out\n    else:\n        return result  # A_LU, pivots, infos\n\ndef _lu_no_infos(A, pivot=True, get_infos=False, out=None):\n    # type: (Tensor, bool, bool, Optional[Tuple[Tensor, Tensor]]) -> Tuple[Tensor, Tensor]\n    # need to check for torch_function here so that we exit if\n    if has_torch_function_unary(A):\n        return handle_torch_function(\n            lu, (A,), A, pivot=pivot, get_infos=get_infos, out=out)\n    result = _lu_impl(A, pivot, get_infos, out)\n    if out is not None:\n        _check_list_size(len(out), get_infos, out)\n        for i in range(len(out)):\n            out[i].resize_as_(result[i]).copy_(result[i])\n        return out\n    else:\n        return result[0], result[1]  # A_LU, pivots\n\n# The return type of lu depends on `get_infos`, so in order to resolve the output type\n# of lu in TorchScript we need to statically know the value of `get_infos`\nlu = boolean_dispatch(\n    arg_name='get_infos',\n    arg_index=2,\n    default=False,\n    if_true=_lu_with_infos,\n    if_false=_lu_no_infos,\n    module_name=__name__,\n    func_name='lu')\nlu.__doc__ = _lu_impl.__doc__\n\ndef align_tensors(*tensors):\n    raise RuntimeError('`align_tensors` not yet implemented.')\n", 1651], "/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_jit_internal.py": ["\"\"\"\nThe weak_script annotation needs to be here instead of inside torch/jit/ so it\ncan be used in other places in torch/ (namely torch.nn) without running into\ncircular dependency problems\n\"\"\"\n\nimport contextlib\nimport collections\nimport enum\nimport inspect\nimport ast\nimport weakref\nimport warnings\nfrom textwrap import dedent\nimport torch\nimport sys\nimport builtins\nimport typing\nimport io\nimport pickle\n# This is needed. `torch._jit_internal` is imported before `torch.distributed.__init__`.\n# Explicitly ask to import `torch.distributed.__init__` first.\n# Otherwise, \"AttributeError: module 'torch' has no attribute 'distributed'\" is raised.\nimport torch.distributed.rpc\nfrom torch._C import Future as CFuture\nfrom torch._sources import get_source_lines_and_file, parse_def, fake_range\nfrom torch.futures import Future\nimport torch.package._mangling as package_mangling\nfrom typing import Any, Callable, Dict, Generic, List, Optional, Tuple, Type, TypeVar, Union  # noqa: F401\n\nif sys.version_info[:2] > (3, 7):\n    from typing import Final\nelse:\n    from typing_extensions import Final\n\nLockType: Type\ntry:\n    import _thread\n    LockType = _thread.LockType\nexcept ImportError:\n    import _dummy_thread\n    LockType = _dummy_thread.LockType\n\n# Wrapper functions that can call either of 2 functions depending on a boolean\n# argument\nboolean_dispatched: 'weakref.WeakKeyDictionary[Callable, Dict[str, Callable]]' = weakref.WeakKeyDictionary()  # noqa: T484\n\n\ndef createResolutionCallbackFromEnv(lookup_base):\n    \"\"\"\n    Creates a resolution callback that will look up qualified names in an\n    environment, starting with `lookup_base` for the base of any qualified\n    names, then proceeding down the lookup chain with the resolved object.\n\n    You should not use this directly, it should only be used from the other\n    createResolutionCallbackFrom* functions.\n    \"\"\"\n    def lookupInModule(qualified_name, module):\n        if '.' in qualified_name:\n            parts = qualified_name.split('.')\n            base = parts[0]\n            remaining_pieces = '.'.join(parts[1:])\n            module_value = getattr(module, base)\n            return lookupInModule(remaining_pieces, module_value)\n        else:\n            return getattr(module, qualified_name)\n\n    def parseNestedExpr(expr, module) -> Tuple[Any, int]:\n        i = 0\n        while i < len(expr) and expr[i] not in (',', '[', ']'):\n            i += 1\n\n        # Special case logic for the empty Tuple as a subscript (used\n        # in the type annotation `Tuple[()]`)\n        if expr[:i] == '()':\n            return (), i\n\n        base = lookupInModule(expr[:i].strip(), module)\n        assert base is not None, f\"Unresolvable type {expr[:i]}\"\n        if i == len(expr) or expr[i] != '[':\n            return base, i\n\n        assert expr[i] == '['\n        parts = []\n        while expr[i] != ']':\n            part_len = 0\n            i += 1\n            part, part_len = parseNestedExpr(expr[i:], module)\n            parts.append(part)\n            i += part_len\n        if len(parts) > 1:\n            return base[tuple(parts)], i + 1\n        else:\n            return base[parts[0]], i + 1\n\n    def parseExpr(expr, module):\n        try:\n            value, len_parsed = parseNestedExpr(expr, module)\n            assert len_parsed == len(expr), \"whole expression was not parsed, falling back to c++ parser\"\n            return value\n        except Exception:\n            \"\"\"\n            The python resolver fails in several cases in known unit tests, and is intended\n            to fall back gracefully to the c++ resolver in general.  For example, python 2 style\n            annotations which are frequent in our unit tests often fail with types e.g. int not\n            resolvable from the calling frame.\n            \"\"\"\n            return None\n\n    return lambda expr: parseExpr(expr, lookup_base)\n\n\ndef createResolutionCallbackFromFrame(frames_up: int = 0):\n    \"\"\"\n    Creates a function which, given a string variable name,\n    returns the value of the variable in the scope of the caller of\n    the function which called createResolutionCallbackFromFrame (by default).\n\n    This is used to enable access in-scope Python variables inside\n    TorchScript fragments.\n\n    frames_up is number of additional frames to go up on the stack.\n    The default value is 0, which correspond to the frame of the caller\n    of createResolutionCallbackFromFrame. Also for example, if frames_up is set\n    to 1, then the frame of the caller's caller of createResolutionCallbackFromFrame\n    will be taken.\n\n    For example, the following program prints 2::\n\n        def bar():\n            cb = createResolutionCallbackFromFrame(1)\n            print(cb(\"foo\"))\n\n        def baz():\n            foo = 2\n            bar()\n\n        baz()\n    \"\"\"\n    frame = inspect.currentframe()\n    i = 0\n    while i < frames_up + 1:\n        assert frame is not None\n        frame = frame.f_back\n        i += 1\n\n    assert frame is not None\n    f_locals = frame.f_locals\n    f_globals = frame.f_globals\n\n    class env(object):\n        def __getattr__(self, key):\n            if key in f_locals:\n                return f_locals[key]\n            elif key in f_globals:\n                return f_globals[key]\n            elif key in dir(builtins):\n                return getattr(builtins, key)\n\n    return createResolutionCallbackFromEnv(env())\n\n\ndef get_closure(fn):\n    \"\"\"\n    Get a dictionary of closed over variables from a function\n    \"\"\"\n    captures = {}\n    captures.update(fn.__globals__)\n\n    for index, captured_name in enumerate(fn.__code__.co_freevars):\n        captures[captured_name] = fn.__closure__[index].cell_contents\n\n    return captures\n\n# [local resolution in python]\n# Depending on where a variable is defined, and where it is used, we may\n# or may not be able to recover its value when recursively compiling a\n# script function. Remember in the general case, a module or function is\n# first defined and then later scripted. This means we do not have a\n# chance to capture the active frames when the function is defined. Hence any\n# name resolution has to happen later on the created closure. The way\n# python captures type annotations restricts what we can recover. The\n# follow example illustrates the different cases:\n#\n#         class MyGlobalClass:\n#         ...\n#         def my_local_scope():\n#             @torch.jit.script\n#             class MyClass:\n#                 ...\n#             @torch.jit.script\n#             class MyClassUsedAsVar:\n#                 ...\n#             def eg(x: MyClass, y: MyGlobalClass):\n#                 a_local_capture : Foo\n#                 return MyClassUsedAsVar(x)\n#\n# MyGlobalClass is defined in the __globals__ dictionary of function\n# 'eg', so it is always recoverable. my_local_scope introduces a new local\n# variable scope in the function. Classes defined here are only visible as\n# local variables. For the case of MyClassUsedAsVar, it is captured\n# because it is used as a variable inside the body of the function, and we\n# can resolve it using the captures returned from `get_closure`. However,\n# the type annotations are not captured by the closure. In Python\n# 3.0--3.9, the _value_ of MyClass and MyGlobalClass will be available as\n# annotations on `eg``, but starting in Python 4.0, they will represented as\n# strings and no longer present. Furthermore, since the body of `eg` does\n# not reference those names, they do not appear in the list of closed over\n# variables. In Python 2.x, type annotations are in comments, leading to a\n# similar situation where their definitions are not available. We anticipate\n# that most users will not run into this issue because their modules and\n# functions will be defined at a global scope like MyGlobalClass. In cases\n# where they are not, it is possible to work around issues by declaring the\n# values global in the function.\n# In Python 3.9 declaring class as global will make it invisible to\n# `inspect.getsource`, see https://bugs.python.org/issue42666 .\n# This could be worked around by manualy adding it to `global()` dictionary.\n\n\n\ndef createResolutionCallbackFromClosure(fn):\n    \"\"\"\n    Create a resolutionCallback by introspecting the function instead of\n    looking up the stack for the enclosing scope\n    \"\"\"\n    closure = get_closure(fn)\n\n    class closure_lookup(object):\n        # This is a class since `closure` is a dict and it's easier in\n        # `env_helper` if everything just works with `getattr` calls\n        def __getattr__(self, key):\n            if key in closure:\n                return closure[key]\n            elif hasattr(typing, key):\n                return getattr(typing, key)\n            elif hasattr(builtins, key):\n                return getattr(builtins, key)\n            return None\n\n    return createResolutionCallbackFromEnv(closure_lookup())\n\n\ndef can_compile_class(cls) -> bool:\n    # If any of the functions on a type don't have a code object, this type can't\n    # be compiled and is probably a builtin / bound from C\n    if is_ignored_fn(cls):\n        return False\n\n    # Ignore the following list of built-in classes.\n    ignored_builtin_classes = (torch.nn.Module, tuple, list, Exception)\n    if issubclass(cls, ignored_builtin_classes):\n        return False\n\n    names = cls.__dict__\n    fns = [getattr(cls, name) for name in names if inspect.isroutine(getattr(cls, name, None))]\n    has_code = [hasattr(fn, '__code__') for fn in fns]\n    return all(has_code)\n\n\ndef get_callable_argument_names(fn) -> List[str]:\n    \"\"\"\n    Gets names of all POSITIONAL_OR_KEYWORD arguments for callable `fn`.\n    Returns an empty list when other types of arguments are present.\n\n    This is used by `torch.jit.trace` to assign meaningful argument names to\n    traced functions and modules.\n\n    Args:\n        fn: A callable.\n    Returns:\n        Argument names: List[str]\n    \"\"\"\n    # inspect.signature may fail, give up in that case.\n    try:\n        callable_signature = inspect.signature(fn)\n    except Exception:\n        return []\n\n    argument_names = []\n    for name, param in callable_signature.parameters.items():\n        # All four other types of arguments do not map to individual values\n        # with a keyword as name.\n        if not param.kind == param.POSITIONAL_OR_KEYWORD:\n            return []\n\n        argument_names.append(name)\n\n    return argument_names\n\n\ndef get_annotation_str(annotation):\n    \"\"\"\n    Convert an AST node containing a type annotation to the string present in the source\n    that represents the same annotation.\n    \"\"\"\n    if isinstance(annotation, ast.Name):\n        return annotation.id\n    elif isinstance(annotation, ast.Attribute):\n        return '.'.join([get_annotation_str(annotation.value), annotation.attr])\n    elif isinstance(annotation, ast.Subscript):\n        # In Python3.9+ subscript indicies are not wrapped in ast.Index\n        subscript_slice = annotation.slice if sys.version_info >= (3, 9) else annotation.slice.value  # type: ignore[attr-defined]\n        return f\"{get_annotation_str(annotation.value)}[{get_annotation_str(subscript_slice)}]\"\n    elif isinstance(annotation, ast.Tuple):\n        return ','.join([get_annotation_str(elt) for elt in annotation.elts])\n    elif isinstance(annotation, ast.Constant) or isinstance(annotation, ast.NameConstant):\n        return f\"{annotation.value}\"\n\n    # If an AST node is not handled here, it's probably handled in ScriptTypeParser.\n    return None\n\n\ndef get_type_hint_captures(fn):\n    \"\"\"\n    Get a dictionary containing type resolution mappings necessary to resolve types\n    for the literal annotations on 'fn'. These are not considered to be closed-over by fn\n    and must be obtained separately (e.g. using this function).\n\n    Args:\n        fn: A callable.\n    Returns:\n        A Dict[str, Any] containing a mapping from the literal annotations used on\n        fn to the Python objects they refer to.\n    \"\"\"\n    # Gather a dictionary of parameter name -> type, skipping any parameters whose annotated\n    # types are strings. These are only understood by TorchScript in the context of a type annotation\n    # that refers to a class in its own definition, but trying to include a mapping for this in the result\n    # function would cause infinite recursion because the class is currently being compiled.\n    # In addition, there is logic in ScriptTypeParser to handle this.\n    signature = inspect.signature(fn)\n    name_to_type = {\n        name: parameter.annotation\n        for name, parameter in signature.parameters.items()\n        if parameter.annotation is not inspect.Parameter.empty and not isinstance(parameter.annotation, str)\n    }\n\n    # Then, get the literal type annotations from the function declaration\n    # by source inspection. This accounts for the case in which aliases are used\n    # to annotate the arguments (e.g device_t = torch.device, and then d: device_t).\n    src = inspect.getsource(fn)\n\n    # frontend.py cannot be used here because it includes _jit_internal, so use ast instead.\n    a = ast.parse(dedent(src))\n    if len(a.body) != 1 or not isinstance(a.body[0], ast.FunctionDef):\n        raise RuntimeError(f\"Expected {fn} to be a function\")\n    f = a.body[0]\n\n    # Prepare a dictionary of source annotation -> type, which will be the final result of this function,\n    # by using the parsed AST (f) to reconstruct source annotations as strings for each parameter and mapping\n    # them to the type object corresponding to the annotation via name_to_type using the parameter name.\n    annotation_to_type = {}\n\n    for arg in f.args.args:\n        # Get the source type annotation string for this argument if possible.\n        arg_annotation_str = get_annotation_str(arg.annotation) if arg.annotation else None\n\n        # If the argument has no annotation or get_annotation_str cannot convert it to a string,\n        # arg_annotation_str will be None. Skip this arg; ScriptTypeParser will probably handle\n        # this in the latter case.\n        if arg_annotation_str is None:\n            continue\n\n        # Insert {arg_annotation_str: type} into annotation_to_type if possible. One reason arg_name may not\n        # be present in name_to_type is that the annotation itself is a string and not a type object\n        # (common for self-refential annotations in classes). Once again, let ScriptTypeParser handle this.\n        arg_name = arg.arg\n        if arg_name in name_to_type:\n            annotation_to_type[arg_annotation_str] = name_to_type[arg_name]\n\n    # If there is a valid return annotation, include it in annotation_to_type. As with argument annotations,\n    # the literal annotation has to be convertible to a string by get_annotation_str, and the actual type\n    # of the annotation cannot be a string.\n    literal_return_annotation = get_annotation_str(f.returns)\n    valid_literal_annotation = literal_return_annotation is not None\n    return_annotation = signature.return_annotation\n    valid_return_annotation_type = return_annotation is not inspect.Parameter.empty and not isinstance(return_annotation, str)\n    if valid_literal_annotation and valid_return_annotation_type:\n        annotation_to_type[literal_return_annotation] = return_annotation\n\n    return annotation_to_type\n\n\ndef createResolutionCallbackForClassMethods(cls):\n    \"\"\"\n    This looks at all the methods defined in a class and pulls their closed-over\n    variables into a dictionary and uses that to resolve variables.\n    \"\"\"\n    # cls is a type here, so `ismethod` is false since the methods on the type\n    # aren't bound to anything, so Python treats them as regular functions\n    fns = [getattr(cls, name) for name in cls.__dict__ if inspect.isroutine(getattr(cls, name))]\n    captures = {}\n\n    for fn in fns:\n        captures.update(get_closure(fn))\n        captures.update(get_type_hint_captures(fn))\n\n    def lookup_in_class(key):\n        if key in captures:\n            return captures[key]\n        else:\n            return getattr(builtins, key, None)\n\n    return lookup_in_class\n\n\ndef boolean_dispatch(arg_name, arg_index, default, if_true, if_false, module_name, func_name):\n    \"\"\"\n    Dispatches to either of 2 script functions based on a boolean argument.\n    In TorchScript, the boolean argument must be constant so that the correct\n    function to use can be determined at compile time.\n    \"\"\"\n    def fn(*args, **kwargs):\n        dispatch_flag = False\n        if arg_name in kwargs:\n            dispatch_flag = kwargs[arg_name]\n        elif arg_index < len(args):\n            dispatch_flag = args[arg_index]\n\n        if dispatch_flag:\n            return if_true(*args, **kwargs)\n        else:\n            return if_false(*args, **kwargs)\n\n    if if_true.__doc__ is None and if_false.__doc__ is not None:\n        doc = if_false.__doc__\n        if_true.__doc__ = doc\n    elif if_false.__doc__ is None and if_true.__doc__ is not None:\n        doc = if_true.__doc__\n        if_false.__doc__ = doc\n    elif if_false.__doc__ is None and if_true.__doc__ is None:\n        # neither function has a docstring\n        doc = None\n    else:\n        raise RuntimeError(\"only one function can have a docstring\")\n    fn.__doc__ = doc\n\n    if module_name is not None:\n        fn.__module__ = module_name\n    if func_name is not None:\n        fn.__name__ = func_name\n\n    boolean_dispatched[fn] = {\n        \"if_true\": if_true,\n        \"if_false\": if_false,\n        \"index\": arg_index,\n        \"default\": default,\n        \"arg_name\": arg_name\n    }\n    return fn\n\n\nclass FunctionModifiers(object):\n    \"\"\"\n    Used to denote the behavior of a function in TorchScript. See export() and\n    ignore() for details.\n    \"\"\"\n    UNUSED = \"unused (ignored and replaced with raising of an exception)\"\n    IGNORE = \"ignore (leave as a call to Python, cannot be torch.jit.save'd)\"\n    EXPORT = \"export (compile this function even if nothing calls it)\"\n    DEFAULT = \"default (compile if called from a exported function / forward)\"\n    COPY_TO_SCRIPT_WRAPPER = \\\n        \"if this method is not scripted, copy the python method onto the scripted model\"\n\n\ndef export(fn):\n    \"\"\"\n    This decorator indicates that a method on an ``nn.Module`` is used as an entry point into a\n    :class:`ScriptModule` and should be compiled.\n\n    ``forward`` implicitly is assumed to be an entry point, so it does not need this decorator.\n    Functions and methods called from ``forward`` are compiled as they are seen\n    by the compiler, so they do not need this decorator either.\n\n    Example (using ``@torch.jit.export`` on a method):\n\n    .. testcode::\n\n        import torch\n        import torch.nn as nn\n\n        class MyModule(nn.Module):\n            def implicitly_compiled_method(self, x):\n                return x + 99\n\n            # `forward` is implicitly decorated with `@torch.jit.export`,\n            # so adding it here would have no effect\n            def forward(self, x):\n                return x + 10\n\n            @torch.jit.export\n            def another_forward(self, x):\n                # When the compiler sees this call, it will compile\n                # `implicitly_compiled_method`\n                return self.implicitly_compiled_method(x)\n\n            def unused_method(self, x):\n                return x - 20\n\n        # `m` will contain compiled methods:\n        #     `forward`\n        #     `another_forward`\n        #     `implicitly_compiled_method`\n        # `unused_method` will not be compiled since it was not called from\n        # any compiled methods and wasn't decorated with `@torch.jit.export`\n        m = torch.jit.script(MyModule())\n    \"\"\"\n    fn._torchscript_modifier = FunctionModifiers.EXPORT\n    return fn\n\n\ndef unused(fn):\n    \"\"\"\n    This decorator indicates to the compiler that a function or method should\n    be ignored and replaced with the raising of an exception. This allows you\n    to leave code in your model that is not yet TorchScript compatible and still\n    export your model.\n\n        Example (using ``@torch.jit.unused`` on a method)::\n\n            import torch\n            import torch.nn as nn\n\n            class MyModule(nn.Module):\n                def __init__(self, use_memory_efficient):\n                    super(MyModule, self).__init__()\n                    self.use_memory_efficient = use_memory_efficient\n\n                @torch.jit.unused\n                def memory_efficient(self, x):\n                    import pdb\n                    pdb.set_trace()\n                    return x + 10\n\n                def forward(self, x):\n                    # Use not-yet-scriptable memory efficient mode\n                    if self.use_memory_efficient:\n                        return self.memory_efficient(x)\n                    else:\n                        return x + 10\n\n            m = torch.jit.script(MyModule(use_memory_efficient=False))\n            m.save(\"m.pt\")\n\n            m = torch.jit.script(MyModule(use_memory_efficient=True))\n            # exception raised\n            m(torch.rand(100))\n    \"\"\"\n    if isinstance(fn, property):\n        prop = fn\n        setattr(prop.fget, \"_torchscript_modifier\", FunctionModifiers.UNUSED)  # noqa: B010\n\n        if prop.fset:\n            setattr(prop.fset, \"_torchscript_modifier\", FunctionModifiers.UNUSED)  # noqa: B010\n\n        return prop\n\n    fn._torchscript_modifier = FunctionModifiers.UNUSED\n    return fn\n\n# No op context manager from python side\nclass _IgnoreContextManager(contextlib.AbstractContextManager):\n    def __init__(self, **kwargs):\n        pass\n\n    def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -> None:\n        pass\n\ndef ignore(drop=False, **kwargs):\n    \"\"\"\n    This decorator indicates to the compiler that a function or method should\n    be ignored and left as a Python function. This allows you to leave code in\n    your model that is not yet TorchScript compatible. If called from TorchScript,\n    ignored functions will dispatch the call to the Python interpreter. Models with ignored\n    functions cannot be exported; use :func:`@torch.jit.unused <torch.jit.unused>` instead.\n\n    Example (using ``@torch.jit.ignore`` on a method)::\n\n        import torch\n        import torch.nn as nn\n\n        class MyModule(nn.Module):\n            @torch.jit.ignore\n            def debugger(self, x):\n                import pdb\n                pdb.set_trace()\n\n            def forward(self, x):\n                x += 10\n                # The compiler would normally try to compile `debugger`,\n                # but since it is `@ignore`d, it will be left as a call\n                # to Python\n                self.debugger(x)\n                return x\n\n        m = torch.jit.script(MyModule())\n\n        # Error! The call `debugger` cannot be saved since it calls into Python\n        m.save(\"m.pt\")\n\n    Example (using ``@torch.jit.ignore(drop=True)`` on a method):\n\n    .. testcode::\n\n        import torch\n        import torch.nn as nn\n\n        class MyModule(nn.Module):\n            @torch.jit.ignore(drop=True)\n            def training_method(self, x):\n                import pdb\n                pdb.set_trace()\n\n            def forward(self, x):\n                if self.training:\n                    self.training_method(x)\n                return x\n\n        m = torch.jit.script(MyModule())\n\n        # This is OK since `training_method` is not saved, the call is replaced\n        # with a `raise`.\n        m.save(\"m.pt\")\n\n    .. testcleanup::\n\n        import os\n        os.remove('m.pt')\n    \"\"\"\n\n    if callable(drop):\n        # used without any args, so drop is actually a function\n        #   @torch.jit.ignore\n        #   def fn(...):\n        fn = drop\n        fn._torchscript_modifier = FunctionModifiers.IGNORE\n        return fn\n\n    if not isinstance(drop, bool):\n        raise RuntimeError(\"Argument to @torch.jit.ignore must be a bool or \"\n                           f\"a function but got {drop}\")\n\n    # for backwards compat\n    drop_on_export = kwargs.pop(\"drop_on_export\", None)\n    if drop_on_export:\n        warnings.warn(\"ignore(drop_on_export=True) has been deprecated. TorchScript will now drop the function \"\n                      \"call on compilation. Use torch.jit.unused now. {}\", category=FutureWarning)\n\n        drop = drop_on_export\n    elif drop:\n        warnings.warn(\"ignore(True) has been deprecated. TorchScript will now drop the function \"\n                      \"call on compilation. Use torch.jit.unused now. {}\", category=FutureWarning)\n\n    def decorator(fn):\n        if drop:\n            fn._torchscript_modifier = FunctionModifiers.UNUSED\n        else:\n            fn._torchscript_modifier = FunctionModifiers.IGNORE\n        return fn\n    return decorator\n\n\ndef _copy_to_script_wrapper(fn):\n    fn._torchscript_modifier = FunctionModifiers.COPY_TO_SCRIPT_WRAPPER\n    return fn\n\ndef module_has_exports(mod):\n    for name in dir(mod):\n        if hasattr(mod, name):\n            item = getattr(mod, name)\n            if callable(item):\n                if get_torchscript_modifier(item) is FunctionModifiers.EXPORT:\n                    return True\n    return False\n\n\n# WARNING: should_drop is currently being used by our JIT code coverage plug-in to mark JIT'd code as covered. If you\n# rename this function, please update references in tools/coverage_plugins_package/src/coverage_plugins/jit_plugin.py to\n# allow JIT'd code to still be covered.\ndef should_drop(fn) -> bool:\n    attr = get_torchscript_modifier(fn)\n    if attr is None:\n        return False\n    return attr is FunctionModifiers.UNUSED\n\n\ndef is_ignored_fn(fn) -> bool:\n    mod = get_torchscript_modifier(fn)\n    return mod is FunctionModifiers.UNUSED or mod is FunctionModifiers.IGNORE\n\n\ndef is_static_fn(cls, fn) -> bool:\n    return isinstance(inspect.getattr_static(cls, fn, default=None), staticmethod)\n\ndef get_static_fn(cls, fn):\n    return inspect.getattr_static(cls, fn).__func__\n\n\ndef get_torchscript_modifier(fn):\n    if not callable(fn):\n        return None\n    if hasattr(fn, '__func__'):\n        fn = fn.__func__\n    return getattr(fn, '_torchscript_modifier', FunctionModifiers.DEFAULT)\n\ndef copy_torchscript_modifier(orig, new) -> None:\n    attr = get_torchscript_modifier(orig)\n    if attr is None:\n        return\n    new._torchscript_modifier = attr\n\n# overloading registration\n# overloads get registered in this file, and compiled in torch/jit/__init__.py\n# so that they can be imported in nn/functional.py without an import cycle\n\n# qualified_name => list[overload_functions]\n_overloaded_fns : Dict[str, List[Callable]] = {}  # noqa: T484\n\n\n_OVERLOAD_EXAMPLE = '''\nExample usage of overload function:\n@torch.jit._overload\ndef my_function(x: type0) -> type0: # decl 1\n    pass\n\n@torch.jit._overload\ndef my_function(x: type1) -> type1: # decl 2\n    pass\n\ndef my_function(x):                 # implementation\n    if isinstance(x, type0):\n        return x\n    elif isinstance(x, type1):\n        return x\n'''\n\ndef get_overload_no_implementation_error_message(kind, obj):\n    sourcelines, file_lineno, filename = get_source_lines_and_file(obj)\n    return (\n        f'Implementation for the {kind} \"{_qualified_name(obj)}\" is missing. Please make '\n        f'sure a definition is provided and defined after all overload declarations.\\n'\n        f'File \"{filename}\", line {file_lineno}:\\n' + ''.join(sourcelines) + \"\\n\" + _OVERLOAD_EXAMPLE\n    )\n\ndef _check_overload_body(func):\n    try:\n        parsed_def = parse_def(func)\n    except OSError as e:\n        # Parsing the function definition can raise an OSError if source is unavailable.\n        # Since this is just an initial check, just raise a warning if this is the case.\n        warnings.warn(f\"Unable to retrieve source for @torch.jit._overload function: {func}.\")\n        return\n\n    body = parsed_def.ast.body[0].body\n\n    def is_pass(x):\n        return isinstance(x, ast.Pass)\n\n    def is_ellipsis(x):\n        return isinstance(x, ast.Expr) and isinstance(x.value, ast.Ellipsis)\n\n    if len(body) != 1 or not (is_pass(body[0]) or is_ellipsis(body[0])):\n        msg = \"Only `pass` statement or `...` can be the body of overload declaration:\\n\"\n        msg += '\\n'.join(parsed_def.source.split(\"\\n\")[:3])\n        msg += \" <- Expecting `pass` or `...` here!\\n\" + _OVERLOAD_EXAMPLE\n        raise RuntimeError(msg)\n\ndef _overload(func):\n    _check_overload_body(func)\n    qual_name = _qualified_name(func)\n    global _overloaded_fns\n    fn_overload_list = _overloaded_fns.get(qual_name)\n    if fn_overload_list is None:\n        fn_overload_list = []\n        _overloaded_fns[qual_name] = fn_overload_list\n    fn_overload_list.append(func)\n    return func\n\ndef _get_fn_overloads(qual_name):\n    return _overloaded_fns.get(qual_name)\n\ndef _clear_fn_overloads(qual_name) -> None:\n    del _overloaded_fns[qual_name]\n\ndef get_class_name_lineno(method) -> Tuple[str, int]:\n    current_frame = inspect.currentframe()\n\n    # one for the get_class_name call, one for _overload_method call\n    for i in range(2):\n        assert current_frame is not None  # assert current frame is not an Optional[FrameType]\n        current_frame = current_frame.f_back\n\n    assert current_frame is not None  # same here\n    class_name = current_frame.f_code.co_name\n    line_no = current_frame.f_code.co_firstlineno\n    return class_name, line_no\n\n# At the the point the decorator is applied to class methods the method\n# has no reference to its owning class. _qualified_name would not include\n# the class it is defined in, so any methods with the same name in the same file\n# would have the same _qualified_name, even if they were defined in different\n# classes. This problem only exists in python 2.\n# We get around this problem by looking at the stack frame and identifying\n# the class name, and throwing an error whenever overloads are used\n# when modules of the same name are in the same file\n\n# qualified_name => class name => list[overload_functions]\n_overloaded_methods : Dict[str, Dict[str, List[Callable]]] = {}  # noqa: T484\n\n\n# (qualified_name, class name) => class_fileno\n_overloaded_method_class_fileno = {}\n\ndef _overload_method(func):\n    _check_overload_body(func)\n    qual_name = _qualified_name(func)\n    global _overloaded_methods\n    class_name_map = _overloaded_methods.get(qual_name, None)\n    if class_name_map is None:\n        class_name_map = {}\n        _overloaded_methods[qual_name] = class_name_map\n\n    class_name, line_no = get_class_name_lineno(func)\n    method_overloads = class_name_map.get(class_name, None)\n    if method_overloads is None:\n        method_overloads = []\n        class_name_map[class_name] = method_overloads\n        _overloaded_method_class_fileno[(qual_name, class_name)] = line_no\n    else:\n        existing_lineno = _overloaded_method_class_fileno[(qual_name, class_name)]\n        if existing_lineno != line_no:\n            raise RuntimeError(\"Cannot currently overload the same method name in two different\"\n                               \" classes with the same name in the same module\")\n\n    method_overloads.append(func)\n    return func\n\ndef _get_overloaded_methods(method, mod_class):\n    # TODO: __name__ not set for submodules in recursive script\n    if not hasattr(method, \"__name__\"):\n        return None\n    qual_name = _qualified_name(method)\n    class_name_map = _overloaded_methods.get(qual_name, None)\n    if class_name_map is None:\n        return None\n    overloads = class_name_map.get(mod_class.__name__, None)\n    if overloads is None:\n        return None\n\n    method_line_no = get_source_lines_and_file(method)[1]\n    mod_class_fileno = get_source_lines_and_file(mod_class)[1]\n    mod_end_fileno = mod_class_fileno + len(get_source_lines_and_file(mod_class)[0])\n    if not (method_line_no >= mod_class_fileno and method_line_no <= mod_end_fileno):\n        raise Exception(\"Overloads are not useable when a module is redeclared within the same file: \" + str(method))\n    return overloads\n\n\ndef is_tuple(ann) -> bool:\n    if ann is Tuple:\n        raise_error_container_parameter_missing(\"Tuple\")\n\n    # For some reason Python 3.7 violates the Type[A, B].__origin__ == Type rule\n    if not hasattr(ann, '__module__'):\n        return False\n    return ann.__module__ == 'typing' and \\\n        (getattr(ann, '__origin__', None) is Tuple or\n            getattr(ann, '__origin__', None) is tuple)\n\ndef is_list(ann) -> bool:\n    if ann is List:\n        raise_error_container_parameter_missing(\"List\")\n\n    if not hasattr(ann, '__module__'):\n        return False\n    return ann.__module__ == 'typing' and \\\n        (getattr(ann, '__origin__', None) is List or\n            getattr(ann, '__origin__', None) is list)\n\ndef is_dict(ann) -> bool:\n    if ann is Dict:\n        raise_error_container_parameter_missing(\"Dict\")\n\n    if not hasattr(ann, '__module__'):\n        return False\n    return ann.__module__ == 'typing' and \\\n        (getattr(ann, '__origin__', None) is Dict or\n            getattr(ann, '__origin__', None) is dict)\n\ndef is_union(ann):\n    if ann is Union:\n        raise_error_container_parameter_missing(\"Union\")\n\n    return (hasattr(ann, '__module__') and\n            ann.__module__ == 'typing' and\n            (getattr(ann, '__origin__', None) is Union))\n\ndef is_optional(ann):\n    if ann is Optional:\n        raise_error_container_parameter_missing(\"Optional\")\n\n    def is_optional_as_optional(ann):\n        return (hasattr(ann, '__module__') and\n                ann.__module__ == 'typing' and\n                (getattr(ann, '__origin__', None) is Optional))\n\n    def is_union_as_optional(ann):\n        ann_args = ann.__args__\n        return len(ann_args) == 2 and None in ann_args\n\n    return is_optional_as_optional(ann) or (is_union(ann) and is_union_as_optional(ann))\n\ndef is_future(ann) -> bool:\n    if ann is Future:\n        raise RuntimeError(\n            \"Attempted to use Future without a \"\n            \"contained type. Please add a contained type, e.g. \"\n            \"Future[int]\"\n        )\n    return getattr(ann, \"__origin__\", None) is Future\n\nif torch.distributed.rpc.is_available():\n    from torch.distributed.rpc import RRef\n    from torch._C._distributed_rpc import PyRRef\n\n    def is_rref(ann) -> bool:\n        if ann is RRef:\n            raise RuntimeError(\n                \"Attempted to use RRef without a \"\n                \"contained type. Please add a contained type, e.g. \"\n                \"RRef[int]\"\n            )\n        return getattr(ann, \"__origin__\", None) is RRef\n\n    def is_rref_instance(obj) -> bool:\n        return isinstance(obj, PyRRef)\n\nelse:\n    def is_rref_instance(obj) -> bool:\n        # If the RPC module doesn't exist then RRefs don't exist either.\n        return False\n\ndef is_final(ann) -> bool:\n    return ann.__module__ in {'typing', 'typing_extensions'} and \\\n        (getattr(ann, '__origin__', None) is Final or isinstance(ann, type(Final)))\n\n# allows BroadcastingList instance to be subscriptable\nclass BroadcastingListCls(object):\n    def __getitem__(self, types):\n        return\n\n# mypy doesn't support parameters on types, so we have to explicitly type each\n# list size\nBroadcastingList1 = BroadcastingListCls()\nfor i in range(2, 7):\n    globals()[f\"BroadcastingList{i}\"] = BroadcastingList1\n\n\ndef is_scripting() -> bool:\n    r\"\"\"\n    Function that returns True when in compilation and False otherwise. This\n    is useful especially with the @unused decorator to leave code in your\n    model that is not yet TorchScript compatible.\n    .. testcode::\n\n        import torch\n\n        @torch.jit.unused\n        def unsupported_linear_op(x):\n            return x\n\n        def linear(x):\n           if torch.jit.is_scripting():\n              return torch.linear(x)\n           else:\n              return unsupported_linear_op(x)\n    \"\"\"\n    return False\n\n\n# Retrieves a fully-qualified name (module hierarchy + classname) for a given obj.\ndef _qualified_name(obj) -> str:\n    # This special case allows us to override the qualified name on a type.\n    # It's currently used in conjunction with tracing, where we create a\n    # fake module to filter only supported attributes. However, since this\n    # new type is defined as a local class, we need a mechanism to override\n    # its qualname so it appears correctly in the TorchScript system. This,\n    # we set '_jit_override_qualname' with the original traced module's\n    # qualified name, which is picked up here\n    if hasattr(obj, '_jit_override_qualname'):\n        return obj._jit_override_qualname\n    # short-circuit in cases where the object already has a known qualified name\n    if isinstance(obj, torch._C.ScriptFunction):\n        return obj.qualified_name\n\n    if getattr(obj, \"__name__\", None):\n        name = obj.__name__\n    # Enum classes do not have `__name__` attr, instead they have `name`.\n    elif isinstance(obj, enum.Enum):\n        name = obj.name\n    else:\n        raise RuntimeError(\"Could not get name of python class object\")\n\n\n    if name == '<lambda>':\n        name = '_lambda'  # make name a valid identifier\n\n    module_name = obj.__module__\n\n    # If the module is actually a torchbind module, then we should short circuit\n    if module_name == \"torch._classes\":\n        return obj.qualified_name\n\n    # The Python docs are very clear that `__module__` can be None, but I can't\n    # figure out when it actually would be.\n    if module_name is None:\n        raise RuntimeError(f\"Could not get qualified name for class '{name}': \"\n                           \"__module__ can't be None.\")\n\n    # if getattr(sys.modules[module_name], name) is not obj:\n    #     raise RuntimeError(f\"Could not get qualified name for class '{name}': \"\n    #                        f\"the attr {name} on module {module_name} is not the the class\")\n\n    # torch.package and TorchScript have separate mangling schemes to avoid\n    # name collisions from multiple packages. To avoid them interfering with\n    # each other, remove the package mangling here.\n    module_name = package_mangling.demangle(module_name)\n\n    # __main__ is a builtin module, so rewrite it to \"__torch__\".\n    if module_name == \"__main__\":\n        module_name = \"__torch__\"\n    else:\n        # Everything else gets a \"__torch__\" prefix to avoid name collisions\n        # with the names of user values.\n        module_name = \"__torch__.\" + module_name\n\n    if \".\" in name:\n        raise RuntimeError(f\"Could not get qualified name for class '{name}': \"\n                           f\"'{name}' is not a valid identifier\")\n\n    return module_name + \".\" + name\n\n\ndef _try_get_dispatched_fn(fn):\n    if not callable(fn):\n        return None\n    return boolean_dispatched.get(fn)\n\n\ndef _get_named_tuple_properties(obj):\n    assert issubclass(obj, tuple) and hasattr(obj, '_fields')\n    if hasattr(obj, \"_field_defaults\"):\n        defaults = [obj._field_defaults[field]\n                    for field in obj._fields\n                    if field in obj._field_defaults]\n    else:\n        defaults = []\n    annotations = []\n    has_annotations = hasattr(obj, '__annotations__')\n    for field in obj._fields:\n        if has_annotations and field in obj.__annotations__:\n            the_type = torch.jit.annotations.ann_to_type(obj.__annotations__[field], fake_range())\n            annotations.append(the_type)\n        else:\n            annotations.append(torch._C.TensorType.getInferred())\n    return type(obj).__name__, obj._fields, annotations, defaults\n\n\ndef _create_named_tuple(t, unqual_name: str, field_names: List[str], defaults: Tuple[Any, ...]):\n    # mypy: namedtuple() expects a string literal as the first argument\n    if sys.version_info < (3, 7, 0):\n        TupleType = collections.namedtuple(unqual_name, field_names)  # type: ignore[no-redef, misc]\n        TupleType.__new__.__defaults__ = defaults    # type: ignore[attr-defined]\n    else:\n        TupleType = collections.namedtuple(unqual_name, field_names, defaults=defaults)  # type: ignore[call-arg, no-redef, misc]\n    return TupleType(*t)\n\n@contextlib.contextmanager\ndef _disable_emit_hooks():\n    hooks = torch._C._jit_get_emit_hooks()\n    torch._C._jit_set_emit_hooks(None, None)\n    yield\n    torch._C._jit_set_emit_hooks(hooks[0], hooks[1])\n\n\ndef _disable_emit_hooks_decorator(_DecoratorContextManager) -> None:  # noqa: F811\n    def __enter__(self) -> None:\n        self.hooks = torch._C._jit_get_emit_hooks()\n        torch._C._jit_set_emit_hooks(None, None)\n\n    def __exit__(self, *args) -> None:\n        torch._C._jit_set_emit_hooks(self.hooks[0], self.hooks[1])\n\ndef _is_exception(obj) -> bool:\n    if not inspect.isclass(obj):\n        return False\n    return issubclass(obj, Exception)\n\ndef raise_error_container_parameter_missing(target_type) -> None:\n    if target_type == 'Dict':\n        raise RuntimeError(\n            \"Attempted to use Dict without \"\n            \"contained types. Please add contained type, e.g. \"\n            \"Dict[int, int]\"\n        )\n    raise RuntimeError(\n        f\"Attempted to use {target_type} without a \"\n        \"contained type. Please add a contained type, e.g. \"\n        f\"{target_type}[int]\"\n    )\n\n\ndef get_origin(target_type):\n    return getattr(target_type, \"__origin__\", None)\n\n\ndef get_args(target_type):\n    return getattr(target_type, \"__args__\", None)\n\n\ndef check_args_exist(target_type) -> None:\n    if target_type is List or target_type is list:\n        raise_error_container_parameter_missing(\"List\")\n    elif target_type is Tuple or target_type is tuple:\n        raise_error_container_parameter_missing(\"Tuple\")\n    elif target_type is Dict or target_type is dict:\n        raise_error_container_parameter_missing(\"Dict\")\n    elif target_type is None or target_type is Optional:\n        raise_error_container_parameter_missing(\"Optional\")\n\n\ndef check_empty_containers(obj) -> None:\n    if obj == [] or obj == {} or obj == ():\n        warnings.warn(\"The inner type of a container is lost when \"\n                      \"calling torch.jit.isinstance in eager mode. For \"\n                      \"example, List[int] would become list and \"\n                      \"therefore falsely return True for List[float] or\"\n                      \" List[str].\")\n\n\n# supports List/Dict/Tuple and Optional types\n# TODO support future\ndef container_checker(obj, target_type) -> bool:\n    origin_type = get_origin(target_type)\n    check_args_exist(target_type)\n    if origin_type is list or origin_type is List:\n        check_empty_containers(obj)\n        if not isinstance(obj, list):\n            return False\n        arg_type = get_args(target_type)[0]\n        arg_origin = get_origin(arg_type)\n        for el in obj:\n            # check if nested container, ex: List[List[str]]\n            if arg_origin:  # processes nested container, ex: List[List[str]]\n                if not container_checker(el, arg_type):\n                    return False\n            elif not isinstance(el, arg_type):\n                return False\n        return True\n    elif origin_type is Dict or origin_type is dict:\n        check_empty_containers(obj)\n        if not isinstance(obj, dict):\n            return False\n        key_type = get_args(target_type)[0]\n        val_type = get_args(target_type)[1]\n        for key, val in obj.items():\n            # check if keys are of right type\n            if not isinstance(key, key_type):\n                return False\n            val_origin = get_origin(val_type)\n            if val_origin:\n                if not container_checker(val, val_type):\n                    return False\n            elif not isinstance(val, val_type):\n                return False\n        return True\n    elif origin_type is Tuple or origin_type is tuple:\n        check_empty_containers(obj)\n        if not isinstance(obj, tuple):\n            return False\n        arg_types = get_args(target_type)\n        if len(obj) != len(arg_types):\n            return False\n        for el, el_type in zip(obj, arg_types):\n            el_origin = get_origin(el_type)\n            if el_origin:\n                if not container_checker(el, el_type):\n                    return False\n            elif not isinstance(el, el_type):\n                return False\n        return True\n    elif origin_type is Union:  # also handles Optional\n        if obj is None:  # check before recursion because None is always fine\n            return True\n        inner_types = get_args(target_type)\n        for t in inner_types:\n            t_origin = get_origin(t)\n            if (t_origin):\n                return container_checker(obj, t)\n            elif isinstance(obj, t):\n                return True\n    return False\n\n\ndef _isinstance(obj, target_type) -> bool:\n    if isinstance(target_type, collections.abc.Container):\n        if not isinstance(target_type, tuple):\n            raise RuntimeError(\"The second argument to \"\n                               \"`torch.jit.isinstance` must be a type \"\n                               \"or a tuple of types\")\n        for t_type in target_type:\n            if _isinstance(obj, t_type):\n                return True\n        return False\n\n    origin_type = get_origin(target_type)\n    if origin_type:\n        return container_checker(obj, target_type)\n\n    # Check to handle weird python type behaviors\n    # 1. python 3.6 returns None for origin of containers without\n    #    contained type (intead of returning outer container type)\n    # 2. non-typed optional origin returns as none instead\n    #    of as optional in 3.6-3.8\n    check_args_exist(target_type)\n\n    # handle non-containers\n    return isinstance(obj, target_type)\n\n\nclass _TensorExtractor(pickle.Pickler):\n    def __init__(self, *args, tensors: List[torch.Tensor], **kwargs):\n        super().__init__(*args, **kwargs)\n        self.tensors = tensors\n\n    def persistent_id(self, obj):\n        if isinstance(obj, torch.Tensor):\n            self.tensors.append(obj)\n            return \"\"\n        # Since we just want to extract tensors, we don't mind if an object is\n        # unpicklable if it doesn't contain tensors, as we can just ignore/skip\n        # it. To play it safe, we only do so for common objects that we're sure\n        # don't contain tensors. Feel free to add new types here. Note also that\n        # even if a type isn't listed here this won't block users, since thet\n        # can just add a __getstate__ or __reduce__ method to their class.\n        if isinstance(obj, LockType):\n            return \"\"\n        # Futures and RRefs don't technically contain a value, they just offer\n        # the means to access a value.\n        if isinstance(obj, CFuture) or is_rref_instance(obj):\n            return \"\"\n        if isinstance(obj, torch.cuda.Event):\n            return \"\"\n        return None\n\n\ndef _extract_tensors(obj):\n    r\"\"\"\n    This function is exclusively called from C++.\n    See ``torch/csrc/jit/python/python_ivalue.h``.\n\n    It extracts the tensors contained in the given object, through pickling.\n    \"\"\"\n    tensors: List[torch.Tensor] = []\n    extractor = _TensorExtractor(io.BytesIO(), protocol=-1, tensors=tensors)\n    extractor.dump(obj)\n    return tensors\n", 1265], "/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/matplotlib/_pylab_helpers.py": ["\"\"\"\nManage figures for the pyplot interface.\n\"\"\"\n\nimport atexit\nfrom collections import OrderedDict\nimport gc\n\n\nclass Gcf:\n    \"\"\"\n    Singleton to maintain the relation between figures and their managers, and\n    keep track of and \"active\" figure and manager.\n\n    The canvas of a figure created through pyplot is associated with a figure\n    manager, which handles the interaction between the figure and the backend.\n    pyplot keeps track of figure managers using an identifier, the \"figure\n    number\" or \"manager number\" (which can actually be any hashable value);\n    this number is available as the :attr:`number` attribute of the manager.\n\n    This class is never instantiated; it consists of an `OrderedDict` mapping\n    figure/manager numbers to managers, and a set of class methods that\n    manipulate this `OrderedDict`.\n\n    Attributes\n    ----------\n    figs : OrderedDict\n        `OrderedDict` mapping numbers to managers; the active manager is at the\n        end.\n    \"\"\"\n\n    figs = OrderedDict()\n\n    @classmethod\n    def get_fig_manager(cls, num):\n        \"\"\"\n        If manager number *num* exists, make it the active one and return it;\n        otherwise return *None*.\n        \"\"\"\n        manager = cls.figs.get(num, None)\n        if manager is not None:\n            cls.set_active(manager)\n        return manager\n\n    @classmethod\n    def destroy(cls, num):\n        \"\"\"\n        Destroy manager *num* -- either a manager instance or a manager number.\n\n        In the interactive backends, this is bound to the window \"destroy\" and\n        \"delete\" events.\n\n        It is recommended to pass a manager instance, to avoid confusion when\n        two managers share the same number.\n        \"\"\"\n        if all(hasattr(num, attr) for attr in [\"num\", \"destroy\"]):\n            manager = num\n            if cls.figs.get(manager.num) is manager:\n                cls.figs.pop(manager.num)\n        else:\n            try:\n                manager = cls.figs.pop(num)\n            except KeyError:\n                return\n        if hasattr(manager, \"_cidgcf\"):\n            manager.canvas.mpl_disconnect(manager._cidgcf)\n        manager.destroy()\n        gc.collect(1)\n\n    @classmethod\n    def destroy_fig(cls, fig):\n        \"\"\"Destroy figure *fig*.\"\"\"\n        num = next((manager.num for manager in cls.figs.values()\n                    if manager.canvas.figure == fig), None)\n        if num is not None:\n            cls.destroy(num)\n\n    @classmethod\n    def destroy_all(cls):\n        \"\"\"Destroy all figures.\"\"\"\n        # Reimport gc in case the module globals have already been removed\n        # during interpreter shutdown.\n        import gc\n        for manager in list(cls.figs.values()):\n            manager.canvas.mpl_disconnect(manager._cidgcf)\n            manager.destroy()\n        cls.figs.clear()\n        gc.collect(1)\n\n    @classmethod\n    def has_fignum(cls, num):\n        \"\"\"Return whether figure number *num* exists.\"\"\"\n        return num in cls.figs\n\n    @classmethod\n    def get_all_fig_managers(cls):\n        \"\"\"Return a list of figure managers.\"\"\"\n        return list(cls.figs.values())\n\n    @classmethod\n    def get_num_fig_managers(cls):\n        \"\"\"Return the number of figures being managed.\"\"\"\n        return len(cls.figs)\n\n    @classmethod\n    def get_active(cls):\n        \"\"\"Return the active manager, or *None* if there is no manager.\"\"\"\n        return next(reversed(cls.figs.values())) if cls.figs else None\n\n    @classmethod\n    def _set_new_active_manager(cls, manager):\n        \"\"\"Adopt *manager* into pyplot and make it the active manager.\"\"\"\n        if not hasattr(manager, \"_cidgcf\"):\n            manager._cidgcf = manager.canvas.mpl_connect(\n                \"button_press_event\", lambda event: cls.set_active(manager))\n        fig = manager.canvas.figure\n        fig.number = manager.num\n        label = fig.get_label()\n        if label:\n            manager.set_window_title(label)\n        cls.set_active(manager)\n\n    @classmethod\n    def set_active(cls, manager):\n        \"\"\"Make *manager* the active manager.\"\"\"\n        cls.figs[manager.num] = manager\n        cls.figs.move_to_end(manager.num)\n\n    @classmethod\n    def draw_all(cls, force=False):\n        \"\"\"\n        Redraw all stale managed figures, or, if *force* is True, all managed\n        figures.\n        \"\"\"\n        for manager in cls.get_all_fig_managers():\n            if force or manager.canvas.figure.stale:\n                manager.canvas.draw_idle()\n\n\natexit.register(Gcf.destroy_all)\n", 140], "/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/progressbar/utils.py": ["from __future__ import absolute_import\nimport atexit\nimport io\nimport os\nimport re\nimport sys\nimport logging\nimport datetime\nfrom python_utils.time import timedelta_to_seconds, epoch, format_time\nfrom python_utils.converters import scale_1024\nfrom python_utils.terminal import get_terminal_size\n\nimport six\n\n\nassert timedelta_to_seconds\nassert get_terminal_size\nassert format_time\nassert scale_1024\nassert epoch\n\n\nANSI_TERMS = (\n    '([xe]|bv)term',\n    '(sco)?ansi',\n    'cygwin',\n    'konsole',\n    'linux',\n    'rxvt',\n    'screen',\n    'tmux',\n    'vt(10[02]|220|320)',\n)\nANSI_TERM_RE = re.compile('^({})'.format('|'.join(ANSI_TERMS)), re.IGNORECASE)\n\n\ndef is_ansi_terminal(fd, is_terminal=None):  # pragma: no cover\n    if is_terminal is None:\n        # Jupyter Notebooks define this variable and support progress bars\n        if 'JPY_PARENT_PID' in os.environ:\n            is_terminal = True\n        # This works for newer versions of pycharm only. older versions there\n        # is no way to check.\n        elif os.environ.get('PYCHARM_HOSTED') == '1':\n            is_terminal = True\n\n    if is_terminal is None:\n        # check if we are writing to a terminal or not. typically a file object\n        # is going to return False if the instance has been overridden and\n        # isatty has not been defined we have no way of knowing so we will not\n        # use ansi.  ansi terminals will typically define one of the 2\n        # environment variables.\n        try:\n            is_tty = fd.isatty()\n            # Try and match any of the huge amount of Linux/Unix ANSI consoles\n            if is_tty and ANSI_TERM_RE.match(os.environ.get('TERM', '')):\n                is_terminal = True\n            # ANSICON is a Windows ANSI compatible console\n            elif 'ANSICON' in os.environ:\n                is_terminal = True\n            else:\n                is_terminal = None\n        except Exception:\n            is_terminal = False\n\n    return is_terminal\n\n\ndef is_terminal(fd, is_terminal=None):\n    if is_terminal is None:\n        # Full ansi support encompasses what we expect from a terminal\n        is_terminal = is_ansi_terminal(True) or None\n\n    if is_terminal is None:\n        # Allow a environment variable override\n        is_terminal = env_flag('PROGRESSBAR_IS_TERMINAL', None)\n\n    if is_terminal is None:  # pragma: no cover\n        # Bare except because a lot can go wrong on different systems. If we do\n        # get a TTY we know this is a valid terminal\n        try:\n            is_terminal = fd.isatty()\n        except Exception:\n            is_terminal = False\n\n    return is_terminal\n\n\ndef deltas_to_seconds(*deltas, **kwargs):  # default=ValueError):\n    '''\n    Convert timedeltas and seconds as int to seconds as float while coalescing\n\n    >>> deltas_to_seconds(datetime.timedelta(seconds=1, milliseconds=234))\n    1.234\n    >>> deltas_to_seconds(123)\n    123.0\n    >>> deltas_to_seconds(1.234)\n    1.234\n    >>> deltas_to_seconds(None, 1.234)\n    1.234\n    >>> deltas_to_seconds(0, 1.234)\n    0.0\n    >>> deltas_to_seconds()\n    Traceback (most recent call last):\n    ...\n    ValueError: No valid deltas passed to `deltas_to_seconds`\n    >>> deltas_to_seconds(None)\n    Traceback (most recent call last):\n    ...\n    ValueError: No valid deltas passed to `deltas_to_seconds`\n    >>> deltas_to_seconds(default=0.0)\n    0.0\n    '''\n    default = kwargs.pop('default', ValueError)\n    assert not kwargs, 'Only the `default` keyword argument is supported'\n\n    for delta in deltas:\n        if delta is None:\n            continue\n        if isinstance(delta, datetime.timedelta):\n            return timedelta_to_seconds(delta)\n        elif not isinstance(delta, float):\n            return float(delta)\n        else:\n            return delta\n\n    if default is ValueError:\n        raise ValueError('No valid deltas passed to `deltas_to_seconds`')\n    else:\n        return default\n\n\ndef no_color(value):\n    '''\n    Return the `value` without ANSI escape codes\n\n    >>> no_color(b'\\u001b[1234]abc') == b'abc'\n    True\n    >>> str(no_color(u'\\u001b[1234]abc'))\n    'abc'\n    >>> str(no_color('\\u001b[1234]abc'))\n    'abc'\n    '''\n    if isinstance(value, bytes):\n        pattern = '\\\\\\u001b\\\\[.*?[@-~]'\n        pattern = pattern.encode()\n        replace = b''\n        assert isinstance(pattern, bytes)\n    else:\n        pattern = u'\\x1b\\\\[.*?[@-~]'\n        replace = ''\n\n    return re.sub(pattern, replace, value)\n\n\ndef len_color(value):\n    '''\n    Return the length of `value` without ANSI escape codes\n\n    >>> len_color(b'\\u001b[1234]abc')\n    3\n    >>> len_color(u'\\u001b[1234]abc')\n    3\n    >>> len_color('\\u001b[1234]abc')\n    3\n    '''\n    return len(no_color(value))\n\n\ndef env_flag(name, default=None):\n    '''\n    Accepts environt variables formatted as y/n, yes/no, 1/0, true/false,\n    on/off, and returns it as a boolean\n\n    If the environment variable is not defined, or has an unknown value,\n    returns `default`\n    '''\n    v = os.getenv(name)\n    if v and v.lower() in ('y', 'yes', 't', 'true', 'on', '1'):\n        return True\n    if v and v.lower() in ('n', 'no', 'f', 'false', 'off', '0'):\n        return False\n    return default\n\n\nclass WrappingIO:\n\n    def __init__(self, target, capturing=False, listeners=set()):\n        self.buffer = six.StringIO()\n        self.target = target\n        self.capturing = capturing\n        self.listeners = listeners\n        self.needs_clear = False\n\n    def isatty(self):  # pragma: no cover\n        return self.target.isatty()\n\n    def write(self, value):\n        if self.capturing:\n            self.buffer.write(value)\n            if '\\n' in value:  # pragma: no branch\n                self.needs_clear = True\n                for listener in self.listeners:  # pragma: no branch\n                    listener.update()\n        else:\n            self.target.write(value)\n            if '\\n' in value:  # pragma: no branch\n                self.flush_target()\n\n    def flush(self):\n        self.buffer.flush()\n\n    def _flush(self):\n        value = self.buffer.getvalue()\n        if value:\n            self.flush()\n            self.target.write(value)\n            self.buffer.seek(0)\n            self.buffer.truncate(0)\n            self.needs_clear = False\n\n        # when explicitly flushing, always flush the target as well\n        self.flush_target()\n\n    def flush_target(self):  # pragma: no cover\n        if not self.target.closed and getattr(self.target, 'flush'):\n            self.target.flush()\n\n\nclass StreamWrapper(object):\n    '''Wrap stdout and stderr globally'''\n\n    def __init__(self):\n        self.stdout = self.original_stdout = sys.stdout\n        self.stderr = self.original_stderr = sys.stderr\n        self.original_excepthook = sys.excepthook\n        self.wrapped_stdout = 0\n        self.wrapped_stderr = 0\n        self.wrapped_excepthook = 0\n        self.capturing = 0\n        self.listeners = set()\n\n        if env_flag('WRAP_STDOUT', default=False):  # pragma: no cover\n            self.wrap_stdout()\n\n        if env_flag('WRAP_STDERR', default=False):  # pragma: no cover\n            self.wrap_stderr()\n\n    def start_capturing(self, bar=None):\n        if bar:  # pragma: no branch\n            self.listeners.add(bar)\n\n        self.capturing += 1\n        self.update_capturing()\n\n    def stop_capturing(self, bar=None):\n        if bar:  # pragma: no branch\n            try:\n                self.listeners.remove(bar)\n            except KeyError:\n                pass\n\n        self.capturing -= 1\n        self.update_capturing()\n\n    def update_capturing(self):  # pragma: no cover\n        if isinstance(self.stdout, WrappingIO):\n            self.stdout.capturing = self.capturing > 0\n\n        if isinstance(self.stderr, WrappingIO):\n            self.stderr.capturing = self.capturing > 0\n\n        if self.capturing <= 0:\n            self.flush()\n\n    def wrap(self, stdout=False, stderr=False):\n        if stdout:\n            self.wrap_stdout()\n\n        if stderr:\n            self.wrap_stderr()\n\n    def wrap_stdout(self):\n        self.wrap_excepthook()\n\n        if not self.wrapped_stdout:\n            self.stdout = sys.stdout = WrappingIO(self.original_stdout,\n                                                  listeners=self.listeners)\n        self.wrapped_stdout += 1\n\n        return sys.stdout\n\n    def wrap_stderr(self):\n        self.wrap_excepthook()\n\n        if not self.wrapped_stderr:\n            self.stderr = sys.stderr = WrappingIO(self.original_stderr,\n                                                  listeners=self.listeners)\n        self.wrapped_stderr += 1\n\n        return sys.stderr\n\n    def unwrap_excepthook(self):\n        if self.wrapped_excepthook:\n            self.wrapped_excepthook -= 1\n            sys.excepthook = self.original_excepthook\n\n    def wrap_excepthook(self):\n        if not self.wrapped_excepthook:\n            logger.debug('wrapping excepthook')\n            self.wrapped_excepthook += 1\n            sys.excepthook = self.excepthook\n\n    def unwrap(self, stdout=False, stderr=False):\n        if stdout:\n            self.unwrap_stdout()\n\n        if stderr:\n            self.unwrap_stderr()\n\n    def unwrap_stdout(self):\n        if self.wrapped_stdout > 1:\n            self.wrapped_stdout -= 1\n        else:\n            sys.stdout = self.original_stdout\n            self.wrapped_stdout = 0\n\n    def unwrap_stderr(self):\n        if self.wrapped_stderr > 1:\n            self.wrapped_stderr -= 1\n        else:\n            sys.stderr = self.original_stderr\n            self.wrapped_stderr = 0\n\n    def needs_clear(self):  # pragma: no cover\n        stdout_needs_clear = getattr(self.stdout, 'needs_clear', False)\n        stderr_needs_clear = getattr(self.stderr, 'needs_clear', False)\n        return stderr_needs_clear or stdout_needs_clear\n\n    def flush(self):\n        if self.wrapped_stdout:  # pragma: no branch\n            try:\n                self.stdout._flush()\n            except (io.UnsupportedOperation,\n                    AttributeError):  # pragma: no cover\n                self.wrapped_stdout = False\n                logger.warn('Disabling stdout redirection, %r is not seekable',\n                            sys.stdout)\n\n        if self.wrapped_stderr:  # pragma: no branch\n            try:\n                self.stderr._flush()\n            except (io.UnsupportedOperation,\n                    AttributeError):  # pragma: no cover\n                self.wrapped_stderr = False\n                logger.warn('Disabling stderr redirection, %r is not seekable',\n                            sys.stderr)\n\n    def excepthook(self, exc_type, exc_value, exc_traceback):\n        self.original_excepthook(exc_type, exc_value, exc_traceback)\n        self.flush()\n\n\nclass AttributeDict(dict):\n    '''\n    A dict that can be accessed with .attribute\n\n    >>> attrs = AttributeDict(spam=123)\n\n    # Reading\n    >>> attrs['spam']\n    123\n    >>> attrs.spam\n    123\n\n    # Read after update using attribute\n    >>> attrs.spam = 456\n    >>> attrs['spam']\n    456\n    >>> attrs.spam\n    456\n\n    # Read after update using dict access\n    >>> attrs['spam'] = 123\n    >>> attrs['spam']\n    123\n    >>> attrs.spam\n    123\n\n    # Read after update using dict access\n    >>> del attrs.spam\n    >>> attrs['spam']\n    Traceback (most recent call last):\n    ...\n    KeyError: 'spam'\n    >>> attrs.spam\n    Traceback (most recent call last):\n    ...\n    AttributeError: No such attribute: spam\n    >>> del attrs.spam\n    Traceback (most recent call last):\n    ...\n    AttributeError: No such attribute: spam\n    '''\n    def __getattr__(self, name):\n        if name in self:\n            return self[name]\n        else:\n            raise AttributeError(\"No such attribute: \" + name)\n\n    def __setattr__(self, name, value):\n        self[name] = value\n\n    def __delattr__(self, name):\n        if name in self:\n            del self[name]\n        else:\n            raise AttributeError(\"No such attribute: \" + name)\n\n\nlogger = logging.getLogger(__name__)\nstreams = StreamWrapper()\natexit.register(streams.flush)\n", 423], "/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/pyopencl/tools.py": ["\"\"\"Various helpful bits and pieces without much of a common theme.\"\"\"\n\n\n__copyright__ = \"Copyright (C) 2010 Andreas Kloeckner\"\n\n__license__ = \"\"\"\nPermission is hereby granted, free of charge, to any person\nobtaining a copy of this software and associated documentation\nfiles (the \"Software\"), to deal in the Software without\nrestriction, including without limitation the rights to use,\ncopy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the\nSoftware is furnished to do so, subject to the following\nconditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\nOF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\nHOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\nWHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\nFROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\nOTHER DEALINGS IN THE SOFTWARE.\n\"\"\"\n\n\nfrom sys import intern\n\n# Do not add a pyopencl import here: This will add an import cycle.\n\nimport numpy as np\nfrom pytools import memoize, memoize_method\nfrom pyopencl._cl import bitlog2  # noqa: F401\nfrom pytools.persistent_dict import KeyBuilder as KeyBuilderBase\n\nimport re\n\nfrom pyopencl.compyte.dtypes import (  # noqa\n        get_or_register_dtype, TypeNameNotKnown,\n        register_dtype, dtype_to_ctype)\n\n\ndef _register_types():\n    from pyopencl.compyte.dtypes import (\n            TYPE_REGISTRY, fill_registry_with_opencl_c_types)\n\n    fill_registry_with_opencl_c_types(TYPE_REGISTRY)\n\n    get_or_register_dtype(\"cfloat_t\", np.complex64)\n    get_or_register_dtype(\"cdouble_t\", np.complex128)\n\n\n_register_types()\n\n\n# {{{ imported names\n\nfrom pyopencl._cl import (  # noqa\n        PooledBuffer as PooledBuffer,\n        _tools_DeferredAllocator as DeferredAllocator,\n        _tools_ImmediateAllocator as ImmediateAllocator,\n        MemoryPool as MemoryPool)\n\n# }}}\n\n\n# {{{ first-arg caches\n\n_first_arg_dependent_caches = []\n\n\ndef first_arg_dependent_memoize(func):\n    def wrapper(cl_object, *args, **kwargs):\n        \"\"\"Provides memoization for a function. Typically used to cache\n        things that get created inside a :class:`pyopencl.Context`, e.g. programs\n        and kernels. Assumes that the first argument of the decorated function is\n        an OpenCL object that might go away, such as a :class:`pyopencl.Context` or\n        a :class:`pyopencl.CommandQueue`, and based on which we might want to clear\n        the cache.\n\n        .. versionadded:: 2011.2\n        \"\"\"\n        if kwargs:\n            cache_key = (args, frozenset(kwargs.items()))\n        else:\n            cache_key = (args,)\n\n        try:\n            ctx_dict = func._pyopencl_first_arg_dep_memoize_dic\n        except AttributeError:\n            # FIXME: This may keep contexts alive longer than desired.\n            # But I guess since the memory in them is freed, who cares.\n            ctx_dict = func._pyopencl_first_arg_dep_memoize_dic = {}\n            _first_arg_dependent_caches.append(ctx_dict)\n\n        try:\n            return ctx_dict[cl_object][cache_key]\n        except KeyError:\n            arg_dict = ctx_dict.setdefault(cl_object, {})\n            result = func(cl_object, *args, **kwargs)\n            arg_dict[cache_key] = result\n            return result\n\n    from functools import update_wrapper\n    update_wrapper(wrapper, func)\n    return wrapper\n\n\ncontext_dependent_memoize = first_arg_dependent_memoize\n\n\ndef first_arg_dependent_memoize_nested(nested_func):\n    \"\"\"Provides memoization for nested functions. Typically used to cache\n    things that get created inside a :class:`pyopencl.Context`, e.g. programs\n    and kernels. Assumes that the first argument of the decorated function is\n    an OpenCL object that might go away, such as a :class:`pyopencl.Context` or\n    a :class:`pyopencl.CommandQueue`, and will therefore respond to\n    :func:`clear_first_arg_caches`.\n\n    .. versionadded:: 2013.1\n\n    Requires Python 2.5 or newer.\n    \"\"\"\n\n    from functools import wraps\n    cache_dict_name = intern(\"_memoize_inner_dic_%s_%s_%d\"\n            % (nested_func.__name__, nested_func.__code__.co_filename,\n                nested_func.__code__.co_firstlineno))\n\n    from inspect import currentframe\n    # prevent ref cycle\n    try:\n        caller_frame = currentframe().f_back\n        cache_context = caller_frame.f_globals[\n                caller_frame.f_code.co_name]\n    finally:\n        #del caller_frame\n        pass\n\n    try:\n        cache_dict = getattr(cache_context, cache_dict_name)\n    except AttributeError:\n        cache_dict = {}\n        _first_arg_dependent_caches.append(cache_dict)\n        setattr(cache_context, cache_dict_name, cache_dict)\n\n    @wraps(nested_func)\n    def new_nested_func(cl_object, *args):\n        try:\n            return cache_dict[cl_object][args]\n        except KeyError:\n            arg_dict = cache_dict.setdefault(cl_object, {})\n            result = nested_func(cl_object, *args)\n            arg_dict[args] = result\n            return result\n\n    return new_nested_func\n\n\ndef clear_first_arg_caches():\n    \"\"\"Empties all first-argument-dependent memoization caches. Also releases\n    all held reference contexts. If it is important to you that the\n    program detaches from its context, you might need to call this\n    function to free all remaining references to your context.\n\n    .. versionadded:: 2011.2\n    \"\"\"\n    for cache in _first_arg_dependent_caches:\n        cache.clear()\n\n\nimport atexit\natexit.register(clear_first_arg_caches)\n\n# }}}\n\n\n# {{{ pytest fixtures\n\nclass _ContextFactory:\n    def __init__(self, device):\n        self.device = device\n\n    def __call__(self):\n        # Get rid of leftovers from past tests.\n        # CL implementations are surprisingly limited in how many\n        # simultaneous contexts they allow...\n        clear_first_arg_caches()\n\n        from gc import collect\n        collect()\n\n        import pyopencl as cl\n        return cl.Context([self.device])\n\n    def __str__(self):\n        # Don't show address, so that parallel test collection works\n        return (\"<context factory for <pyopencl.Device '%s' on '%s'>>\" %\n                (self.device.name.strip(),\n                 self.device.platform.name.strip()))\n\n\ndef get_test_platforms_and_devices(plat_dev_string=None):\n    \"\"\"Parse a string of the form 'PYOPENCL_TEST=0:0,1;intel:i5'.\n\n    :return: list of tuples (platform, [device, device, ...])\n    \"\"\"\n\n    import pyopencl as cl\n\n    if plat_dev_string is None:\n        import os\n        plat_dev_string = os.environ.get(\"PYOPENCL_TEST\", None)\n\n    def find_cl_obj(objs, identifier):\n        try:\n            num = int(identifier)\n        except Exception:\n            pass\n        else:\n            return objs[num]\n\n        found = False\n        for obj in objs:\n            if identifier.lower() in (obj.name + \" \" + obj.vendor).lower():\n                return obj\n        if not found:\n            raise RuntimeError(\"object '%s' not found\" % identifier)\n\n    if plat_dev_string:\n        result = []\n\n        for entry in plat_dev_string.split(\";\"):\n            lhsrhs = entry.split(\":\")\n\n            if len(lhsrhs) == 1:\n                platform = find_cl_obj(cl.get_platforms(), lhsrhs[0])\n                result.append((platform, platform.get_devices()))\n\n            elif len(lhsrhs) != 2:\n                raise RuntimeError(\"invalid syntax of PYOPENCL_TEST\")\n            else:\n                plat_str, dev_strs = lhsrhs\n\n                platform = find_cl_obj(cl.get_platforms(), plat_str)\n                devs = platform.get_devices()\n                result.append(\n                        (platform,\n                            [find_cl_obj(devs, dev_id)\n                                for dev_id in dev_strs.split(\",\")]))\n\n        return result\n\n    else:\n        return [\n                (platform, platform.get_devices())\n                for platform in cl.get_platforms()]\n\n\ndef get_pyopencl_fixture_arg_names(metafunc, extra_arg_names=None):\n    if extra_arg_names is None:\n        extra_arg_names = []\n\n    supported_arg_names = [\n            \"platform\", \"device\",\n            \"ctx_factory\", \"ctx_getter\",\n            ] + extra_arg_names\n\n    arg_names = []\n    for arg in supported_arg_names:\n        if arg not in metafunc.fixturenames:\n            continue\n\n        if arg == \"ctx_getter\":\n            from warnings import warn\n            warn(\"The 'ctx_getter' arg is deprecated in \"\n                    \"favor of 'ctx_factory'.\",\n                    DeprecationWarning)\n\n        arg_names.append(arg)\n\n    return arg_names\n\n\ndef get_pyopencl_fixture_arg_values():\n    import pyopencl as cl\n\n    arg_values = []\n    for platform, devices in get_test_platforms_and_devices():\n        for device in devices:\n            arg_dict = {\n                \"platform\": platform,\n                \"device\": device,\n                \"ctx_factory\": _ContextFactory(device),\n                \"ctx_getter\": _ContextFactory(device)\n            }\n            arg_values.append(arg_dict)\n\n    def idfn(val):\n        if isinstance(val, cl.Platform):\n            # Don't show address, so that parallel test collection works\n            return f\"<pyopencl.Platform '{val.name}'>\"\n        else:\n            return str(val)\n\n    return arg_values, idfn\n\n\ndef pytest_generate_tests_for_pyopencl(metafunc):\n    arg_names = get_pyopencl_fixture_arg_names(metafunc)\n    if not arg_names:\n        return\n\n    arg_values, ids = get_pyopencl_fixture_arg_values()\n    arg_values = [\n            tuple(arg_dict[name] for name in arg_names)\n            for arg_dict in arg_values\n            ]\n\n    metafunc.parametrize(arg_names, arg_values, ids=ids)\n\n# }}}\n\n\n# {{{ C argument lists\n\nclass Argument:\n    pass\n\n\nclass DtypedArgument(Argument):\n    def __init__(self, dtype, name):\n        self.dtype = np.dtype(dtype)\n        self.name = name\n\n    def __repr__(self):\n        return \"{}({!r}, {})\".format(\n                self.__class__.__name__,\n                self.name,\n                self.dtype)\n\n    def __eq__(self, other):\n        return (type(self) == type(other)\n                and self.dtype == other.dtype\n                and self.name == other.name)\n\n    def __hash__(self):\n        return (\n                hash(type(self))\n                ^ hash(self.dtype)\n                ^ hash(self.name))\n\n\nclass VectorArg(DtypedArgument):\n    def __init__(self, dtype, name, with_offset=False):\n        super().__init__(dtype, name)\n        self.with_offset = with_offset\n\n    def declarator(self):\n        if self.with_offset:\n            # Two underscores -> less likelihood of a name clash.\n            return \"__global {} *{}__base, long {}__offset\".format(\n                    dtype_to_ctype(self.dtype), self.name, self.name)\n        else:\n            result = \"__global {} *{}\".format(dtype_to_ctype(self.dtype), self.name)\n\n        return result\n\n    def __eq__(self, other):\n        return (super().__eq__(other)\n                and self.with_offset == other.with_offset)\n\n    def __hash__(self):\n        return super().__hash__() ^ hash(self.with_offset)\n\n\nclass ScalarArg(DtypedArgument):\n    def declarator(self):\n        return \"{} {}\".format(dtype_to_ctype(self.dtype), self.name)\n\n\nclass OtherArg(Argument):\n    def __init__(self, declarator, name):\n        self.decl = declarator\n        self.name = name\n\n    def declarator(self):\n        return self.decl\n\n    def __eq__(self, other):\n        return (type(self) == type(other)\n                and self.decl == other.decl\n                and self.name == other.name)\n\n    def __hash__(self):\n        return (\n                hash(type(self))\n                ^ hash(self.decl)\n                ^ hash(self.name))\n\n\ndef parse_c_arg(c_arg, with_offset=False):\n    for aspace in [\"__local\", \"__constant\"]:\n        if aspace in c_arg:\n            raise RuntimeError(\"cannot deal with local or constant \"\n                    \"OpenCL address spaces in C argument lists \")\n\n    c_arg = c_arg.replace(\"__global\", \"\")\n\n    if with_offset:\n        def vec_arg_factory(dtype, name):\n            return VectorArg(dtype, name, with_offset=True)\n    else:\n        vec_arg_factory = VectorArg\n\n    from pyopencl.compyte.dtypes import parse_c_arg_backend\n    return parse_c_arg_backend(c_arg, ScalarArg, vec_arg_factory)\n\n\ndef parse_arg_list(arguments, with_offset=False):\n    \"\"\"Parse a list of kernel arguments. *arguments* may be a comma-separate\n    list of C declarators in a string, a list of strings representing C\n    declarators, or :class:`Argument` objects.\n    \"\"\"\n\n    if isinstance(arguments, str):\n        arguments = arguments.split(\",\")\n\n    def parse_single_arg(obj):\n        if isinstance(obj, str):\n            from pyopencl.tools import parse_c_arg\n            return parse_c_arg(obj, with_offset=with_offset)\n        else:\n            return obj\n\n    return [parse_single_arg(arg) for arg in arguments]\n\n\ndef get_arg_list_arg_types(arg_types):\n    result = []\n\n    for arg_type in arg_types:\n        if isinstance(arg_type, ScalarArg):\n            result.append(arg_type.dtype)\n        elif isinstance(arg_type, VectorArg):\n            result.append(arg_type)\n        else:\n            raise RuntimeError(\"arg type not understood: %s\" % type(arg_type))\n\n    return tuple(result)\n\n\ndef get_arg_list_scalar_arg_dtypes(arg_types):\n    result = []\n\n    for arg_type in arg_types:\n        if isinstance(arg_type, ScalarArg):\n            result.append(arg_type.dtype)\n        elif isinstance(arg_type, VectorArg):\n            result.append(None)\n            if arg_type.with_offset:\n                result.append(np.int64)\n        else:\n            raise RuntimeError(\"arg type not understood: %s\" % type(arg_type))\n\n    return result\n\n\ndef get_arg_offset_adjuster_code(arg_types):\n    result = []\n\n    for arg_type in arg_types:\n        if isinstance(arg_type, VectorArg) and arg_type.with_offset:\n            result.append(\"__global %(type)s *%(name)s = \"\n                    \"(__global %(type)s *) \"\n                    \"((__global char *) %(name)s__base + %(name)s__offset);\"\n                    % dict(\n                        type=dtype_to_ctype(arg_type.dtype),\n                        name=arg_type.name))\n\n    return \"\\n\".join(result)\n\n# }}}\n\n\ndef get_gl_sharing_context_properties():\n    import pyopencl as cl\n\n    ctx_props = cl.context_properties\n\n    from OpenGL import platform as gl_platform\n\n    props = []\n\n    import sys\n    if sys.platform in [\"linux\", \"linux2\"]:\n        from OpenGL import GLX\n        props.append(\n            (ctx_props.GL_CONTEXT_KHR, GLX.glXGetCurrentContext()))\n        props.append(\n                (ctx_props.GLX_DISPLAY_KHR,\n                    GLX.glXGetCurrentDisplay()))\n    elif sys.platform == \"win32\":\n        from OpenGL import WGL\n        props.append(\n            (ctx_props.GL_CONTEXT_KHR, gl_platform.GetCurrentContext()))\n        props.append(\n                (ctx_props.WGL_HDC_KHR,\n                    WGL.wglGetCurrentDC()))\n    elif sys.platform == \"darwin\":\n        props.append(\n            (ctx_props.CONTEXT_PROPERTY_USE_CGL_SHAREGROUP_APPLE,\n                cl.get_apple_cgl_share_group()))\n    else:\n        raise NotImplementedError(\"platform '%s' not yet supported\"\n                % sys.platform)\n\n    return props\n\n\nclass _CDeclList:\n    def __init__(self, device):\n        self.device = device\n        self.declared_dtypes = set()\n        self.declarations = []\n        self.saw_double = False\n        self.saw_complex = False\n\n    def add_dtype(self, dtype):\n        dtype = np.dtype(dtype)\n\n        if dtype in [np.float64 or np.complex128]:\n            self.saw_double = True\n\n        if dtype.kind == \"c\":\n            self.saw_complex = True\n\n        if dtype.kind != \"V\":\n            return\n\n        if dtype in self.declared_dtypes:\n            return\n\n        import pyopencl.cltypes\n        if dtype in pyopencl.cltypes.vec_type_to_scalar_and_count:\n            return\n\n        if hasattr(dtype, \"subdtype\") and dtype.subdtype is not None:\n            self.add_dtype(dtype.subdtype[0])\n            return\n\n        for _name, field_data in sorted(dtype.fields.items()):\n            field_dtype, offset = field_data[:2]\n            self.add_dtype(field_dtype)\n\n        _, cdecl = match_dtype_to_c_struct(\n                self.device, dtype_to_ctype(dtype), dtype)\n\n        self.declarations.append(cdecl)\n        self.declared_dtypes.add(dtype)\n\n    def visit_arguments(self, arguments):\n        for arg in arguments:\n            dtype = arg.dtype\n            if dtype in [np.float64 or np.complex128]:\n                self.saw_double = True\n\n            if dtype.kind == \"c\":\n                self.saw_complex = True\n\n    def get_declarations(self):\n        result = \"\\n\\n\".join(self.declarations)\n\n        if self.saw_complex:\n            result = (\n                    \"#include <pyopencl-complex.h>\\n\\n\"\n                    + result)\n\n        if self.saw_double:\n            result = (\n                    \"\"\"\n                    #if __OPENCL_C_VERSION__ < 120\n                    #pragma OPENCL EXTENSION cl_khr_fp64: enable\n                    #endif\n                    #define PYOPENCL_DEFINE_CDOUBLE\n                    \"\"\"\n                    + result)\n\n        return result\n\n\n@memoize\ndef match_dtype_to_c_struct(device, name, dtype, context=None):\n    \"\"\"Return a tuple `(dtype, c_decl)` such that the C struct declaration\n    in `c_decl` and the structure :class:`numpy.dtype` instance `dtype`\n    have the same memory layout.\n\n    Note that *dtype* may be modified from the value that was passed in,\n    for example to insert padding.\n\n    (As a remark on implementation, this routine runs a small kernel on\n    the given *device* to ensure that :mod:`numpy` and C offsets and\n    sizes match.)\n\n    .. versionadded: 2013.1\n\n    This example explains the use of this function::\n\n        >>> import numpy as np\n        >>> import pyopencl as cl\n        >>> import pyopencl.tools\n        >>> ctx = cl.create_some_context()\n        >>> dtype = np.dtype([(\"id\", np.uint32), (\"value\", np.float32)])\n        >>> dtype, c_decl = pyopencl.tools.match_dtype_to_c_struct(\n        ...     ctx.devices[0], 'id_val', dtype)\n        >>> print c_decl\n        typedef struct {\n          unsigned id;\n          float value;\n        } id_val;\n        >>> print dtype\n        [('id', '<u4'), ('value', '<f4')]\n        >>> cl.tools.get_or_register_dtype('id_val', dtype)\n\n    As this example shows, it is important to call\n    :func:`get_or_register_dtype` on the modified `dtype` returned by this\n    function, not the original one.\n    \"\"\"\n\n    import pyopencl as cl\n\n    fields = sorted(dtype.fields.items(),\n            key=lambda name_dtype_offset: name_dtype_offset[1][1])\n\n    c_fields = []\n    for field_name, dtype_and_offset in fields:\n        field_dtype, offset = dtype_and_offset[:2]\n        if hasattr(field_dtype, \"subdtype\") and field_dtype.subdtype is not None:\n            array_dtype = field_dtype.subdtype[0]\n            if hasattr(array_dtype, \"subdtype\") and array_dtype.subdtype is not None:\n                raise NotImplementedError(\"nested array dtypes are not supported\")\n            array_dims = field_dtype.subdtype[1]\n            dims_str = \"\"\n            try:\n                for dim in array_dims:\n                    dims_str += \"[%d]\" % dim\n            except TypeError:\n                dims_str = \"[%d]\" % array_dims\n            c_fields.append(\"  {} {}{};\".format(\n                dtype_to_ctype(array_dtype), field_name, dims_str)\n            )\n        else:\n            c_fields.append(\n                    \"  {} {};\".format(dtype_to_ctype(field_dtype), field_name))\n\n    c_decl = \"typedef struct {{\\n{}\\n}} {};\\n\\n\".format(\n            \"\\n\".join(c_fields),\n            name)\n\n    cdl = _CDeclList(device)\n    for _field_name, dtype_and_offset in fields:\n        field_dtype, offset = dtype_and_offset[:2]\n        cdl.add_dtype(field_dtype)\n\n    pre_decls = cdl.get_declarations()\n\n    offset_code = \"\\n\".join(\n            \"result[%d] = pycl_offsetof(%s, %s);\" % (i+1, name, field_name)\n            for i, (field_name, _) in enumerate(fields))\n\n    src = r\"\"\"\n        #define pycl_offsetof(st, m) \\\n                 ((uint) ((__local char *) &(dummy.m) \\\n                 - (__local char *)&dummy ))\n\n        %(pre_decls)s\n\n        %(my_decl)s\n\n        __kernel void get_size_and_offsets(__global uint *result)\n        {\n            result[0] = sizeof(%(my_type)s);\n            __local %(my_type)s dummy;\n            %(offset_code)s\n        }\n    \"\"\" % dict(\n            pre_decls=pre_decls,\n            my_decl=c_decl,\n            my_type=name,\n            offset_code=offset_code)\n\n    if context is None:\n        context = cl.Context([device])\n\n    queue = cl.CommandQueue(context)\n\n    prg = cl.Program(context, src)\n    knl = prg.build(devices=[device]).get_size_and_offsets\n\n    import pyopencl.array  # noqa\n    result_buf = cl.array.empty(queue, 1+len(fields), np.uint32)\n    knl(queue, (1,), (1,), result_buf.data)\n    queue.finish()\n    size_and_offsets = result_buf.get()\n\n    size = int(size_and_offsets[0])\n\n    offsets = size_and_offsets[1:]\n    if any(ofs >= size for ofs in offsets):\n        # offsets not plausible\n\n        if dtype.itemsize == size:\n            # If sizes match, use numpy's idea of the offsets.\n            offsets = [dtype_and_offset[1]\n                    for field_name, dtype_and_offset in fields]\n        else:\n            raise RuntimeError(\n                    \"OpenCL compiler reported offsetof() past sizeof() \"\n                    \"for struct layout on '%s'. \"\n                    \"This makes no sense, and it's usually indicates a \"\n                    \"compiler bug. \"\n                    \"Refusing to discover struct layout.\" % device)\n\n    result_buf.data.release()\n    del knl\n    del prg\n    del queue\n    del context\n\n    try:\n        dtype_arg_dict = {\n            \"names\": [field_name\n                      for field_name, (field_dtype, offset) in fields],\n            \"formats\": [field_dtype\n                        for field_name, (field_dtype, offset) in fields],\n            \"offsets\": [int(x) for x in offsets],\n            \"itemsize\": int(size_and_offsets[0]),\n            }\n        dtype = np.dtype(dtype_arg_dict)\n        if dtype.itemsize != size_and_offsets[0]:\n            # \"Old\" versions of numpy (1.6.x?) silently ignore \"itemsize\". Boo.\n            dtype_arg_dict[\"names\"].append(\"_pycl_size_fixer\")\n            dtype_arg_dict[\"formats\"].append(np.uint8)\n            dtype_arg_dict[\"offsets\"].append(int(size_and_offsets[0])-1)\n            dtype = np.dtype(dtype_arg_dict)\n    except NotImplementedError:\n        def calc_field_type():\n            total_size = 0\n            padding_count = 0\n            for offset, (field_name, (field_dtype, _)) in zip(offsets, fields):\n                if offset > total_size:\n                    padding_count += 1\n                    yield (\"__pycl_padding%d\" % padding_count,\n                           \"V%d\" % offset - total_size)\n                yield field_name, field_dtype\n                total_size = field_dtype.itemsize + offset\n        dtype = np.dtype(list(calc_field_type()))\n\n    assert dtype.itemsize == size_and_offsets[0]\n\n    return dtype, c_decl\n\n\n@memoize\ndef dtype_to_c_struct(device, dtype):\n    if dtype.fields is None:\n        return \"\"\n\n    import pyopencl.cltypes\n    if dtype in pyopencl.cltypes.vec_type_to_scalar_and_count:\n        # Vector types are built-in. Don't try to redeclare those.\n        return \"\"\n\n    matched_dtype, c_decl = match_dtype_to_c_struct(\n            device, dtype_to_ctype(dtype), dtype)\n\n    def dtypes_match():\n        result = len(dtype.fields) == len(matched_dtype.fields)\n\n        for name, val in dtype.fields.items():\n            result = result and matched_dtype.fields[name] == val\n\n        return result\n\n    assert dtypes_match()\n\n    return c_decl\n\n\n# {{{ code generation/templating helper\n\ndef _process_code_for_macro(code):\n    code = code.replace(\"//CL//\", \"\\n\")\n\n    if \"//\" in code:\n        raise RuntimeError(\"end-of-line comments ('//') may not be used in \"\n                \"code snippets\")\n\n    return code.replace(\"\\n\", \" \\\\\\n\")\n\n\nclass _SimpleTextTemplate:\n    def __init__(self, txt):\n        self.txt = txt\n\n    def render(self, context):\n        return self.txt\n\n\nclass _PrintfTextTemplate:\n    def __init__(self, txt):\n        self.txt = txt\n\n    def render(self, context):\n        return self.txt % context\n\n\nclass _MakoTextTemplate:\n    def __init__(self, txt):\n        from mako.template import Template\n        self.template = Template(txt, strict_undefined=True)\n\n    def render(self, context):\n        return self.template.render(**context)\n\n\nclass _ArgumentPlaceholder:\n    \"\"\"A placeholder for subclasses of :class:`DtypedArgument`. This is needed\n    because the concrete dtype of the argument is not known at template\n    creation time--it may be a type alias that will only be filled in\n    at run time. These types take the place of these proto-arguments until\n    all types are known.\n\n    See also :class:`_TemplateRenderer.render_arg`.\n    \"\"\"\n\n    def __init__(self, typename, name, **extra_kwargs):\n        self.typename = typename\n        self.name = name\n        self.extra_kwargs = extra_kwargs\n\n\nclass _VectorArgPlaceholder(_ArgumentPlaceholder):\n    target_class = VectorArg\n\n\nclass _ScalarArgPlaceholder(_ArgumentPlaceholder):\n    target_class = ScalarArg\n\n\nclass _TemplateRenderer:\n    def __init__(self, template, type_aliases, var_values, context=None,\n            options=None):\n        self.template = template\n        self.type_aliases = dict(type_aliases)\n        self.var_dict = dict(var_values)\n\n        for name in self.var_dict:\n            if name.startswith(\"macro_\"):\n                self.var_dict[name] = _process_code_for_macro(\n                        self.var_dict[name])\n\n        self.context = context\n        self.options = options\n\n    def __call__(self, txt):\n        if txt is None:\n            return txt\n\n        result = self.template.get_text_template(txt).render(self.var_dict)\n\n        return str(result)\n\n    def get_rendered_kernel(self, txt, kernel_name):\n        import pyopencl as cl\n        prg = cl.Program(self.context, self(txt)).build(self.options)\n\n        kernel_name_prefix = self.var_dict.get(\"kernel_name_prefix\")\n        if kernel_name_prefix is not None:\n            kernel_name = kernel_name_prefix+kernel_name\n\n        return getattr(prg, kernel_name)\n\n    def parse_type(self, typename):\n        if isinstance(typename, str):\n            try:\n                return self.type_aliases[typename]\n            except KeyError:\n                from pyopencl.compyte.dtypes import NAME_TO_DTYPE\n                return NAME_TO_DTYPE[typename]\n        else:\n            return np.dtype(typename)\n\n    def render_arg(self, arg_placeholder):\n        return arg_placeholder.target_class(\n                self.parse_type(arg_placeholder.typename),\n                arg_placeholder.name,\n                **arg_placeholder.extra_kwargs)\n\n    _C_COMMENT_FINDER = re.compile(r\"/\\*.*?\\*/\")\n\n    def render_argument_list(self, *arg_lists, **kwargs):\n        with_offset = kwargs.pop(\"with_offset\", False)\n        if kwargs:\n            raise TypeError(\"unrecognized kwargs: \" + \", \".join(kwargs))\n\n        all_args = []\n\n        for arg_list in arg_lists:\n            if isinstance(arg_list, str):\n                arg_list = str(\n                        self.template\n                        .get_text_template(arg_list).render(self.var_dict))\n                arg_list = self._C_COMMENT_FINDER.sub(\"\", arg_list)\n                arg_list = arg_list.replace(\"\\n\", \" \")\n\n                all_args.extend(arg_list.split(\",\"))\n            else:\n                all_args.extend(arg_list)\n\n        if with_offset:\n            def vec_arg_factory(typename, name):\n                return _VectorArgPlaceholder(typename, name, with_offset=True)\n        else:\n            vec_arg_factory = _VectorArgPlaceholder\n\n        from pyopencl.compyte.dtypes import parse_c_arg_backend\n        parsed_args = []\n        for arg in all_args:\n            if isinstance(arg, str):\n                arg = arg.strip()\n                if not arg:\n                    continue\n\n                ph = parse_c_arg_backend(arg,\n                        _ScalarArgPlaceholder, vec_arg_factory,\n                        name_to_dtype=lambda x: x)\n                parsed_arg = self.render_arg(ph)\n\n            elif isinstance(arg, Argument):\n                parsed_arg = arg\n            elif isinstance(arg, tuple):\n                parsed_arg = ScalarArg(self.parse_type(arg[0]), arg[1])\n\n            parsed_args.append(parsed_arg)\n\n        return parsed_args\n\n    def get_type_decl_preamble(self, device, decl_type_names, arguments=None):\n        cdl = _CDeclList(device)\n\n        for typename in decl_type_names:\n            cdl.add_dtype(self.parse_type(typename))\n\n        if arguments is not None:\n            cdl.visit_arguments(arguments)\n\n        for _, tv in sorted(self.type_aliases.items()):\n            cdl.add_dtype(tv)\n\n        type_alias_decls = [\n                \"typedef {} {};\".format(dtype_to_ctype(val), name)\n                for name, val in sorted(self.type_aliases.items())\n                ]\n\n        return cdl.get_declarations() + \"\\n\" + \"\\n\".join(type_alias_decls)\n\n\nclass KernelTemplateBase:\n    def __init__(self, template_processor=None):\n        self.template_processor = template_processor\n\n        self.build_cache = {}\n        _first_arg_dependent_caches.append(self.build_cache)\n\n    def get_preamble(self):\n        pass\n\n    _TEMPLATE_PROCESSOR_PATTERN = re.compile(r\"^//CL(?::([a-zA-Z0-9_]+))?//\")\n\n    @memoize_method\n    def get_text_template(self, txt):\n        proc_match = self._TEMPLATE_PROCESSOR_PATTERN.match(txt)\n        tpl_processor = None\n\n        if proc_match is not None:\n            tpl_processor = proc_match.group(1)\n            # chop off //CL// mark\n            txt = txt[len(proc_match.group(0)):]\n        if tpl_processor is None:\n            tpl_processor = self.template_processor\n\n        if tpl_processor is None or tpl_processor == \"none\":\n            return _SimpleTextTemplate(txt)\n        elif tpl_processor == \"printf\":\n            return _PrintfTextTemplate(txt)\n        elif tpl_processor == \"mako\":\n            return _MakoTextTemplate(txt)\n        else:\n            raise RuntimeError(\n                    \"unknown template processor '%s'\" % proc_match.group(1))\n\n    def get_renderer(self, type_aliases, var_values, context=None, options=None):\n        return _TemplateRenderer(self, type_aliases, var_values)\n\n    def build_inner(self, context, *args, **kwargs):\n        raise NotImplementedError\n\n    def build(self, context, *args, **kwargs):\n        \"\"\"Provide caching for an :meth:`build_inner`.\"\"\"\n\n        cache_key = (context, args, tuple(sorted(kwargs.items())))\n        try:\n            return self.build_cache[cache_key]\n        except KeyError:\n            result = self.build_inner(context, *args, **kwargs)\n            self.build_cache[cache_key] = result\n            return result\n\n# }}}\n\n\n# {{{ array_module\n\nclass _CLFakeArrayModule:\n    def __init__(self, queue):\n        self.queue = queue\n\n    @property\n    def ndarray(self):\n        from pyopencl.array import Array\n        return Array\n\n    def dot(self, x, y):\n        from pyopencl.array import dot\n        return dot(x, y, queue=self.queue).get()\n\n    def vdot(self, x, y):\n        from pyopencl.array import vdot\n        return vdot(x, y, queue=self.queue).get()\n\n    def empty(self, shape, dtype, order=\"C\"):\n        from pyopencl.array import empty\n        return empty(self.queue, shape, dtype, order=order)\n\n    def hstack(self, arrays):\n        from pyopencl.array import hstack\n        return hstack(arrays, self.queue)\n\n\ndef array_module(a):\n    if isinstance(a, np.ndarray):\n        return np\n    else:\n        from pyopencl.array import Array\n        if isinstance(a, Array):\n            return _CLFakeArrayModule(a.queue)\n        else:\n            raise TypeError(\"array type not understood: %s\" % type(a))\n\n# }}}\n\n\ndef is_spirv(s):\n    spirv_magic = b\"\\x07\\x23\\x02\\x03\"\n    return (\n            isinstance(s, bytes)\n            and (\n                s[:4] == spirv_magic\n                or s[:4] == spirv_magic[::-1]))\n\n\n# {{{ numpy key types builder\n\nclass _NumpyTypesKeyBuilder(KeyBuilderBase):\n    def update_for_VectorArg(self, key_hash, key):  # noqa: N802\n        self.rec(key_hash, key.dtype)\n        self.update_for_str(key_hash, key.name)\n        self.rec(key_hash, key.with_offset)\n\n    def update_for_type(self, key_hash, key):\n        if issubclass(key, np.generic):\n            self.update_for_str(key_hash, key.__name__)\n            return\n\n        raise TypeError(\"unsupported type for persistent hash keying: %s\"\n                % type(key))\n\n# }}}\n\n# vim: foldmethod=marker\n", 1094], "/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/utils/data/_utils/__init__.py": ["r\"\"\"Utility classes & functions for data loading. Code in this folder is mostly\nused by ../dataloder.py.\n\nA lot of multiprocessing is used in data loading, which only supports running\nfunctions defined in global environment (py2 can't serialize static methods).\nTherefore, for code tidiness we put these functions into different files in this\nfolder.\n\"\"\"\n\nimport sys\nimport atexit\n\n# old private location of the ExceptionWrapper that some users rely on:\nfrom torch._utils import ExceptionWrapper\n\n\nIS_WINDOWS = sys.platform == \"win32\"\n\n\nMP_STATUS_CHECK_INTERVAL = 5.0\nr\"\"\"Interval (in seconds) to check status of processes to avoid hanging in\n    multiprocessing data loading. This is mainly used in getting data from\n    another process, in which case we need to periodically check whether the\n    sender is alive to prevent hanging.\"\"\"\n\n\npython_exit_status = False\nr\"\"\"Whether Python is shutting down. This flag is guaranteed to be set before\nthe Python core library resources are freed, but Python may already be exiting\nfor some time when this is set.\n\nHook to set this flag is `_set_python_exit_flag`, and is inspired by a similar\nhook in Python 3.7 multiprocessing library:\nhttps://github.com/python/cpython/blob/d4d60134b29290049e28df54f23493de4f1824b6/Lib/multiprocessing/util.py#L277-L327\n\"\"\"\n\n\ntry:\n    import numpy\n    HAS_NUMPY = True\nexcept ModuleNotFoundError:\n    HAS_NUMPY = False\n\n\ndef _set_python_exit_flag():\n    global python_exit_status\n    python_exit_status = True\n\natexit.register(_set_python_exit_flag)\n\n\nfrom . import worker, signal_handling, pin_memory, collate, fetch\n", 52], "/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/util.py": ["#\n# Module providing various facilities to other parts of the package\n#\n# multiprocessing/util.py\n#\n# Copyright (c) 2006-2008, R Oudkerk\n# Licensed to PSF under a Contributor Agreement.\n#\n\nimport os\nimport itertools\nimport sys\nimport weakref\nimport atexit\nimport threading        # we want threading to install it's\n                        # cleanup function before multiprocessing does\nfrom subprocess import _args_from_interpreter_flags\n\nfrom . import process\n\n__all__ = [\n    'sub_debug', 'debug', 'info', 'sub_warning', 'get_logger',\n    'log_to_stderr', 'get_temp_dir', 'register_after_fork',\n    'is_exiting', 'Finalize', 'ForkAwareThreadLock', 'ForkAwareLocal',\n    'close_all_fds_except', 'SUBDEBUG', 'SUBWARNING',\n    ]\n\n#\n# Logging\n#\n\nNOTSET = 0\nSUBDEBUG = 5\nDEBUG = 10\nINFO = 20\nSUBWARNING = 25\n\nLOGGER_NAME = 'multiprocessing'\nDEFAULT_LOGGING_FORMAT = '[%(levelname)s/%(processName)s] %(message)s'\n\n_logger = None\n_log_to_stderr = False\n\ndef sub_debug(msg, *args):\n    if _logger:\n        _logger.log(SUBDEBUG, msg, *args)\n\ndef debug(msg, *args):\n    if _logger:\n        _logger.log(DEBUG, msg, *args)\n\ndef info(msg, *args):\n    if _logger:\n        _logger.log(INFO, msg, *args)\n\ndef sub_warning(msg, *args):\n    if _logger:\n        _logger.log(SUBWARNING, msg, *args)\n\ndef get_logger():\n    '''\n    Returns logger used by multiprocessing\n    '''\n    global _logger\n    import logging\n\n    logging._acquireLock()\n    try:\n        if not _logger:\n\n            _logger = logging.getLogger(LOGGER_NAME)\n            _logger.propagate = 0\n\n            # XXX multiprocessing should cleanup before logging\n            if hasattr(atexit, 'unregister'):\n                atexit.unregister(_exit_function)\n                atexit.register(_exit_function)\n            else:\n                atexit._exithandlers.remove((_exit_function, (), {}))\n                atexit._exithandlers.append((_exit_function, (), {}))\n\n    finally:\n        logging._releaseLock()\n\n    return _logger\n\ndef log_to_stderr(level=None):\n    '''\n    Turn on logging and add a handler which prints to stderr\n    '''\n    global _log_to_stderr\n    import logging\n\n    logger = get_logger()\n    formatter = logging.Formatter(DEFAULT_LOGGING_FORMAT)\n    handler = logging.StreamHandler()\n    handler.setFormatter(formatter)\n    logger.addHandler(handler)\n\n    if level:\n        logger.setLevel(level)\n    _log_to_stderr = True\n    return _logger\n\n\n# Abstract socket support\n\ndef _platform_supports_abstract_sockets():\n    if sys.platform == \"linux\":\n        return True\n    if hasattr(sys, 'getandroidapilevel'):\n        return True\n    return False\n\n\ndef is_abstract_socket_namespace(address):\n    if not address:\n        return False\n    if isinstance(address, bytes):\n        return address[0] == 0\n    elif isinstance(address, str):\n        return address[0] == \"\\0\"\n    raise TypeError('address type of {address!r} unrecognized')\n\n\nabstract_sockets_supported = _platform_supports_abstract_sockets()\n\n#\n# Function returning a temp directory which will be removed on exit\n#\n\ndef _remove_temp_dir(rmtree, tempdir):\n    rmtree(tempdir)\n\n    current_process = process.current_process()\n    # current_process() can be None if the finalizer is called\n    # late during Python finalization\n    if current_process is not None:\n        current_process._config['tempdir'] = None\n\ndef get_temp_dir():\n    # get name of a temp directory which will be automatically cleaned up\n    tempdir = process.current_process()._config.get('tempdir')\n    if tempdir is None:\n        import shutil, tempfile\n        tempdir = tempfile.mkdtemp(prefix='pymp-')\n        info('created temp directory %s', tempdir)\n        # keep a strong reference to shutil.rmtree(), since the finalizer\n        # can be called late during Python shutdown\n        Finalize(None, _remove_temp_dir, args=(shutil.rmtree, tempdir),\n                 exitpriority=-100)\n        process.current_process()._config['tempdir'] = tempdir\n    return tempdir\n\n#\n# Support for reinitialization of objects when bootstrapping a child process\n#\n\n_afterfork_registry = weakref.WeakValueDictionary()\n_afterfork_counter = itertools.count()\n\ndef _run_after_forkers():\n    items = list(_afterfork_registry.items())\n    items.sort()\n    for (index, ident, func), obj in items:\n        try:\n            func(obj)\n        except Exception as e:\n            info('after forker raised exception %s', e)\n\ndef register_after_fork(obj, func):\n    _afterfork_registry[(next(_afterfork_counter), id(obj), func)] = obj\n\n#\n# Finalization using weakrefs\n#\n\n_finalizer_registry = {}\n_finalizer_counter = itertools.count()\n\n\nclass Finalize(object):\n    '''\n    Class which supports object finalization using weakrefs\n    '''\n    def __init__(self, obj, callback, args=(), kwargs=None, exitpriority=None):\n        if (exitpriority is not None) and not isinstance(exitpriority,int):\n            raise TypeError(\n                \"Exitpriority ({0!r}) must be None or int, not {1!s}\".format(\n                    exitpriority, type(exitpriority)))\n\n        if obj is not None:\n            self._weakref = weakref.ref(obj, self)\n        elif exitpriority is None:\n            raise ValueError(\"Without object, exitpriority cannot be None\")\n\n        self._callback = callback\n        self._args = args\n        self._kwargs = kwargs or {}\n        self._key = (exitpriority, next(_finalizer_counter))\n        self._pid = os.getpid()\n\n        _finalizer_registry[self._key] = self\n\n    def __call__(self, wr=None,\n                 # Need to bind these locally because the globals can have\n                 # been cleared at shutdown\n                 _finalizer_registry=_finalizer_registry,\n                 sub_debug=sub_debug, getpid=os.getpid):\n        '''\n        Run the callback unless it has already been called or cancelled\n        '''\n        try:\n            del _finalizer_registry[self._key]\n        except KeyError:\n            sub_debug('finalizer no longer registered')\n        else:\n            if self._pid != getpid():\n                sub_debug('finalizer ignored because different process')\n                res = None\n            else:\n                sub_debug('finalizer calling %s with args %s and kwargs %s',\n                          self._callback, self._args, self._kwargs)\n                res = self._callback(*self._args, **self._kwargs)\n            self._weakref = self._callback = self._args = \\\n                            self._kwargs = self._key = None\n            return res\n\n    def cancel(self):\n        '''\n        Cancel finalization of the object\n        '''\n        try:\n            del _finalizer_registry[self._key]\n        except KeyError:\n            pass\n        else:\n            self._weakref = self._callback = self._args = \\\n                            self._kwargs = self._key = None\n\n    def still_active(self):\n        '''\n        Return whether this finalizer is still waiting to invoke callback\n        '''\n        return self._key in _finalizer_registry\n\n    def __repr__(self):\n        try:\n            obj = self._weakref()\n        except (AttributeError, TypeError):\n            obj = None\n\n        if obj is None:\n            return '<%s object, dead>' % self.__class__.__name__\n\n        x = '<%s object, callback=%s' % (\n                self.__class__.__name__,\n                getattr(self._callback, '__name__', self._callback))\n        if self._args:\n            x += ', args=' + str(self._args)\n        if self._kwargs:\n            x += ', kwargs=' + str(self._kwargs)\n        if self._key[0] is not None:\n            x += ', exitpriority=' + str(self._key[0])\n        return x + '>'\n\n\ndef _run_finalizers(minpriority=None):\n    '''\n    Run all finalizers whose exit priority is not None and at least minpriority\n\n    Finalizers with highest priority are called first; finalizers with\n    the same priority will be called in reverse order of creation.\n    '''\n    if _finalizer_registry is None:\n        # This function may be called after this module's globals are\n        # destroyed.  See the _exit_function function in this module for more\n        # notes.\n        return\n\n    if minpriority is None:\n        f = lambda p : p[0] is not None\n    else:\n        f = lambda p : p[0] is not None and p[0] >= minpriority\n\n    # Careful: _finalizer_registry may be mutated while this function\n    # is running (either by a GC run or by another thread).\n\n    # list(_finalizer_registry) should be atomic, while\n    # list(_finalizer_registry.items()) is not.\n    keys = [key for key in list(_finalizer_registry) if f(key)]\n    keys.sort(reverse=True)\n\n    for key in keys:\n        finalizer = _finalizer_registry.get(key)\n        # key may have been removed from the registry\n        if finalizer is not None:\n            sub_debug('calling %s', finalizer)\n            try:\n                finalizer()\n            except Exception:\n                import traceback\n                traceback.print_exc()\n\n    if minpriority is None:\n        _finalizer_registry.clear()\n\n#\n# Clean up on exit\n#\n\ndef is_exiting():\n    '''\n    Returns true if the process is shutting down\n    '''\n    return _exiting or _exiting is None\n\n_exiting = False\n\ndef _exit_function(info=info, debug=debug, _run_finalizers=_run_finalizers,\n                   active_children=process.active_children,\n                   current_process=process.current_process):\n    # We hold on to references to functions in the arglist due to the\n    # situation described below, where this function is called after this\n    # module's globals are destroyed.\n\n    global _exiting\n\n    if not _exiting:\n        _exiting = True\n\n        info('process shutting down')\n        debug('running all \"atexit\" finalizers with priority >= 0')\n        _run_finalizers(0)\n\n        if current_process() is not None:\n            # We check if the current process is None here because if\n            # it's None, any call to ``active_children()`` will raise\n            # an AttributeError (active_children winds up trying to\n            # get attributes from util._current_process).  One\n            # situation where this can happen is if someone has\n            # manipulated sys.modules, causing this module to be\n            # garbage collected.  The destructor for the module type\n            # then replaces all values in the module dict with None.\n            # For instance, after setuptools runs a test it replaces\n            # sys.modules with a copy created earlier.  See issues\n            # #9775 and #15881.  Also related: #4106, #9205, and\n            # #9207.\n\n            for p in active_children():\n                if p.daemon:\n                    info('calling terminate() for daemon %s', p.name)\n                    p._popen.terminate()\n\n            for p in active_children():\n                info('calling join() for process %s', p.name)\n                p.join()\n\n        debug('running the remaining \"atexit\" finalizers')\n        _run_finalizers()\n\natexit.register(_exit_function)\n\n#\n# Some fork aware types\n#\n\nclass ForkAwareThreadLock(object):\n    def __init__(self):\n        self._lock = threading.Lock()\n        self.acquire = self._lock.acquire\n        self.release = self._lock.release\n        register_after_fork(self, ForkAwareThreadLock._at_fork_reinit)\n\n    def _at_fork_reinit(self):\n        self._lock._at_fork_reinit()\n\n    def __enter__(self):\n        return self._lock.__enter__()\n\n    def __exit__(self, *args):\n        return self._lock.__exit__(*args)\n\n\nclass ForkAwareLocal(threading.local):\n    def __init__(self):\n        register_after_fork(self, lambda obj : obj.__dict__.clear())\n    def __reduce__(self):\n        return type(self), ()\n\n#\n# Close fds except those specified\n#\n\ntry:\n    MAXFD = os.sysconf(\"SC_OPEN_MAX\")\nexcept Exception:\n    MAXFD = 256\n\ndef close_all_fds_except(fds):\n    fds = list(fds) + [-1, MAXFD]\n    fds.sort()\n    assert fds[-1] == MAXFD, 'fd too large'\n    for i in range(len(fds) - 1):\n        os.closerange(fds[i]+1, fds[i+1])\n#\n# Close sys.stdin and replace stdin with os.devnull\n#\n\ndef _close_stdin():\n    if sys.stdin is None:\n        return\n\n    try:\n        sys.stdin.close()\n    except (OSError, ValueError):\n        pass\n\n    try:\n        fd = os.open(os.devnull, os.O_RDONLY)\n        try:\n            sys.stdin = open(fd, closefd=False)\n        except:\n            os.close(fd)\n            raise\n    except (OSError, ValueError):\n        pass\n\n#\n# Flush standard streams, if any\n#\n\ndef _flush_std_streams():\n    try:\n        sys.stdout.flush()\n    except (AttributeError, ValueError):\n        pass\n    try:\n        sys.stderr.flush()\n    except (AttributeError, ValueError):\n        pass\n\n#\n# Start a program with only specified fds kept open\n#\n\ndef spawnv_passfds(path, args, passfds):\n    import _posixsubprocess\n    passfds = tuple(sorted(map(int, passfds)))\n    errpipe_read, errpipe_write = os.pipe()\n    try:\n        return _posixsubprocess.fork_exec(\n            args, [os.fsencode(path)], True, passfds, None, None,\n            -1, -1, -1, -1, -1, -1, errpipe_read, errpipe_write,\n            False, False, None, None, None, -1, None)\n    finally:\n        os.close(errpipe_read)\n        os.close(errpipe_write)\n\n\ndef close_fds(*fds):\n    \"\"\"Close each file descriptor given as an argument\"\"\"\n    for fd in fds:\n        os.close(fd)\n\n\ndef _cleanup_tests():\n    \"\"\"Cleanup multiprocessing resources when multiprocessing tests\n    completed.\"\"\"\n\n    from test import support\n\n    # cleanup multiprocessing\n    process._cleanup()\n\n    # Stop the ForkServer process if it's running\n    from multiprocessing import forkserver\n    forkserver._forkserver._stop()\n\n    # Stop the ResourceTracker process if it's running\n    from multiprocessing import resource_tracker\n    resource_tracker._resource_tracker._stop()\n\n    # bpo-37421: Explicitly call _run_finalizers() to remove immediately\n    # temporary directories created by multiprocessing.util.get_temp_dir().\n    _run_finalizers()\n    support.gc_collect()\n\n    support.reap_children()\n", 489], "/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/process.py": ["#\n# Module providing the `Process` class which emulates `threading.Thread`\n#\n# multiprocessing/process.py\n#\n# Copyright (c) 2006-2008, R Oudkerk\n# Licensed to PSF under a Contributor Agreement.\n#\n\n__all__ = ['BaseProcess', 'current_process', 'active_children',\n           'parent_process']\n\n#\n# Imports\n#\n\nimport os\nimport sys\nimport signal\nimport itertools\nimport threading\nfrom _weakrefset import WeakSet\n\n#\n#\n#\n\ntry:\n    ORIGINAL_DIR = os.path.abspath(os.getcwd())\nexcept OSError:\n    ORIGINAL_DIR = None\n\n#\n# Public functions\n#\n\ndef current_process():\n    '''\n    Return process object representing the current process\n    '''\n    return _current_process\n\ndef active_children():\n    '''\n    Return list of process objects corresponding to live child processes\n    '''\n    _cleanup()\n    return list(_children)\n\n\ndef parent_process():\n    '''\n    Return process object representing the parent process\n    '''\n    return _parent_process\n\n#\n#\n#\n\ndef _cleanup():\n    # check for processes which have finished\n    for p in list(_children):\n        if p._popen.poll() is not None:\n            _children.discard(p)\n\n#\n# The `Process` class\n#\n\nclass BaseProcess(object):\n    '''\n    Process objects represent activity that is run in a separate process\n\n    The class is analogous to `threading.Thread`\n    '''\n    def _Popen(self):\n        raise NotImplementedError\n\n    def __init__(self, group=None, target=None, name=None, args=(), kwargs={},\n                 *, daemon=None):\n        assert group is None, 'group argument must be None for now'\n        count = next(_process_counter)\n        self._identity = _current_process._identity + (count,)\n        self._config = _current_process._config.copy()\n        self._parent_pid = os.getpid()\n        self._parent_name = _current_process.name\n        self._popen = None\n        self._closed = False\n        self._target = target\n        self._args = tuple(args)\n        self._kwargs = dict(kwargs)\n        self._name = name or type(self).__name__ + '-' + \\\n                     ':'.join(str(i) for i in self._identity)\n        if daemon is not None:\n            self.daemon = daemon\n        _dangling.add(self)\n\n    def _check_closed(self):\n        if self._closed:\n            raise ValueError(\"process object is closed\")\n\n    def run(self):\n        '''\n        Method to be run in sub-process; can be overridden in sub-class\n        '''\n        if self._target:\n            self._target(*self._args, **self._kwargs)\n\n    def start(self):\n        '''\n        Start child process\n        '''\n        self._check_closed()\n        assert self._popen is None, 'cannot start a process twice'\n        assert self._parent_pid == os.getpid(), \\\n               'can only start a process object created by current process'\n        assert not _current_process._config.get('daemon'), \\\n               'daemonic processes are not allowed to have children'\n        _cleanup()\n        self._popen = self._Popen(self)\n        self._sentinel = self._popen.sentinel\n        # Avoid a refcycle if the target function holds an indirect\n        # reference to the process object (see bpo-30775)\n        del self._target, self._args, self._kwargs\n        _children.add(self)\n\n    def terminate(self):\n        '''\n        Terminate process; sends SIGTERM signal or uses TerminateProcess()\n        '''\n        self._check_closed()\n        self._popen.terminate()\n\n    def kill(self):\n        '''\n        Terminate process; sends SIGKILL signal or uses TerminateProcess()\n        '''\n        self._check_closed()\n        self._popen.kill()\n\n    def join(self, timeout=None):\n        '''\n        Wait until child process terminates\n        '''\n        self._check_closed()\n        assert self._parent_pid == os.getpid(), 'can only join a child process'\n        assert self._popen is not None, 'can only join a started process'\n        res = self._popen.wait(timeout)\n        if res is not None:\n            _children.discard(self)\n\n    def is_alive(self):\n        '''\n        Return whether process is alive\n        '''\n        self._check_closed()\n        if self is _current_process:\n            return True\n        assert self._parent_pid == os.getpid(), 'can only test a child process'\n\n        if self._popen is None:\n            return False\n\n        returncode = self._popen.poll()\n        if returncode is None:\n            return True\n        else:\n            _children.discard(self)\n            return False\n\n    def close(self):\n        '''\n        Close the Process object.\n\n        This method releases resources held by the Process object.  It is\n        an error to call this method if the child process is still running.\n        '''\n        if self._popen is not None:\n            if self._popen.poll() is None:\n                raise ValueError(\"Cannot close a process while it is still running. \"\n                                 \"You should first call join() or terminate().\")\n            self._popen.close()\n            self._popen = None\n            del self._sentinel\n            _children.discard(self)\n        self._closed = True\n\n    @property\n    def name(self):\n        return self._name\n\n    @name.setter\n    def name(self, name):\n        assert isinstance(name, str), 'name must be a string'\n        self._name = name\n\n    @property\n    def daemon(self):\n        '''\n        Return whether process is a daemon\n        '''\n        return self._config.get('daemon', False)\n\n    @daemon.setter\n    def daemon(self, daemonic):\n        '''\n        Set whether process is a daemon\n        '''\n        assert self._popen is None, 'process has already started'\n        self._config['daemon'] = daemonic\n\n    @property\n    def authkey(self):\n        return self._config['authkey']\n\n    @authkey.setter\n    def authkey(self, authkey):\n        '''\n        Set authorization key of process\n        '''\n        self._config['authkey'] = AuthenticationString(authkey)\n\n    @property\n    def exitcode(self):\n        '''\n        Return exit code of process or `None` if it has yet to stop\n        '''\n        self._check_closed()\n        if self._popen is None:\n            return self._popen\n        return self._popen.poll()\n\n    @property\n    def ident(self):\n        '''\n        Return identifier (PID) of process or `None` if it has yet to start\n        '''\n        self._check_closed()\n        if self is _current_process:\n            return os.getpid()\n        else:\n            return self._popen and self._popen.pid\n\n    pid = ident\n\n    @property\n    def sentinel(self):\n        '''\n        Return a file descriptor (Unix) or handle (Windows) suitable for\n        waiting for process termination.\n        '''\n        self._check_closed()\n        try:\n            return self._sentinel\n        except AttributeError:\n            raise ValueError(\"process not started\") from None\n\n    def __repr__(self):\n        exitcode = None\n        if self is _current_process:\n            status = 'started'\n        elif self._closed:\n            status = 'closed'\n        elif self._parent_pid != os.getpid():\n            status = 'unknown'\n        elif self._popen is None:\n            status = 'initial'\n        else:\n            exitcode = self._popen.poll()\n            if exitcode is not None:\n                status = 'stopped'\n            else:\n                status = 'started'\n\n        info = [type(self).__name__, 'name=%r' % self._name]\n        if self._popen is not None:\n            info.append('pid=%s' % self._popen.pid)\n        info.append('parent=%s' % self._parent_pid)\n        info.append(status)\n        if exitcode is not None:\n            exitcode = _exitcode_to_name.get(exitcode, exitcode)\n            info.append('exitcode=%s' % exitcode)\n        if self.daemon:\n            info.append('daemon')\n        return '<%s>' % ' '.join(info)\n\n    ##\n\n    def _bootstrap(self, parent_sentinel=None):\n        from . import util, context\n        global _current_process, _parent_process, _process_counter, _children\n\n        try:\n            if self._start_method is not None:\n                context._force_start_method(self._start_method)\n            _process_counter = itertools.count(1)\n            _children = set()\n            util._close_stdin()\n            old_process = _current_process\n            _current_process = self\n            _parent_process = _ParentProcess(\n                self._parent_name, self._parent_pid, parent_sentinel)\n            if threading._HAVE_THREAD_NATIVE_ID:\n                threading.main_thread()._set_native_id()\n            try:\n                util._finalizer_registry.clear()\n                util._run_after_forkers()\n            finally:\n                # delay finalization of the old process object until after\n                # _run_after_forkers() is executed\n                del old_process\n            util.info('child process calling self.run()')\n            try:\n                self.run()\n                exitcode = 0\n            finally:\n                util._exit_function()\n        except SystemExit as e:\n            if e.code is None:\n                exitcode = 0\n            elif isinstance(e.code, int):\n                exitcode = e.code\n            else:\n                sys.stderr.write(str(e.code) + '\\n')\n                exitcode = 1\n        except:\n            exitcode = 1\n            import traceback\n            sys.stderr.write('Process %s:\\n' % self.name)\n            traceback.print_exc()\n        finally:\n            threading._shutdown()\n            util.info('process exiting with exitcode %d' % exitcode)\n            util._flush_std_streams()\n\n        return exitcode\n\n#\n# We subclass bytes to avoid accidental transmission of auth keys over network\n#\n\nclass AuthenticationString(bytes):\n    def __reduce__(self):\n        from .context import get_spawning_popen\n        if get_spawning_popen() is None:\n            raise TypeError(\n                'Pickling an AuthenticationString object is '\n                'disallowed for security reasons'\n                )\n        return AuthenticationString, (bytes(self),)\n\n\n#\n# Create object representing the parent process\n#\n\nclass _ParentProcess(BaseProcess):\n\n    def __init__(self, name, pid, sentinel):\n        self._identity = ()\n        self._name = name\n        self._pid = pid\n        self._parent_pid = None\n        self._popen = None\n        self._closed = False\n        self._sentinel = sentinel\n        self._config = {}\n\n    def is_alive(self):\n        from multiprocessing.connection import wait\n        return not wait([self._sentinel], timeout=0)\n\n    @property\n    def ident(self):\n        return self._pid\n\n    def join(self, timeout=None):\n        '''\n        Wait until parent process terminates\n        '''\n        from multiprocessing.connection import wait\n        wait([self._sentinel], timeout=timeout)\n\n    pid = ident\n\n#\n# Create object representing the main process\n#\n\nclass _MainProcess(BaseProcess):\n\n    def __init__(self):\n        self._identity = ()\n        self._name = 'MainProcess'\n        self._parent_pid = None\n        self._popen = None\n        self._closed = False\n        self._config = {'authkey': AuthenticationString(os.urandom(32)),\n                        'semprefix': '/mp'}\n        # Note that some versions of FreeBSD only allow named\n        # semaphores to have names of up to 14 characters.  Therefore\n        # we choose a short prefix.\n        #\n        # On MacOSX in a sandbox it may be necessary to use a\n        # different prefix -- see #19478.\n        #\n        # Everything in self._config will be inherited by descendant\n        # processes.\n\n    def close(self):\n        pass\n\n\n_parent_process = None\n_current_process = _MainProcess()\n_process_counter = itertools.count(1)\n_children = set()\ndel _MainProcess\n\n#\n# Give names to some return codes\n#\n\n_exitcode_to_name = {}\n\nfor name, signum in list(signal.__dict__.items()):\n    if name[:3]=='SIG' and '_' not in name:\n        _exitcode_to_name[-signum] = f'-{name}'\n\n# For debug and leak testing\n_dangling = WeakSet()\n", 432]}, "functions": {"<module> (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/jsonschema/_format.py:1)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/jsonschema/_format.py", 1], "<module> (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/jsonschema/_types.py:1)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/jsonschema/_types.py", 1], "<module> (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/jsonschema/validators.py:1)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/jsonschema/validators.py", 1], "__getattr__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/jsonschema/validators.py:30)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/jsonschema/validators.py", 30], "<module> (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/jsonschema/__init__.py:1)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/jsonschema/__init__.py", 1], "TorchPlaceHolder (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:20)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py", 20], "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:1)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py", 1], "TuneResults (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/integration.py:61)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/integration.py", 61], "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/integration.py:1)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/integration.py", 1], "_module_matches_namespace (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/pkg_resources/extern/__init__.py:24)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/pkg_resources/extern/__init__.py", 24], "find_spec (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/pkg_resources/extern/__init__.py:57)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/pkg_resources/extern/__init__.py", 57], "find_spec (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/six.py:194)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/six.py", 194], "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/cupy.py:1)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/cupy.py", 1], "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/cuda.py:1)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/cuda.py", 1], "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/opencl.py:1)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/opencl.py", 1], "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/c.py:1)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/c.py", 1], "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/python.py:1)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/python.py", 1], "<genexpr> (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/collections/__init__.py:419)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/collections/__init__.py", 419], "namedtuple (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/collections/__init__.py:345)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/collections/__init__.py", 345], "KernelInstance (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/core.py:31)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/core.py", 31], "KernelSource (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/core.py:48)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/core.py", 48], "DeviceInterface (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/core.py:194)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/core.py", 194], "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/core.py:1)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/core.py", 1], "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/runners/__init__.py:1)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/runners/__init__.py", 1], "SequentialRunner (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/runners/sequential.py:11)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/runners/sequential.py", 11], "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/runners/sequential.py:1)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/runners/sequential.py", 1], "SimulationLangFunction (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/runners/simulation.py:10)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/runners/simulation.py", 10], "SimulationDeviceInterface (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/runners/simulation.py:54)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/runners/simulation.py", 54], "SimulationRunner (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/runners/simulation.py:173)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/runners/simulation.py", 173], "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/runners/simulation.py:1)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/runners/simulation.py", 1], "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/__init__.py:1)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/__init__.py", 1], "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/brute_force.py:1)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/brute_force.py", 1], "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/random_sample.py:1)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/random_sample.py", 1], "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/diff_evo.py:1)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/diff_evo.py", 1], "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/basinhopping.py:1)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/basinhopping.py", 1], "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/genetic_algorithm.py:1)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/genetic_algorithm.py", 1], "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/mls.py:1)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/mls.py", 1], "Particle (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/pso.py:85)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/pso.py", 85], "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/pso.py:1)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/pso.py", 1], "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/simulated_annealing.py:1)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/simulated_annealing.py", 1], "Firefly (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/firefly_algorithm.py:93)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/firefly_algorithm.py", 93], "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/firefly_algorithm.py:1)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/firefly_algorithm.py", 1], "_type_check (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:137)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py", 137], "<genexpr> (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:919)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py", 919], "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:738)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py", 738], "copy_with (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:840)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py", 840], "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:908)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py", 908], "inner (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py:271)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/typing.py", 271], "BayesianOptimization (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt.py:135)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt.py", 135], "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt.py:1)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt.py", 1], "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/greedy_ils.py:1)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/greedy_ils.py", 1], "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/ordered_greedy_mls.py:1)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/ordered_greedy_mls.py", 1], "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/dual_annealing.py:1)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/dual_annealing.py", 1], "BayesianOptimization (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_old.py:135)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_old.py", 135], "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_old.py:1)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_old.py", 1], "ExactGPModel (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch.py:140)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch.py", 140], "BayesianOptimization (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch.py:154)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch.py", 154], "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch.py:1)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch.py", 1], "ExactGPModel (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:89)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py", 89], "BayesianOptimization (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:105)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py", 105], "CustomWarning (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:928)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py", 928], "AvoidedLossSurgeWarning (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:942)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py", 942], "NotPSDTrainingWarning (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:948)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py", 948], "NaNTrainingWarning (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:954)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py", 954], "NaNPredictionWarning (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:960)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py", 960], "NotPSDPredictionWarning (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:966)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py", 966], "ResetModelWarning (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:972)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py", 972], "MultipleMinimaWarning (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:978)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py", 978], "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:1)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py", 1], "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_alt_BOTorch.py:1)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_alt_BOTorch.py", 1], "Options (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:73)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py", 73], "_get_docstring (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:380)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py", 380], "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:1)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py", 1], "<module> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/__init__.py:2)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/__init__.py", 2], "<genexpr> (/Users/fjwillemsen/Library/CloudStorage/OneDrive-NetherlandseScienceCenter/Projects/Bayesian Optimization in Kernel Tuner/Code/cached_data_used/bootstrap_hyperparamtuning.py:63)": ["/Users/fjwillemsen/Library/CloudStorage/OneDrive-NetherlandseScienceCenter/Projects/Bayesian Optimization in Kernel Tuner/Code/cached_data_used/bootstrap_hyperparamtuning.py", 63], "_prod_dispatcher (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/fromnumeric.py:2928)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/fromnumeric.py", 2928], "<dictcomp> (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/fromnumeric.py:70)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/fromnumeric.py", 70], "_wrapreduction (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/fromnumeric.py:69)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/fromnumeric.py", 69], "prod (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/fromnumeric.py:2933)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/fromnumeric.py", 2933], "DurationObserver (/Users/fjwillemsen/Library/CloudStorage/OneDrive-NetherlandseScienceCenter/Projects/Bayesian Optimization in Kernel Tuner/Code/cached_data_used/bootstrap_hyperparamtuning.py:66)": ["/Users/fjwillemsen/Library/CloudStorage/OneDrive-NetherlandseScienceCenter/Projects/Bayesian Optimization in Kernel Tuner/Code/cached_data_used/bootstrap_hyperparamtuning.py", 66], "__new__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/abc.py:105)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/abc.py", 105], "__init__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/core.py:58)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/core.py", 58], "_acquireLock (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:218)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py", 218], "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:771)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py", 771], "_checkLevel (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:193)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py", 193], "_releaseLock (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:227)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py", 227], "_addHandlerRef (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:838)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py", 838], "RLock (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/threading.py:82)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/threading.py", 82], "add (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/_weakrefset.py:86)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/_weakrefset.py", 86], "_register_at_fork_reinit_lock (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:246)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py", 246], "createLock (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:886)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py", 886], "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:857)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py", 857], "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1049)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py", 1049], "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:418)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py", 418], "validate (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:424)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py", 424], "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:553)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py", 553], "setFormatter (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:957)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py", 957], "addHandler (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1601)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py", 1601], "basicConfig (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1908)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py", 1908], "disable (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1276)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py", 1276], "getEffectiveLevel (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1675)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py", 1675], "isEnabledFor (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1689)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py", 1689], "debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:1424)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py", 1424], "debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py:2099)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/logging/__init__.py", 2099], "<listcomp> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:397)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py", 397], "looks_like_a_filename (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:379)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py", 379], "isfile (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/genericpath.py:27)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/genericpath.py", 27], "getpreferredencoding (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/_bootlocale.py:33)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/_bootlocale.py", 33], "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/codecs.py:260)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/codecs.py", 260], "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/codecs.py:309)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/codecs.py", 309], "decode (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/codecs.py:319)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/codecs.py", 319], "read_file (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:469)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py", 469], "get_kernel_string (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:222)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py", 222], "get_kernel_string (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/core.py:72)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/core.py", 72], "isstring (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_compile.py:595)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_compile.py", 595], "__next (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:233)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py", 233], "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:224)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py", 224], "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:76)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py", 76], "tell (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:286)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py", 286], "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:111)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py", 111], "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:254)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py", 254], "append (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:172)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py", 172], "match (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:249)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py", 249], "_uniq (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:432)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py", 432], "__len__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:160)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py", 160], "__getitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:164)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py", 164], "__setitem__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:168)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py", 168], "_escape (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:355)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py", 355], "_parse (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:493)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py", 493], "_parse_sub (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:435)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py", 435], "fix_flags (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:921)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py", 921], "parse (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:937)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py", 937], "getwidth (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:174)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py", 174], "_get_iscased (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_compile.py:453)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_compile.py", 453], "_get_literal_prefix (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_compile.py:461)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_compile.py", 461], "_generate_overlap_table (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_compile.py:432)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_compile.py", 432], "_compile_info (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_compile.py:536)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_compile.py", 536], "_simple (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_compile.py:423)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_compile.py", 423], "_optimize_charset (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_compile.py:276)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_compile.py", 276], "_compile_charset (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_compile.py:249)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_compile.py", 249], "_compile (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_compile.py:71)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_compile.py", 71], "_code (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_compile.py:598)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_compile.py", 598], "groups (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py:81)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_parse.py", 81], "compile (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_compile.py:759)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/sre_compile.py", 759], "__new__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/enum.py:670)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/enum.py", 670], "__call__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/enum.py:358)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/enum.py", 358], "__and__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/enum.py:977)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/enum.py", 977], "_compile (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/re.py:289)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/re.py", 289], "finditer (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/re.py:243)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/re.py", 243], "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py:403)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py", 403], "getlines (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/linecache.py:36)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/linecache.py", 36], "getline (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/linecache.py:26)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/linecache.py", 26], "_formatwarnmsg_impl (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py:35)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py", 35], "formatwarning (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py:15)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py", 15], "_formatwarning (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/bokeh/__init__.py:98)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/bokeh/__init__.py", 98], "_formatwarnmsg (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py:117)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py", 117], "_showwarnmsg_impl (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py:20)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py", 20], "_showwarnmsg (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py:96)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/warnings.py", 96], "check_argument_list (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:54)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py", 54], "check_argument_lists (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/core.py:182)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/core.py", 182], "check_block_size_names (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:100)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py", 100], "_check_user_input (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:609)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py", 609], "check_tune_params_list (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:92)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py", 92], "<listcomp> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:121)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py", 121], "check_block_size_params_names_list (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:115)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py", 115], "<listcomp> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:430)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py", 430], "<listcomp> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:431)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py", 431], "<listcomp> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:432)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py", 432], "compact_number (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:176)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py", 176], "get_config_string (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:173)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py", 173], "__getattr__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:76)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py", 76], "uname (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/platform.py:825)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/platform.py", 825], "__enter__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py:1014)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py", 1014], "_try_wait (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py:1872)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py", 1872], "_handle_exitstatus (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py:1825)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py", 1825], "_wait (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py:1885)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py", 1885], "wait (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py:1184)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py", 1184], "communicate (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py:1090)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py", 1090], "_internal_poll (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py:1837)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py", 1837], "poll (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py:1158)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py", 1158], "__exit__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py:1017)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py", 1017], "__init__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py:439)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py", 439], "run (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py:464)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py", 464], "__del__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py:1045)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py", 1045], "check_output (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py:377)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/subprocess.py", 377], "from_subprocess (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/platform.py:760)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/platform.py", 760], "get (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/platform.py:743)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/platform.py", 743], "_unknown_as_blank (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/platform.py:774)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/platform.py", 774], "processor (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/platform.py:792)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/platform.py", 792], "__get__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/functools.py:962)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/functools.py", 962], "processor (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/platform.py:960)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/platform.py", 960], "read_or_stop (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/tokenize.py:319)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/tokenize.py", 319], "find_cookie (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/tokenize.py:325)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/tokenize.py", 325], "detect_encoding (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/tokenize.py:295)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/tokenize.py", 295], "open (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/tokenize.py:388)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/tokenize.py", 388], "updatecache (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/linecache.py:80)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/linecache.py", 80], "__init__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/python.py:34)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/python.py", 34], "__enter__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/python.py:61)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/python.py", 61], "__init__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/core.py:197)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/core.py", 197], "__enter__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/core.py:266)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/core.py", 266], "ready_argument_list (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/python.py:67)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/python.py", 67], "ready_argument_list (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/core.py:478)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/core.py", 478], "__init__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/runners/sequential.py:14)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/runners/sequential.py", 14], "__enter__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/runners/sequential.py:44)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/runners/sequential.py", 44], "normalize_verify_function (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:503)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py", 503], "raw_decode (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/json/decoder.py:343)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/json/decoder.py", 343], "decode (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/json/decoder.py:332)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/json/decoder.py", 332], "loads (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/json/__init__.py:299)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/json/__init__.py", 299], "process_cache (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:550)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py", 550], "is_available (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/cuda/__init__.py:74)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/cuda/__init__.py", 74], "get_valid_configs (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py:263)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/util.py", 263], "get_hyperparam (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:730)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py", 730], "set_acquisition_function (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:751)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py", 751], "_deepcopy_atomic (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py:182)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py", 182], "deepcopy (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py:128)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py", 128], "<listcomp> (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py:210)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py", 210], "_deepcopy_tuple (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py:209)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py", 209], "_deepcopy_list (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py:200)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py", 200], "_keep_alive (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py:242)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py", 242], "<listcomp> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:771)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py", 771], "_reconstruct (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py:258)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/copy.py", 258], "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:774)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py", 774], "transform_nonnumerical_params (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:763)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py", 763], "__len__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_tensor.py:620)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_tensor.py", 620], "__iter__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_tensor.py:632)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_tensor.py", 632], "apply_scaling_to_inputs (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:694)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py", 694], "<listcomp> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:289)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py", 289], "<listcomp> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/minimize.py:77)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/minimize.py", 77], "_cost_func (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/minimize.py:59)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/minimize.py", 59], "objective_function (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:553)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py", 553], "_std_dispatcher (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3444)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/fromnumeric.py", 3444], "_count_reduce_items (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/_methods.py:66)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/_methods.py", 66], "_var (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/_methods.py:195)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/_methods.py", 195], "_std (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/_methods.py:260)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/_methods.py", 260], "std (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3449)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/fromnumeric.py", 3449], "register_result (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:565)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py", 565], "<listcomp> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:592)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py", 592], "update_unique_results (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:588)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py", 588], "evaluate_config (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:556)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py", 556], "import_cached_evaluations (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:284)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py", 284], "__subclasscheck__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/abc.py:121)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/abc.py", 121], "__instancecheck__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/abc.py:117)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/abc.py", 117], "getrandbits (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/random.py:791)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/random.py", 791], "concatenate (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/multiarray.py:148)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/multiarray.py", 148], "_recreate_cm (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/contextlib.py:63)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/contextlib.py", 63], "geterr (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/_ufunc_config.py:131)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/_ufunc_config.py", 131], "seterr (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/_ufunc_config.py:32)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/_ufunc_config.py", 32], "__enter__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/_ufunc_config.py:429)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/_ufunc_config.py", 429], "__exit__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/_ufunc_config.py:434)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/_ufunc_config.py", 434], "inner (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/contextlib.py:76)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/contextlib.py", 76], "_around_dispatcher (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3216)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/fromnumeric.py", 3216], "_wrapfunc (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/fromnumeric.py:51)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/fromnumeric.py", 51], "around (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3220)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/fromnumeric.py", 3220], "round_ (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3730)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/numpy/core/fromnumeric.py", 3730], "<listcomp> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:350)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py", 350], "<genexpr> (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:367)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py", 367], "__getattr__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_VF.py:25)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_VF.py", 25], "_unique_impl (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/functional.py:660)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/functional.py", 660], "_return_output (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/functional.py:815)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/functional.py", 815], "fn (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_jit_internal.py:412)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_jit_internal.py", 412], "unique (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_tensor.py:520)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_tensor.py", 520], "get_lhs_samples (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:345)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py", 345], "__rsub__ (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_tensor.py:544)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_tensor.py", 544], "wrapped (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_tensor.py:25)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/_tensor.py", 25], "get_middle_index_of_least_evaluated_region (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:410)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py", 410], "initial_sample (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:302)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py", 302], "initialize_model (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:251)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py", 251], "__init__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:107)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py", 107], "tune (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py:29)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/strategies/bayes_opt_GPyTorch_lean.py", 29], "__exit__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/python.py:64)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/python.py", 64], "__exit__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/core.py:499)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/core.py", 499], "__exit__ (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/runners/sequential.py:113)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/runners/sequential.py", 113], "tune_kernel (/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py:403)": ["/Users/fjwillemsen/University/PhD/OneDrive - Netherlands eScience Center/Projects/Bayesian Optimization in Kernel Tuner/Code/kernel_tuner/kernel_tuner/interface.py", 403], "tune (/Users/fjwillemsen/Library/CloudStorage/OneDrive-NetherlandseScienceCenter/Projects/Bayesian Optimization in Kernel Tuner/Code/cached_data_used/bootstrap_hyperparamtuning.py:13)": ["/Users/fjwillemsen/Library/CloudStorage/OneDrive-NetherlandseScienceCenter/Projects/Bayesian Optimization in Kernel Tuner/Code/cached_data_used/bootstrap_hyperparamtuning.py", 13], "<module> (/Users/fjwillemsen/Library/CloudStorage/OneDrive-NetherlandseScienceCenter/Projects/Bayesian Optimization in Kernel Tuner/Code/cached_data_used/bootstrap_hyperparamtuning.py:2)": ["/Users/fjwillemsen/Library/CloudStorage/OneDrive-NetherlandseScienceCenter/Projects/Bayesian Optimization in Kernel Tuner/Code/cached_data_used/bootstrap_hyperparamtuning.py", 2], "destroy_all (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/matplotlib/_pylab_helpers.py:78)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/matplotlib/_pylab_helpers.py", 78], "flush (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/progressbar/utils.py:340)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/progressbar/utils.py", 340], "clear_first_arg_caches (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/pyopencl/tools.py:163)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/pyopencl/tools.py", 163], "_set_python_exit_flag (/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/utils/data/_utils/__init__.py:45)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/envs/kerneltuner_bayesopt/lib/python3.9/site-packages/torch/utils/data/_utils/__init__.py", 45], "info (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/util.py:52)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/util.py", 52], "debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/util.py:48)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/util.py", 48], "<lambda> (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/util.py:284)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/util.py", 284], "<listcomp> (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/util.py:291)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/util.py", 291], "_run_finalizers (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/util.py:268)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/util.py", 268], "current_process (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/process.py:37)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/process.py", 37], "_cleanup (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/process.py:61)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/process.py", 61], "active_children (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/process.py:43)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/process.py", 43], "<lambda> (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/util.py:282)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/util.py", 282], "sub_debug (/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/util.py:44)": ["/Users/fjwillemsen/.pyenv/versions/3.9.9/lib/python3.9/multiprocessing/util.py", 44]}}}